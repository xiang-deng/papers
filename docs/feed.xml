<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.2">Jekyll</generator><link href="https://xiang-deng.github.io/docs/feed.xml" rel="self" type="application/atom+xml" /><link href="https://xiang-deng.github.io/docs/" rel="alternate" type="text/html" /><updated>2022-06-04T18:23:47-04:00</updated><id>https://xiang-deng.github.io/docs/feed.xml</id><title type="html">Xiang’s Paper Reading List</title><subtitle>Tracking papers via Google Scholar.</subtitle><entry><title type="html">Aspect-based sentiment analysis with enhanced aspect-sensitive word embeddings</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/04516118fcc9398507deee45ffdf4496.html" rel="alternate" type="text/html" title="Aspect-based sentiment analysis with enhanced aspect-sensitive word embeddings" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/04516118fcc9398507deee45ffdf4496</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/04516118fcc9398507deee45ffdf4496.html">&lt;p&gt;Aspect term sentiment classification (ATSC) aims at identifying sentiment polarities towards some aspect terms described in a text. One of the challenges in the ATSC is that the same word may express different sentiment polarities for distinct aspects. For instance, if the word “high” is used to describe the quality of a product, this word is most likely used to express a positive opinion towards the product. However, if the aspect term is about the price of the product, the same word “high” is quite likely used … Cites: ‪Aspect level sentiment classification with deep memory network‬&lt;/p&gt;</content><author><name>Y Qi, X Zheng, X Huang - Knowledge and Information Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Aspect term sentiment classification (ATSC) aims at identifying sentiment polarities towards some aspect terms described in a text. One of the challenges in the ATSC is that the same word may express different sentiment polarities for distinct aspects. For instance, if the word “high” is used to describe the quality of a product, this word is most likely used to express a positive opinion towards the product. However, if the aspect term is about the price of the product, the same word “high” is quite likely used … Cites: ‪Aspect level sentiment classification with deep memory network‬</summary></entry><entry><title type="html">Benchmarking the Robustness of LiDAR-Camera Fusion for 3D Object Detection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/053f7846fa90667fa0b14ca6e316cc37.html" rel="alternate" type="text/html" title="Benchmarking the Robustness of LiDAR-Camera Fusion for 3D Object Detection" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/053f7846fa90667fa0b14ca6e316cc37</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/053f7846fa90667fa0b14ca6e316cc37.html">&lt;p&gt;There are two critical sensors for 3D perception in autonomous driving, the camera and the LiDAR. The camera provides rich semantic information such as color, texture, and the LiDAR reflects the 3D shape and locations of surrounding objects. People discover that fusing these two modalities can significantly boost the performance of 3D perception models as each modality has complementary information to the other. However, we observe that current datasets are captured … Cites: ‪DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object …‬&lt;/p&gt;</content><author><name>K Yu, T Tao, H Xie, Z Lin, Z Wu, Z Xia, T Liang, H Sun… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">There are two critical sensors for 3D perception in autonomous driving, the camera and the LiDAR. The camera provides rich semantic information such as color, texture, and the LiDAR reflects the 3D shape and locations of surrounding objects. People discover that fusing these two modalities can significantly boost the performance of 3D perception models as each modality has complementary information to the other. However, we observe that current datasets are captured … Cites: ‪DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object …‬</summary></entry><entry><title type="html">CoNT: Contrastive Neural Text Generation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/080655372e5ffad7e26c317f754cc6cb.html" rel="alternate" type="text/html" title="CoNT: Contrastive Neural Text Generation" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/080655372e5ffad7e26c317f754cc6cb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/080655372e5ffad7e26c317f754cc6cb.html">&lt;p&gt;Recently, contrastive learning attracts increasing interests in neural text generation as a new solution to alleviate the exposure bias problem. It introduces a sequence-level training signal which is crucial to generation tasks that always rely on auto-regressive decoding. However, previous methods using contrastive learning in neural text generation usually lead to inferior performance. In this paper, we analyse the underlying reasons and propose a new Contrastive Neural Text generation … Cites: ‪RankGen: Improving Text Generation with Large Ranking Models‬&lt;/p&gt;</content><author><name>C An, J Feng, K Lv, L Kong, X Qiu, X Huang - arXiv preprint arXiv:2205.14690, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recently, contrastive learning attracts increasing interests in neural text generation as a new solution to alleviate the exposure bias problem. It introduces a sequence-level training signal which is crucial to generation tasks that always rely on auto-regressive decoding. However, previous methods using contrastive learning in neural text generation usually lead to inferior performance. In this paper, we analyse the underlying reasons and propose a new Contrastive Neural Text generation … Cites: ‪RankGen: Improving Text Generation with Large Ranking Models‬</summary></entry><entry><title type="html">External Validation of Deep Learning Algorithms for Radiologic Diagnosis: A Systematic Review</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/0ef897963c5554490d36bc59359beeef.html" rel="alternate" type="text/html" title="External Validation of Deep Learning Algorithms for Radiologic Diagnosis: A Systematic Review" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/0ef897963c5554490d36bc59359beeef</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/0ef897963c5554490d36bc59359beeef.html">&lt;p&gt;Materials and Methods In this systematic review, the PubMed database was searched for peer-reviewed studies of DL algorithms for image-based radiologic diagnosis that included external validation, published from January 1, 2015, through April 1, 2021. Studies using nonimaging features or incorporating non-DL methods for feature extraction or classification were excluded. Two reviewers independently evaluated studies for inclusion, and any discrepancies were resolved by consensus … Cites: ‪Evaluation of combined artificial intelligence and radiologist …‬&lt;/p&gt;</content><author><name>CY Alice, B Mohajer, J Eng - Radiology: Artificial Intelligence, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Materials and Methods In this systematic review, the PubMed database was searched for peer-reviewed studies of DL algorithms for image-based radiologic diagnosis that included external validation, published from January 1, 2015, through April 1, 2021. Studies using nonimaging features or incorporating non-DL methods for feature extraction or classification were excluded. Two reviewers independently evaluated studies for inclusion, and any discrepancies were resolved by consensus … Cites: ‪Evaluation of combined artificial intelligence and radiologist …‬</summary></entry><entry><title type="html">Learning Open Domain Multi-hop Search Using Reinforcement Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/0fb3e195d629bc88dad16c3e7d582b5d.html" rel="alternate" type="text/html" title="Learning Open Domain Multi-hop Search Using Reinforcement Learning" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/0fb3e195d629bc88dad16c3e7d582b5d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/0fb3e195d629bc88dad16c3e7d582b5d.html">&lt;p&gt;We propose a method to teach an automated agent to learn how to search for multi-hop paths of relations between entities in an open domain. The method learns a policy for directing existing information retrieval and machine reading resources to focus on relevant regions of a corpus. The approach formulates the learning problem as a Markov decision process with a state representation that encodes the dynamics of the search process and a reward structure that minimizes the number of … Cites: ‪Relational inference for wikification‬&lt;/p&gt;</content><author><name>E Noriega-Atala, M Surdeanu, CT Morrison - arXiv preprint arXiv:2205.15281, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose a method to teach an automated agent to learn how to search for multi-hop paths of relations between entities in an open domain. The method learns a policy for directing existing information retrieval and machine reading resources to focus on relevant regions of a corpus. The approach formulates the learning problem as a Markov decision process with a state representation that encodes the dynamics of the search process and a reward structure that minimizes the number of … Cites: ‪Relational inference for wikification‬</summary></entry><entry><title type="html">Augmenting Scientific Creativity with an Analogical Search Engine</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1175665a54a724725975ae265de31034.html" rel="alternate" type="text/html" title="Augmenting Scientific Creativity with an Analogical Search Engine" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1175665a54a724725975ae265de31034</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1175665a54a724725975ae265de31034.html">&lt;p&gt;Analogies have been central to creative problem-solving throughout the history of science and technology. As the number of scientific papers continues to increase exponentially, there is a growing opportunity for finding diverse solutions to existing problems. However, realizing this potential requires the development of a means for searching through a large corpus that goes beyond surface matches and simple keywords. Here we contribute the first end-to-end system for analogical search on … Cites: ‪Does the Whole Exceed its Parts? The Effect of AI Explanations on …‬&lt;/p&gt;</content><author><name>HB Kang, X Qian, T Hope, D Shahaf, J Chan, A Kittur - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Analogies have been central to creative problem-solving throughout the history of science and technology. As the number of scientific papers continues to increase exponentially, there is a growing opportunity for finding diverse solutions to existing problems. However, realizing this potential requires the development of a means for searching through a large corpus that goes beyond surface matches and simple keywords. Here we contribute the first end-to-end system for analogical search on … Cites: ‪Does the Whole Exceed its Parts? The Effect of AI Explanations on …‬</summary></entry><entry><title type="html">A REVIEW ON DATA NORMALIZATION OF DUPLICATE RECORDS FROM MULTIPLE SOURCES</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/13967bf7ca425a86408f80e252cef11d.html" rel="alternate" type="text/html" title="A REVIEW ON DATA NORMALIZATION OF DUPLICATE RECORDS FROM MULTIPLE SOURCES" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/13967bf7ca425a86408f80e252cef11d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/13967bf7ca425a86408f80e252cef11d.html">&lt;p&gt;In this paper, The bulk data is generated in the world wide web. Based on the user search parameter the data is collected from various sources. The usefulness of data increases when it is linked and fused with other data from numerous (Web) sources. The promise of Big Data hinges upon addressing several big data integration challenges, such as record linkage at scale, realtime data fusion, and integrating Deep Web. Although much work has been conducted on these problems, there is … Cites: ‪Webtables: exploring the power of tables on the web‬&lt;/p&gt;</content><author><name>N MOUNIKA, MBP KRISHNA</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper, The bulk data is generated in the world wide web. Based on the user search parameter the data is collected from various sources. The usefulness of data increases when it is linked and fused with other data from numerous (Web) sources. The promise of Big Data hinges upon addressing several big data integration challenges, such as record linkage at scale, realtime data fusion, and integrating Deep Web. Although much work has been conducted on these problems, there is … Cites: ‪Webtables: exploring the power of tables on the web‬</summary></entry><entry><title type="html">The future of sustainable digital infrastructures: A landscape of solutions, adoption factors, impediments, open problems, and scenarios</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1560e3f07eb6613e83bda3401926d143.html" rel="alternate" type="text/html" title="The future of sustainable digital infrastructures: A landscape of solutions, adoption factors, impediments, open problems, and scenarios" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1560e3f07eb6613e83bda3401926d143</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1560e3f07eb6613e83bda3401926d143.html">&lt;p&gt;Background: Digital infrastructures, ie, ICT systems, or system-of-systems, providing digital capabilities, such as storage and computational services, are experiencing an ever-growing demand for data consumption, which is only expected to increase in the future. This trend leads to a question we need to answer: How can we evolve digital infrastructures to keep up with the increasing data demand in a sustainable way? Objective: The goal of this study is to understand what is the future of … Cites: ‪Green AI‬&lt;/p&gt;</content><author><name>R Verdecchia, P Lago, C de Vries - Sustainable Computing: Informatics and Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Background: Digital infrastructures, ie, ICT systems, or system-of-systems, providing digital capabilities, such as storage and computational services, are experiencing an ever-growing demand for data consumption, which is only expected to increase in the future. This trend leads to a question we need to answer: How can we evolve digital infrastructures to keep up with the increasing data demand in a sustainable way? Objective: The goal of this study is to understand what is the future of … Cites: ‪Green AI‬</summary></entry><entry><title type="html">Mitigating Dataset Bias by Using Per-sample Gradient</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/17be843de2f0394415f81a2346c09ca2.html" rel="alternate" type="text/html" title="Mitigating Dataset Bias by Using Per-sample Gradient" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/17be843de2f0394415f81a2346c09ca2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/17be843de2f0394415f81a2346c09ca2.html">&lt;p&gt;The performance of deep neural networks is strongly influenced by the training dataset setup. In particular, when attributes having a strong correlation with the target attribute are present, the trained model can provide unintended prejudgments and show significant inference errors (ie, the dataset bias problem). Various methods have been proposed to mitigate dataset bias, and their emphasis is on weakly correlated samples, called bias-conflicting samples. These methods are based on … Cites: ‪Catastrophic fisher explosion: Early phase fisher matrix impacts …‬&lt;/p&gt;</content><author><name>S Ahn, S Kim, S Yun - arXiv preprint arXiv:2205.15704, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The performance of deep neural networks is strongly influenced by the training dataset setup. In particular, when attributes having a strong correlation with the target attribute are present, the trained model can provide unintended prejudgments and show significant inference errors (ie, the dataset bias problem). Various methods have been proposed to mitigate dataset bias, and their emphasis is on weakly correlated samples, called bias-conflicting samples. These methods are based on … Cites: ‪Catastrophic fisher explosion: Early phase fisher matrix impacts …‬</summary></entry><entry><title type="html">One Reference Is Not Enough: Diverse Distillation with Reference Selection for Non-Autoregressive Translation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/180bb31912a4ac8aa4a2d11086394429.html" rel="alternate" type="text/html" title="One Reference Is Not Enough: Diverse Distillation with Reference Selection for Non-Autoregressive Translation" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/180bb31912a4ac8aa4a2d11086394429</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/180bb31912a4ac8aa4a2d11086394429.html">&lt;p&gt;Non-autoregressive neural machine translation (NAT) suffers from the multi-modality problem: the source sentence may have multiple correct translations, but the loss function is calculated only according to the reference sentence. Sequence-level knowledge distillation makes the target more deterministic by replacing the target with the output from an autoregressive model. However, the multi-modality problem in the distilled dataset is still nonnegligible. Furthermore, learning from a specific … Cites: ‪Latent-variable non-autoregressive neural machine translation …‬&lt;/p&gt;</content><author><name>C Shao, X Wu, Y Feng - arXiv preprint arXiv:2205.14333, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Non-autoregressive neural machine translation (NAT) suffers from the multi-modality problem: the source sentence may have multiple correct translations, but the loss function is calculated only according to the reference sentence. Sequence-level knowledge distillation makes the target more deterministic by replacing the target with the output from an autoregressive model. However, the multi-modality problem in the distilled dataset is still nonnegligible. Furthermore, learning from a specific … Cites: ‪Latent-variable non-autoregressive neural machine translation …‬</summary></entry><entry><title type="html">Inter-and Intra-Modal Contrastive Hybrid Learning Framework for Multimodal Abstractive Summarization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/189df85d1b51b2ca385718ec837e3952.html" rel="alternate" type="text/html" title="Inter-and Intra-Modal Contrastive Hybrid Learning Framework for Multimodal Abstractive Summarization" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/189df85d1b51b2ca385718ec837e3952</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/189df85d1b51b2ca385718ec837e3952.html">&lt;p&gt;Internet users are benefiting from technologies of abstractive summarization enabling them to view articles on the internet by reading article summaries only instead of an entire article. However, there are disadvantages to technologies for analyzing articles with texts and images due to the semantic gap between vision and language. These technologies focus more on aggregating features and neglect the heterogeneity of each modality. At the same time, the lack of consideration of intrinsic … Cites: ‪Learning to deceive with attention-based explanations‬&lt;/p&gt;</content><author><name>J Li, Z Zhang, B Wang, Q Zhao, C Zhang - Entropy, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Internet users are benefiting from technologies of abstractive summarization enabling them to view articles on the internet by reading article summaries only instead of an entire article. However, there are disadvantages to technologies for analyzing articles with texts and images due to the semantic gap between vision and language. These technologies focus more on aggregating features and neglect the heterogeneity of each modality. At the same time, the lack of consideration of intrinsic … Cites: ‪Learning to deceive with attention-based explanations‬</summary></entry><entry><title type="html">Precise Learning Curves and Higher-Order Scaling Limits for Dot Product Kernel Regression</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/19e0fccfb1ada3c21a87887df0c5ca47.html" rel="alternate" type="text/html" title="Precise Learning Curves and Higher-Order Scaling Limits for Dot Product Kernel Regression" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/19e0fccfb1ada3c21a87887df0c5ca47</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/19e0fccfb1ada3c21a87887df0c5ca47.html">&lt;p&gt;As modern machine learning models continue to advance the computational frontier, it has become increasingly important to develop precise estimates for expected performance improvements under different model and data scaling regimes. Currently, theoretical understanding of the learning curves that characterize how the prediction error depends on the number of samples is restricted to either large-sample asymptotics ($ m\to\infty $) or, for certain simple data distributions, to the high … Cites: ‪Palm: Scaling language modeling with pathways‬&lt;/p&gt;</content><author><name>L Xiao, J Pennington - arXiv preprint arXiv:2205.14846, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As modern machine learning models continue to advance the computational frontier, it has become increasingly important to develop precise estimates for expected performance improvements under different model and data scaling regimes. Currently, theoretical understanding of the learning curves that characterize how the prediction error depends on the number of samples is restricted to either large-sample asymptotics ($ m\to\infty $) or, for certain simple data distributions, to the high … Cites: ‪Palm: Scaling language modeling with pathways‬</summary></entry><entry><title type="html">Natural Language Interfaces to Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1c9af77f30ac90a9f2a24aa9a6fa364a.html" rel="alternate" type="text/html" title="Natural Language Interfaces to Data" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1c9af77f30ac90a9f2a24aa9a6fa364a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1c9af77f30ac90a9f2a24aa9a6fa364a.html">&lt;p&gt;Recent advances in natural language understanding and processing have resulted in renewed interest in natural language interfaces to data, which provide an easy mechanism for non-technical users to access and query the data. While early systems evolved from keyword search and focused on simple factual queries, the complexity of both the input sentences as well as the generated SQL queries has evolved over time. More recently, there has also been a lot of focus on using … Cites: ‪Rat-sql: Relation-aware schema encoding and linking for text-to …‬&lt;/p&gt;</content><author><name>A Quamar, V Efthymiou, C Lei, F Özcan - Foundations and Trends® in Databases, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent advances in natural language understanding and processing have resulted in renewed interest in natural language interfaces to data, which provide an easy mechanism for non-technical users to access and query the data. While early systems evolved from keyword search and focused on simple factual queries, the complexity of both the input sentences as well as the generated SQL queries has evolved over time. More recently, there has also been a lot of focus on using … Cites: ‪Rat-sql: Relation-aware schema encoding and linking for text-to …‬</summary></entry><entry><title type="html">Legal AI in HKILL: Similar Case Matching</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1dcf3ea9ecf05d70b7170884d25a51a9.html" rel="alternate" type="text/html" title="Legal AI in HKILL: Similar Case Matching" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1dcf3ea9ecf05d70b7170884d25a51a9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1dcf3ea9ecf05d70b7170884d25a51a9.html">&lt;p&gt;Similar case matching aims at recommending other legal case documents to users based on similarity, which will be a creative and major component in the new HKILL website to improve the user experience. In this report, we mainly focus on the literature review to analyse existing methods  pros and cons. We find that text representation and knowledge based integration are the two main methods of similar case matching. Existing methods have a clear problem: when constructing the … Cites: ‪Document modeling with gated recurrent neural network for …‬&lt;/p&gt;</content><author><name>Y Liu, C Ma - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Similar case matching aims at recommending other legal case documents to users based on similarity, which will be a creative and major component in the new HKILL website to improve the user experience. In this report, we mainly focus on the literature review to analyse existing methods pros and cons. We find that text representation and knowledge based integration are the two main methods of similar case matching. Existing methods have a clear problem: when constructing the … Cites: ‪Document modeling with gated recurrent neural network for …‬</summary></entry><entry><title type="html">Probabilistic Transformer: Modelling Ambiguities and Distributions for RNA Folding and Molecule Design</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1e09162079dda40e62e25ed1345cf8e6.html" rel="alternate" type="text/html" title="Probabilistic Transformer: Modelling Ambiguities and Distributions for RNA Folding and Molecule Design" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1e09162079dda40e62e25ed1345cf8e6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/1e09162079dda40e62e25ed1345cf8e6.html">&lt;p&gt;Our world is ambiguous and this is reflected in the data we use to train our algorithms. This is especially true when we try to model natural processes where collected data is affected by noisy measurements and differences in measurement techniques. Sometimes, the process itself can be ambiguous, such as in the case of RNA folding, where a single nucleotide sequence can fold into multiple structures. This ambiguity suggests that a predictive model should have similar probabilistic … Cites: ‪Palm: Scaling language modeling with pathways‬&lt;/p&gt;</content><author><name>JKH Franke, F Runge, F Hutter - arXiv preprint arXiv:2205.13927, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Our world is ambiguous and this is reflected in the data we use to train our algorithms. This is especially true when we try to model natural processes where collected data is affected by noisy measurements and differences in measurement techniques. Sometimes, the process itself can be ambiguous, such as in the case of RNA folding, where a single nucleotide sequence can fold into multiple structures. This ambiguity suggests that a predictive model should have similar probabilistic … Cites: ‪Palm: Scaling language modeling with pathways‬</summary></entry><entry><title type="html">Semeval-2022 Task 1: CODWOE–Comparing Dictionaries and Word Embeddings</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/202b948295c3a913ed6a8193844cc8b8.html" rel="alternate" type="text/html" title="Semeval-2022 Task 1: CODWOE–Comparing Dictionaries and Word Embeddings" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/202b948295c3a913ed6a8193844cc8b8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/202b948295c3a913ed6a8193844cc8b8.html">&lt;p&gt;Word embeddings have advanced the state of the art in NLP across numerous tasks. Understanding the contents of dense neural representations is of utmost interest to the computational semantics community. We propose to focus on relating these opaque word vectors with human-readable definitions, as found in dictionaries. This problem naturally divides into two subtasks: converting definitions into embeddings, and converting embeddings into definitions. This task was conducted in a … Cites: ‪Pre-training transformers as energy-based cloze models‬&lt;/p&gt;</content><author><name>T Mickus, K van Deemter, M Constant, D Paperno - arXiv preprint arXiv:2205.13858, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Word embeddings have advanced the state of the art in NLP across numerous tasks. Understanding the contents of dense neural representations is of utmost interest to the computational semantics community. We propose to focus on relating these opaque word vectors with human-readable definitions, as found in dictionaries. This problem naturally divides into two subtasks: converting definitions into embeddings, and converting embeddings into definitions. This task was conducted in a … Cites: ‪Pre-training transformers as energy-based cloze models‬</summary></entry><entry><title type="html">Data-driven Numerical Invariant Synthesis with Automatic Generation of Attributes</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/20aa439b855facd703e4ec374994de26.html" rel="alternate" type="text/html" title="Data-driven Numerical Invariant Synthesis with Automatic Generation of Attributes" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/20aa439b855facd703e4ec374994de26</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/20aa439b855facd703e4ec374994de26.html">&lt;p&gt;We propose a data-driven algorithm for numerical invariant synthesis and verification. The algorithm is based on the ICE-DT schema for learning decision trees from samples that include positive and negative states and additionally implications corresponding to transitions in the program. The main issue we address is the discovery of relevant attributes to be used in the learning process of numerical invariants. We define a method for solving this problem that is guided by the data … Cites: ‪Learning invariants using decision trees and implication …‬&lt;/p&gt;</content><author><name>A Bouajjani, WA Boutglay, P Habermehl - arXiv preprint arXiv:2205.14943, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose a data-driven algorithm for numerical invariant synthesis and verification. The algorithm is based on the ICE-DT schema for learning decision trees from samples that include positive and negative states and additionally implications corresponding to transitions in the program. The main issue we address is the discovery of relevant attributes to be used in the learning process of numerical invariants. We define a method for solving this problem that is guided by the data … Cites: ‪Learning invariants using decision trees and implication …‬</summary></entry><entry><title type="html">Parameter-Efficient and Student-Friendly Knowledge Distillation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/23fc531bac2af0ca5045db7dd0761218.html" rel="alternate" type="text/html" title="Parameter-Efficient and Student-Friendly Knowledge Distillation" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/23fc531bac2af0ca5045db7dd0761218</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/23fc531bac2af0ca5045db7dd0761218.html">&lt;p&gt;Knowledge distillation (KD) has been extensively employed to transfer the knowledge from a large teacher model to the smaller students, where the parameters of the teacher are fixed (or partially) during training. Recent studies show that this mode may cause difficulties in knowledge transfer due to the mismatched model capacities. To alleviate the mismatch problem, teacher-student joint training methods, eg, online distillation, have been proposed, but it always requires … Cites: ‪Towards a unified view of parameter-efficient transfer learning‬&lt;/p&gt;</content><author><name>J Rao, X Meng, L Ding, S Qi, D Tao - arXiv preprint arXiv:2205.15308, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Knowledge distillation (KD) has been extensively employed to transfer the knowledge from a large teacher model to the smaller students, where the parameters of the teacher are fixed (or partially) during training. Recent studies show that this mode may cause difficulties in knowledge transfer due to the mismatched model capacities. To alleviate the mismatch problem, teacher-student joint training methods, eg, online distillation, have been proposed, but it always requires … Cites: ‪Towards a unified view of parameter-efficient transfer learning‬</summary></entry><entry><title type="html">X-SCITLDR: Cross-Lingual Extreme Summarization of Scholarly Documents</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/264eab66b457891a77d031ba48e2ce10.html" rel="alternate" type="text/html" title="X-SCITLDR: Cross-Lingual Extreme Summarization of Scholarly Documents" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/264eab66b457891a77d031ba48e2ce10</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/264eab66b457891a77d031ba48e2ce10.html">&lt;p&gt;The number of scientific publications nowadays is rapidly increasing, causing information overload for researchers and making it hard for scholars to keep up to date with current trends and lines of work. Consequently, recent work on applying text mining technologies for scholarly publications has investigated the application of automatic text summarization technologies, including extreme summarization, for this domain. However, previous work has concentrated only on monolingual settings … Cites: ‪Text summarization with pretrained encoders‬&lt;/p&gt;</content><author><name>S Takeshita, T Green, N Friedrich, K Eckert… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The number of scientific publications nowadays is rapidly increasing, causing information overload for researchers and making it hard for scholars to keep up to date with current trends and lines of work. Consequently, recent work on applying text mining technologies for scholarly publications has investigated the application of automatic text summarization technologies, including extreme summarization, for this domain. However, previous work has concentrated only on monolingual settings … Cites: ‪Text summarization with pretrained encoders‬</summary></entry><entry><title type="html">60 Years of Databases (part three)</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/272939336001fc7d9b10850ca3e86153.html" rel="alternate" type="text/html" title="60 Years of Databases (part three)" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/272939336001fc7d9b10850ca3e86153</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/272939336001fc7d9b10850ca3e86153.html">&lt;p&gt;The article provides an overview of research and development of databases since their appearance in the 60s of the last century to the present time. The following stages are distinguished: the emergence formation and rapid development, the era of relational databases, extended relational databases, post-relational databases and big data. At the stage of formation, the systems IDS, IMS, Total and Adabas are described. At the stage of rapid development, issues of ANSI/X3/SPARC database Cites: ‪What can database do for peer-to-peer?‬&lt;/p&gt;</content><author><name>VA Reznichenko - PROBLEMS IN PROGRAMMING, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The article provides an overview of research and development of databases since their appearance in the 60s of the last century to the present time. The following stages are distinguished: the emergence formation and rapid development, the era of relational databases, extended relational databases, post-relational databases and big data. At the stage of formation, the systems IDS, IMS, Total and Adabas are described. At the stage of rapid development, issues of ANSI/X3/SPARC database Cites: ‪What can database do for peer-to-peer?‬</summary></entry><entry><title type="html">Prompting ELECTRA: Few-Shot Learning with Discriminative Pre-Trained Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/2a5cb3ab80f1b01a37abaff83336bb40.html" rel="alternate" type="text/html" title="Prompting ELECTRA: Few-Shot Learning with Discriminative Pre-Trained Models" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/2a5cb3ab80f1b01a37abaff83336bb40</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/2a5cb3ab80f1b01a37abaff83336bb40.html">&lt;p&gt;Pre-trained masked language models successfully perform few-shot learning by formulating downstream tasks as text infilling. However, as a strong alternative in full-shot settings, discriminative pre-trained models like ELECTRA do not fit into the paradigm. In this work, we adapt prompt-based few-shot learning to ELECTRA and show that it outperforms masked language models in a wide range of tasks. ELECTRA is pre-trained to distinguish if a token is generated or original. We … Cites: ‪Prompt Tuning for Discriminative Pre-trained Language Models‬&lt;/p&gt;</content><author><name>M Xia, M Artetxe, J Du, D Chen, V Stoyanov - arXiv preprint arXiv:2205.15223, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pre-trained masked language models successfully perform few-shot learning by formulating downstream tasks as text infilling. However, as a strong alternative in full-shot settings, discriminative pre-trained models like ELECTRA do not fit into the paradigm. In this work, we adapt prompt-based few-shot learning to ELECTRA and show that it outperforms masked language models in a wide range of tasks. ELECTRA is pre-trained to distinguish if a token is generated or original. We … Cites: ‪Prompt Tuning for Discriminative Pre-trained Language Models‬</summary></entry><entry><title type="html">LSRML: A Latent Space Regularization based Meta-Learning Framework for MR Image Segmentation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/2c39895f0b58401d1ad2ae1d3d56c957.html" rel="alternate" type="text/html" title="LSRML: A Latent Space Regularization based Meta-Learning Framework for MR Image Segmentation" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/2c39895f0b58401d1ad2ae1d3d56c957</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/2c39895f0b58401d1ad2ae1d3d56c957.html">&lt;p&gt;Data sources for medical image segmentation can be quite extensive, and models trained with data from a source domain may perform poorly on data from the target domain owing to domain shift issues. To overcome the impact of domain shift, we propose a novel meta-learning-based multi-source domain adaptation framework for medical image segmentation. Specifically, we designed a domain discriminator module to produce category prediction over the latent features, and an image … Cites: ‪Multi-Source Domain Adaptation for Text Classification via …‬&lt;/p&gt;</content><author><name>B Zhang, Y Tan, H Wang, Z Zhang, X Zhou, J Wu, Y Mi… - Pattern Recognition, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Data sources for medical image segmentation can be quite extensive, and models trained with data from a source domain may perform poorly on data from the target domain owing to domain shift issues. To overcome the impact of domain shift, we propose a novel meta-learning-based multi-source domain adaptation framework for medical image segmentation. Specifically, we designed a domain discriminator module to produce category prediction over the latent features, and an image … Cites: ‪Multi-Source Domain Adaptation for Text Classification via …‬</summary></entry><entry><title type="html">Climate risks, uncertainty and information failures in the low-carbon transition</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/2f2b7184e55d1ad1e987dfdfeee8f691.html" rel="alternate" type="text/html" title="Climate risks, uncertainty and information failures in the low-carbon transition" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/2f2b7184e55d1ad1e987dfdfeee8f691</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/2f2b7184e55d1ad1e987dfdfeee8f691.html">&lt;p&gt;It is now almost 15 years that climate change has been characterised as the “biggest market failure the world has seen”(Stern 2008). Meanwhile, more intense and more frequent extreme weather events have become a major source of economic losses for the global economy, and are likely to intensify in the future (Pörtner et al. 2022). To sustain economic welfare and prevent dangerous climate tipping points, governments, individuals and companies worldwide need to implement effective … Cites: ‪ClimaText: A dataset for climate change topic detection‬&lt;/p&gt;</content><author><name>JA Bingler - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">It is now almost 15 years that climate change has been characterised as the “biggest market failure the world has seen”(Stern 2008). Meanwhile, more intense and more frequent extreme weather events have become a major source of economic losses for the global economy, and are likely to intensify in the future (Pörtner et al. 2022). To sustain economic welfare and prevent dangerous climate tipping points, governments, individuals and companies worldwide need to implement effective … Cites: ‪ClimaText: A dataset for climate change topic detection‬</summary></entry><entry><title type="html">A Survey in Mathematical Language Processing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/35c6d6d6484a94493a3564c9bebd208c.html" rel="alternate" type="text/html" title="A Survey in Mathematical Language Processing" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/35c6d6d6484a94493a3564c9bebd208c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/35c6d6d6484a94493a3564c9bebd208c.html">&lt;p&gt;Informal mathematical text underpins real-world quantitative reasoning and communication. Developing sophisticated methods of retrieval and abstraction from this dual modality is crucial in the pursuit of the vision of automating discovery in quantitative science and mathematics. We track the development of informal mathematical language processing approaches across five strategic sub-areas in recent years, highlighting the prevailing successful methodological elements along … Cites: ‪Naturalproofs: Mathematical theorem proving in natural language‬&lt;/p&gt;</content><author><name>J Meadows, A Freitas - arXiv preprint arXiv:2205.15231, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Informal mathematical text underpins real-world quantitative reasoning and communication. Developing sophisticated methods of retrieval and abstraction from this dual modality is crucial in the pursuit of the vision of automating discovery in quantitative science and mathematics. We track the development of informal mathematical language processing approaches across five strategic sub-areas in recent years, highlighting the prevailing successful methodological elements along … Cites: ‪Naturalproofs: Mathematical theorem proving in natural language‬</summary></entry><entry><title type="html">Additive Feature Attribution Explainable Methods to Craft Adversarial Attacks for Text Classification and Text Regression</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/37debb849fb4e3054fc0237bcd25f18f.html" rel="alternate" type="text/html" title="Additive Feature Attribution Explainable Methods to Craft Adversarial Attacks for Text Classification and Text Regression" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/37debb849fb4e3054fc0237bcd25f18f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/37debb849fb4e3054fc0237bcd25f18f.html">&lt;p&gt;Deep learning (DL) models have significantly improved the performance of text classification and text regression tasks. However, DL models are often strikingly vulnerable to adversarial attacks. Many researchers have aimed to develop adversarial attacks against DL models in realistic black-box settings (ie, assumes no model knowledge is accessible to attackers) that typically operate with a two-phase framework:(1) sensitivity estimation through gradient-based or deletion-based … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬&lt;/p&gt;</content><author><name>Y Chai, R Liang, S Samtani, H Zhu, M Wang, Y Liu…</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning (DL) models have significantly improved the performance of text classification and text regression tasks. However, DL models are often strikingly vulnerable to adversarial attacks. Many researchers have aimed to develop adversarial attacks against DL models in realistic black-box settings (ie, assumes no model knowledge is accessible to attackers) that typically operate with a two-phase framework:(1) sensitivity estimation through gradient-based or deletion-based … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬</summary></entry><entry><title type="html">GALOIS: Boosting Deep Reinforcement Learning via Generalizable Logic Synthesis</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3987923a38f89385ea058efe186d295f.html" rel="alternate" type="text/html" title="GALOIS: Boosting Deep Reinforcement Learning via Generalizable Logic Synthesis" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3987923a38f89385ea058efe186d295f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3987923a38f89385ea058efe186d295f.html">&lt;p&gt;Despite achieving superior performance in human-level control problems, unlike humans, deep reinforcement learning (DRL) lacks high-order intelligence (eg, logic deduction and reuse), thus it behaves ineffectively than humans regarding learning and generalization in complex problems. Previous works attempt to directly synthesize a white-box logic program as the DRL policy, manifesting logic-driven behaviors. However, most synthesis methods are built on imperative or declarative … Cites: ‪Introduction to statistical relational learning‬&lt;/p&gt;</content><author><name>Y Cao, Z Li, T Yang, H Zhang, Y Zheng, Y Li, J Hao… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Despite achieving superior performance in human-level control problems, unlike humans, deep reinforcement learning (DRL) lacks high-order intelligence (eg, logic deduction and reuse), thus it behaves ineffectively than humans regarding learning and generalization in complex problems. Previous works attempt to directly synthesize a white-box logic program as the DRL policy, manifesting logic-driven behaviors. However, most synthesis methods are built on imperative or declarative … Cites: ‪Introduction to statistical relational learning‬</summary></entry><entry><title type="html">Guided Exploration of Data Summaries</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3b9840fa8688a5429bc5ce16170f460a.html" rel="alternate" type="text/html" title="Guided Exploration of Data Summaries" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3b9840fa8688a5429bc5ce16170f460a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3b9840fa8688a5429bc5ce16170f460a.html">&lt;p&gt;Data summarization is the process of producing interpretable and representative subsets of an input dataset. It is usually performed following a one-shot process with the purpose of finding the best summary. A useful summary contains k individually uniform sets that are collectively diverse to be representative. Uniformity addresses interpretability and diversity addresses representativity. Finding such as summary is a difficult task when data is highly diverse and large. We examine the applicability of … Cites: ‪Constructing and exploring composite items‬&lt;/p&gt;</content><author><name>B Youngmann, S Amer-Yahia, A Personnaz - arXiv preprint arXiv:2205.13956, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Data summarization is the process of producing interpretable and representative subsets of an input dataset. It is usually performed following a one-shot process with the purpose of finding the best summary. A useful summary contains k individually uniform sets that are collectively diverse to be representative. Uniformity addresses interpretability and diversity addresses representativity. Finding such as summary is a difficult task when data is highly diverse and large. We examine the applicability of … Cites: ‪Constructing and exploring composite items‬</summary></entry><entry><title type="html">Detecting extreme traffic events via a context augmented graph autoencoder</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3d919d0a25502b2fbf54f86510cb21fe.html" rel="alternate" type="text/html" title="Detecting extreme traffic events via a context augmented graph autoencoder" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3d919d0a25502b2fbf54f86510cb21fe</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3d919d0a25502b2fbf54f86510cb21fe.html">&lt;p&gt;Accurate and timely detection of large events on urban transportation networks enables informed mobility management. This work tackles the problem of extreme event detection on large scale transportation networks using origin-destination mobility data, which is now widely available. Such data is highly structured in time and space, but high dimensional and sparse. Current multivariate time series anomaly detection methods cannot fully address these challenges. To exploit the … Cites: ‪Graph neural networks: A review of methods and applications‬&lt;/p&gt;</content><author><name>Y Hu, A Qu, D Work - ACM Transactions on Intelligent Systems and …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Accurate and timely detection of large events on urban transportation networks enables informed mobility management. This work tackles the problem of extreme event detection on large scale transportation networks using origin-destination mobility data, which is now widely available. Such data is highly structured in time and space, but high dimensional and sparse. Current multivariate time series anomaly detection methods cannot fully address these challenges. To exploit the … Cites: ‪Graph neural networks: A review of methods and applications‬</summary></entry><entry><title type="html">Nearest Neighbor Zero-Shot Inference</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3df39794d95bd3b3c6b08ea89db15e05.html" rel="alternate" type="text/html" title="Nearest Neighbor Zero-Shot Inference" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3df39794d95bd3b3c6b08ea89db15e05</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3df39794d95bd3b3c6b08ea89db15e05.html">&lt;p&gt;We introduce kNN-Prompt, a simple and effective technique to use k-nearest neighbor (kNN) retrieval augmentation (Khandelwal et al., 2021) for zero-shot inference with language models (LMs). Key to our approach is the introduction of fuzzy verbalizers which leverage the sparse kNN distribution for downstream tasks by automatically associating each classification label with a set of natural language tokens. Across eleven diverse end-tasks (spanning text classification, fact retrieval … Cites: ‪Efficient Nearest Neighbor Language Models‬&lt;/p&gt;</content><author><name>W Shi, J Michael, S Gururangan, L Zettlemoyer - arXiv preprint arXiv:2205.13792, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We introduce kNN-Prompt, a simple and effective technique to use k-nearest neighbor (kNN) retrieval augmentation (Khandelwal et al., 2021) for zero-shot inference with language models (LMs). Key to our approach is the introduction of fuzzy verbalizers which leverage the sparse kNN distribution for downstream tasks by automatically associating each classification label with a set of natural language tokens. Across eleven diverse end-tasks (spanning text classification, fact retrieval … Cites: ‪Efficient Nearest Neighbor Language Models‬</summary></entry><entry><title type="html">Machine Learning for Microcontroller-Class Hardware–A Review</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3f834c4431859d5fd0af546c53dd1d87.html" rel="alternate" type="text/html" title="Machine Learning for Microcontroller-Class Hardware–A Review" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3f834c4431859d5fd0af546c53dd1d87</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3f834c4431859d5fd0af546c53dd1d87.html">&lt;p&gt;The advancements in machine learning opened a new opportunity to bring intelligence to the low-end Internet-of-Things nodes such as microcontrollers. Conventional machine learning deployment has high memory and compute footprint hindering their direct deployment on ultra resource-constrained microcontroller nodes. This paper highlights the unique challenges of enabling onboard machine learning for microcontroller class devices. Recently, researchers have used a … Cites: ‪Efficientdet: Scalable and efficient object detection‬&lt;/p&gt;</content><author><name>SS Saha, SS Sandha, M Srivastava - arXiv preprint arXiv:2205.14550, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The advancements in machine learning opened a new opportunity to bring intelligence to the low-end Internet-of-Things nodes such as microcontrollers. Conventional machine learning deployment has high memory and compute footprint hindering their direct deployment on ultra resource-constrained microcontroller nodes. This paper highlights the unique challenges of enabling onboard machine learning for microcontroller class devices. Recently, researchers have used a … Cites: ‪Efficientdet: Scalable and efficient object detection‬</summary></entry><entry><title type="html">AraXLNet: pre-trained language model for sentiment analysis of Arabic</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3fac33d1c28e1e4950c48960ee228711.html" rel="alternate" type="text/html" title="AraXLNet: pre-trained language model for sentiment analysis of Arabic" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3fac33d1c28e1e4950c48960ee228711</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/3fac33d1c28e1e4950c48960ee228711.html">&lt;p&gt;The Arabic language is a complex language with little resources; therefore, its limitations create a challenge to produce accurate text classification tasks such as sentiment analysis. The main goal of sentiment analysis is to determine the overall orientation of a given text in terms of whether it is positive, negative, or neutral. Recently, language models have shown great results in promoting the accuracy of text classification in English. The models are pre-trained on a large dataset and then … Cites: ‪BERT: pre-training of deep bidirectional transformers for language …‬&lt;/p&gt;</content><author><name>A Alduailej, A Alothaim - Journal of Big Data, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The Arabic language is a complex language with little resources; therefore, its limitations create a challenge to produce accurate text classification tasks such as sentiment analysis. The main goal of sentiment analysis is to determine the overall orientation of a given text in terms of whether it is positive, negative, or neutral. Recently, language models have shown great results in promoting the accuracy of text classification in English. The models are pre-trained on a large dataset and then … Cites: ‪BERT: pre-training of deep bidirectional transformers for language …‬</summary></entry><entry><title type="html">The Good, the Bad and the Ugly: Exploring the Robustness and Applicability of Adversarial Machine Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4261c5659a878367808a6b0032c74f85.html" rel="alternate" type="text/html" title="The Good, the Bad and the Ugly: Exploring the Robustness and Applicability of Adversarial Machine Learning" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4261c5659a878367808a6b0032c74f85</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4261c5659a878367808a6b0032c74f85.html">&lt;p&gt;Neural networks have been widely adopted to address different real-world problems. Despite the remarkable achievements in machine learning tasks, they remain vulnerable to adversarial examples that are imperceptible to humans but can mislead the state-of-the-art models. More specifically, such adversarial examples can be generalized to a variety of common data structures, including images, texts and networked data. Faced with the significant threat that adversarial attacks pose to … Cites: ‪Semantically Equivalent Adversarial Rules for Debugging NLP …‬&lt;/p&gt;</content><author><name>X Li - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Neural networks have been widely adopted to address different real-world problems. Despite the remarkable achievements in machine learning tasks, they remain vulnerable to adversarial examples that are imperceptible to humans but can mislead the state-of-the-art models. More specifically, such adversarial examples can be generalized to a variety of common data structures, including images, texts and networked data. Faced with the significant threat that adversarial attacks pose to … Cites: ‪Semantically Equivalent Adversarial Rules for Debugging NLP …‬</summary></entry><entry><title type="html">GIT: A Generative Image-to-text Transformer for Vision and Language</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4589cee4694f19f26612164e537fb32f.html" rel="alternate" type="text/html" title="GIT: A Generative Image-to-text Transformer for Vision and Language" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4589cee4694f19f26612164e537fb32f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4589cee4694f19f26612164e537fb32f.html">&lt;p&gt;In this paper, we design and train a Generative Image-to-text Transformer, GIT, to unify vision-language tasks such as image/video captioning and question answering. While generative models provide a consistent network architecture between pre-training and fine-tuning, existing work typically contains complex structures (uni/multi-modal encoder/decoder) and depends on external modules such as object detectors/taggers and optical character recognition (OCR). In GIT, we simplify the … Cites: ‪How Much Can CLIP Benefit Vision-and-Language Tasks?‬&lt;/p&gt;</content><author><name>J Wang, Z Yang, X Hu, L Li, K Lin, Z Gan, Z Liu, C Liu… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper, we design and train a Generative Image-to-text Transformer, GIT, to unify vision-language tasks such as image/video captioning and question answering. While generative models provide a consistent network architecture between pre-training and fine-tuning, existing work typically contains complex structures (uni/multi-modal encoder/decoder) and depends on external modules such as object detectors/taggers and optical character recognition (OCR). In GIT, we simplify the … Cites: ‪How Much Can CLIP Benefit Vision-and-Language Tasks?‬</summary></entry><entry><title type="html">Label-Enhanced Graph Neural Network for Semi-supervised Node Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/45ed74cb3cd7933de061e66bf84d270e.html" rel="alternate" type="text/html" title="Label-Enhanced Graph Neural Network for Semi-supervised Node Classification" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/45ed74cb3cd7933de061e66bf84d270e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/45ed74cb3cd7933de061e66bf84d270e.html">&lt;p&gt;Graph Neural Networks (GNNs) have been widely applied in the semi-supervised node classification task, where a key point lies in how to sufficiently leverage the limited but valuable label information. Most of the classical GNNs solely use the known labels for computing the classification loss at the output. In recent years, several methods have been designed to additionally utilize the labels at the input. One part of the methods augment the node features via concatenating or adding … Cites: ‪Learning with Local and Global Consistency.‬&lt;/p&gt;</content><author><name>L Yu, L Sun, B Du, T Zhu, W Lv - arXiv preprint arXiv:2205.15653, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Graph Neural Networks (GNNs) have been widely applied in the semi-supervised node classification task, where a key point lies in how to sufficiently leverage the limited but valuable label information. Most of the classical GNNs solely use the known labels for computing the classification loss at the output. In recent years, several methods have been designed to additionally utilize the labels at the input. One part of the methods augment the node features via concatenating or adding … Cites: ‪Learning with Local and Global Consistency.‬</summary></entry><entry><title type="html">Web-history: designing a course, shaping the discipline</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/48edd1a2ff976f0ca7a2c819f50bc303.html" rel="alternate" type="text/html" title="Web-history: designing a course, shaping the discipline" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/48edd1a2ff976f0ca7a2c819f50bc303</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/48edd1a2ff976f0ca7a2c819f50bc303.html">&lt;p&gt;A full-fledged reconstruction of the history of contemporary society is impossible without studying web archives as the most valuable historical source storing artifacts of the information age. At the same time, web history as a discipline is just beginning its formation as a research field. The specific methodology, source base, methods, and techniques of using the archived resources are being determined. The development of web history as a discipline can be facilitated by specialized … Cites: ‪The unreasonable effectiveness of data‬&lt;/p&gt;</content><author><name>N Povroznik - International Journal of Digital Humanities, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A full-fledged reconstruction of the history of contemporary society is impossible without studying web archives as the most valuable historical source storing artifacts of the information age. At the same time, web history as a discipline is just beginning its formation as a research field. The specific methodology, source base, methods, and techniques of using the archived resources are being determined. The development of web history as a discipline can be facilitated by specialized … Cites: ‪The unreasonable effectiveness of data‬</summary></entry><entry><title type="html">Commonsense and Named Entity Aware Knowledge Grounded Dialogue Generation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/49c68abe77088cd605f255f7c46fbdf3.html" rel="alternate" type="text/html" title="Commonsense and Named Entity Aware Knowledge Grounded Dialogue Generation" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/49c68abe77088cd605f255f7c46fbdf3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/49c68abe77088cd605f255f7c46fbdf3.html">&lt;p&gt;Grounding dialogue on external knowledge and interpreting linguistic patterns in dialogue history context, such as ellipsis, anaphora, and co-references is critical for dialogue comprehension and generation. In this paper, we present a novel open-domain dialogue generation model which effectively utilizes the large-scale commonsense and named entity based knowledge in addition to the unstructured topic-specific knowledge associated with each utterance. We enhance the … Cites: ‪Conversing by reading: Contentful neural conversation with on …‬&lt;/p&gt;</content><author><name>D Varshney, A Prabhakar, A Ekbal - arXiv preprint arXiv:2205.13928, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Grounding dialogue on external knowledge and interpreting linguistic patterns in dialogue history context, such as ellipsis, anaphora, and co-references is critical for dialogue comprehension and generation. In this paper, we present a novel open-domain dialogue generation model which effectively utilizes the large-scale commonsense and named entity based knowledge in addition to the unstructured topic-specific knowledge associated with each utterance. We enhance the … Cites: ‪Conversing by reading: Contentful neural conversation with on …‬</summary></entry><entry><title type="html">Transfer language selection for zero-shot cross-lingual abusive language detection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4bf96fceed780d70c19b15ec3065b17d.html" rel="alternate" type="text/html" title="Transfer language selection for zero-shot cross-lingual abusive language detection" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4bf96fceed780d70c19b15ec3065b17d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4bf96fceed780d70c19b15ec3065b17d.html">&lt;p&gt;We study the selection of transfer languages for automatic abusive language detection. Instead of preparing a dataset for every language, we demonstrate the effectiveness of cross-lingual transfer learning for zero-shot abusive language detection. This way we can use existing data from higher-resource languages to build better detection systems for low-resource languages. Our datasets are from seven different languages from three language families. We measure the distance … Cites: ‪XTREME: A massively multilingual multi-task benchmark for …‬&lt;/p&gt;</content><author><name>J Eronen, M Ptaszynski, F Masui, M Arata, G Leliwa… - Information Processing &amp; …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We study the selection of transfer languages for automatic abusive language detection. Instead of preparing a dataset for every language, we demonstrate the effectiveness of cross-lingual transfer learning for zero-shot abusive language detection. This way we can use existing data from higher-resource languages to build better detection systems for low-resource languages. Our datasets are from seven different languages from three language families. We measure the distance … Cites: ‪XTREME: A massively multilingual multi-task benchmark for …‬</summary></entry><entry><title type="html">Knowledge Transfer between Structured and Unstructured Sources for Complex Question Answering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4e1a5a4db9b55546899bb6e18fac22f7.html" rel="alternate" type="text/html" title="Knowledge Transfer between Structured and Unstructured Sources for Complex Question Answering" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4e1a5a4db9b55546899bb6e18fac22f7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4e1a5a4db9b55546899bb6e18fac22f7.html">&lt;p&gt;Multi-hop question answering (QA) combines multiple pieces of evidence to search for the correct answer. Reasoning over a text corpus (TextQA) and/or a knowledge base (KBQA) has been extensively studied and led to distinct system architectures. However, knowledge transfer between such two QA systems has been under-explored. Research questions like what knowledge is transferred or whether the transferred knowledge can help answer over one source using another one, are yet … Cites: ‪The web as a knowledge-base for answering complex questions‬&lt;/p&gt;</content><author><name>L Mo, Z Wang, J Zhao, H Sun</name></author><category term="jekyll" /><category term="update" /><summary type="html">Multi-hop question answering (QA) combines multiple pieces of evidence to search for the correct answer. Reasoning over a text corpus (TextQA) and/or a knowledge base (KBQA) has been extensively studied and led to distinct system architectures. However, knowledge transfer between such two QA systems has been under-explored. Research questions like what knowledge is transferred or whether the transferred knowledge can help answer over one source using another one, are yet … Cites: ‪The web as a knowledge-base for answering complex questions‬</summary></entry><entry><title type="html">Radial Basis Function Attention for Named Entity Recognition</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4e249f5b9e31917d4125e8eaa355fde3.html" rel="alternate" type="text/html" title="Radial Basis Function Attention for Named Entity Recognition" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4e249f5b9e31917d4125e8eaa355fde3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4e249f5b9e31917d4125e8eaa355fde3.html">&lt;p&gt;Attention mechanism is an increasingly important approach in the field of natural language processing (NLP). In the attention-based named entity recognition (NER) model, most attention mechanisms can calculate attention coefficient to express the importance of sentence semantic information, but cannot adjust the position distribution of contextual feature vectors in the semantic space. To address this issue, a radial basis function attention (RBF-attention) layer is proposed to adaptively … Cites: ‪Long short-term memory-networks for machine reading‬&lt;/p&gt;</content><author><name>J Chen, X Xu, X Zhang - Transactions on Asian and Low-Resource Language …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Attention mechanism is an increasingly important approach in the field of natural language processing (NLP). In the attention-based named entity recognition (NER) model, most attention mechanisms can calculate attention coefficient to express the importance of sentence semantic information, but cannot adjust the position distribution of contextual feature vectors in the semantic space. To address this issue, a radial basis function attention (RBF-attention) layer is proposed to adaptively … Cites: ‪Long short-term memory-networks for machine reading‬</summary></entry><entry><title type="html">Multi-Game Decision Transformers</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4fca7bf581ae35f9e3f7221f89f04587.html" rel="alternate" type="text/html" title="Multi-Game Decision Transformers" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4fca7bf581ae35f9e3f7221f89f04587</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/4fca7bf581ae35f9e3f7221f89f04587.html">&lt;p&gt;A longstanding goal of the field of AI is a strategy for compiling diverse experience into a highly capable, generalist agent. In the subfields of vision and language, this was largely achieved by scaling up transformer-based models and training them on large, diverse datasets. Motivated by this progress, we investigate whether the same strategy can be used to produce generalist reinforcement learning agents. Specifically, we show that a single transformer-based model-with a single set of … Cites: ‪Gedi: Generative discriminator guided sequence generation‬&lt;/p&gt;</content><author><name>KH Lee, O Nachum, M Yang, L Lee, D Freeman, W Xu… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A longstanding goal of the field of AI is a strategy for compiling diverse experience into a highly capable, generalist agent. In the subfields of vision and language, this was largely achieved by scaling up transformer-based models and training them on large, diverse datasets. Motivated by this progress, we investigate whether the same strategy can be used to produce generalist reinforcement learning agents. Specifically, we show that a single transformer-based model-with a single set of … Cites: ‪Gedi: Generative discriminator guided sequence generation‬</summary></entry><entry><title type="html">EfficientViT: Enhanced Linear Attention for High-Resolution Low-Computation Visual Recognition</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/519db048a4b4c2a6f98c1153d3a6f65a.html" rel="alternate" type="text/html" title="EfficientViT: Enhanced Linear Attention for High-Resolution Low-Computation Visual Recognition" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/519db048a4b4c2a6f98c1153d3a6f65a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/519db048a4b4c2a6f98c1153d3a6f65a.html">&lt;p&gt;Vision Transformer (ViT) has achieved remarkable performance in many vision tasks. However, ViT is inferior to convolutional neural networks (CNNs) when targeting high-resolution mobile vision applications. The key computational bottleneck of ViT is the softmax attention module which has quadratic computational complexity with the input resolution. It is essential to reduce the cost of ViT to deploy it on edge devices. Existing methods (eg, Swin, PVT) restrict the softmax attention within local windows … Cites: ‪Coatnet: Marrying convolution and attention for all data sizes‬&lt;/p&gt;</content><author><name>H Cai, C Gan, S Han - arXiv preprint arXiv:2205.14756, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Vision Transformer (ViT) has achieved remarkable performance in many vision tasks. However, ViT is inferior to convolutional neural networks (CNNs) when targeting high-resolution mobile vision applications. The key computational bottleneck of ViT is the softmax attention module which has quadratic computational complexity with the input resolution. It is essential to reduce the cost of ViT to deploy it on edge devices. Existing methods (eg, Swin, PVT) restrict the softmax attention within local windows … Cites: ‪Coatnet: Marrying convolution and attention for all data sizes‬</summary></entry><entry><title type="html">Overview of AI-Based Approaches to Remote Monitoring and Assistance in Orthopedic Rehabilitation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/561502d0e92f66df874fc75c6b036c18.html" rel="alternate" type="text/html" title="Overview of AI-Based Approaches to Remote Monitoring and Assistance in Orthopedic Rehabilitation" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/561502d0e92f66df874fc75c6b036c18</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/561502d0e92f66df874fc75c6b036c18.html">&lt;p&gt;The recent years have seen the unprecedented rise in computational power and storage. Both have become widespread, thanks to the major cloud providers. Today, Graphical Processing Units in application clouds are becoming available at minimum or no cost, facilitating efficient training of models and increased productivity in numerical experiments. In such circumstances, the Machine Learning tools and approaches started to emerge at extremely fast pace, as the flagship technology for … Cites: ‪Model-agnostic interpretability of machine learning‬&lt;/p&gt;</content><author><name>D Misic, M Zdravkovic - Personalized Orthopedics: Contributions and …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The recent years have seen the unprecedented rise in computational power and storage. Both have become widespread, thanks to the major cloud providers. Today, Graphical Processing Units in application clouds are becoming available at minimum or no cost, facilitating efficient training of models and increased productivity in numerical experiments. In such circumstances, the Machine Learning tools and approaches started to emerge at extremely fast pace, as the flagship technology for … Cites: ‪Model-agnostic interpretability of machine learning‬</summary></entry><entry><title type="html">Concept-level Debugging of Part-Prototype Networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/5647612bf98f69c00077f10326216592.html" rel="alternate" type="text/html" title="Concept-level Debugging of Part-Prototype Networks" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/5647612bf98f69c00077f10326216592</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/5647612bf98f69c00077f10326216592.html">&lt;p&gt;Part-prototype Networks (ProtoPNets) are concept-based classifiers designed to achieve the same performance as black-box models without compromising transparency. ProtoPNets compute predictions based on similarity to class-specific part-prototypes learned to recognize parts of training examples, making it easy to faithfully determine what examples are responsible for any target prediction and why. However, like other models, they are prone to picking up confounds and shortcuts … Cites: ‪Evaluating Explainable AI: Which Algorithmic Explanations Help …‬&lt;/p&gt;</content><author><name>A Bontempelli, S Teso, F Giunchiglia, A Passerini - arXiv preprint arXiv:2205.15769, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Part-prototype Networks (ProtoPNets) are concept-based classifiers designed to achieve the same performance as black-box models without compromising transparency. ProtoPNets compute predictions based on similarity to class-specific part-prototypes learned to recognize parts of training examples, making it easy to faithfully determine what examples are responsible for any target prediction and why. However, like other models, they are prone to picking up confounds and shortcuts … Cites: ‪Evaluating Explainable AI: Which Algorithmic Explanations Help …‬</summary></entry><entry><title type="html">Knowledge graph and knowledge reasoning: A systematic review</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/586e02c4562ba70c7034be8aa7d895ef.html" rel="alternate" type="text/html" title="Knowledge graph and knowledge reasoning: A systematic review" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/586e02c4562ba70c7034be8aa7d895ef</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/586e02c4562ba70c7034be8aa7d895ef.html">&lt;p&gt;The knowledge graph (KG) that represents structural relations among entities has become an increasingly important research field for knowledge-driven artificial intelligence. In this survey, a comprehensive review of KG and KG reasoning is provided. It introduces an overview of KGs, including representation, storage, and essential technologies. Specifically, it summarizes several types of knowledge reasoning approaches, including logic rules-based, representation-based, and … Cites: ‪Efficient and Expressive Knowledge Base Completion Using …‬&lt;/p&gt;</content><author><name>L Tian, X Zhou, YP Wu, WT Zhou, JH Zhang, TS Zhang - Journal of Electronic Science …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The knowledge graph (KG) that represents structural relations among entities has become an increasingly important research field for knowledge-driven artificial intelligence. In this survey, a comprehensive review of KG and KG reasoning is provided. It introduces an overview of KGs, including representation, storage, and essential technologies. Specifically, it summarizes several types of knowledge reasoning approaches, including logic rules-based, representation-based, and … Cites: ‪Efficient and Expressive Knowledge Base Completion Using …‬</summary></entry><entry><title type="html">Supervised Knowledge Aggregation for Knowledge Graph Completion</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/5be6b4192998caa87fd8405bd5def6f8.html" rel="alternate" type="text/html" title="Supervised Knowledge Aggregation for Knowledge Graph Completion" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/5be6b4192998caa87fd8405bd5def6f8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/5be6b4192998caa87fd8405bd5def6f8.html">&lt;p&gt;We explore data-driven rule aggregation based on latent feature representations in the context of knowledge graph completion. For a given query and a collection of rules obtained by a symbolic rule learning system, we propose end-to-end trainable aggregation functions for combining the rules into a confidence score answering the query. Despite using latent feature representations for rules, the proposed models remain fully interpretable in terms of the underlying symbolic approach. While our … Cites: ‪Learning reasoning strategies in end-to-end differentiable proving‬&lt;/p&gt;</content><author><name>P Betz, C Meilicke, H Stuckenschmidt</name></author><category term="jekyll" /><category term="update" /><summary type="html">We explore data-driven rule aggregation based on latent feature representations in the context of knowledge graph completion. For a given query and a collection of rules obtained by a symbolic rule learning system, we propose end-to-end trainable aggregation functions for combining the rules into a confidence score answering the query. Despite using latent feature representations for rules, the proposed models remain fully interpretable in terms of the underlying symbolic approach. While our … Cites: ‪Learning reasoning strategies in end-to-end differentiable proving‬</summary></entry><entry><title type="html">SeSG: a search string generator for Secondary Studies with hybrid search strategies using text mining</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/5d09bc77c8cc7cc635f34a97db57c523.html" rel="alternate" type="text/html" title="SeSG: a search string generator for Secondary Studies with hybrid search strategies using text mining" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/5d09bc77c8cc7cc635f34a97db57c523</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/5d09bc77c8cc7cc635f34a97db57c523.html">&lt;p&gt;Abstract A Secondary Study (SS) is an important research method used in several areas. A crucial step in the Conduction phase of a SS is the search of studies. This step is time-consuming and error-prone, mainly due to the refinement of the search string. The objective of this study is to validate the effectiveness of an automatic formulation of search strings for SS. Our approach, termed Search String Generator (SeSG), takes as input a small set of studies (as a Quasi-Gold Standard) and … Cites: ‪Deep contextualized word representations‬&lt;/p&gt;</content><author><name>LF Alves, FJS Vasconcellos, BM Nogueira - Empirical Software Engineering, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract A Secondary Study (SS) is an important research method used in several areas. A crucial step in the Conduction phase of a SS is the search of studies. This step is time-consuming and error-prone, mainly due to the refinement of the search string. The objective of this study is to validate the effectiveness of an automatic formulation of search strings for SS. Our approach, termed Search String Generator (SeSG), takes as input a small set of studies (as a Quasi-Gold Standard) and … Cites: ‪Deep contextualized word representations‬</summary></entry><entry><title type="html">Regularizing Visual Semantic Embedding with Contrastive Learning for Image-Text Matching</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/5d61efead85ef04ed12cf1442bd98c1c.html" rel="alternate" type="text/html" title="Regularizing Visual Semantic Embedding with Contrastive Learning for Image-Text Matching" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/5d61efead85ef04ed12cf1442bd98c1c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/5d61efead85ef04ed12cf1442bd98c1c.html">&lt;p&gt;Learning visual semantic embedding for image-text matching has achieved high success by using triplet loss to pull positive image-text pairs which share similar semantic meaning and to push negative image-text pairs which share different semantic meaning. Without modeling constraints from image-image or text-text pairs, the generated visual semantic embedding inevitably faces the problem of semantic misalignments among similar images or among similar texts. To solve this problem … Cites: ‪Vinvl: Revisiting visual representations in vision-language models‬&lt;/p&gt;</content><author><name>Y Liu, H Liu, H Wang, M Liu - IEEE Signal Processing Letters, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Learning visual semantic embedding for image-text matching has achieved high success by using triplet loss to pull positive image-text pairs which share similar semantic meaning and to push negative image-text pairs which share different semantic meaning. Without modeling constraints from image-image or text-text pairs, the generated visual semantic embedding inevitably faces the problem of semantic misalignments among similar images or among similar texts. To solve this problem … Cites: ‪Vinvl: Revisiting visual representations in vision-language models‬</summary></entry><entry><title type="html">Temporal knowledge graph question answering via subgraph reasoning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/608d90910298f3bd775701a6d5e79ab1.html" rel="alternate" type="text/html" title="Temporal knowledge graph question answering via subgraph reasoning" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/608d90910298f3bd775701a6d5e79ab1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/608d90910298f3bd775701a6d5e79ab1.html">&lt;p&gt;Abstract Knowledge graph question answering (KGQA) has recently received a lot of attention and many innovative methods have been proposed in this area, but few have been developed for temporal KGQA. Most of the existing temporal KGQA methods focus on semantic or temporal level matching and lack the ability to reason about time constraints. In this paper we propose a subgraph-based model for answering complex questions over temporal knowledge graphs (TKG), inspired by … Cites: ‪Semantic parsing on freebase from question-answer pairs‬&lt;/p&gt;</content><author><name>Z Chen, X Zhao, J Liao, X Li, E Kanoulas - Knowledge-Based Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Knowledge graph question answering (KGQA) has recently received a lot of attention and many innovative methods have been proposed in this area, but few have been developed for temporal KGQA. Most of the existing temporal KGQA methods focus on semantic or temporal level matching and lack the ability to reason about time constraints. In this paper we propose a subgraph-based model for answering complex questions over temporal knowledge graphs (TKG), inspired by … Cites: ‪Semantic parsing on freebase from question-answer pairs‬</summary></entry><entry><title type="html">ADAPT: Vision-Language Navigation with Modality-Aligned Action Prompts</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6232e1df7998b647c740cf5ac3749c88.html" rel="alternate" type="text/html" title="ADAPT: Vision-Language Navigation with Modality-Aligned Action Prompts" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6232e1df7998b647c740cf5ac3749c88</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6232e1df7998b647c740cf5ac3749c88.html">&lt;p&gt;Vision-Language Navigation (VLN) is a challenging task that requires an embodied agent to perform action-level modality alignment, ie, make instruction-asked actions sequentially in complex visual environments. Most existing VLN agents learn the instruction-path data directly and cannot sufficiently explore action-level alignment knowledge inside the multi-modal inputs. In this paper, we propose modAlity-aligneD Action PrompTs (ADAPT), which provides the VLN agent with action prompts to … Cites: ‪Pre-train, prompt, and predict: A systematic survey of prompting …‬&lt;/p&gt;</content><author><name>B Lin, Y Zhu, Z Chen, X Liang, J Liu, X Liang - arXiv preprint arXiv:2205.15509, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Vision-Language Navigation (VLN) is a challenging task that requires an embodied agent to perform action-level modality alignment, ie, make instruction-asked actions sequentially in complex visual environments. Most existing VLN agents learn the instruction-path data directly and cannot sufficiently explore action-level alignment knowledge inside the multi-modal inputs. In this paper, we propose modAlity-aligneD Action PrompTs (ADAPT), which provides the VLN agent with action prompts to … Cites: ‪Pre-train, prompt, and predict: A systematic survey of prompting …‬</summary></entry><entry><title type="html">You Have Earned a Trophy: Characterize In-Game Achievements and Their Completions</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/631f82483adfb11ef00b1bb58803dd3c.html" rel="alternate" type="text/html" title="You Have Earned a Trophy: Characterize In-Game Achievements and Their Completions" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/631f82483adfb11ef00b1bb58803dd3c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/631f82483adfb11ef00b1bb58803dd3c.html">&lt;p&gt;Achievement systems have been actively adopted in gaming platforms to maintain players  interests. Among them, trophies in PlayStation games are one of the most successful achievement systems. While the importance of trophy design has been casually discussed in many game developers  forums, there has been no systematic study of the historical dataset of trophies yet. In this work, we construct a complete dataset of PlayStation games and their trophies and investigate them from both the … Cites: ‪Deep semantic role labeling: What works and what’s next‬&lt;/p&gt;</content><author><name>H Kwak - arXiv preprint arXiv:2205.15163, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Achievement systems have been actively adopted in gaming platforms to maintain players interests. Among them, trophies in PlayStation games are one of the most successful achievement systems. While the importance of trophy design has been casually discussed in many game developers forums, there has been no systematic study of the historical dataset of trophies yet. In this work, we construct a complete dataset of PlayStation games and their trophies and investigate them from both the … Cites: ‪Deep semantic role labeling: What works and what’s next‬</summary></entry><entry><title type="html">Excess Risk of Two-Layer ReLU Neural Networks in Teacher-Student Settings and its Superiority to Kernel Methods</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/63bc98713c239bf0d834836d7ad09754.html" rel="alternate" type="text/html" title="Excess Risk of Two-Layer ReLU Neural Networks in Teacher-Student Settings and its Superiority to Kernel Methods" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/63bc98713c239bf0d834836d7ad09754</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/63bc98713c239bf0d834836d7ad09754.html">&lt;p&gt;While deep learning has outperformed other methods for various tasks, theoretical frameworks that explain its reason have not been fully established. To address this issue, we investigate the excess risk of two-layer ReLU neural networks in a teacher-student regression model, in which a student network learns an unknown teacher network through its outputs. Especially, we consider the student network that has the same width as the teacher network and is trained in two phases: first by noisy … Cites: ‪Towards understanding hierarchical learning: Benefits of neural …‬&lt;/p&gt;</content><author><name>S Akiyama, T Suzuki - arXiv preprint arXiv:2205.14818, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">While deep learning has outperformed other methods for various tasks, theoretical frameworks that explain its reason have not been fully established. To address this issue, we investigate the excess risk of two-layer ReLU neural networks in a teacher-student regression model, in which a student network learns an unknown teacher network through its outputs. Especially, we consider the student network that has the same width as the teacher network and is trained in two phases: first by noisy … Cites: ‪Towards understanding hierarchical learning: Benefits of neural …‬</summary></entry><entry><title type="html">Learning Based Methods for Code Runtime Complexity Prediction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/67fa08c9b4845b1d03ebe6a6e19b5677.html" rel="alternate" type="text/html" title="Learning Based Methods for Code Runtime Complexity Prediction" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/67fa08c9b4845b1d03ebe6a6e19b5677</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/67fa08c9b4845b1d03ebe6a6e19b5677.html">&lt;p&gt;Predicting the runtime complexity of a programming code is an arduous task. In fact, even for humans, it requires a subtle analysis and comprehensive knowledge of algorithms to predict time complexity with high fidelity, given any code. As per Turing s Halting problem proof, estimating code complexity is mathematically impossible. Nevertheless, an approximate solution to such a task can help developers to get real-time feedback for the efficiency of their code. In this work, we … Cites: ‪Learning to mine aligned code and natural language pairs from …‬&lt;/p&gt;</content><author><name>RR Shah, R Zimmermann</name></author><category term="jekyll" /><category term="update" /><summary type="html">Predicting the runtime complexity of a programming code is an arduous task. In fact, even for humans, it requires a subtle analysis and comprehensive knowledge of algorithms to predict time complexity with high fidelity, given any code. As per Turing s Halting problem proof, estimating code complexity is mathematically impossible. Nevertheless, an approximate solution to such a task can help developers to get real-time feedback for the efficiency of their code. In this work, we … Cites: ‪Learning to mine aligned code and natural language pairs from …‬</summary></entry><entry><title type="html">Learning from Self-Sampled Correct and Partially-Correct Programs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6849e52a388413fda53803e7324d7422.html" rel="alternate" type="text/html" title="Learning from Self-Sampled Correct and Partially-Correct Programs" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6849e52a388413fda53803e7324d7422</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6849e52a388413fda53803e7324d7422.html">&lt;p&gt;Program synthesis aims to generate executable programs that are consistent with the user specification. While there are often multiple programs that satisfy the same user specification, existing neural program synthesis models are often only learned from one reference program by maximizing its log-likelihood. This causes the model to be overly confident in its predictions as it sees the single solution repeatedly during training. This leads to poor generalization on unseen examples, even when multiple … Cites: ‪A Systematic Evaluation of Large Language Models of Code‬&lt;/p&gt;</content><author><name>A Ni, JP Inala, C Wang, O Polozov, C Meek, D Radev… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Program synthesis aims to generate executable programs that are consistent with the user specification. While there are often multiple programs that satisfy the same user specification, existing neural program synthesis models are often only learned from one reference program by maximizing its log-likelihood. This causes the model to be overly confident in its predictions as it sees the single solution repeatedly during training. This leads to poor generalization on unseen examples, even when multiple … Cites: ‪A Systematic Evaluation of Large Language Models of Code‬</summary></entry><entry><title type="html">Adversarial Robustness of Deep Neural Networks: A Survey from a Formal Verification Perspective</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/68960f60eb7c668f570927b026515caf.html" rel="alternate" type="text/html" title="Adversarial Robustness of Deep Neural Networks: A Survey from a Formal Verification Perspective" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/68960f60eb7c668f570927b026515caf</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/68960f60eb7c668f570927b026515caf.html">&lt;p&gt;Neural networks have been widely applied in security applications such as spam and phishing detection, intrusion prevention, and malware detection. This black-box method, however, often has uncertainty and poor explainability in applications. Furthermore, neural networks themselves are often vulnerable to adversarial attacks. For those reasons, there is a high demand for trustworthy and rigorous methods to verify the robustness of neural network models. Adversarial robustness, which … Cites: ‪Enabling certification of verification-agnostic networks via memory …‬&lt;/p&gt;</content><author><name>MH Meng, G Bai, SG Teo, Z Hou, Y Xiao, Y Lin… - IEEE Transactions on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Neural networks have been widely applied in security applications such as spam and phishing detection, intrusion prevention, and malware detection. This black-box method, however, often has uncertainty and poor explainability in applications. Furthermore, neural networks themselves are often vulnerable to adversarial attacks. For those reasons, there is a high demand for trustworthy and rigorous methods to verify the robustness of neural network models. Adversarial robustness, which … Cites: ‪Enabling certification of verification-agnostic networks via memory …‬</summary></entry><entry><title type="html">Social-RippleNet: Jointly modeling of ripple net and social information for recommendation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6c11ebdf8ab9f5eaed9349675f4297b0.html" rel="alternate" type="text/html" title="Social-RippleNet: Jointly modeling of ripple net and social information for recommendation" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6c11ebdf8ab9f5eaed9349675f4297b0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6c11ebdf8ab9f5eaed9349675f4297b0.html">&lt;p&gt;To alleviate the data sparseness and cold-start problem of recommender systems and improve the accuracy, researchers tend to use side information to improve recommendation performance. Previous studies have investigated social recommendation and knowledge graph recommendation separately, rarely integrated them into one model for the recommendation. We propose a model (Social-RippleNet) which jointly combines knowledge graphs and social information … Cites: ‪Recommender systems with social regularization‬&lt;/p&gt;</content><author><name>W Jiang, Y Sun - Applied Intelligence, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">To alleviate the data sparseness and cold-start problem of recommender systems and improve the accuracy, researchers tend to use side information to improve recommendation performance. Previous studies have investigated social recommendation and knowledge graph recommendation separately, rarely integrated them into one model for the recommendation. We propose a model (Social-RippleNet) which jointly combines knowledge graphs and social information … Cites: ‪Recommender systems with social regularization‬</summary></entry><entry><title type="html">Considering Temporal Aspects in Recommender Systems: A Survey</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6c5969b40d5cd07d6ec01180aed67176.html" rel="alternate" type="text/html" title="Considering Temporal Aspects in Recommender Systems: A Survey" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6c5969b40d5cd07d6ec01180aed67176</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6c5969b40d5cd07d6ec01180aed67176.html">&lt;p&gt;The widespread use of temporal aspects in user modeling indicates their importance, and their consideration showed to be highly effective in various domains related to user modeling, especially in recommender systems. Still, past and ongoing research, spread over several decades, provided multiple ad-hoc solutions, but no common understanding of the issue. There is no standardization and there is often little commonality in considering temporal aspects in different applications. This may … Cites: ‪Automatic construction of travel itineraries using social breadcrumbs‬&lt;/p&gt;</content><author><name>V Bogina, T Kuflik, D Jannach, M Bielikova, M Kompan…</name></author><category term="jekyll" /><category term="update" /><summary type="html">The widespread use of temporal aspects in user modeling indicates their importance, and their consideration showed to be highly effective in various domains related to user modeling, especially in recommender systems. Still, past and ongoing research, spread over several decades, provided multiple ad-hoc solutions, but no common understanding of the issue. There is no standardization and there is often little commonality in considering temporal aspects in different applications. This may … Cites: ‪Automatic construction of travel itineraries using social breadcrumbs‬</summary></entry><entry><title type="html">CEBaB: Estimating the Causal Effects of Real-World Concepts on NLP Model Behavior</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6f952f7df852adebfb2097bfdde0b20f.html" rel="alternate" type="text/html" title="CEBaB: Estimating the Causal Effects of Real-World Concepts on NLP Model Behavior" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6f952f7df852adebfb2097bfdde0b20f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/6f952f7df852adebfb2097bfdde0b20f.html">&lt;p&gt;The increasing size and complexity of modern ML systems has improved their predictive capabilities but made their behavior harder to explain. Many techniques for model explanation have been developed in response, but we lack clear criteria for assessing these techniques. In this paper, we cast model explanation as the causal inference problem of estimating causal effects of real-world concepts on the output behavior of ML models given actual input data. We introduce CEBaB, a new … Cites: ‪Dynabench: Rethinking benchmarking in NLP‬&lt;/p&gt;</content><author><name>ED Abraham, K D Oosterlinck, A Feder, YO Gat… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The increasing size and complexity of modern ML systems has improved their predictive capabilities but made their behavior harder to explain. Many techniques for model explanation have been developed in response, but we lack clear criteria for assessing these techniques. In this paper, we cast model explanation as the causal inference problem of estimating causal effects of real-world concepts on the output behavior of ML models given actual input data. We introduce CEBaB, a new … Cites: ‪Dynabench: Rethinking benchmarking in NLP‬</summary></entry><entry><title type="html">A Multi-level Supervised Contrastive Learning Framework for Low-Resource Natural Language Inference</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/70c1d3458c26e091aa66a4674279f6c7.html" rel="alternate" type="text/html" title="A Multi-level Supervised Contrastive Learning Framework for Low-Resource Natural Language Inference" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/70c1d3458c26e091aa66a4674279f6c7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/70c1d3458c26e091aa66a4674279f6c7.html">&lt;p&gt;Natural Language Inference (NLI) is a growingly essential task in natural language understanding, which requires inferring the relationship between the sentence pairs (premise and hypothesis). Recently, low-resource natural language inference has gained increasing attention, due to significant savings in manual annotation costs and a better fit with real-world scenarios. Existing works fail to characterize discriminative representations between different classes with limited training data … Cites: ‪ERICA: Improving Entity and Relation Understanding for Pre …‬&lt;/p&gt;</content><author><name>S Li, X Hu, L Lin, A Liu, L Wen, PS Yu - arXiv preprint arXiv:2205.15550, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Natural Language Inference (NLI) is a growingly essential task in natural language understanding, which requires inferring the relationship between the sentence pairs (premise and hypothesis). Recently, low-resource natural language inference has gained increasing attention, due to significant savings in manual annotation costs and a better fit with real-world scenarios. Existing works fail to characterize discriminative representations between different classes with limited training data … Cites: ‪ERICA: Improving Entity and Relation Understanding for Pre …‬</summary></entry><entry><title type="html">Neural Retriever and Go Beyond: A Thesis Proposal</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/722bece3e8008195a61c3ee27dd9414c.html" rel="alternate" type="text/html" title="Neural Retriever and Go Beyond: A Thesis Proposal" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/722bece3e8008195a61c3ee27dd9414c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/722bece3e8008195a61c3ee27dd9414c.html">&lt;p&gt;Information Retriever (IR) aims to find the relevant documents (eg snippets, passages, and articles) to a given query at large scale. IR plays an important role in many tasks such as open domain question answering and dialogue systems, where external knowledge is needed. In the past, searching algorithms based on term matching have been widely used. Recently, neural-based algorithms (termed as neural retrievers) have gained more attention which can mitigate the limitations of … Cites: ‪Multilingual autoregressive entity linking‬&lt;/p&gt;</content><author><name>M Luo - arXiv preprint arXiv:2205.16005, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Information Retriever (IR) aims to find the relevant documents (eg snippets, passages, and articles) to a given query at large scale. IR plays an important role in many tasks such as open domain question answering and dialogue systems, where external knowledge is needed. In the past, searching algorithms based on term matching have been widely used. Recently, neural-based algorithms (termed as neural retrievers) have gained more attention which can mitigate the limitations of … Cites: ‪Multilingual autoregressive entity linking‬</summary></entry><entry><title type="html">Update with care: Testing candidate bug fixes and integrating selective updates through binary rewriting</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/72e97515c36ea71bd278db80ede34d80.html" rel="alternate" type="text/html" title="Update with care: Testing candidate bug fixes and integrating selective updates through binary rewriting" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/72e97515c36ea71bd278db80ede34d80</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/72e97515c36ea71bd278db80ede34d80.html">&lt;p&gt;Enterprise software updates depend on the interaction between user and developer organizations. This interaction becomes especially complex when a single developer organization writes software that services hundreds of different user organizations. Miscommunication during patching and deployment efforts lead to insecure or malfunctioning software installations. While developers oversee the code, the update process starts and ends outside their control. Since developer test suites may fail to … Cites: ‪Sledgehammer:{Cluster-Fueled} Debugging‬&lt;/p&gt;</content><author><name>A Saieva, G Kaiser - Journal of Systems and Software, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Enterprise software updates depend on the interaction between user and developer organizations. This interaction becomes especially complex when a single developer organization writes software that services hundreds of different user organizations. Miscommunication during patching and deployment efforts lead to insecure or malfunctioning software installations. While developers oversee the code, the update process starts and ends outside their control. Since developer test suites may fail to … Cites: ‪Sledgehammer:{Cluster-Fueled} Debugging‬</summary></entry><entry><title type="html">Learning Locality and Isotropy in Dialogue Modeling</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/75673ecdbaf1199d34b6844d0feedf02.html" rel="alternate" type="text/html" title="Learning Locality and Isotropy in Dialogue Modeling" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/75673ecdbaf1199d34b6844d0feedf02</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/75673ecdbaf1199d34b6844d0feedf02.html">&lt;p&gt;Existing dialogue modeling methods have achieved promising performance on various dialogue tasks with the aid of Transformer and the large-scale pre-trained language models. However, some recent studies revealed that the context representations produced by these methods suffer the problem of anisotropy. In this paper, we find that the generated representations are also not conversational, losing the conversation structure information during the context modeling stage. To this end … Cites: ‪BARTScore: Evaluating Generated Text as Text Generation‬&lt;/p&gt;</content><author><name>H Wu, H Tan, M Zhan, G Zhao, S Lu, D Liang, L Song - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Existing dialogue modeling methods have achieved promising performance on various dialogue tasks with the aid of Transformer and the large-scale pre-trained language models. However, some recent studies revealed that the context representations produced by these methods suffer the problem of anisotropy. In this paper, we find that the generated representations are also not conversational, losing the conversation structure information during the context modeling stage. To this end … Cites: ‪BARTScore: Evaluating Generated Text as Text Generation‬</summary></entry><entry><title type="html">Towards Explainability of Tree-Based Ensemble Models. A Critical Overview</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/76599e6d4293df0016265afa5cec1cf7.html" rel="alternate" type="text/html" title="Towards Explainability of Tree-Based Ensemble Models. A Critical Overview" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/76599e6d4293df0016265afa5cec1cf7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/76599e6d4293df0016265afa5cec1cf7.html">&lt;p&gt;Tree-based ensemble models are widely applied in artificial intelligence systems due to their robustness and generality. However, those models are not transparent. For the sake of making systems trustworthy and dependable, multiple explanation techniques are developed. Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬&lt;/p&gt;</content><author><name>D Sepiolo, A Ligęza - … Conference on Dependability and Complex Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Tree-based ensemble models are widely applied in artificial intelligence systems due to their robustness and generality. However, those models are not transparent. For the sake of making systems trustworthy and dependable, multiple explanation techniques are developed. Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬</summary></entry><entry><title type="html">Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/773cd3ba4d216cada8ad853fe6db292b.html" rel="alternate" type="text/html" title="Contrastive Learning Rivals Masked Image Modeling in Fine-tuning via Feature Distillation" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/773cd3ba4d216cada8ad853fe6db292b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/773cd3ba4d216cada8ad853fe6db292b.html">&lt;p&gt;Masked image modeling (MIM) learns representations with remarkably good fine-tuning performances, overshadowing previous prevalent pre-training approaches such as image classification, instance contrastive learning, and image-text alignment. In this paper, we show that the inferior fine-tuning performance of these pre-training approaches can be significantly improved by a simple post-processing in the form of feature distillation (FD). The feature distillation converts the old … Cites: ‪Robust fine-tuning of zero-shot models‬&lt;/p&gt;</content><author><name>Y Wei, H Hu, Z Xie, Z Zhang, Y Cao, J Bao, D Chen… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Masked image modeling (MIM) learns representations with remarkably good fine-tuning performances, overshadowing previous prevalent pre-training approaches such as image classification, instance contrastive learning, and image-text alignment. In this paper, we show that the inferior fine-tuning performance of these pre-training approaches can be significantly improved by a simple post-processing in the form of feature distillation (FD). The feature distillation converts the old … Cites: ‪Robust fine-tuning of zero-shot models‬</summary></entry><entry><title type="html">Journal: Proceedings of the 2018 World Wide Web Conference on World Wide Web-WWW 18, 2018</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/7792b4257a9b50c1bd9ec91a0f6b5a37.html" rel="alternate" type="text/html" title="Journal: Proceedings of the 2018 World Wide Web Conference on World Wide Web-WWW 18, 2018" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/7792b4257a9b50c1bd9ec91a0f6b5a37</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/7792b4257a9b50c1bd9ec91a0f6b5a37.html">&lt;p&gt;OUCI logo Search Analytics About укр Українською CrimeBB https://doi.org/10.1145/3178876.3186178   Journal: Proceedings of the 2018 World Wide Web Conference on World Wide Web   - WWW  18, 2018 Publisher: ACM Press Authors: Sergio Pastrana, Daniel R. Thomas,   Alice Hutchings, Richard Clayton Funder Engineering and Physical Sciences   Research Council (EPSRC) List of references 1.Judith Aldridge and David Décary-Hétu   . 2015. Not an &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;eBay for drugs : The cryptomarket &lt;/code&gt;Silk Road  as a paradigm shifting … Cites: ‪Tools for Automated Analysis of Cybercriminal Markets‬&lt;/p&gt;</content><author><name>S Pastrana, DR Thomas, A Hutchings, R Clayton</name></author><category term="jekyll" /><category term="update" /><summary type="html">OUCI logo Search Analytics About укр Українською CrimeBB https://doi.org/10.1145/3178876.3186178 Journal: Proceedings of the 2018 World Wide Web Conference on World Wide Web - WWW 18, 2018 Publisher: ACM Press Authors: Sergio Pastrana, Daniel R. Thomas, Alice Hutchings, Richard Clayton Funder Engineering and Physical Sciences Research Council (EPSRC) List of references 1.Judith Aldridge and David Décary-Hétu . 2015. Not an eBay for drugs : The cryptomarket Silk Road as a paradigm shifting … Cites: ‪Tools for Automated Analysis of Cybercriminal Markets‬</summary></entry><entry><title type="html">UPB at SemEval-2022 Task 5: Enhancing UNITER with Image Sentiment and Graph Convolutional Networks for Multimedia Automatic Misogyny Identification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/7af45be75b2e19ad82fb12baeb73e1e6.html" rel="alternate" type="text/html" title="UPB at SemEval-2022 Task 5: Enhancing UNITER with Image Sentiment and Graph Convolutional Networks for Multimedia Automatic Misogyny Identification" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/7af45be75b2e19ad82fb12baeb73e1e6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/7af45be75b2e19ad82fb12baeb73e1e6.html">&lt;p&gt;In recent times, the detection of hate-speech, offensive, or abusive language in online media has become an important topic in NLP research due to the exponential growth of social media and the propagation of such messages, as well as their impact. Misogyny detection, even though it plays an important part in hate-speech detection, has not received the same attention. In this paper, we describe our classification systems submitted to the SemEval-2022 Task 5: MAMI-Multimedia … Cites: ‪LXMERT: Learning Cross-Modality Encoder Representations from …‬&lt;/p&gt;</content><author><name>A Paraschiv, M Dascalu, DC Cercel - arXiv preprint arXiv:2205.14769, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In recent times, the detection of hate-speech, offensive, or abusive language in online media has become an important topic in NLP research due to the exponential growth of social media and the propagation of such messages, as well as their impact. Misogyny detection, even though it plays an important part in hate-speech detection, has not received the same attention. In this paper, we describe our classification systems submitted to the SemEval-2022 Task 5: MAMI-Multimedia … Cites: ‪LXMERT: Learning Cross-Modality Encoder Representations from …‬</summary></entry><entry><title type="html">Billions of Parameters Are Worth More Than In-domain Training Data: A case study in the Legal Case Entailment Task</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/7b7d97b5fb40809e2f40b8a67ab499c6.html" rel="alternate" type="text/html" title="Billions of Parameters Are Worth More Than In-domain Training Data: A case study in the Legal Case Entailment Task" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/7b7d97b5fb40809e2f40b8a67ab499c6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/7b7d97b5fb40809e2f40b8a67ab499c6.html">&lt;p&gt;Recent work has shown that language models scaled to billions of parameters, such as GPT-3, perform remarkably well in zero-shot and few-shot scenarios. In this work, we experiment with zero-shot models in the legal case entailment task of the COLIEE 2022 competition. Our experiments show that scaling the number of parameters in a language model improves the F1 score of our previous zero-shot result by more than 6 points, suggesting that stronger zero-shot capability may be a characteristic of … Cites: ‪Rapidly deploying a neural search engine for the covid-19 open …‬&lt;/p&gt;</content><author><name>GM Rosa, L Bonifacio, V Jeronymo, H Abonizio… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent work has shown that language models scaled to billions of parameters, such as GPT-3, perform remarkably well in zero-shot and few-shot scenarios. In this work, we experiment with zero-shot models in the legal case entailment task of the COLIEE 2022 competition. Our experiments show that scaling the number of parameters in a language model improves the F1 score of our previous zero-shot result by more than 6 points, suggesting that stronger zero-shot capability may be a characteristic of … Cites: ‪Rapidly deploying a neural search engine for the covid-19 open …‬</summary></entry><entry><title type="html">CyCLIP: Cyclic Contrastive Language-Image Pretraining</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/82ab4ba2f3d0d908f9c4c9ef7a869768.html" rel="alternate" type="text/html" title="CyCLIP: Cyclic Contrastive Language-Image Pretraining" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/82ab4ba2f3d0d908f9c4c9ef7a869768</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/82ab4ba2f3d0d908f9c4c9ef7a869768.html">&lt;p&gt;Recent advances in contrastive representation learning over paired image-text data have led to models such as CLIP that achieve state-of-the-art performance for zero-shot classification and distributional robustness. Such models typically require joint reasoning in the image and text representation spaces for downstream inference tasks. Contrary to prior beliefs, we demonstrate that the image and text representations learned via a standard contrastive objective are not interchangeable … Cites: ‪Combined Scaling for Zero-shot Transfer Learning‬&lt;/p&gt;</content><author><name>S Goel, H Bansal, S Bhatia, RA Rossi, V Vinay… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent advances in contrastive representation learning over paired image-text data have led to models such as CLIP that achieve state-of-the-art performance for zero-shot classification and distributional robustness. Such models typically require joint reasoning in the image and text representation spaces for downstream inference tasks. Contrary to prior beliefs, we demonstrate that the image and text representations learned via a standard contrastive objective are not interchangeable … Cites: ‪Combined Scaling for Zero-shot Transfer Learning‬</summary></entry><entry><title type="html">TRIESTE: translation based defense for text classifiers</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/84aef6a4fe6ab30be2eca95069fe1735.html" rel="alternate" type="text/html" title="TRIESTE: translation based defense for text classifiers" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/84aef6a4fe6ab30be2eca95069fe1735</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/84aef6a4fe6ab30be2eca95069fe1735.html">&lt;p&gt;The field of natural language processing (NLP) has significantly evolved with the advent of state-of-the-art models. The discovery of these models has entirely revolutionised how NLP tasks such as machine translation, sentiment analysis and many others are performed. However, despite their high efficacy and meticulous performance, these models are prone to adversarial attacks. Adversarial attacks involve the introduction of perturbations imperceptible to humans, which can … Cites: ‪Adversarial Example Generation with Syntactically Controlled …‬&lt;/p&gt;</content><author><name>AK Gupta, V Paliwal, A Rastogi, P Gupta - Journal of Ambient Intelligence and …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The field of natural language processing (NLP) has significantly evolved with the advent of state-of-the-art models. The discovery of these models has entirely revolutionised how NLP tasks such as machine translation, sentiment analysis and many others are performed. However, despite their high efficacy and meticulous performance, these models are prone to adversarial attacks. Adversarial attacks involve the introduction of perturbations imperceptible to humans, which can … Cites: ‪Adversarial Example Generation with Syntactically Controlled …‬</summary></entry><entry><title type="html">Understanding Long Programming Languages with Structure-Aware Sparse Attention</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/85c76a42502fb93fb746e3c0577c123b.html" rel="alternate" type="text/html" title="Understanding Long Programming Languages with Structure-Aware Sparse Attention" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/85c76a42502fb93fb746e3c0577c123b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/85c76a42502fb93fb746e3c0577c123b.html">&lt;p&gt;Programming-based Pre-trained Language Models (PPLMs) such as CodeBERT have achieved great success in many downstream code-related tasks. Since the memory and computational complexity of self-attention in the Transformer grow quadratically with the sequence length, PPLMs typically limit the code length to 512. However, codes in real-world applications are generally long, such as code searches, which cannot be processed efficiently by existing PPLMs. To solve this … Cites: ‪Dawn Drain‬&lt;/p&gt;</content><author><name>T Liu, C Wang, C Chen, M Gao, A Zhou - arXiv preprint arXiv:2205.13730, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Programming-based Pre-trained Language Models (PPLMs) such as CodeBERT have achieved great success in many downstream code-related tasks. Since the memory and computational complexity of self-attention in the Transformer grow quadratically with the sequence length, PPLMs typically limit the code length to 512. However, codes in real-world applications are generally long, such as code searches, which cannot be processed efficiently by existing PPLMs. To solve this … Cites: ‪Dawn Drain‬</summary></entry><entry><title type="html">How statistical modeling and machine learning could help in the calibration of numerical simulation and fluid mechanics models? Application to the calibration of …</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/884ea41901ebfa7851491e65fcd1663d.html" rel="alternate" type="text/html" title="How statistical modeling and machine learning could help in the calibration of numerical simulation and fluid mechanics models? Application to the calibration of …" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/884ea41901ebfa7851491e65fcd1663d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/884ea41901ebfa7851491e65fcd1663d.html">&lt;p&gt;The world of fluid mechanics is increasingly generating a large amount of data, thanks to the use of numerical simulation techniques. This offers interesting opportunities for incorporating machine learning methods to solve data-related problems such as model calibration. One of the applications that machine learning can offer to the world of Engineering and Fluid Mechanics in particular is the calibration of models making it possible to approximate a phenomenon. Indeed, the … Cites: ‪Approval voting and incentives in crowdsourcing‬&lt;/p&gt;</content><author><name>H Amroun, F Hafid, A Mehdi - Array, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The world of fluid mechanics is increasingly generating a large amount of data, thanks to the use of numerical simulation techniques. This offers interesting opportunities for incorporating machine learning methods to solve data-related problems such as model calibration. One of the applications that machine learning can offer to the world of Engineering and Fluid Mechanics in particular is the calibration of models making it possible to approximate a phenomenon. Indeed, the … Cites: ‪Approval voting and incentives in crowdsourcing‬</summary></entry><entry><title type="html">Differentially Private Decoding in Large Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/8c03850aad60a968c0cbc3a83ff39328.html" rel="alternate" type="text/html" title="Differentially Private Decoding in Large Language Models" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/8c03850aad60a968c0cbc3a83ff39328</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/8c03850aad60a968c0cbc3a83ff39328.html">&lt;p&gt;Recent large-scale natural language processing (NLP) systems use a pre-trained Large Language Model (LLM) on massive and diverse corpora as a headstart. In practice, the pre-trained model is adapted to a wide array of tasks via fine-tuning on task-specific datasets. LLMs, while effective, have been shown to memorize instances of training data thereby potentially revealing private information processed during pre-training. The potential leakage might further propagate to the downstream … Cites: ‪Large language models can be strong differentially private learners‬&lt;/p&gt;</content><author><name>J Majmudar, C Dupuy, C Peris, S Smaili, R Gupta… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent large-scale natural language processing (NLP) systems use a pre-trained Large Language Model (LLM) on massive and diverse corpora as a headstart. In practice, the pre-trained model is adapted to a wide array of tasks via fine-tuning on task-specific datasets. LLMs, while effective, have been shown to memorize instances of training data thereby potentially revealing private information processed during pre-training. The potential leakage might further propagate to the downstream … Cites: ‪Large language models can be strong differentially private learners‬</summary></entry><entry><title type="html">Do Deep Neural Networks Always Perform Better When Eating More Data?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/8c619676758fdc0e63b7d68d2e071885.html" rel="alternate" type="text/html" title="Do Deep Neural Networks Always Perform Better When Eating More Data?" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/8c619676758fdc0e63b7d68d2e071885</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/8c619676758fdc0e63b7d68d2e071885.html">&lt;p&gt;Data has now become a shortcoming of deep learning. Researchers in their own fields share the thinking that  deep neural networks might not always perform better when they eat more data,  which still lacks experimental validation and a convincing guiding theory. Here to fill this lack, we design experiments from Identically Independent Distribution (IID) and Out of Distribution (OOD), which give powerful answers. For the purpose of guidance, based on the discussion of results, two … Cites: ‪Deep learning-enabled medical computer vision‬&lt;/p&gt;</content><author><name>J Yang, Z Zhang, Y Gong, S Ma, X Guo, Y Yang, S Xiao… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Data has now become a shortcoming of deep learning. Researchers in their own fields share the thinking that deep neural networks might not always perform better when they eat more data, which still lacks experimental validation and a convincing guiding theory. Here to fill this lack, we design experiments from Identically Independent Distribution (IID) and Out of Distribution (OOD), which give powerful answers. For the purpose of guidance, based on the discussion of results, two … Cites: ‪Deep learning-enabled medical computer vision‬</summary></entry><entry><title type="html">Entity Resolution On-Demand</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/8fc8c7cfd00b4a51b649e21f6d4bf7e8.html" rel="alternate" type="text/html" title="Entity Resolution On-Demand" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/8fc8c7cfd00b4a51b649e21f6d4bf7e8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/8fc8c7cfd00b4a51b649e21f6d4bf7e8.html">&lt;p&gt;Entity Resolution (ER) aims to identify and merge records that refer to the same real-world entity. ER is typically employed as an expensive cleaning step on the entire data before consuming it. Yet, determining which entities are useful once cleaned depends solely on the user s application, which may need only a fraction of them. For instance, when dealing with Web data, we would like to be able to filter the entities of interest gathered from multiple sources without cleaning the entire, continuously … Cites: ‪Bootstrapping pay-as-you-go data integration systems‬&lt;/p&gt;</content><author><name>G Simonini, L Zecchini, S Bergamaschi, N Felix - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Entity Resolution (ER) aims to identify and merge records that refer to the same real-world entity. ER is typically employed as an expensive cleaning step on the entire data before consuming it. Yet, determining which entities are useful once cleaned depends solely on the user s application, which may need only a fraction of them. For instance, when dealing with Web data, we would like to be able to filter the entities of interest gathered from multiple sources without cleaning the entire, continuously … Cites: ‪Bootstrapping pay-as-you-go data integration systems‬</summary></entry><entry><title type="html">Can Foundation Models Help Us Achieve Perfect Secrecy?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/937859e0cec2f82e4853573dbdf6423c.html" rel="alternate" type="text/html" title="Can Foundation Models Help Us Achieve Perfect Secrecy?" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/937859e0cec2f82e4853573dbdf6423c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/937859e0cec2f82e4853573dbdf6423c.html">&lt;p&gt;A key promise of machine learning is the ability to assist users with personal tasks. Because the personal context required to make accurate predictions is often sensitive, we require systems that protect privacy. A gold standard privacy-preserving system will satisfy perfect secrecy, meaning that interactions with the system provably reveal no additional private information to adversaries. This guarantee should hold even as we perform multiple personal tasks over the same underlying data … Cites: ‪Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper …‬&lt;/p&gt;</content><author><name>S Arora, C Ré - arXiv preprint arXiv:2205.13722, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A key promise of machine learning is the ability to assist users with personal tasks. Because the personal context required to make accurate predictions is often sensitive, we require systems that protect privacy. A gold standard privacy-preserving system will satisfy perfect secrecy, meaning that interactions with the system provably reveal no additional private information to adversaries. This guarantee should hold even as we perform multiple personal tasks over the same underlying data … Cites: ‪Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper …‬</summary></entry><entry><title type="html">Why Robust Generalization in Deep Learning is Difficult: Perspective of Expressive Power</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/937c55bdf5c6a16aa16dc9bed0d9841c.html" rel="alternate" type="text/html" title="Why Robust Generalization in Deep Learning is Difficult: Perspective of Expressive Power" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/937c55bdf5c6a16aa16dc9bed0d9841c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/937c55bdf5c6a16aa16dc9bed0d9841c.html">&lt;p&gt;It is well-known that modern neural networks are vulnerable to adversarial examples. To mitigate this problem, a series of robust learning algorithms have been proposed. However, although the robust training error can be near zero via some methods, all existing algorithms lead to a high robust generalization error. In this paper, we provide a theoretical understanding of this puzzling phenomenon from the perspective of expressive power for deep neural networks. Specifically, for binary … Cites: ‪Adversarial training can hurt generalization‬&lt;/p&gt;</content><author><name>B Li, J Jin, H Zhong, JE Hopcroft, L Wang - arXiv preprint arXiv:2205.13863, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">It is well-known that modern neural networks are vulnerable to adversarial examples. To mitigate this problem, a series of robust learning algorithms have been proposed. However, although the robust training error can be near zero via some methods, all existing algorithms lead to a high robust generalization error. In this paper, we provide a theoretical understanding of this puzzling phenomenon from the perspective of expressive power for deep neural networks. Specifically, for binary … Cites: ‪Adversarial training can hurt generalization‬</summary></entry><entry><title type="html">Data integration and ethical quality: fundamental steps of the data analysis pipeline</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/93eac1e5993b5083edb10dfaf4b71f8e.html" rel="alternate" type="text/html" title="Data integration and ethical quality: fundamental steps of the data analysis pipeline" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/93eac1e5993b5083edb10dfaf4b71f8e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/93eac1e5993b5083edb10dfaf4b71f8e.html">&lt;p&gt;Abstract in italiano L uso di tecniche di data science ha un ruolo molto importante nella società attuale, e in molti ambiti (es. medicina di precisione, rilevamento delle frodi o veicoli autonomi) consente di ottenere benefici che hanno un impatto significativo sulla nostra vita quotidiana e che altrimenti sarebbero impossibili da conseguire. Sfortunatamente, spesso i dati utilizzati nei progetti di data science sono molto eterogenei e questo ci impedisce di utilizzarli facilmente nelle attività di analisi … Cites: ‪Principles of data integration‬&lt;/p&gt;</content><author><name>F Azzalini - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract in italiano L uso di tecniche di data science ha un ruolo molto importante nella società attuale, e in molti ambiti (es. medicina di precisione, rilevamento delle frodi o veicoli autonomi) consente di ottenere benefici che hanno un impatto significativo sulla nostra vita quotidiana e che altrimenti sarebbero impossibili da conseguire. Sfortunatamente, spesso i dati utilizzati nei progetti di data science sono molto eterogenei e questo ci impedisce di utilizzarli facilmente nelle attività di analisi … Cites: ‪Principles of data integration‬</summary></entry><entry><title type="html">Automatic Short Math Answer Grading via In-context Meta-learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/940e2916b4205f885d7f189e57fc349a.html" rel="alternate" type="text/html" title="Automatic Short Math Answer Grading via In-context Meta-learning" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/940e2916b4205f885d7f189e57fc349a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/940e2916b4205f885d7f189e57fc349a.html">&lt;p&gt;Automatic short answer grading is an important research direction in the exploration of how to use artificial intelligence (AI)-based tools to improve education. Current state-of-the-art approaches use neural language models to create vectorized representations of students responses, followed by classifiers to predict the score. However, these approaches have several key limitations, including i) they use pre-trained language models that are not well-adapted to educational subject domains … Cites: ‪Metaicl: Learning to learn in context‬&lt;/p&gt;</content><author><name>M Zhang, S Baral, N Heffernan, A Lan - arXiv preprint arXiv:2205.15219, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Automatic short answer grading is an important research direction in the exploration of how to use artificial intelligence (AI)-based tools to improve education. Current state-of-the-art approaches use neural language models to create vectorized representations of students responses, followed by classifiers to predict the score. However, these approaches have several key limitations, including i) they use pre-trained language models that are not well-adapted to educational subject domains … Cites: ‪Metaicl: Learning to learn in context‬</summary></entry><entry><title type="html">E2S2: Encoding-Enhanced Sequence-to-Sequence Pretraining for Language Understanding and Generation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/95689ff84eb4bf925266f7992f393720.html" rel="alternate" type="text/html" title="E2S2: Encoding-Enhanced Sequence-to-Sequence Pretraining for Language Understanding and Generation" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/95689ff84eb4bf925266f7992f393720</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/95689ff84eb4bf925266f7992f393720.html">&lt;p&gt;Sequence-to-sequence (seq2seq) learning has become a popular trend for pretraining language models, due to its succinct and universal framework. However, the prior seq2seq pretraining models generally focus on reconstructive objectives on the decoder side and neglect the effect of encoder-side supervisions, which may lead to sub-optimal performance. To this end, we propose an encoding-enhanced seq2seq pretraining strategy, namely E2S2, which improves the seq2seq models via … Cites: ‪Don t give me the details, just the summary! topic-aware …‬&lt;/p&gt;</content><author><name>Q Zhong, L Ding, J Liu, B Du, D Tao - arXiv preprint arXiv:2205.14912, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Sequence-to-sequence (seq2seq) learning has become a popular trend for pretraining language models, due to its succinct and universal framework. However, the prior seq2seq pretraining models generally focus on reconstructive objectives on the decoder side and neglect the effect of encoder-side supervisions, which may lead to sub-optimal performance. To this end, we propose an encoding-enhanced seq2seq pretraining strategy, namely E2S2, which improves the seq2seq models via … Cites: ‪Don t give me the details, just the summary! topic-aware …‬</summary></entry><entry><title type="html">FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/97cb8c30d22f143f2b5cdee05cae8b45.html" rel="alternate" type="text/html" title="FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/97cb8c30d22f143f2b5cdee05cae8b45</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/97cb8c30d22f143f2b5cdee05cae8b45.html">&lt;p&gt;Transformers are slow and memory-hungry on long sequences, since the time and memory complexity of self-attention are quadratic in sequence length. Approximate attention methods have attempted to address this problem by trading off model quality to reduce the compute complexity, but often do not achieve wall-clock speedup. We argue that a missing principle is making attention algorithms IO-aware–accounting for reads and writes between levels of GPU memory. We propose … Cites: ‪Transformer quality in linear time‬&lt;/p&gt;</content><author><name>T Dao, DY Fu, S Ermon, A Rudra, C Ré - arXiv preprint arXiv:2205.14135, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Transformers are slow and memory-hungry on long sequences, since the time and memory complexity of self-attention are quadratic in sequence length. Approximate attention methods have attempted to address this problem by trading off model quality to reduce the compute complexity, but often do not achieve wall-clock speedup. We argue that a missing principle is making attention algorithms IO-aware–accounting for reads and writes between levels of GPU memory. We propose … Cites: ‪Transformer quality in linear time‬</summary></entry><entry><title type="html">Exposing Fine-grained Adversarial Vulnerability of Face Anti-spoofing Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/9a6c2cee6ed721bb8fb93523363e5895.html" rel="alternate" type="text/html" title="Exposing Fine-grained Adversarial Vulnerability of Face Anti-spoofing Models" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/9a6c2cee6ed721bb8fb93523363e5895</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/9a6c2cee6ed721bb8fb93523363e5895.html">&lt;p&gt;Adversarial attacks seriously threaten the high accuracy of face anti-spoofing models. Little adversarial noise can perturb their classification of live and spoofing. The existing adversarial attacks fail to figure out which part of the target face anti-spoofing model is vulnerable, making adversarial analysis tricky. So we propose fine-grained attacks for exposing adversarial vulnerability of face anti-spoofing models. Firstly, we propose Semantic Feature Augmentation (SFA) module, which makes … Cites: ‪Avoiding Reasoning Shortcuts: Adversarial Evaluation, Training …‬&lt;/p&gt;</content><author><name>S Yang, W Wang, C Xu, B Peng, J Dong - arXiv preprint arXiv:2205.14851, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Adversarial attacks seriously threaten the high accuracy of face anti-spoofing models. Little adversarial noise can perturb their classification of live and spoofing. The existing adversarial attacks fail to figure out which part of the target face anti-spoofing model is vulnerable, making adversarial analysis tricky. So we propose fine-grained attacks for exposing adversarial vulnerability of face anti-spoofing models. Firstly, we propose Semantic Feature Augmentation (SFA) module, which makes … Cites: ‪Avoiding Reasoning Shortcuts: Adversarial Evaluation, Training …‬</summary></entry><entry><title type="html">Fast and Light-Weight Answer Text Retrieval in Dialogue Systems</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/9c65e8d7130f86d5b527bcb99cb60fb4.html" rel="alternate" type="text/html" title="Fast and Light-Weight Answer Text Retrieval in Dialogue Systems" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/9c65e8d7130f86d5b527bcb99cb60fb4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/9c65e8d7130f86d5b527bcb99cb60fb4.html">&lt;p&gt;Dialogue systems can benefit from being able to search through a corpus of text to find information relevant to user requests, especially when encountering a request for which no manually curated response is available. The state-of-the-art technology for neural dense retrieval or re-ranking involves deep learning models with hundreds of millions of parameters. However, it is difficult and expensive to get such models to operate at an industrial scale, especially for cloud services that often need to support … Cites: ‪KILT: a benchmark for knowledge intensive language tasks‬&lt;/p&gt;</content><author><name>H Wan, SS Patel, JW Murdock, S Potdar, S Joshi - arXiv preprint arXiv:2205.14226, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Dialogue systems can benefit from being able to search through a corpus of text to find information relevant to user requests, especially when encountering a request for which no manually curated response is available. The state-of-the-art technology for neural dense retrieval or re-ranking involves deep learning models with hundreds of millions of parameters. However, it is difficult and expensive to get such models to operate at an industrial scale, especially for cloud services that often need to support … Cites: ‪KILT: a benchmark for knowledge intensive language tasks‬</summary></entry><entry><title type="html">Computer Science Department</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/9eed0b1bb3fc5816be9e9c24a812c205.html" rel="alternate" type="text/html" title="Computer Science Department" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/9eed0b1bb3fc5816be9e9c24a812c205</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/9eed0b1bb3fc5816be9e9c24a812c205.html">&lt;p&gt;This work proposes a novel data augmentation technique based on symbolic methods SDAR that generates annotations in the text space. The SDAR annotator is an ensemble of multiple sub-annotators, each equipped with a searcher and a symbolic knowledge retriever. We demonstrate that SDAR can boost the performance of smaller models to a comparable degree of or even surpass larger models with a magnitude more parameters and establish the STOA single model … Cites: ‪Language models as knowledge bases?‬&lt;/p&gt;</content><author><name>M Li - Digipen Institute of Technology, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This work proposes a novel data augmentation technique based on symbolic methods SDAR that generates annotations in the text space. The SDAR annotator is an ensemble of multiple sub-annotators, each equipped with a searcher and a symbolic knowledge retriever. We demonstrate that SDAR can boost the performance of smaller models to a comparable degree of or even surpass larger models with a magnitude more parameters and establish the STOA single model … Cites: ‪Language models as knowledge bases?‬</summary></entry><entry><title type="html">Self-Attention based encoder-Decoder for multistep human density prediction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/9f5630a8700887d57428ffcdb7102d09.html" rel="alternate" type="text/html" title="Self-Attention based encoder-Decoder for multistep human density prediction" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/9f5630a8700887d57428ffcdb7102d09</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/9f5630a8700887d57428ffcdb7102d09.html">&lt;p&gt;Abstract Multistep Human Density Prediction (MHDP) is an emerging challenge in urban mobility with lots of applications in several domains such as Smart Cities, Edge Computing and Epidemiology Modeling. The basic goal is to estimate the density of people gathered in a set of urban Regions of Interests (ROIs) or Points of Interests (POIs) in a forecast horizon of different granularities. Accordingly, this paper aims to contribute and go beyond the existing literature on human density prediction … Cites: ‪WiFiMod: Transformer-based Indoor Human Mobility Modeling …‬&lt;/p&gt;</content><author><name>J Violos, T Theodoropoulos, AC Maroudis, A Leivadeas… - Journal of Urban Mobility, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Multistep Human Density Prediction (MHDP) is an emerging challenge in urban mobility with lots of applications in several domains such as Smart Cities, Edge Computing and Epidemiology Modeling. The basic goal is to estimate the density of people gathered in a set of urban Regions of Interests (ROIs) or Points of Interests (POIs) in a forecast horizon of different granularities. Accordingly, this paper aims to contribute and go beyond the existing literature on human density prediction … Cites: ‪WiFiMod: Transformer-based Indoor Human Mobility Modeling …‬</summary></entry><entry><title type="html">Deep Embedded Clustering with Distribution Consistency Preservation for Attributed Networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a05c3e8b48c497f73a509ed94ad1492d.html" rel="alternate" type="text/html" title="Deep Embedded Clustering with Distribution Consistency Preservation for Attributed Networks" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a05c3e8b48c497f73a509ed94ad1492d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a05c3e8b48c497f73a509ed94ad1492d.html">&lt;p&gt;Many complex systems in the real world can be characterized by attributed networks. To mine the potential information in these networks, deep embedded clustering, which obtains node representations and clusters simultaneously, has been paid much attention in recent years. Under the assumption of consistency for data in different views, the cluster structure of network topology and that of node attributes should be consistent for an attributed network. However, many existing methods … Cites: ‪Adaptive Graph Encoder for Attributed Graph Embedding‬&lt;/p&gt;</content><author><name>Y Zheng, C Jia, J Yu, X Li - arXiv preprint arXiv:2205.14303, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Many complex systems in the real world can be characterized by attributed networks. To mine the potential information in these networks, deep embedded clustering, which obtains node representations and clusters simultaneously, has been paid much attention in recent years. Under the assumption of consistency for data in different views, the cluster structure of network topology and that of node attributes should be consistent for an attributed network. However, many existing methods … Cites: ‪Adaptive Graph Encoder for Attributed Graph Embedding‬</summary></entry><entry><title type="html">可视化与人工智能交叉研究综述</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a15525083510e112db584559759f0d3f.html" rel="alternate" type="text/html" title="可视化与人工智能交叉研究综述" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a15525083510e112db584559759f0d3f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a15525083510e112db584559759f0d3f.html">&lt;p&gt;摘要随着人工智能技术的突破性进展, 人工智能与可视化的交叉研究成为当前的研究热点之一, 为人工智能和大数据分析领域的若干核心难题提供了启发式的理论, 方法和技术. 一方面, 人工智能技术的创新应用提升了可视化的分析效率, 拓展了分析功能, 为大数据可视分析提供了强有力的工具. 另一方面, 可视化技术增强了以深度学习为代表的人工智能的可解释性和交互性, 为可解释人工智能提供了可靠的技术基础. 本文从面向人工智能的可视化技术和人工 … Cites: ‪Interactive Context-Aware Anomaly Detection Guided by User …‬&lt;/p&gt;</content><author><name>夏佳志， 李杰， 陈思明， 秦红星， 刘世霞 - 中国科学: 信息科学, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">摘要随着人工智能技术的突破性进展, 人工智能与可视化的交叉研究成为当前的研究热点之一, 为人工智能和大数据分析领域的若干核心难题提供了启发式的理论, 方法和技术. 一方面, 人工智能技术的创新应用提升了可视化的分析效率, 拓展了分析功能, 为大数据可视分析提供了强有力的工具. 另一方面, 可视化技术增强了以深度学习为代表的人工智能的可解释性和交互性, 为可解释人工智能提供了可靠的技术基础. 本文从面向人工智能的可视化技术和人工 … Cites: ‪Interactive Context-Aware Anomaly Detection Guided by User …‬</summary></entry><entry><title type="html">Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a337c2052454f4b979eadb0384ba033c.html" rel="alternate" type="text/html" title="Challenges in Applying Explainability Methods to Improve the Fairness of NLP Models" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a337c2052454f4b979eadb0384ba033c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a337c2052454f4b979eadb0384ba033c.html">&lt;p&gt;Motivations for methods in explainable artificial intelligence (XAI) often include detecting, quantifying and mitigating bias, and contributing to making machine learning models fairer. However, exactly how an XAI method can help in combating biases is often left unspecified. In this paper, we briefly review trends in explainability and fairness in NLP research, identify the current practices in which explainability methods are applied to detect and mitigate bias, and investigate the barriers … Cites: ‪Polyjuice: Generating Counterfactuals for Explaining, Evaluating …‬&lt;/p&gt;</content><author><name>E Balkır, S Kiritchenko, I Nejadgholi, KC Fraser</name></author><category term="jekyll" /><category term="update" /><summary type="html">Motivations for methods in explainable artificial intelligence (XAI) often include detecting, quantifying and mitigating bias, and contributing to making machine learning models fairer. However, exactly how an XAI method can help in combating biases is often left unspecified. In this paper, we briefly review trends in explainability and fairness in NLP research, identify the current practices in which explainability methods are applied to detect and mitigate bias, and investigate the barriers … Cites: ‪Polyjuice: Generating Counterfactuals for Explaining, Evaluating …‬</summary></entry><entry><title type="html">A Sea of Words: An In-Depth Analysis of Anchors for Text Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a36c3e1d6d8b502e7e55885e9c28aa59.html" rel="alternate" type="text/html" title="A Sea of Words: An In-Depth Analysis of Anchors for Text Data" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a36c3e1d6d8b502e7e55885e9c28aa59</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a36c3e1d6d8b502e7e55885e9c28aa59.html">&lt;p&gt;Anchors [Ribeiro et al.(2018)] is a post-hoc, rule-based interpretability method. For text data, it proposes to explain a decision by highlighting a small set of words (an anchor) such that the model to explain has similar outputs when they are present in a document. In this paper, we present the first theoretical analysis of Anchors, considering that the search for the best anchor is exhaustive. We leverage this analysis to gain insights on the behavior of Anchors on simple models, including … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬&lt;/p&gt;</content><author><name>G Lopardo, D Garreau, F Precioso - arXiv preprint arXiv:2205.13789, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Anchors [Ribeiro et al.(2018)] is a post-hoc, rule-based interpretability method. For text data, it proposes to explain a decision by highlighting a small set of words (an anchor) such that the model to explain has similar outputs when they are present in a document. In this paper, we present the first theoretical analysis of Anchors, considering that the search for the best anchor is exhaustive. We leverage this analysis to gain insights on the behavior of Anchors on simple models, including … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬</summary></entry><entry><title type="html">Augment Small Training Sets Using Matching-Graphs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a4ae4cd1af74ad40946f6fb78b588579.html" rel="alternate" type="text/html" title="Augment Small Training Sets Using Matching-Graphs" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a4ae4cd1af74ad40946f6fb78b588579</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a4ae4cd1af74ad40946f6fb78b588579.html">&lt;p&gt;Both data access and data acquisition have become increasingly easy over the past decade, leading to rapid developments in many areas of intelligent information processing. In many cases, the underlying data is complex, making vectorial structures rather inappropriate for data representation. In these cases graphs provide a versatile alternative to purely numerical approaches. Regardless the representation formalism actually used, it is inevitable for supervised pattern … Cites: ‪The unreasonable effectiveness of data‬&lt;/p&gt;</content><author><name>M Fuchs, K Riesen - Pattern Recognition and Artificial Intelligence: Third …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Both data access and data acquisition have become increasingly easy over the past decade, leading to rapid developments in many areas of intelligent information processing. In many cases, the underlying data is complex, making vectorial structures rather inappropriate for data representation. In these cases graphs provide a versatile alternative to purely numerical approaches. Regardless the representation formalism actually used, it is inevitable for supervised pattern … Cites: ‪The unreasonable effectiveness of data‬</summary></entry><entry><title type="html">NeuPSL: Neural Probabilistic Soft Logic</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a5e8fae0f16b3e18e3e8a183841a6f47.html" rel="alternate" type="text/html" title="NeuPSL: Neural Probabilistic Soft Logic" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a5e8fae0f16b3e18e3e8a183841a6f47</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a5e8fae0f16b3e18e3e8a183841a6f47.html">&lt;p&gt;We present Neural Probabilistic Soft Logic (NeuPSL), a novel neuro-symbolic (NeSy) framework that unites state-of-the-art symbolic reasoning with the low-level perception of deep neural networks. To explicitly model the boundary between neural and symbolic representations, we introduce NeSy Energy-Based Models, a general family of energy-based models that combine neural and symbolic reasoning. Using this framework, we show how to seamlessly integrate neural and symbolic … Cites: ‪Programming with a differentiable forth interpreter‬&lt;/p&gt;</content><author><name>C Pryor, C Dickens, E Augustine, A Albalak, W Wang… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present Neural Probabilistic Soft Logic (NeuPSL), a novel neuro-symbolic (NeSy) framework that unites state-of-the-art symbolic reasoning with the low-level perception of deep neural networks. To explicitly model the boundary between neural and symbolic representations, we introduce NeSy Energy-Based Models, a general family of energy-based models that combine neural and symbolic reasoning. Using this framework, we show how to seamlessly integrate neural and symbolic … Cites: ‪Programming with a differentiable forth interpreter‬</summary></entry><entry><title type="html">Reliable Visual Question Answering: Abstain Rather Than Answer Incorrectly</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a80a41f1f0f2185ca63382dbd86e1962.html" rel="alternate" type="text/html" title="Reliable Visual Question Answering: Abstain Rather Than Answer Incorrectly" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a80a41f1f0f2185ca63382dbd86e1962</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/a80a41f1f0f2185ca63382dbd86e1962.html">&lt;p&gt;Abstract Machine learning has advanced dramatically, narrowing the accuracy gap to humans in multimodal tasks like visual question answering (VQA). However, while humans can say “I don t know” when they are uncertain (ie, abstain from answering a question), such ability has been largely neglected in multimodal research, despite the importance of this problem to the usage of VQA in real settings. In this work, we promote a problem formulation for reliable VQA, where we prefer abstention over … Cites: ‪Confidence modeling for neural semantic parsing‬&lt;/p&gt;</content><author><name>V Shakib, S Whitehead, S Petryk, J Gonzalez, T Darrell… - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Machine learning has advanced dramatically, narrowing the accuracy gap to humans in multimodal tasks like visual question answering (VQA). However, while humans can say “I don t know” when they are uncertain (ie, abstain from answering a question), such ability has been largely neglected in multimodal research, despite the importance of this problem to the usage of VQA in real settings. In this work, we promote a problem formulation for reliable VQA, where we prefer abstention over … Cites: ‪Confidence modeling for neural semantic parsing‬</summary></entry><entry><title type="html">Boundary assembling method for joint entity and relation extraction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ab58fbb153af855a43836aae46aa359b.html" rel="alternate" type="text/html" title="Boundary assembling method for joint entity and relation extraction" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ab58fbb153af855a43836aae46aa359b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ab58fbb153af855a43836aae46aa359b.html">&lt;p&gt;In recent years, a paradigm shift has occurred in the field of joint entity and relation extraction from token tagging to span classification, because the latter can handle nested named entities in a sentence and better utilize the global features of a possible named entity. Because relation extraction should verify every entity pair in a sentence, the performance of joint entity and relation extraction significantly depends on the quality of the entity span proposals. Most models enumerate numerous … Cites: ‪Generalizing Natural Language Analysis through Span-relation …‬&lt;/p&gt;</content><author><name>R Tang, Y Chen, Y Qin, R Huang, B Dong, Q Zheng - Knowledge-Based Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In recent years, a paradigm shift has occurred in the field of joint entity and relation extraction from token tagging to span classification, because the latter can handle nested named entities in a sentence and better utilize the global features of a possible named entity. Because relation extraction should verify every entity pair in a sentence, the performance of joint entity and relation extraction significantly depends on the quality of the entity span proposals. Most models enumerate numerous … Cites: ‪Generalizing Natural Language Analysis through Span-relation …‬</summary></entry><entry><title type="html">Data Imputation for Multivariate Time Series Sensor Data with Large Gaps of Missing Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/accf34b3a543acee5f43a74f6b92ad05.html" rel="alternate" type="text/html" title="Data Imputation for Multivariate Time Series Sensor Data with Large Gaps of Missing Data" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/accf34b3a543acee5f43a74f6b92ad05</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/accf34b3a543acee5f43a74f6b92ad05.html">&lt;p&gt;Imputation of missing sensor-collected data is often an important step prior to machine learning and statistical data analysis. One particular data imputation challenge is filling large data gaps when the only related data comes from the same sensor station. In this paper, we propose a framework to improve the popular multivariate imputation by chained equations (MICE) method for dealing with missing data. One key strategy we use to improve model accuracy is to reshape the original … Cites: ‪Recurrent neural networks for multivariate time series with missing …‬&lt;/p&gt;</content><author><name>R Wu, SD Hamshaw, L Yang, DW Kincaid, R Etheridge… - IEEE Sensors Journal, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Imputation of missing sensor-collected data is often an important step prior to machine learning and statistical data analysis. One particular data imputation challenge is filling large data gaps when the only related data comes from the same sensor station. In this paper, we propose a framework to improve the popular multivariate imputation by chained equations (MICE) method for dealing with missing data. One key strategy we use to improve model accuracy is to reshape the original … Cites: ‪Recurrent neural networks for multivariate time series with missing …‬</summary></entry><entry><title type="html">Learning as Conversation: Dialogue Systems Reinforced for Information Acquisition</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ad39a833f4ea0945f0b5831025e0b1a8.html" rel="alternate" type="text/html" title="Learning as Conversation: Dialogue Systems Reinforced for Information Acquisition" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ad39a833f4ea0945f0b5831025e0b1a8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ad39a833f4ea0945f0b5831025e0b1a8.html">&lt;p&gt;We propose novel AI-empowered chat bots for learning as conversation where a user does not read a passage but gains information and knowledge through conversation with a teacher bot. Our information-acquisition-oriented dialogue system employs a novel adaptation of reinforced self-play so that the system can be transferred to various domains without in-domain dialogue data, and can carry out conversations both informative and attentive to users. Our extensive subjective and … Cites: ‪Detecting Hallucinated Content in Conditional Neural Sequence …‬&lt;/p&gt;</content><author><name>P Cai, H Wan, F Liu, M Yu, H Yu, S Joshi - arXiv preprint arXiv:2205.14748, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose novel AI-empowered chat bots for learning as conversation where a user does not read a passage but gains information and knowledge through conversation with a teacher bot. Our information-acquisition-oriented dialogue system employs a novel adaptation of reinforced self-play so that the system can be transferred to various domains without in-domain dialogue data, and can carry out conversations both informative and attentive to users. Our extensive subjective and … Cites: ‪Detecting Hallucinated Content in Conditional Neural Sequence …‬</summary></entry><entry><title type="html">Reinforcement Learning for Branch-and-Bound Optimisation using Retrospective Trajectories</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/b0a5361598c9bcf899190cdc65a0310e.html" rel="alternate" type="text/html" title="Reinforcement Learning for Branch-and-Bound Optimisation using Retrospective Trajectories" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/b0a5361598c9bcf899190cdc65a0310e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/b0a5361598c9bcf899190cdc65a0310e.html">&lt;p&gt;Combinatorial optimisation problems framed as mixed integer linear programmes (MILPs) are ubiquitous across a range of real-world applications. The canonical branch-and-bound (B&amp;amp;B) algorithm seeks to exactly solve MILPs by constructing a search tree of increasingly constrained sub-problems. In practice, its solving time performance is dependent on heuristics, such as the choice of the next variable to constrain ( branching ). Recently, machine learning (ML) has emerged as a … Cites: ‪Keeping your distance: Solving sparse reward tasks using self …‬&lt;/p&gt;</content><author><name>CWF Parsonson, A Laterre, TD Barrett - arXiv preprint arXiv:2205.14345, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Combinatorial optimisation problems framed as mixed integer linear programmes (MILPs) are ubiquitous across a range of real-world applications. The canonical branch-and-bound (B&amp;amp;B) algorithm seeks to exactly solve MILPs by constructing a search tree of increasingly constrained sub-problems. In practice, its solving time performance is dependent on heuristics, such as the choice of the next variable to constrain ( branching ). Recently, machine learning (ML) has emerged as a … Cites: ‪Keeping your distance: Solving sparse reward tasks using self …‬</summary></entry><entry><title type="html">AANG: Automating Auxiliary Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/b1c6dbb36533918af1eadefc24f34d84.html" rel="alternate" type="text/html" title="AANG: Automating Auxiliary Learning" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/b1c6dbb36533918af1eadefc24f34d84</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/b1c6dbb36533918af1eadefc24f34d84.html">&lt;p&gt;When faced with data-starved or highly complex end-tasks, it is commonplace for machine learning practitioners to introduce auxiliary objectives as supplementary learning signals. Whilst much work has been done to formulate useful auxiliary objectives, their construction is still an art which proceeds by slow and tedious hand-design. Intuitions about how and when these objectives improve end-task performance have also had limited theoretical backing. In this work, we present an … Cites: ‪Deep contextualized word representations‬&lt;/p&gt;</content><author><name>LM Dery, P Michel, M Khodak, G Neubig, A Talwalkar - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">When faced with data-starved or highly complex end-tasks, it is commonplace for machine learning practitioners to introduce auxiliary objectives as supplementary learning signals. Whilst much work has been done to formulate useful auxiliary objectives, their construction is still an art which proceeds by slow and tedious hand-design. Intuitions about how and when these objectives improve end-task performance have also had limited theoretical backing. In this work, we present an … Cites: ‪Deep contextualized word representations‬</summary></entry><entry><title type="html">Multi-Task Learning with Multi-query Transformer for Dense Prediction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/b72500c2cc6263a30a7bcff410922c7a.html" rel="alternate" type="text/html" title="Multi-Task Learning with Multi-query Transformer for Dense Prediction" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/b72500c2cc6263a30a7bcff410922c7a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/b72500c2cc6263a30a7bcff410922c7a.html">&lt;p&gt;Previous multi-task dense prediction studies developed complex pipelines such as multi-modal distillations in multiple stages or searching for task relational contexts for each task. The core insight beyond these methods is to maximize the mutual effects between each task. Inspired by the recent query-based Transformers, we propose a simpler pipeline named Multi-Query Transformer (MQTransformer) that is equipped with multiple queries from different tasks to facilitate the reasoning among multiple … Cites: ‪Multi-task self-training for learning general representations‬&lt;/p&gt;</content><author><name>Y Xu, X Li, H Yuan, Y Yang, J Zhang, Y Tong, L Zhang… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Previous multi-task dense prediction studies developed complex pipelines such as multi-modal distillations in multiple stages or searching for task relational contexts for each task. The core insight beyond these methods is to maximize the mutual effects between each task. Inspired by the recent query-based Transformers, we propose a simpler pipeline named Multi-Query Transformer (MQTransformer) that is equipped with multiple queries from different tasks to facilitate the reasoning among multiple … Cites: ‪Multi-task self-training for learning general representations‬</summary></entry><entry><title type="html">Spartan: Differentiable Sparsity via Regularized Transportation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/b9e240a897452c5b5be8f8a3a2d401a9.html" rel="alternate" type="text/html" title="Spartan: Differentiable Sparsity via Regularized Transportation" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/b9e240a897452c5b5be8f8a3a2d401a9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/b9e240a897452c5b5be8f8a3a2d401a9.html">&lt;p&gt;We present Spartan, a method for training sparse neural network models with a predetermined level of sparsity. Spartan is based on a combination of two techniques:(1) soft top-k masking of low-magnitude parameters via a regularized optimal transportation problem and (2) dual averaging-based parameter updates with hard sparsification in the forward pass. This scheme realizes an exploration-exploitation tradeoff: early in training, the learner is able to explore various sparsity … Cites: ‪Structured Pruning Learns Compact and Accurate Models‬&lt;/p&gt;</content><author><name>KS Tai, T Tian, SN Lim - arXiv preprint arXiv:2205.14107, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present Spartan, a method for training sparse neural network models with a predetermined level of sparsity. Spartan is based on a combination of two techniques:(1) soft top-k masking of low-magnitude parameters via a regularized optimal transportation problem and (2) dual averaging-based parameter updates with hard sparsification in the forward pass. This scheme realizes an exploration-exploitation tradeoff: early in training, the learner is able to explore various sparsity … Cites: ‪Structured Pruning Learns Compact and Accurate Models‬</summary></entry><entry><title type="html">Why are NLP Models Fumbling at Elementary Math? A Survey of Deep Learning based Word Problem Solvers</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ba5d7e219a11cb6239771efe0eefcb01.html" rel="alternate" type="text/html" title="Why are NLP Models Fumbling at Elementary Math? A Survey of Deep Learning based Word Problem Solvers" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ba5d7e219a11cb6239771efe0eefcb01</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ba5d7e219a11cb6239771efe0eefcb01.html">&lt;p&gt;From the latter half of the last decade, there has been a growing interest in developing algorithms for automatically solving mathematical word problems (MWP). It is a challenging and unique task that demands blending surface level text pattern recognition with mathematical reasoning. In spite of extensive research, we are still miles away from building robust representations of elementary math word problems and effective solutions for the general task. In this paper, we critically examine the … Cites: ‪Deep contextualized word representations‬&lt;/p&gt;</content><author><name>SS Sundaram, S Gurajada, M Fisichella, SS Abraham - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">From the latter half of the last decade, there has been a growing interest in developing algorithms for automatically solving mathematical word problems (MWP). It is a challenging and unique task that demands blending surface level text pattern recognition with mathematical reasoning. In spite of extensive research, we are still miles away from building robust representations of elementary math word problems and effective solutions for the general task. In this paper, we critically examine the … Cites: ‪Deep contextualized word representations‬</summary></entry><entry><title type="html">Learnersourcing in Theory and Practice: Synthesizing the Literature and Charting the Future</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ba9e546ce6c809c9cf4aa38447db02fc.html" rel="alternate" type="text/html" title="Learnersourcing in Theory and Practice: Synthesizing the Literature and Charting the Future" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ba9e546ce6c809c9cf4aa38447db02fc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ba9e546ce6c809c9cf4aa38447db02fc.html">&lt;p&gt;Given the growing interest in learnersourcing–a pedagogically supported form of crowdsourcing that harnesses the knowledge and creativity of learners for the creation of learning resources–we propose a theoretical framework to study, design, and deploy learnersourcing systems. By integrating ideas from crowdsourcing and learning theories focusing on learner-centered pedagogy, this work provides a review and classification of learnersourcing systems from the perspective of its three … Cites: ‪Crowdsourcing systems on the world-wide web‬&lt;/p&gt;</content><author><name>A Singh, C Brooks, S Doroudi - Proceedings of the Ninth ACM Conference on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Given the growing interest in learnersourcing–a pedagogically supported form of crowdsourcing that harnesses the knowledge and creativity of learners for the creation of learning resources–we propose a theoretical framework to study, design, and deploy learnersourcing systems. By integrating ideas from crowdsourcing and learning theories focusing on learner-centered pedagogy, this work provides a review and classification of learnersourcing systems from the perspective of its three … Cites: ‪Crowdsourcing systems on the world-wide web‬</summary></entry><entry><title type="html">Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/bff9d1adb972cfb2edf0b170551db4c2.html" rel="alternate" type="text/html" title="Decoupling Knowledge from Memorization: Retrieval-augmented Prompt Learning" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/bff9d1adb972cfb2edf0b170551db4c2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/bff9d1adb972cfb2edf0b170551db4c2.html">&lt;p&gt;Prompt learning approaches have made waves in natural language processing by inducing better few-shot performance while they still follow a parametric-based learning paradigm; the oblivion and rote memorization problems in learning may encounter unstable generalization issues. Specifically, vanilla prompt learning may struggle to utilize atypical instances by rote during fully-supervised training or overfit shallow patterns with low-shot data. To alleviate such limitations, we develop … Cites: ‪Knowledgeable Prompt-tuning: Incorporating Knowledge into …‬&lt;/p&gt;</content><author><name>X Chen, L Li, N Zhang, X Liang, S Deng, C Tan… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Prompt learning approaches have made waves in natural language processing by inducing better few-shot performance while they still follow a parametric-based learning paradigm; the oblivion and rote memorization problems in learning may encounter unstable generalization issues. Specifically, vanilla prompt learning may struggle to utilize atypical instances by rote during fully-supervised training or overfit shallow patterns with low-shot data. To alleviate such limitations, we develop … Cites: ‪Knowledgeable Prompt-tuning: Incorporating Knowledge into …‬</summary></entry><entry><title type="html">Patching Leaks in the Charformer for Efficient Character-Level Generation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c4832ec11485b3ce0412708d74916cbb.html" rel="alternate" type="text/html" title="Patching Leaks in the Charformer for Efficient Character-Level Generation" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c4832ec11485b3ce0412708d74916cbb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c4832ec11485b3ce0412708d74916cbb.html">&lt;p&gt;Character-based representations have important advantages over subword-based ones for morphologically rich languages. They come with increased robustness to noisy input and do not need a separate tokenization step. However, they also have a crucial disadvantage: they notably increase the length of text sequences. The GBST method from Charformer groups (aka downsamples) characters to solve this, but allows information to leak when applied to a Transformer decoder. We solve this … Cites: ‪Charformer: Fast character transformers via gradient-based …‬&lt;/p&gt;</content><author><name>L Edman, A Toral, G van Noord - arXiv preprint arXiv:2205.14086, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Character-based representations have important advantages over subword-based ones for morphologically rich languages. They come with increased robustness to noisy input and do not need a separate tokenization step. However, they also have a crucial disadvantage: they notably increase the length of text sequences. The GBST method from Charformer groups (aka downsamples) characters to solve this, but allows information to leak when applied to a Transformer decoder. We solve this … Cites: ‪Charformer: Fast character transformers via gradient-based …‬</summary></entry><entry><title type="html">Happenstance: Utilizing Semantic Search to Track Russian State Media Narratives about the Russo-Ukrainian War On Reddit</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c52bb5d5a0322285261f6e878cb9d3e4.html" rel="alternate" type="text/html" title="Happenstance: Utilizing Semantic Search to Track Russian State Media Narratives about the Russo-Ukrainian War On Reddit" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c52bb5d5a0322285261f6e878cb9d3e4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c52bb5d5a0322285261f6e878cb9d3e4.html">&lt;p&gt;In the buildup to and in the weeks following the Russian Federation s invasion of Ukraine, Russian disinformation outlets output torrents of misleading and outright false information. In this work, we study the coordinated information campaign to understand the most prominent disinformation narratives touted by the Russian government to English-speaking audiences. To do this, we first perform sentence-level topic analysis using the large-language model MPNet on articles published by … Cites: ‪Whiteningbert: An easy unsupervised sentence embedding …‬&lt;/p&gt;</content><author><name>HWA Hanley, D Kumar, Z Durumeric - arXiv preprint arXiv:2205.14484, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In the buildup to and in the weeks following the Russian Federation s invasion of Ukraine, Russian disinformation outlets output torrents of misleading and outright false information. In this work, we study the coordinated information campaign to understand the most prominent disinformation narratives touted by the Russian government to English-speaking audiences. To do this, we first perform sentence-level topic analysis using the large-language model MPNet on articles published by … Cites: ‪Whiteningbert: An easy unsupervised sentence embedding …‬</summary></entry><entry><title type="html">YASM (Yet Another Surveillance Mechanism)</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c53c20fb46c5e72b40a1da7ec75b0f91.html" rel="alternate" type="text/html" title="YASM (Yet Another Surveillance Mechanism)" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c53c20fb46c5e72b40a1da7ec75b0f91</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c53c20fb46c5e72b40a1da7ec75b0f91.html">&lt;p&gt;Client-Side Scanning (CSS) see in the Child Sexual Abuse Material Detection (CSAMD) represent ubiquitous mass scanning. Apple proposed to scan their systems for such imagery. CSAMD was since pushed back, but the European Union decided to propose forced CSS to combat and prevent child sexual abuse and weaken encryption. CSS is mass surveillance of personal property, pictures and text, without considerations of privacy and cybersecurity and the law. We first argue why … Cites: ‪On consequentialism and fairness‬&lt;/p&gt;</content><author><name>KR Ludvigsen, S Nagaraja, A Daly - arXiv preprint arXiv:2205.14601, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Client-Side Scanning (CSS) see in the Child Sexual Abuse Material Detection (CSAMD) represent ubiquitous mass scanning. Apple proposed to scan their systems for such imagery. CSAMD was since pushed back, but the European Union decided to propose forced CSS to combat and prevent child sexual abuse and weaken encryption. CSS is mass surveillance of personal property, pictures and text, without considerations of privacy and cybersecurity and the law. We first argue why … Cites: ‪On consequentialism and fairness‬</summary></entry><entry><title type="html">Memorial GAN With Joint Semantic Optimization for Unpaired Image Captioning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c547accc5789c7e9105793f4745cf6fa.html" rel="alternate" type="text/html" title="Memorial GAN With Joint Semantic Optimization for Unpaired Image Captioning" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c547accc5789c7e9105793f4745cf6fa</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c547accc5789c7e9105793f4745cf6fa.html">&lt;p&gt;Most works of image captioning are implemented under the full supervision of paired image-caption data. Limited to expensive cost of data collection, the task of unpaired image captioning has attracted researchers  attention. In this article, we propose a novel memorial GAN (MemGAN) with the joint semantic optimization for unpaired image captioning. The core idea is to explore implicit semantic correlation between disjointed images and sentences through building a multimodal semantic-aware … Cites: ‪Unsupervised neural machine translation‬&lt;/p&gt;</content><author><name>P Song, D Guo, J Zhou, M Xu, M Wang - IEEE Transactions on Cybernetics, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Most works of image captioning are implemented under the full supervision of paired image-caption data. Limited to expensive cost of data collection, the task of unpaired image captioning has attracted researchers attention. In this article, we propose a novel memorial GAN (MemGAN) with the joint semantic optimization for unpaired image captioning. The core idea is to explore implicit semantic correlation between disjointed images and sentences through building a multimodal semantic-aware … Cites: ‪Unsupervised neural machine translation‬</summary></entry><entry><title type="html">Joint learning of morphology and syntax with cross-level contextual information flow</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c6866f2bbcdeb6e2bb4f3bcb99e41e40.html" rel="alternate" type="text/html" title="Joint learning of morphology and syntax with cross-level contextual information flow" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c6866f2bbcdeb6e2bb4f3bcb99e41e40</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c6866f2bbcdeb6e2bb4f3bcb99e41e40.html">&lt;p&gt;We propose an integrated deep learning model for morphological segmentation, morpheme tagging, part-of-speech (POS) tagging, and syntactic parsing onto dependencies, using cross-level contextual information flow for every word, from segments to dependencies, with an attention mechanism at horizontal flow. Our model extends the work of Nguyen and Verspoor (2018) on joint POS tagging and dependency parsing to also include morphological segmentation and morphological … Cites: ‪Dynet: The dynamic neural network toolkit‬&lt;/p&gt;</content><author><name>B Can Buglalilar, H Aleçakır, S Manandhar, C Bozşahin - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose an integrated deep learning model for morphological segmentation, morpheme tagging, part-of-speech (POS) tagging, and syntactic parsing onto dependencies, using cross-level contextual information flow for every word, from segments to dependencies, with an attention mechanism at horizontal flow. Our model extends the work of Nguyen and Verspoor (2018) on joint POS tagging and dependency parsing to also include morphological segmentation and morphological … Cites: ‪Dynet: The dynamic neural network toolkit‬</summary></entry><entry><title type="html">Duplex Conversation: Towards Human-like Interaction in Spoken Dialogue System</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c6e93ea5a85c711e0c24466975f8a20f.html" rel="alternate" type="text/html" title="Duplex Conversation: Towards Human-like Interaction in Spoken Dialogue System" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c6e93ea5a85c711e0c24466975f8a20f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c6e93ea5a85c711e0c24466975f8a20f.html">&lt;p&gt;In this paper, we present Duplex Conversation, a multi-turn, multimodal spoken dialogue system that enables telephone-based agents to interact with customers like a human. We use the concept of full-duplex in telecommunication to demonstrate what a human-like interactive experience should be and how to achieve smooth turn-taking through three subtasks: user state detection, backchannel selection, and barge-in detection. Besides, we propose semi-supervised learning with multimodal … Cites: ‪Spoken language interaction with robots: Recommendations for …‬&lt;/p&gt;</content><author><name>TE Lin, Y Wu, F Huang, L Si, J Sun, Y Li - arXiv preprint arXiv:2205.15060, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper, we present Duplex Conversation, a multi-turn, multimodal spoken dialogue system that enables telephone-based agents to interact with customers like a human. We use the concept of full-duplex in telecommunication to demonstrate what a human-like interactive experience should be and how to achieve smooth turn-taking through three subtasks: user state detection, backchannel selection, and barge-in detection. Besides, we propose semi-supervised learning with multimodal … Cites: ‪Spoken language interaction with robots: Recommendations for …‬</summary></entry><entry><title type="html">Quark: Controllable Text Generation with Reinforced Unlearning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c91b7ccacb391216cef210af0005e004.html" rel="alternate" type="text/html" title="Quark: Controllable Text Generation with Reinforced Unlearning" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c91b7ccacb391216cef210af0005e004</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c91b7ccacb391216cef210af0005e004.html">&lt;p&gt;Large-scale language models often learn behaviors that are misaligned with user expectations. Generated text may contain offensive or toxic language, contain significant repetition, or be of a different sentiment than desired by the user. We …&lt;/p&gt;</content><author><name>X Lu, S Welleck, L Jiang, J Hessel, L Qin, P West… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Large-scale language models often learn behaviors that are misaligned with user expectations. Generated text may contain offensive or toxic language, contain significant repetition, or be of a different sentiment than desired by the user. We …</summary></entry><entry><title type="html">Learning Adaptive Propagation for Knowledge Graph Reasoning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c9bb6ce26aed925aae33d02c9c9261f0.html" rel="alternate" type="text/html" title="Learning Adaptive Propagation for Knowledge Graph Reasoning" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c9bb6ce26aed925aae33d02c9c9261f0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/c9bb6ce26aed925aae33d02c9c9261f0.html">&lt;p&gt;Due to the success of Graph Neural Networks (GNNs) in learning from graph-structured data, various GNN-based methods have been introduced to learn from knowledge graphs (KGs). In this paper, to reveal the key factors underneath existing GNN-based methods, we revisit exemplar works from the lens of the propagation path. We find that the answer entity can be close to queried one, but the information dependency can be long. Thus, better reasoning performance can be obtained by … Cites: ‪Convolutional 2d knowledge graph embeddings‬&lt;/p&gt;</content><author><name>Y Zhang, Z Zhou, Q Yao, X Chu, B Han - arXiv preprint arXiv:2205.15319, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Due to the success of Graph Neural Networks (GNNs) in learning from graph-structured data, various GNN-based methods have been introduced to learn from knowledge graphs (KGs). In this paper, to reveal the key factors underneath existing GNN-based methods, we revisit exemplar works from the lens of the propagation path. We find that the answer entity can be close to queried one, but the information dependency can be long. Thus, better reasoning performance can be obtained by … Cites: ‪Convolutional 2d knowledge graph embeddings‬</summary></entry><entry><title type="html">Academic Term Search Support System for Beginners in Inquiry-Based Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/cdeee711e85f672b7004e300ab0ca8c7.html" rel="alternate" type="text/html" title="Academic Term Search Support System for Beginners in Inquiry-Based Learning" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/cdeee711e85f672b7004e300ab0ca8c7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/cdeee711e85f672b7004e300ab0ca8c7.html">&lt;p&gt;Previous studies on journal searching have proposed models to assist those with experience in publishing articles in journals. We propose a search engine to retrieve academic terms using non-academic terms to support beginner students while searching for academic journals. The proposed search engine supports beginner students with insufficient knowledge regarding academic terms, which limits their ability to find articles that they want to read. Our search engine uses a classifier to … Cites: ‪Importance of Semantic Representation: Dataless Classification.‬&lt;/p&gt;</content><author><name>Y Sumikawa, R Ikejiri, Y Yamauchi - … Conference on Smart Education and E-Learning, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Previous studies on journal searching have proposed models to assist those with experience in publishing articles in journals. We propose a search engine to retrieve academic terms using non-academic terms to support beginner students while searching for academic journals. The proposed search engine supports beginner students with insufficient knowledge regarding academic terms, which limits their ability to find articles that they want to read. Our search engine uses a classifier to … Cites: ‪Importance of Semantic Representation: Dataless Classification.‬</summary></entry><entry><title type="html">A Comprehensive Survey on Various Fully Automatic Machine Translation Evaluation Metrics</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ce57f97880e24780f3c1a352bad46cf3.html" rel="alternate" type="text/html" title="A Comprehensive Survey on Various Fully Automatic Machine Translation Evaluation Metrics" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ce57f97880e24780f3c1a352bad46cf3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ce57f97880e24780f3c1a352bad46cf3.html">&lt;p&gt;The fast advancement in machine translation models necessitates the development of accurate evaluation metrics that would allow researchers to track the progress in text languages. The evaluation of machine translation models is crucial since its results are exploited for improvements of translation models. However fully automatically evaluating the machine translation models in itself is a huge challenge for the researchers as human evaluation is very expensive, time-consuming … Cites: ‪Deep contextualized word representations‬&lt;/p&gt;</content><author><name>S Chauhan, P Daniel - Neural Processing Letters, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The fast advancement in machine translation models necessitates the development of accurate evaluation metrics that would allow researchers to track the progress in text languages. The evaluation of machine translation models is crucial since its results are exploited for improvements of translation models. However fully automatically evaluating the machine translation models in itself is a huge challenge for the researchers as human evaluation is very expensive, time-consuming … Cites: ‪Deep contextualized word representations‬</summary></entry><entry><title type="html">Knowledge Graph Programming with a Human-in-the-Loop</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ce6ccdfeb9d9f691cad8cf97f320b3ff.html" rel="alternate" type="text/html" title="Knowledge Graph Programming with a Human-in-the-Loop" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ce6ccdfeb9d9f691cad8cf97f320b3ff</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ce6ccdfeb9d9f691cad8cf97f320b3ff.html">&lt;p&gt;OUCI logo Search Analytics About укр Українською Knowledge Graph Programming with   a Human-in-the-Loop https://doi.org/10.1145/3328519.3329132 Journal: Proceedings of   the Workshop on Human-In-the-Loop Data Analytics - HILDA 19, 2019 Publisher: ACM …&lt;/p&gt;</content><author><name>Y Lou, M Uddin, N Brown, M Cafarella</name></author><category term="jekyll" /><category term="update" /><summary type="html">OUCI logo Search Analytics About укр Українською Knowledge Graph Programming with a Human-in-the-Loop https://doi.org/10.1145/3328519.3329132 Journal: Proceedings of the Workshop on Human-In-the-Loop Data Analytics - HILDA 19, 2019 Publisher: ACM …</summary></entry><entry><title type="html">Interactive Query Clarification and Refinement via User Simulation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/cf3a51368f1f560f7cfdd4e06e194909.html" rel="alternate" type="text/html" title="Interactive Query Clarification and Refinement via User Simulation" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/cf3a51368f1f560f7cfdd4e06e194909</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/cf3a51368f1f560f7cfdd4e06e194909.html">&lt;p&gt;When users initiate search sessions, their queries are often unclear or might lack of context; this resulting in inefficient document ranking. Multiple approaches have been proposed by the Information Retrieval community to add context and retrieve documents aligned with users  intents. While some work focus on query disambiguation using users  browsing history, a recent line of work proposes to interact with users by asking clarification questions or/and proposing clarification … Cites: ‪Multi-stage document ranking with BERT‬&lt;/p&gt;</content><author><name>P Erbacher, L Denoyer, L Soulier - arXiv preprint arXiv:2205.15918, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">When users initiate search sessions, their queries are often unclear or might lack of context; this resulting in inefficient document ranking. Multiple approaches have been proposed by the Information Retrieval community to add context and retrieve documents aligned with users intents. While some work focus on query disambiguation using users browsing history, a recent line of work proposes to interact with users by asking clarification questions or/and proposing clarification … Cites: ‪Multi-stage document ranking with BERT‬</summary></entry><entry><title type="html">FinBERT-MRC: financial named entity recognition using BERT under the machine reading comprehension paradigm</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d26cff2d66fb9649fb83ab4a3877f534.html" rel="alternate" type="text/html" title="FinBERT-MRC: financial named entity recognition using BERT under the machine reading comprehension paradigm" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d26cff2d66fb9649fb83ab4a3877f534</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d26cff2d66fb9649fb83ab4a3877f534.html">&lt;p&gt;Financial named entity recognition (FinNER) from literature is a challenging task in the field of financial text information extraction, which aims to extract a large amount of financial knowledge from unstructured texts. It is widely accepted to use sequence tagging frameworks to implement FinNER tasks. However, such sequence tagging models cannot fully take advantage of the semantic information in the texts. Instead, we formulate the FinNER task as a machine reading comprehension (MRC) problem … Cites: ‪Representation Learning for Natural Language Processing‬&lt;/p&gt;</content><author><name>Y Zhang, H Zhang - arXiv preprint arXiv:2205.15485, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Financial named entity recognition (FinNER) from literature is a challenging task in the field of financial text information extraction, which aims to extract a large amount of financial knowledge from unstructured texts. It is widely accepted to use sequence tagging frameworks to implement FinNER tasks. However, such sequence tagging models cannot fully take advantage of the semantic information in the texts. Instead, we formulate the FinNER task as a machine reading comprehension (MRC) problem … Cites: ‪Representation Learning for Natural Language Processing‬</summary></entry><entry><title type="html">StereoKG: Data-Driven Knowledge Graph Construction for Cultural Knowledge and Stereotypes</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d2df53f9549f3da8e7b09863cc00230a.html" rel="alternate" type="text/html" title="StereoKG: Data-Driven Knowledge Graph Construction for Cultural Knowledge and Stereotypes" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d2df53f9549f3da8e7b09863cc00230a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d2df53f9549f3da8e7b09863cc00230a.html">&lt;p&gt;Analyzing ethnic or religious bias is important for improving fairness, accountability, and transparency of natural language processing models. However, many techniques rely on human-compiled lists of bias terms, which are expensive to create and are limited in coverage. In this study, we present a fully data-driven pipeline for generating a knowledge graph (KG) of cultural knowledge and stereotypes. Our resulting KG covers 5 religious groups and 5 nationalities and can easily be … Cites: ‪From natural language processing to neural databases‬&lt;/p&gt;</content><author><name>A Deshpande, D Ruiter, M Mosbach, D Klakow - arXiv preprint arXiv:2205.14036, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Analyzing ethnic or religious bias is important for improving fairness, accountability, and transparency of natural language processing models. However, many techniques rely on human-compiled lists of bias terms, which are expensive to create and are limited in coverage. In this study, we present a fully data-driven pipeline for generating a knowledge graph (KG) of cultural knowledge and stereotypes. Our resulting KG covers 5 religious groups and 5 nationalities and can easily be … Cites: ‪From natural language processing to neural databases‬</summary></entry><entry><title type="html">Enhancing Event-Level Sentiment Analysis with Structured Arguments</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d36b0e149c56968db64329e2d7409ee6.html" rel="alternate" type="text/html" title="Enhancing Event-Level Sentiment Analysis with Structured Arguments" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d36b0e149c56968db64329e2d7409ee6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d36b0e149c56968db64329e2d7409ee6.html">&lt;p&gt;Previous studies about event-level sentiment analysis (SA) usually model the event as a topic, a category or target terms, while the structured arguments (eg, subject, object, time and location) that have potential effects on the sentiment are not well studied. In this paper, we redefine the task as structured event-level SA and propose an End-to-End Event-level Sentiment Analysis ($\textit {E}^{3}\textit {SA} $) approach to solve this issue. Specifically, we explicitly extract and model the event structure … Cites: ‪Stanza: A python natural language processing toolkit for many …‬&lt;/p&gt;</content><author><name>Q Zhang, J Zhou, Q Chen, Q Bai, L He - arXiv preprint arXiv:2205.15511, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Previous studies about event-level sentiment analysis (SA) usually model the event as a topic, a category or target terms, while the structured arguments (eg, subject, object, time and location) that have potential effects on the sentiment are not well studied. In this paper, we redefine the task as structured event-level SA and propose an End-to-End Event-level Sentiment Analysis ($\textit {E}^{3}\textit {SA} $) approach to solve this issue. Specifically, we explicitly extract and model the event structure … Cites: ‪Stanza: A python natural language processing toolkit for many …‬</summary></entry><entry><title type="html">Learning verifiable representations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d3b1d6ee767e85162c6382f5137b160c.html" rel="alternate" type="text/html" title="Learning verifiable representations" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d3b1d6ee767e85162c6382f5137b160c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d3b1d6ee767e85162c6382f5137b160c.html">&lt;p&gt;Deep learning has enabled breakthroughs in challenging computing problems and has emerged as the standard problem-solving tool for computer vision and natural language processing tasks. One exception to this trend is safety-critical tasks where robustness and resilience requirements contradict the black-box nature of neural networks. To deploy deep learning methods for these tasks, it is vital to provide guarantees on neural network agents  safety and robustness criteria. This can be … Cites: ‪Fine-tuning can distort pretrained features and underperform out-of …‬&lt;/p&gt;</content><author><name>M Lechner - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning has enabled breakthroughs in challenging computing problems and has emerged as the standard problem-solving tool for computer vision and natural language processing tasks. One exception to this trend is safety-critical tasks where robustness and resilience requirements contradict the black-box nature of neural networks. To deploy deep learning methods for these tasks, it is vital to provide guarantees on neural network agents safety and robustness criteria. This can be … Cites: ‪Fine-tuning can distort pretrained features and underperform out-of …‬</summary></entry><entry><title type="html">Learning to Represent Programs with Code Hierarchies</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d7266dd85c0f117ac3cb33d87132d8a4.html" rel="alternate" type="text/html" title="Learning to Represent Programs with Code Hierarchies" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d7266dd85c0f117ac3cb33d87132d8a4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d7266dd85c0f117ac3cb33d87132d8a4.html">&lt;p&gt;When used to process source code, graph neural networks have been shown to produce impressive results for a wide range of software engineering tasks. Existing techniques, however, still have two issues:(1) long-term dependency and (2) different code components are treated as equals when they should not be. To address these issues, we propose a method for representing code as a hierarchy (Code Hierarchy), in which different code components are represented separately at various levels of … Cites: ‪Graphcodebert: Pre-training code representations with data flow‬&lt;/p&gt;</content><author><name>M Nguyen, NDQ Bui - arXiv preprint arXiv:2205.15479, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">When used to process source code, graph neural networks have been shown to produce impressive results for a wide range of software engineering tasks. Existing techniques, however, still have two issues:(1) long-term dependency and (2) different code components are treated as equals when they should not be. To address these issues, we propose a method for representing code as a hierarchy (Code Hierarchy), in which different code components are represented separately at various levels of … Cites: ‪Graphcodebert: Pre-training code representations with data flow‬</summary></entry><entry><title type="html">Weakly Supervised Object Detection Based on Active Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d74ca5b33304e08442600e35ab6b88ba.html" rel="alternate" type="text/html" title="Weakly Supervised Object Detection Based on Active Learning" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d74ca5b33304e08442600e35ab6b88ba</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/d74ca5b33304e08442600e35ab6b88ba.html">&lt;p&gt;Weakly supervised object detection which reduces the need for strong supersivison during training has recently made significant achievements. However, it remains a challenging issue due to the time-consuming and labor-intensive problems in application. To further reduce the label cost, we introduce a new fusion method of weakly supervised learning and active learning in a unied framework for object detection. Weakly supervised learning based on min-entropy latent model is used to … Cites: ‪Margin-based active learning for structured output spaces‬&lt;/p&gt;</content><author><name>X Wang, X Xiang, B Zhang, X Liu, J Zheng, QL Hu - Neural Processing Letters, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Weakly supervised object detection which reduces the need for strong supersivison during training has recently made significant achievements. However, it remains a challenging issue due to the time-consuming and labor-intensive problems in application. To further reduce the label cost, we introduce a new fusion method of weakly supervised learning and active learning in a unied framework for object detection. Weakly supervised learning based on min-entropy latent model is used to … Cites: ‪Margin-based active learning for structured output spaces‬</summary></entry><entry><title type="html">Securing Data using Artificial Intelligence and Block Chain</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/da3d1db822e4753d828c1b67ba189913.html" rel="alternate" type="text/html" title="Securing Data using Artificial Intelligence and Block Chain" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/da3d1db822e4753d828c1b67ba189913</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/da3d1db822e4753d828c1b67ba189913.html">&lt;p&gt;The input for several Artificial Intelligence algorithms is Data which is used for mining the valuable features. But, data on the internet are unbelievable and difficult to authorize. It is very difficult to verify the data for the users in this complex cyberspace. So, for this we proposed SecNet in this paper. SecNet, An architecture that helps in securing data storage, processing of data and sharing large scale Internet environments. The main aim of this architecture is to create a more secure … Cites: ‪The unreasonable effectiveness of data‬&lt;/p&gt;</content><author><name>DP Srivasta, DS Babu, S Kanakala - International Journal of Computational …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The input for several Artificial Intelligence algorithms is Data which is used for mining the valuable features. But, data on the internet are unbelievable and difficult to authorize. It is very difficult to verify the data for the users in this complex cyberspace. So, for this we proposed SecNet in this paper. SecNet, An architecture that helps in securing data storage, processing of data and sharing large scale Internet environments. The main aim of this architecture is to create a more secure … Cites: ‪The unreasonable effectiveness of data‬</summary></entry><entry><title type="html">Cluster-based Evaluation of Automatically Generated Text</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/dea484ee8df77fbf9342e9a25827eade.html" rel="alternate" type="text/html" title="Cluster-based Evaluation of Automatically Generated Text" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/dea484ee8df77fbf9342e9a25827eade</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/dea484ee8df77fbf9342e9a25827eade.html">&lt;p&gt;While probabilistic language generators have improved dramatically over the last few years, the automatic evaluation metrics used to assess them have not kept pace with this progress. In the domain of language generation, a good metric must correlate highly with human judgements. Yet, with few exceptions, there is a lack of such metrics in the literature. In this work, we analyse the general paradigm of language generator evaluation. We first discuss the computational and qualitative … Cites: ‪Neural text generation with unlikelihood training‬&lt;/p&gt;</content><author><name>T Pimentel, C Meister, R Cotterell - arXiv preprint arXiv:2205.16001, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">While probabilistic language generators have improved dramatically over the last few years, the automatic evaluation metrics used to assess them have not kept pace with this progress. In the domain of language generation, a good metric must correlate highly with human judgements. Yet, with few exceptions, there is a lack of such metrics in the literature. In this work, we analyse the general paradigm of language generator evaluation. We first discuss the computational and qualitative … Cites: ‪Neural text generation with unlikelihood training‬</summary></entry><entry><title type="html">A Survey of Event Relation Extraction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/df2a4d8739e06caaac9af50c4c718cde.html" rel="alternate" type="text/html" title="A Survey of Event Relation Extraction" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/df2a4d8739e06caaac9af50c4c718cde</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/df2a4d8739e06caaac9af50c4c718cde.html">&lt;p&gt;Human beings recognize and understand the real world in units of events. In recent years, events have been used as the basic unit to process unstructured text in the field of natural language processing, but there is often a connection between events and events. Therefore, recognizing the relationship between events and events in unstructured text has become an important task in the field of natural language processing and has attracted more and more researchers  attention. This paper first … Cites: ‪Improving temporal relation extraction with a globally acquired …‬&lt;/p&gt;</content><author><name>QL Xie, JL Pan, T Liu, BB Qian, XC Wang, X Wang - International Conference on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Human beings recognize and understand the real world in units of events. In recent years, events have been used as the basic unit to process unstructured text in the field of natural language processing, but there is often a connection between events and events. Therefore, recognizing the relationship between events and events in unstructured text has become an important task in the field of natural language processing and has attracted more and more researchers attention. This paper first … Cites: ‪Improving temporal relation extraction with a globally acquired …‬</summary></entry><entry><title type="html">ZusammenQA: Data Augmentation with Specialized Models for Cross-lingual Open-retrieval Question Answering System</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/dfb2df15a8e98e65e7a79f5b5918094f.html" rel="alternate" type="text/html" title="ZusammenQA: Data Augmentation with Specialized Models for Cross-lingual Open-retrieval Question Answering System" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/dfb2df15a8e98e65e7a79f5b5918094f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/dfb2df15a8e98e65e7a79f5b5918094f.html">&lt;p&gt;This paper introduces our proposed system for the MIA Shared Task on Cross-lingual Open-retrieval Question Answering (COQA). In this challenging scenario, given an input question the system has to gather evidence documents from a multilingual pool and generate from them an answer in the language of the question. We devised several approaches combining different model variants for three main components: Data Augmentation, Passage Retrieval, and Answer Generation. For … Cites: ‪Retrieval-augmented generation for knowledge-intensive nlp tasks‬&lt;/p&gt;</content><author><name>CC Hung, T Green, R Litschko, T Tsereteli, S Takeshita… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper introduces our proposed system for the MIA Shared Task on Cross-lingual Open-retrieval Question Answering (COQA). In this challenging scenario, given an input question the system has to gather evidence documents from a multilingual pool and generate from them an answer in the language of the question. We devised several approaches combining different model variants for three main components: Data Augmentation, Passage Retrieval, and Answer Generation. For … Cites: ‪Retrieval-augmented generation for knowledge-intensive nlp tasks‬</summary></entry><entry><title type="html">HTKG: Deep Keyphrase Generation with Neural Hierarchical Topic Guidance</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e26edf3aed7954288f17699de123e8c2.html" rel="alternate" type="text/html" title="HTKG: Deep Keyphrase Generation with Neural Hierarchical Topic Guidance" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e26edf3aed7954288f17699de123e8c2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e26edf3aed7954288f17699de123e8c2.html">&lt;p&gt;Keyphrases can concisely describe the high-level topics discussed in a document that usually possesses hierarchical topic structures. Thus, it is crucial to understand the hierarchical topic structures and employ it to guide the keyphrase identification. However, integrating the hierarchical topic information into a deep keyphrase generation model is unexplored. In this paper, we focus on how to effectively exploit the hierarchical topic to improve the keyphrase generation performance (HTKG) … Cites: ‪Text summarization with latent queries‬&lt;/p&gt;</content><author><name>Y Zhang, T Jiang, T Yang, X Li, S Wang - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Keyphrases can concisely describe the high-level topics discussed in a document that usually possesses hierarchical topic structures. Thus, it is crucial to understand the hierarchical topic structures and employ it to guide the keyphrase identification. However, integrating the hierarchical topic information into a deep keyphrase generation model is unexplored. In this paper, we focus on how to effectively exploit the hierarchical topic to improve the keyphrase generation performance (HTKG) … Cites: ‪Text summarization with latent queries‬</summary></entry><entry><title type="html">Un algorithme d analyse sémantique fondée sur les graphes via le problème de l arborescence généralisée couvrante</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e2dca83a1e4de2462508407f9d6013c2.html" rel="alternate" type="text/html" title="Un algorithme d analyse sémantique fondée sur les graphes via le problème de l arborescence généralisée couvrante" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e2dca83a1e4de2462508407f9d6013c2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e2dca83a1e4de2462508407f9d6013c2.html">&lt;p&gt;Un algorithme d’analyse sémantique fondée sur les graphes via le problème de l’arborescence   généralisée couvrante 1 In Page 1 Un algorithme d’analyse sémantique fondée sur   les graphes via le problème de l’arborescence généralisée couvrante Alban Petit   Caio Corro Université Paris-Saclay, CNRS, LISN, 91400, Orsay, France {alban.petit,caio.corro}@lisn.upsaclay.fr   RÉSUMÉ Nous proposons un nouvel algorithme pour l’analyse sémantique fondée   sur les graphes via le problème de l’arborescence généralisée couvrante … Cites: ‪Rat-sql: Relation-aware schema encoding and linking for text-to …‬&lt;/p&gt;</content><author><name>APC Corro</name></author><category term="jekyll" /><category term="update" /><summary type="html">Un algorithme d’analyse sémantique fondée sur les graphes via le problème de l’arborescence généralisée couvrante 1 In Page 1 Un algorithme d’analyse sémantique fondée sur les graphes via le problème de l’arborescence généralisée couvrante Alban Petit Caio Corro Université Paris-Saclay, CNRS, LISN, 91400, Orsay, France {alban.petit,caio.corro}@lisn.upsaclay.fr RÉSUMÉ Nous proposons un nouvel algorithme pour l’analyse sémantique fondée sur les graphes via le problème de l’arborescence généralisée couvrante … Cites: ‪Rat-sql: Relation-aware schema encoding and linking for text-to …‬</summary></entry><entry><title type="html">Heterogenous affinity graph inference network for Document-level Relation Extraction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e3606bb9d974622008be5ad95cd48d0f.html" rel="alternate" type="text/html" title="Heterogenous affinity graph inference network for Document-level Relation Extraction" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e3606bb9d974622008be5ad95cd48d0f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e3606bb9d974622008be5ad95cd48d0f.html">&lt;p&gt;Document-level relation extraction (Doc-level RE) is a more practical and challenging task, which provides a new perspective on obtaining factual knowledge from the more complex cross-sentence text. Recent Doc-level RE, based on pre-trained language models, uses graph neural networks to implicitly model relation reasoning in a document. However, it is not perfect that the model neglects explicit reasoning clues, leading to a weak ability and a lack of capability to model long … Cites: ‪Coreferential reasoning learning for language representation‬&lt;/p&gt;</content><author><name>R Li, J Zhong, Z Xue, Q Dai, X Li - Knowledge-Based Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Document-level relation extraction (Doc-level RE) is a more practical and challenging task, which provides a new perspective on obtaining factual knowledge from the more complex cross-sentence text. Recent Doc-level RE, based on pre-trained language models, uses graph neural networks to implicitly model relation reasoning in a document. However, it is not perfect that the model neglects explicit reasoning clues, leading to a weak ability and a lack of capability to model long … Cites: ‪Coreferential reasoning learning for language representation‬</summary></entry><entry><title type="html">Lifting the Information Ratio: An Information-Theoretic Analysis of Thompson Sampling for Contextual Bandits</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e509082e4cf9aa6ce011d1b94799b31b.html" rel="alternate" type="text/html" title="Lifting the Information Ratio: An Information-Theoretic Analysis of Thompson Sampling for Contextual Bandits" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e509082e4cf9aa6ce011d1b94799b31b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e509082e4cf9aa6ce011d1b94799b31b.html">&lt;p&gt;We study the Bayesian regret of the renowned Thompson Sampling algorithm in contextual bandits with binary losses and adversarially-selected contexts. We adapt the information-theoretic perspective of Russo and Van Roy [2016] to the contextual setting by introducing a new concept of information ratio based on the mutual information between the unknown model parameter and the observed loss. This allows us to bound the regret in terms of the entropy of the prior distribution through a … Cites: ‪Provably optimal algorithms for generalized linear contextual bandits‬&lt;/p&gt;</content><author><name>G Neu, J Olkhovskaya, M Papini, L Schwartz - arXiv preprint arXiv:2205.13924, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We study the Bayesian regret of the renowned Thompson Sampling algorithm in contextual bandits with binary losses and adversarially-selected contexts. We adapt the information-theoretic perspective of Russo and Van Roy [2016] to the contextual setting by introducing a new concept of information ratio based on the mutual information between the unknown model parameter and the observed loss. This allows us to bound the regret in terms of the entropy of the prior distribution through a … Cites: ‪Provably optimal algorithms for generalized linear contextual bandits‬</summary></entry><entry><title type="html">RESEARCH ON THE GEOLOGICAL ENTITIES BUSINESS RELATION EXTRACTION BASED ON THE BOOTSTRAPPING METHOD.</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e70b20c88d594da37f6c079572b05b6b.html" rel="alternate" type="text/html" title="RESEARCH ON THE GEOLOGICAL ENTITIES BUSINESS RELATION EXTRACTION BASED ON THE BOOTSTRAPPING METHOD." /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e70b20c88d594da37f6c079572b05b6b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e70b20c88d594da37f6c079572b05b6b.html">&lt;p&gt;The purpose of entity-relation extraction research is to extract structured entity-relation data from unstructured documents. Through entity-relation extraction technology, scattered and independent literature resources can be constructed into a knowledge system with interrelated and multi dimensional content, which helps people quickly discover the structural context between entities, and obtain target information intuitively and systematically. Entity-relation extraction research methods … Cites: ‪Textrunner: open information extraction on the web‬&lt;/p&gt;</content><author><name>L Pengfei, Y Zheng, W Chunning, Z Yueqin, L Wei - Transformations in Business &amp; …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The purpose of entity-relation extraction research is to extract structured entity-relation data from unstructured documents. Through entity-relation extraction technology, scattered and independent literature resources can be constructed into a knowledge system with interrelated and multi dimensional content, which helps people quickly discover the structural context between entities, and obtain target information intuitively and systematically. Entity-relation extraction research methods … Cites: ‪Textrunner: open information extraction on the web‬</summary></entry><entry><title type="html">BadDet: Backdoor Attacks on Object Detection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e95acff2408099d0ed3f46a6c4568d95.html" rel="alternate" type="text/html" title="BadDet: Backdoor Attacks on Object Detection" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e95acff2408099d0ed3f46a6c4568d95</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/e95acff2408099d0ed3f46a6c4568d95.html">&lt;p&gt;Deep learning models have been deployed in numerous real-world applications such as autonomous driving and surveillance. However, these models are vulnerable in adversarial environments. Backdoor attack is emerging as a severe security threat which injects a backdoor trigger into a small portion of training data such that the trained model behaves normally on benign inputs but gives incorrect predictions when the specific trigger appears. While most research in backdoor … Cites: ‪Weight Poisoning Attacks on Pre-trained Models‬&lt;/p&gt;</content><author><name>SH Chan, Y Dong, J Zhu, X Zhang, J Zhou - arXiv preprint arXiv:2205.14497, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning models have been deployed in numerous real-world applications such as autonomous driving and surveillance. However, these models are vulnerable in adversarial environments. Backdoor attack is emerging as a severe security threat which injects a backdoor trigger into a small portion of training data such that the trained model behaves normally on benign inputs but gives incorrect predictions when the specific trigger appears. While most research in backdoor … Cites: ‪Weight Poisoning Attacks on Pre-trained Models‬</summary></entry><entry><title type="html">Efficient recommendations in collaborative filtering recommender system: A multi-objective evolutionary approach based on NSGA-II algorithm</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ea7b6a18ad7f71b7f2bf09edfa4cedfd.html" rel="alternate" type="text/html" title="Efficient recommendations in collaborative filtering recommender system: A multi-objective evolutionary approach based on NSGA-II algorithm" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ea7b6a18ad7f71b7f2bf09edfa4cedfd</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ea7b6a18ad7f71b7f2bf09edfa4cedfd.html">&lt;p&gt;The final objective of the Recommender Systems (RSs) is to offer recommendations to the user that are close to his/her taste. When the user enters the system, the most similar data cluster to the user s taste can be selected, and by creating a neighborhood of the users similar to him/her within the selected cluster, the proposal generation can be followed. Determining the appropriate number of neighbors of the user can lead to increased accuracy of the recommendations made. Due to the … Cites: ‪Pareto-efficient hybridization for multi-objective recommender …‬&lt;/p&gt;</content><author><name>T Mohammadpour, AM Bidgoli, R Enayatifar… - International Journal of …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The final objective of the Recommender Systems (RSs) is to offer recommendations to the user that are close to his/her taste. When the user enters the system, the most similar data cluster to the user s taste can be selected, and by creating a neighborhood of the users similar to him/her within the selected cluster, the proposal generation can be followed. Determining the appropriate number of neighbors of the user can lead to increased accuracy of the recommendations made. Due to the … Cites: ‪Pareto-efficient hybridization for multi-objective recommender …‬</summary></entry><entry><title type="html">Improving Item Cold-start Recommendation via Model-agnostic Conditional Variational Autoencoder</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ea83396d01a30bed687690b50ca245ce.html" rel="alternate" type="text/html" title="Improving Item Cold-start Recommendation via Model-agnostic Conditional Variational Autoencoder" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ea83396d01a30bed687690b50ca245ce</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ea83396d01a30bed687690b50ca245ce.html">&lt;p&gt;Embedding &amp;amp; MLP has become a paradigm for modern large-scale recommendation system. However, this paradigm suffers from the cold-start problem which will seriously compromise the ecological health of recommendation systems. This paper attempts to tackle the item cold-start problem by generating enhanced warmed-up ID embeddings for cold items with historical data and limited interaction records. From the aspect of industrial practice, we mainly focus on the following three points of item … Cites: ‪Multiobjective pareto-efficient approaches for recommender systems‬&lt;/p&gt;</content><author><name>X Zhao, Y Ren, Y Du, S Zhang, N Wang - arXiv preprint arXiv:2205.13795, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Embedding &amp;amp; MLP has become a paradigm for modern large-scale recommendation system. However, this paradigm suffers from the cold-start problem which will seriously compromise the ecological health of recommendation systems. This paper attempts to tackle the item cold-start problem by generating enhanced warmed-up ID embeddings for cold items with historical data and limited interaction records. From the aspect of industrial practice, we mainly focus on the following three points of item … Cites: ‪Multiobjective pareto-efficient approaches for recommender systems‬</summary></entry><entry><title type="html">A Knowledge-Enhanced Adversarial Model for Cross-lingual Structured Sentiment Analysis</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/eb06e37a960f43ec75ada69306ce8029.html" rel="alternate" type="text/html" title="A Knowledge-Enhanced Adversarial Model for Cross-lingual Structured Sentiment Analysis" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/eb06e37a960f43ec75ada69306ce8029</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/eb06e37a960f43ec75ada69306ce8029.html">&lt;p&gt;Structured sentiment analysis, which aims to extract the complex semantic structures such as holders, expressions, targets, and polarities, has obtained widespread attention from both industry and academia. Unfortunately, the existing structured sentiment analysis datasets refer to a few languages and are relatively small, limiting neural network models  performance. In this paper, we focus on the cross-lingual structured sentiment analysis task, which aims to transfer the knowledge from the … Cites: ‪A language-independent neural network for event detection‬&lt;/p&gt;</content><author><name>Q Zhang, J Zhou, Q Chen, Q Bai, J Xiao, L He - arXiv preprint arXiv:2205.15514, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Structured sentiment analysis, which aims to extract the complex semantic structures such as holders, expressions, targets, and polarities, has obtained widespread attention from both industry and academia. Unfortunately, the existing structured sentiment analysis datasets refer to a few languages and are relatively small, limiting neural network models performance. In this paper, we focus on the cross-lingual structured sentiment analysis task, which aims to transfer the knowledge from the … Cites: ‪A language-independent neural network for event detection‬</summary></entry><entry><title type="html">Data-driven Crosslinguistic Syntactic Transfer in Second Language Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ecc60a427fb9444cb97d5aebd7b0e393.html" rel="alternate" type="text/html" title="Data-driven Crosslinguistic Syntactic Transfer in Second Language Learning" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ecc60a427fb9444cb97d5aebd7b0e393</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ecc60a427fb9444cb97d5aebd7b0e393.html">&lt;p&gt;Abstract Second-language (L2) learning is characterized by both positive and negative transfer from the first language (L1). However, prior psycholinguistic studies tend to focus on a few syntactic phenomena and L1-L2 pairs at a time, resulting in an incomplete picture. We apply machine learning to seven learner corpora in English and Spanish with 39 language pairs, showing that statistical models combined with simple n-grams of part-of-speech tags and syntactic dependency relations achieve … Cites: ‪Algorithm selection and model adaptation for ESL correction tasks‬&lt;/p&gt;</content><author><name>Z Liu, T Eisape, E Prud hommeaux, JK Hartshorne</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Second-language (L2) learning is characterized by both positive and negative transfer from the first language (L1). However, prior psycholinguistic studies tend to focus on a few syntactic phenomena and L1-L2 pairs at a time, resulting in an incomplete picture. We apply machine learning to seven learner corpora in English and Spanish with 39 language pairs, showing that statistical models combined with simple n-grams of part-of-speech tags and syntactic dependency relations achieve … Cites: ‪Algorithm selection and model adaptation for ESL correction tasks‬</summary></entry><entry><title type="html">Diffusion-LM Improves Controllable Text Generation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/f396bc3e56f75f18eeb21808f60a34a2.html" rel="alternate" type="text/html" title="Diffusion-LM Improves Controllable Text Generation" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/f396bc3e56f75f18eeb21808f60a34a2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/f396bc3e56f75f18eeb21808f60a34a2.html">&lt;p&gt;Controlling the behavior of language models (LMs) without re-training is a major open problem in natural language generation. While recent works have demonstrated successes on controlling simple sentence attributes (eg, sentiment) …&lt;/p&gt;</content><author><name>XL Li, J Thickstun, I Gulrajani, P Liang, TB Hashimoto - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Controlling the behavior of language models (LMs) without re-training is a major open problem in natural language generation. While recent works have demonstrated successes on controlling simple sentence attributes (eg, sentiment) …</summary></entry><entry><title type="html">Class-Wise Denoising for Robust Learning under Label Noise</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/f6c7b4489bd6224376e6c8810c035e32.html" rel="alternate" type="text/html" title="Class-Wise Denoising for Robust Learning under Label Noise" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/f6c7b4489bd6224376e6c8810c035e32</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/f6c7b4489bd6224376e6c8810c035e32.html">&lt;p&gt;Label noise is ubiquitous in many real-world scenarios which often misleads training algorithm and brings about the degraded classification performance. Therefore, many approaches have been proposed to correct the loss function given corrupted labels to combat such label noise. Among them, a trend of works unbiasedly estimate the data centroid, which plays an important role in constructing an unbiased risk estimator. However, they usually handle the noisy labels in different classes all at … Cites: ‪Dividemix: Learning with noisy labels as semi-supervised learning‬&lt;/p&gt;</content><author><name>C Gong, Y Ding, B Han, G Niu, J Yang, JJ You, D Tao… - IEEE Transactions on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Label noise is ubiquitous in many real-world scenarios which often misleads training algorithm and brings about the degraded classification performance. Therefore, many approaches have been proposed to correct the loss function given corrupted labels to combat such label noise. Among them, a trend of works unbiasedly estimate the data centroid, which plays an important role in constructing an unbiased risk estimator. However, they usually handle the noisy labels in different classes all at … Cites: ‪Dividemix: Learning with noisy labels as semi-supervised learning‬</summary></entry><entry><title type="html">Qualitative Measures for Ad hoc Table Retrieval</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/fa00d23583c53b086ce6ca1bcd1a7d97.html" rel="alternate" type="text/html" title="Qualitative Measures for Ad hoc Table Retrieval" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/fa00d23583c53b086ce6ca1bcd1a7d97</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/fa00d23583c53b086ce6ca1bcd1a7d97.html">&lt;p&gt;The focus of our work is the ad hoc table retrieval task, which aims to rank a list of structured tabular objects in response to a user query. Given the importance of this task, various methods have already been proposed in the literature that focus on syntactic, semantic and neural representations of tables for determining table relevance. However, recent works have highlighted queries that are consistently difficult for baseline methods to satisfy, referred to as hard queries. For this reason … Cites: ‪Webtables: exploring the power of tables on the web‬&lt;/p&gt;</content><author><name>M Khodabakhsh, E Bagheri - Information Sciences, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The focus of our work is the ad hoc table retrieval task, which aims to rank a list of structured tabular objects in response to a user query. Given the importance of this task, various methods have already been proposed in the literature that focus on syntactic, semantic and neural representations of tables for determining table relevance. However, recent works have highlighted queries that are consistently difficult for baseline methods to satisfy, referred to as hard queries. For this reason … Cites: ‪Webtables: exploring the power of tables on the web‬</summary></entry><entry><title type="html">Few-Shot Adaptation of Pre-Trained Networks for Domain Shift</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/fe6eeafee33c884bb3efb13781cb8463.html" rel="alternate" type="text/html" title="Few-Shot Adaptation of Pre-Trained Networks for Domain Shift" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/fe6eeafee33c884bb3efb13781cb8463</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/fe6eeafee33c884bb3efb13781cb8463.html">&lt;p&gt;Deep networks are prone to performance degradation when there is a domain shift between the source (training) data and target (test) data. Recent test-time adaptation methods update batch normalization layers of pre-trained source models deployed in new target environments with streaming data to mitigate such performance degradation. Although such methods can adapt on-the-fly without first collecting a large target domain dataset, their performance is dependent on streaming conditions … Cites: ‪Wilds: A benchmark of in-the-wild distribution shifts‬&lt;/p&gt;</content><author><name>W Zhang, L Shen, W Zhang, CS Foo - arXiv preprint arXiv:2205.15234, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep networks are prone to performance degradation when there is a domain shift between the source (training) data and target (test) data. Recent test-time adaptation methods update batch normalization layers of pre-trained source models deployed in new target environments with streaming data to mitigate such performance degradation. Although such methods can adapt on-the-fly without first collecting a large target domain dataset, their performance is dependent on streaming conditions … Cites: ‪Wilds: A benchmark of in-the-wild distribution shifts‬</summary></entry><entry><title type="html">DEEP NEURAL NETWORK-BASED DECISION NETWORK</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ff8c3e35494bf6825af63d3487af3693.html" rel="alternate" type="text/html" title="DEEP NEURAL NETWORK-BASED DECISION NETWORK" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ff8c3e35494bf6825af63d3487af3693</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ff8c3e35494bf6825af63d3487af3693.html">&lt;p&gt;The technology disclosed proposes using a combination of computationally cheap, less-accurate bag of words (BoW) model and computationally expensive, more-accurate long short-term memory (LSTM) model to perform natural processing tasks …&lt;/p&gt;</content><author><name>AR Johansen, B Mccann, J Bradbury, R Socher - US Patent App. 17/670,368, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The technology disclosed proposes using a combination of computationally cheap, less-accurate bag of words (BoW) model and computationally expensive, more-accurate long short-term memory (LSTM) model to perform natural processing tasks …</summary></entry><entry><title type="html">Knowledge Graph Entity Type Prediction with Relational Aggregation Graph Attention Network</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ffa6d377c7dba79fa2d32a82c76686f6.html" rel="alternate" type="text/html" title="Knowledge Graph Entity Type Prediction with Relational Aggregation Graph Attention Network" /><published>2022-06-04T01:43:25-04:00</published><updated>2022-06-04T01:43:25-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ffa6d377c7dba79fa2d32a82c76686f6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/04/ffa6d377c7dba79fa2d32a82c76686f6.html">&lt;p&gt;Most of the knowledge graph completion methods focus on inferring missing entities or relations between entities in the knowledge graphs. However, many knowledge graphs are missing entity types. The goal of entity type prediction in the knowledge graph is to infer the missing entity types that belong to entities in the knowledge graph, that is,(entity, entity type=?). At present, most knowledge graph entity type prediction models tend to model entities and entity types, which will cause the … Cites: ‪Inferring missing entity type instances for knowledge base …‬&lt;/p&gt;</content><author><name>C Zou, J An, G Li</name></author><category term="jekyll" /><category term="update" /><summary type="html">Most of the knowledge graph completion methods focus on inferring missing entities or relations between entities in the knowledge graphs. However, many knowledge graphs are missing entity types. The goal of entity type prediction in the knowledge graph is to infer the missing entity types that belong to entities in the knowledge graph, that is,(entity, entity type=?). At present, most knowledge graph entity type prediction models tend to model entities and entity types, which will cause the … Cites: ‪Inferring missing entity type instances for knowledge base …‬</summary></entry><entry><title type="html">Exploration of Black Boxes of Supervised Machine Learning Models: A Demonstration on Development of Predictive Heart Risk Score</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/053c0280bcbc868643e5d6a01e0cedb0.html" rel="alternate" type="text/html" title="Exploration of Black Boxes of Supervised Machine Learning Models: A Demonstration on Development of Predictive Heart Risk Score" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/053c0280bcbc868643e5d6a01e0cedb0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/053c0280bcbc868643e5d6a01e0cedb0.html">&lt;p&gt;Abstract Machine learning (ML) often provides applicable high-performance models to facilitate decision-makers in various fields. However, this high performance is achieved at the expense of the interpretability of these models, which has been criticized by practitioners and has become a significant hindrance in their application. Therefore, in highly sensitive decisions, black boxes of ML models are not recommended. We proposed a novel methodology that uses complex supervised ML … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/p&gt;</content><author><name>RS Mirza, AA Khan, HM Albar, N Muhammad, W Sami… - … and Neuroscience: CIN, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Machine learning (ML) often provides applicable high-performance models to facilitate decision-makers in various fields. However, this high performance is achieved at the expense of the interpretability of these models, which has been criticized by practitioners and has become a significant hindrance in their application. Therefore, in highly sensitive decisions, black boxes of ML models are not recommended. We proposed a novel methodology that uses complex supervised ML … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">Information and Communication Technologies applied to intelligent buildings: a review</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/054cba586cac74fc87baf74262f033d5.html" rel="alternate" type="text/html" title="Information and Communication Technologies applied to intelligent buildings: a review" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/054cba586cac74fc87baf74262f033d5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/054cba586cac74fc87baf74262f033d5.html">&lt;p&gt;In this paper an insight on innovative implementation strategies and operative Information and Communication Technologies (ICT) regarding Intelligent Buildings (IBs) is provided. Data-driven knowledge extraction and re-usage can be a valid source of information to study the whole building life-cycle as a process to optimize. Today, new challenges can be provided thanks to ICT and Internet of Things (IoT) paradigms that allow big data to be stored, processed and analysed. This approach … Cites: ‪COMET: Commonsense transformers for automatic knowledge …‬&lt;/p&gt;</content><author><name>F Parisi, MP Fanti, AM Mangini - Journal of Information Technology in Construction …, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper an insight on innovative implementation strategies and operative Information and Communication Technologies (ICT) regarding Intelligent Buildings (IBs) is provided. Data-driven knowledge extraction and re-usage can be a valid source of information to study the whole building life-cycle as a process to optimize. Today, new challenges can be provided thanks to ICT and Internet of Things (IoT) paradigms that allow big data to be stored, processed and analysed. This approach … Cites: ‪COMET: Commonsense transformers for automatic knowledge …‬</summary></entry><entry><title type="html">Contrast Learning Visual Attention for Multi Label Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/07b931dfa6dcb769ae16750e5dee7901.html" rel="alternate" type="text/html" title="Contrast Learning Visual Attention for Multi Label Classification" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/07b931dfa6dcb769ae16750e5dee7901</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/07b931dfa6dcb769ae16750e5dee7901.html">&lt;p&gt;Recently, as an effective way of learning latent representations, contrastive learning has been increasingly popular and successful in various domains. The success of constrastive learning in single-label classifications motivates us to leverage this learning framework to enhance distinctiveness for better performance in multi-label image classification. In this paper, we show that a direct application of contrastive learning can hardly improve in multi-label cases. Accordingly, we propose a novel … Cites: ‪Randaugment: Practical automated data augmentation with a …‬&lt;/p&gt;</content><author><name>SDDEZ Dinh, PJ Cai</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recently, as an effective way of learning latent representations, contrastive learning has been increasingly popular and successful in various domains. The success of constrastive learning in single-label classifications motivates us to leverage this learning framework to enhance distinctiveness for better performance in multi-label image classification. In this paper, we show that a direct application of contrastive learning can hardly improve in multi-label cases. Accordingly, we propose a novel … Cites: ‪Randaugment: Practical automated data augmentation with a …‬</summary></entry><entry><title type="html">The Duality of Information: Characterizing the Availability and Accuracy of Obesity Content from Health Providers and Social Media</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/092790d4d7fde4d58148720e24651656.html" rel="alternate" type="text/html" title="The Duality of Information: Characterizing the Availability and Accuracy of Obesity Content from Health Providers and Social Media" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/092790d4d7fde4d58148720e24651656</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/092790d4d7fde4d58148720e24651656.html">&lt;p&gt;Abstract Statement of the Problem: Obesity is an epidemic in the United States (US) and associated with COVID-19 severity. Yet, accessing quality obesity information involves a trade-off. Access to accurate information from clinicians may be limited in rural settings, while social media content is widely accessible with dubious accuracy. This dissertation quantifies gaps in information access and accuracy by (1) assessing geospatial access to obesity medicine “diplomates”(2) quantifying … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬&lt;/p&gt;</content><author><name>CC Pollack - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Statement of the Problem: Obesity is an epidemic in the United States (US) and associated with COVID-19 severity. Yet, accessing quality obesity information involves a trade-off. Access to accurate information from clinicians may be limited in rural settings, while social media content is widely accessible with dubious accuracy. This dissertation quantifies gaps in information access and accuracy by (1) assessing geospatial access to obesity medicine “diplomates”(2) quantifying … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬</summary></entry><entry><title type="html">Corpus-based translation and interpreting studies: A forward-looking review</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0b650274ed93cd8598fc5b95592176a8.html" rel="alternate" type="text/html" title="Corpus-based translation and interpreting studies: A forward-looking review" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0b650274ed93cd8598fc5b95592176a8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0b650274ed93cd8598fc5b95592176a8.html">&lt;p&gt;The origin of corpus-based translation studies (CBTS) can be traced back to an article entitled  Corpus Linguistics and Translation Studies: Implications and Applications (1993). In that ground-breaking paper, Mona Baker convincingly argues against the view that translated texts are unworthy of academic enquiry and advocates applying the methods and techniques of corpus linguistics to translated texts. A few years later, Shlesinger (1998) made a similar proposal for interpreting … Cites: ‪Making way in corpus-based interpreting studies‬&lt;/p&gt;</content><author><name>S Granger, MA Lefer - Extending the Scope of Corpus-based Translation …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The origin of corpus-based translation studies (CBTS) can be traced back to an article entitled Corpus Linguistics and Translation Studies: Implications and Applications (1993). In that ground-breaking paper, Mona Baker convincingly argues against the view that translated texts are unworthy of academic enquiry and advocates applying the methods and techniques of corpus linguistics to translated texts. A few years later, Shlesinger (1998) made a similar proposal for interpreting … Cites: ‪Making way in corpus-based interpreting studies‬</summary></entry><entry><title type="html">A Cooperative Lightweight Translation Algorithm Combined with Sparse-ReLU</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0bd67773c8f13ed42cb51cd81205b3bc.html" rel="alternate" type="text/html" title="A Cooperative Lightweight Translation Algorithm Combined with Sparse-ReLU" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0bd67773c8f13ed42cb51cd81205b3bc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0bd67773c8f13ed42cb51cd81205b3bc.html">&lt;p&gt;In the field of natural language processing (NLP), machine translation algorithm based on Transformer is challenging to deploy on hardware due to a large number of parameters and low parametric sparsity of the network weights. Meanwhile, the accuracy of lightweight machine translation networks also needs to be improved. To solve this problem, we first design a new activation function, Sparse-ReLU, to improve the parametric sparsity of weights and feature maps, which facilitates … Cites: ‪Random feature attention‬&lt;/p&gt;</content><author><name>X Xu, Y Liu, G Chen, J Ye, Z Li, H Lu - Computational Intelligence and Neuroscience, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In the field of natural language processing (NLP), machine translation algorithm based on Transformer is challenging to deploy on hardware due to a large number of parameters and low parametric sparsity of the network weights. Meanwhile, the accuracy of lightweight machine translation networks also needs to be improved. To solve this problem, we first design a new activation function, Sparse-ReLU, to improve the parametric sparsity of weights and feature maps, which facilitates … Cites: ‪Random feature attention‬</summary></entry><entry><title type="html">Building Vision and Language Models with Implicit Supervision and Increased Efficiency</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0c7e48dc41a7a6c990b1cd75232341f1.html" rel="alternate" type="text/html" title="Building Vision and Language Models with Implicit Supervision and Increased Efficiency" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0c7e48dc41a7a6c990b1cd75232341f1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0c7e48dc41a7a6c990b1cd75232341f1.html">&lt;p&gt;An important objective of AI is to understand real-world observations and build up interactive communication with people. The ability to interpret and react to the perception reveals the important necessity of developing such a system across both the modalities of Vision (V) and Language (L). Although there have been massive efforts on various VL tasks, eg, Image/Video Captioning, Visual Question Answering, and Textual Grounding, very few of them focus on building the VL models with … Cites: ‪Wslln: Weakly supervised natural language localization networks‬&lt;/p&gt;</content><author><name>Z Fang - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">An important objective of AI is to understand real-world observations and build up interactive communication with people. The ability to interpret and react to the perception reveals the important necessity of developing such a system across both the modalities of Vision (V) and Language (L). Although there have been massive efforts on various VL tasks, eg, Image/Video Captioning, Visual Question Answering, and Textual Grounding, very few of them focus on building the VL models with … Cites: ‪Wslln: Weakly supervised natural language localization networks‬</summary></entry><entry><title type="html">Automatic construction of real‐world‐based typing‐error test dataset</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0f7115ae10ab405cc63be6188cac968b.html" rel="alternate" type="text/html" title="Automatic construction of real‐world‐based typing‐error test dataset" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0f7115ae10ab405cc63be6188cac968b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0f7115ae10ab405cc63be6188cac968b.html">&lt;p&gt;In this study, we aim to automatically construct a test dataset for testing the performance of spelling error correction systems. The Google Web 1T corpus, which includes data on 10 quadrillion phrases, is used for this purpose. Therefore, error words used in the test dataset use error words generated by real web users. There are seven types of error words. In order to obtain the error word, a word set that appears simultaneously with the surrounding context (3‐g range) of the location of … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬&lt;/p&gt;</content><author><name>JH Lee, HC Kwon - Electronics Letters</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this study, we aim to automatically construct a test dataset for testing the performance of spelling error correction systems. The Google Web 1T corpus, which includes data on 10 quadrillion phrases, is used for this purpose. Therefore, error words used in the test dataset use error words generated by real web users. There are seven types of error words. In order to obtain the error word, a word set that appears simultaneously with the surrounding context (3‐g range) of the location of … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬</summary></entry><entry><title type="html">Shortcomings of Question Answering Based Factuality Frameworks for Error Localization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0f7c3bcd1c2a74a4130c5166fb7cdbcb.html" rel="alternate" type="text/html" title="Shortcomings of Question Answering Based Factuality Frameworks for Error Localization" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0f7c3bcd1c2a74a4130c5166fb7cdbcb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/0f7c3bcd1c2a74a4130c5166fb7cdbcb.html">&lt;p&gt;Despite recent progress in abstractive summarization, models often generate summaries with factual errors. Numerous approaches to detect these errors have been proposed, the most popular of which are question answering (QA)-based factuality metrics. These have been shown to work well at predicting summarylevel factuality and have potential to localize errors within summaries, but this latter capability has not been systematically evaluated in past research. In this paper, we … Cites: ‪Don t give me the details, just the summary! topic-aware …‬&lt;/p&gt;</content><author><name>R Kamoi, T Goyal, G Durrett</name></author><category term="jekyll" /><category term="update" /><summary type="html">Despite recent progress in abstractive summarization, models often generate summaries with factual errors. Numerous approaches to detect these errors have been proposed, the most popular of which are question answering (QA)-based factuality metrics. These have been shown to work well at predicting summarylevel factuality and have potential to localize errors within summaries, but this latter capability has not been systematically evaluated in past research. In this paper, we … Cites: ‪Don t give me the details, just the summary! topic-aware …‬</summary></entry><entry><title type="html">Breaking the Privacy Paradox: Pushing AI to the Edge with Provable Guarantees</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/12e19f62420019cefed875dde974bdde.html" rel="alternate" type="text/html" title="Breaking the Privacy Paradox: Pushing AI to the Edge with Provable Guarantees" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/12e19f62420019cefed875dde974bdde</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/12e19f62420019cefed875dde974bdde.html">&lt;p&gt;As an immense number of connected edge devices such as mobile devices, wearables, and autonomous vehicles generate massive amounts of data each day to develop machine learning based intelligent services, multiple spheres of human life, such as healthcare, entertainment, and industry, are being transformed. The traditional process for developing machine learning applications is to gather a large dataset, train a model on the data, and run the trained model on a cloud server. Due … Cites: ‪Recommender systems with social regularization‬&lt;/p&gt;</content><author><name>R Hu - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As an immense number of connected edge devices such as mobile devices, wearables, and autonomous vehicles generate massive amounts of data each day to develop machine learning based intelligent services, multiple spheres of human life, such as healthcare, entertainment, and industry, are being transformed. The traditional process for developing machine learning applications is to gather a large dataset, train a model on the data, and run the trained model on a cloud server. Due … Cites: ‪Recommender systems with social regularization‬</summary></entry><entry><title type="html">Applications of Recurrent Neural Network: Overview and Case Studies</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/12fc960e396bb3ef44feb39906a219c0.html" rel="alternate" type="text/html" title="Applications of Recurrent Neural Network: Overview and Case Studies" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/12fc960e396bb3ef44feb39906a219c0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/12fc960e396bb3ef44feb39906a219c0.html">&lt;p&gt;Recurrent neural network (RNN) architecture is popular among researchers due to many of the advantages, among which most important are processing sequences of different lengths, handling vanishing gradient, and capability to capture temporal and spatial features in its hidden state within a sequence of inputs. RNNs have simple and hybrid architectures with a number of input-output combinations. In this chapter, the versatility of RNN is depicted through two case studies. Multiclass classification of … Cites: ‪Learning phrase representations using RNN encoder-decoder for …‬&lt;/p&gt;</content><author><name>KK Dutta, S Poornima, R Sharma, D Nair, PG Ploeger - Recurrent Neural Networks</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recurrent neural network (RNN) architecture is popular among researchers due to many of the advantages, among which most important are processing sequences of different lengths, handling vanishing gradient, and capability to capture temporal and spatial features in its hidden state within a sequence of inputs. RNNs have simple and hybrid architectures with a number of input-output combinations. In this chapter, the versatility of RNN is depicted through two case studies. Multiclass classification of … Cites: ‪Learning phrase representations using RNN encoder-decoder for …‬</summary></entry><entry><title type="html">Interactively Providing Explanations for Transformer Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/1870f344b811b24636967a18b07762d9.html" rel="alternate" type="text/html" title="Interactively Providing Explanations for Transformer Language Models" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/1870f344b811b24636967a18b07762d9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/1870f344b811b24636967a18b07762d9.html">&lt;p&gt;Results. As Tab. 2 shows and expected from literature [7], interpretability comes along with a trade-off in accuracy. Still, our first experimental results demonstrate that Proto-Trex networks perform on par with non-interpretable baseline LMs. More importantly, we showcase that users can interact with ease by simply manipulating the interpretable layer, ie a prototype (cf. Fig. 1). In Tab. 1, a user manipulates a prototypical explanation successively. While the accuracy remains unchanged, the … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/p&gt;</content><author><name>F Friedrich, P Schramowski, C Tauchmann, K Kersting - arXiv e-prints, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">Results. As Tab. 2 shows and expected from literature [7], interpretability comes along with a trade-off in accuracy. Still, our first experimental results demonstrate that Proto-Trex networks perform on par with non-interpretable baseline LMs. More importantly, we showcase that users can interact with ease by simply manipulating the interpretable layer, ie a prototype (cf. Fig. 1). In Tab. 1, a user manipulates a prototypical explanation successively. While the accuracy remains unchanged, the … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">Radar technical language modeling with named entity recognition and text classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/19fc71c6c25c30a22a8a8148db75905e.html" rel="alternate" type="text/html" title="Radar technical language modeling with named entity recognition and text classification" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/19fc71c6c25c30a22a8a8148db75905e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/19fc71c6c25c30a22a8a8148db75905e.html">&lt;p&gt;This paper introduces the radar text data set (RadarTD) for technical language modeling. This data set is comprised of sentences containing radar parameters, values, and units determined from real-world values. This data set is created based on values determined from published academic research. Additionally, each statement is assigned a sentiment label and goal priority label. Preliminary investigations into the applicability of this data set are explored using the BERT … Cites: ‪Well-Read Students Learn Better: On the Importance of Pre …‬&lt;/p&gt;</content><author><name>JS Zaunegger, PG Singerman, RM Narayanan… - Radar Sensor Technology …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper introduces the radar text data set (RadarTD) for technical language modeling. This data set is comprised of sentences containing radar parameters, values, and units determined from real-world values. This data set is created based on values determined from published academic research. Additionally, each statement is assigned a sentiment label and goal priority label. Preliminary investigations into the applicability of this data set are explored using the BERT … Cites: ‪Well-Read Students Learn Better: On the Importance of Pre …‬</summary></entry><entry><title type="html">A deep learning approach for context-aware citation recommendation using rhetorical zone classification and similarity to overcome cold-start problem</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/1acd3157111c2fdfa9225827054390b4.html" rel="alternate" type="text/html" title="A deep learning approach for context-aware citation recommendation using rhetorical zone classification and similarity to overcome cold-start problem" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/1acd3157111c2fdfa9225827054390b4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/1acd3157111c2fdfa9225827054390b4.html">&lt;p&gt;In the recent decade, the citation recommendation has emerged as an important research topic due to its need for the huge size of published scientific work. Among other citation recommendation techniques, the widely used content-based filtering (CBF) exploits research articles  textual content to produce recommendations. However, CBF techniques are prone to the well-known cold-start problem. On the other hand, deep learning has shown its effectiveness in understanding the … Cites: ‪Bert: Pre-training of deep bidirectional transformers for language …‬&lt;/p&gt;</content><author><name>MA Abbas, S Ajayi, M Bilal, A Oyegoke, M Pasha… - Journal of Ambient …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In the recent decade, the citation recommendation has emerged as an important research topic due to its need for the huge size of published scientific work. Among other citation recommendation techniques, the widely used content-based filtering (CBF) exploits research articles textual content to produce recommendations. However, CBF techniques are prone to the well-known cold-start problem. On the other hand, deep learning has shown its effectiveness in understanding the … Cites: ‪Bert: Pre-training of deep bidirectional transformers for language …‬</summary></entry><entry><title type="html">DramatVis Personae: Visual Text Analytics for Identifying Social Biases in Creative Writing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/1e905a0d95aa70fa4cb33e2cfdea1c12.html" rel="alternate" type="text/html" title="DramatVis Personae: Visual Text Analytics for Identifying Social Biases in Creative Writing" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/1e905a0d95aa70fa4cb33e2cfdea1c12</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/1e905a0d95aa70fa4cb33e2cfdea1c12.html">&lt;p&gt;Implicit biases and stereotypes are often pervasive in different forms of creative writing such as novels, screenplays, and children s books. To understand the kind of biases writers are concerned about and how they mitigate those in their writing, we conducted formative interviews with nine writers. The interviews suggested that despite a writer s best interest, tracking and managing implicit biases such as a lack of agency, supporting or submissive roles, or Cites: ‪Creative writing with a machine in the loop: Case studies on …‬&lt;/p&gt;</content><author><name>MN Hoque, B Ghai, N Elmqvist - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Implicit biases and stereotypes are often pervasive in different forms of creative writing such as novels, screenplays, and children s books. To understand the kind of biases writers are concerned about and how they mitigate those in their writing, we conducted formative interviews with nine writers. The interviews suggested that despite a writer s best interest, tracking and managing implicit biases such as a lack of agency, supporting or submissive roles, or Cites: ‪Creative writing with a machine in the loop: Case studies on …‬</summary></entry><entry><title type="html">Cross-Domain Fake News Detection on Social Media: A Context-Aware Adversarial Approach</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/20e2f74a7a60cac01e26d4ded81820c1.html" rel="alternate" type="text/html" title="Cross-Domain Fake News Detection on Social Media: A Context-Aware Adversarial Approach" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/20e2f74a7a60cac01e26d4ded81820c1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/20e2f74a7a60cac01e26d4ded81820c1.html">&lt;p&gt;People nowadays increasingly consume information from social media due to its convenience and fast dissemination. However, social media also accelerate the propagation of disinformation and fake news, causing detrimental effects. Thus, detecting fake news is a critical task for benefiting individuals and society. However, it is a non-trivial task due to the expensive annotation cost and the diverse nature of news domains. Thus, it is important to exploit auxiliary information to help improve … Cites: ‪BERT: pre-training of deep bidirectional transformers for language …‬&lt;/p&gt;</content><author><name>K Shu, A Mosallanezhad, H Liu - Frontiers in Fake Media Generation and Detection, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">People nowadays increasingly consume information from social media due to its convenience and fast dissemination. However, social media also accelerate the propagation of disinformation and fake news, causing detrimental effects. Thus, detecting fake news is a critical task for benefiting individuals and society. However, it is a non-trivial task due to the expensive annotation cost and the diverse nature of news domains. Thus, it is important to exploit auxiliary information to help improve … Cites: ‪BERT: pre-training of deep bidirectional transformers for language …‬</summary></entry><entry><title type="html">Improving Ontology Alignment Using Machine Learning Techniques</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/219239f419cb6ae447593626760618d8.html" rel="alternate" type="text/html" title="Improving Ontology Alignment Using Machine Learning Techniques" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/219239f419cb6ae447593626760618d8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/219239f419cb6ae447593626760618d8.html">&lt;p&gt;Ontologies play an important role in storing and exchanging digitized data. As the need for semantic web information grows, organizations from around the globe has defined ontologies in different domains to better represent the data. But different organizations define ontologies of the same entity in their own way. Finding ontologies of the same entity in different fields and domains has become very important for unifying and improving interoperability of data between these multiple … Cites: ‪Learning to match ontologies on the semantic web‬&lt;/p&gt;</content><author><name>TM Nasim - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Ontologies play an important role in storing and exchanging digitized data. As the need for semantic web information grows, organizations from around the globe has defined ontologies in different domains to better represent the data. But different organizations define ontologies of the same entity in their own way. Finding ontologies of the same entity in different fields and domains has become very important for unifying and improving interoperability of data between these multiple … Cites: ‪Learning to match ontologies on the semantic web‬</summary></entry><entry><title type="html">Code to comment translation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/25f1a6eee99a70631cb2c7440317eb22.html" rel="alternate" type="text/html" title="Code to comment translation" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/25f1a6eee99a70631cb2c7440317eb22</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/25f1a6eee99a70631cb2c7440317eb22.html">&lt;p&gt;OUCI logo Search Analytics About укр Українською Code to comment  translation    https://doi.org/10.1145/3324884.3416546 Journal: Proceedings of the 35th IEEE/ACM   International Conference on Automated Software Engineering, 2020 Publisher: ACM   Authors: David Gros, Hariharan Sezhiyan, Prem Devanbu, Zhou Yu Funder National   Science Foundation List of references 1.Rajas Agashe , Srinivasan Iyer , and Luke   Zettlemoyer . 2019. JuICe: A Large Scale Distantly Supervised Dataset for Open Domain … Cites: ‪Know what you don t know: Unanswerable questions for SQuAD‬&lt;/p&gt;</content><author><name>D Gros, H Sezhiyan, P Devanbu, Z Yu</name></author><category term="jekyll" /><category term="update" /><summary type="html">OUCI logo Search Analytics About укр Українською Code to comment translation https://doi.org/10.1145/3324884.3416546 Journal: Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering, 2020 Publisher: ACM Authors: David Gros, Hariharan Sezhiyan, Prem Devanbu, Zhou Yu Funder National Science Foundation List of references 1.Rajas Agashe , Srinivasan Iyer , and Luke Zettlemoyer . 2019. JuICe: A Large Scale Distantly Supervised Dataset for Open Domain … Cites: ‪Know what you don t know: Unanswerable questions for SQuAD‬</summary></entry><entry><title type="html">Reconstruction of Human Faces from Voice</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/264ef5acb3b5714faf842e4826bd83ac.html" rel="alternate" type="text/html" title="Reconstruction of Human Faces from Voice" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/264ef5acb3b5714faf842e4826bd83ac</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/264ef5acb3b5714faf842e4826bd83ac.html">&lt;p&gt;Voices and faces play pivotal roles in our social interactions. Despite their different physical manifestations, voices and faces contain highly similar types of information, including linguistic information (phonemes for voice and viseme for faces), affective state, and identity characteristics (weight, gender, age, etc.). For this reason, the associations between voices and faces have gathered significant research interest in psychology, cognitive science, artificial intelligence, and many other fields. Cites: ‪Xml retrieval‬&lt;/p&gt;</content><author><name>Y Wen - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Voices and faces play pivotal roles in our social interactions. Despite their different physical manifestations, voices and faces contain highly similar types of information, including linguistic information (phonemes for voice and viseme for faces), affective state, and identity characteristics (weight, gender, age, etc.). For this reason, the associations between voices and faces have gathered significant research interest in psychology, cognitive science, artificial intelligence, and many other fields. Cites: ‪Xml retrieval‬</summary></entry><entry><title type="html">BIM-driven data augmentation method for semantic segmentation in superpoint-based deep learning network</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/289488a8827aa67335bca6a7e501b48d.html" rel="alternate" type="text/html" title="BIM-driven data augmentation method for semantic segmentation in superpoint-based deep learning network" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/289488a8827aa67335bca6a7e501b48d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/289488a8827aa67335bca6a7e501b48d.html">&lt;p&gt;This paper describes a universal workflow to synthesize point clouds containing both geometry and color information by utilizing the IFC model or its 3D geometry model to automatically generate annotated point clouds for semantic segmentation in deep learning. In our experiments, we selected 44 scenes from the S3DIS dataset to rebuild BIM models and synthesize point clouds, replaced training datasets in different proportions with synthetic point clouds, and fed the mixed datasets to a … Cites: ‪Learning data augmentation strategies for object detection‬&lt;/p&gt;</content><author><name>R Zhai, J Zou, Y He, L Meng - Automation in Construction, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper describes a universal workflow to synthesize point clouds containing both geometry and color information by utilizing the IFC model or its 3D geometry model to automatically generate annotated point clouds for semantic segmentation in deep learning. In our experiments, we selected 44 scenes from the S3DIS dataset to rebuild BIM models and synthesize point clouds, replaced training datasets in different proportions with synthetic point clouds, and fed the mixed datasets to a … Cites: ‪Learning data augmentation strategies for object detection‬</summary></entry><entry><title type="html">Genome-wide identification, characterization and expression analysis of the BRI1 gene family in Triticum aestivum L.</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/291681e4763d2a0074a1ed4b39917e00.html" rel="alternate" type="text/html" title="Genome-wide identification, characterization and expression analysis of the BRI1 gene family in Triticum aestivum L." /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/291681e4763d2a0074a1ed4b39917e00</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/291681e4763d2a0074a1ed4b39917e00.html">&lt;p&gt;Brassinosteroids (BRs) are important plant growth regulators affecting the growth and development of plants. Brassinosteroids are perceived by Brassinosteroid insensitive1 (BRI1) at the cell surface and a plethora of events occurs through brassinosteroid signalling, leading to changes in growth and developmental processes. In this study, a whole-genome investigation of the BRI1 gene family was carried out in wheat, Triticum aestivum, by using the currently available wheat … Cites: ‪BRL1 and BRL3 are novel brassinosteroid receptors that function …‬&lt;/p&gt;</content><author><name>N Sharma, P Khurana - Plant Biotechnology Reports, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Brassinosteroids (BRs) are important plant growth regulators affecting the growth and development of plants. Brassinosteroids are perceived by Brassinosteroid insensitive1 (BRI1) at the cell surface and a plethora of events occurs through brassinosteroid signalling, leading to changes in growth and developmental processes. In this study, a whole-genome investigation of the BRI1 gene family was carried out in wheat, Triticum aestivum, by using the currently available wheat … Cites: ‪BRL1 and BRL3 are novel brassinosteroid receptors that function …‬</summary></entry><entry><title type="html">iKeyCriteria: A Qualitative and Quantitative Analysis Method to Infer Key Criteria since a Systematic Literature Review for the Computing Domain</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/2ef9202a974ca8fd0cca10a67b100168.html" rel="alternate" type="text/html" title="iKeyCriteria: A Qualitative and Quantitative Analysis Method to Infer Key Criteria since a Systematic Literature Review for the Computing Domain" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/2ef9202a974ca8fd0cca10a67b100168</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/2ef9202a974ca8fd0cca10a67b100168.html">&lt;p&gt;A systematic literature review is a synthesis of the available evidence, in which a review of quantitative and qualitative aspects of primary studies is carried out, to summarize the existing information regarding a particular topic. The researchers extract key criteria from papers collected about their study area, answering research questions and conducting document analysis. Nonetheless, in some cases, these criteria are improperly justified, unknowing their true level of importance in the study … Cites: ‪Introduction to information retrieval‬&lt;/p&gt;</content><author><name>M Carrión-Toro, J Aguilar, M Santórum, M Pérez… - Data, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A systematic literature review is a synthesis of the available evidence, in which a review of quantitative and qualitative aspects of primary studies is carried out, to summarize the existing information regarding a particular topic. The researchers extract key criteria from papers collected about their study area, answering research questions and conducting document analysis. Nonetheless, in some cases, these criteria are improperly justified, unknowing their true level of importance in the study … Cites: ‪Introduction to information retrieval‬</summary></entry><entry><title type="html">Explaining CNN Classifications by Propositional Rules Generated from DCT Feature Maps</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/33e173a3a445cc33087e6ef7075399b0.html" rel="alternate" type="text/html" title="Explaining CNN Classifications by Propositional Rules Generated from DCT Feature Maps" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/33e173a3a445cc33087e6ef7075399b0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/33e173a3a445cc33087e6ef7075399b0.html">&lt;p&gt;So far, propositional rules have been extracted from Multi Layer Perceptrons to explain how they achieve to classify data. This type of explanation technique is much less prevalent with deep models, such as convolutional neural networks (CNNs). In this work, we propose to transfer the feature maps generated by a CNN to a simpler neural network model from which propositional rules have been generated. To enable the execution of our rule extraction algorithm in a reasonable time, the … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/p&gt;</content><author><name>G Bologna - Bio-inspired Systems and Applications: from Robotics …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">So far, propositional rules have been extracted from Multi Layer Perceptrons to explain how they achieve to classify data. This type of explanation technique is much less prevalent with deep models, such as convolutional neural networks (CNNs). In this work, we propose to transfer the feature maps generated by a CNN to a simpler neural network model from which propositional rules have been generated. To enable the execution of our rule extraction algorithm in a reasonable time, the … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">MaChAmp at SemEval-2022 tasks 2, 3, 4, 6, 10, 11, and 12: Multi-task Multi-lingual Learning for a Pre-selected Set of Semantic Datasets</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/34daa5729ae26407e505c82b2258a556.html" rel="alternate" type="text/html" title="MaChAmp at SemEval-2022 tasks 2, 3, 4, 6, 10, 11, and 12: Multi-task Multi-lingual Learning for a Pre-selected Set of Semantic Datasets" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/34daa5729ae26407e505c82b2258a556</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/34daa5729ae26407e505c82b2258a556.html">&lt;p&gt;Previous work on multi-task learning in Natural Language Processing (NLP) often incorporated carefully selected tasks as well as carefully tuning of architectures to share information across tasks. Recently, it has shown that for autoregressive language models, a multitask second pre-training step on a wide variety of NLP tasks leads to a set of parameters that more easily adapt for other NLP tasks. In this paper, we examine whether a similar setup can be used in autoencoder language models … Cites: ‪Exploring and predicting transferability across nlp tasks‬&lt;/p&gt;</content><author><name>R van der Goot - Proceedings of the 16th International Workshop on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Previous work on multi-task learning in Natural Language Processing (NLP) often incorporated carefully selected tasks as well as carefully tuning of architectures to share information across tasks. Recently, it has shown that for autoregressive language models, a multitask second pre-training step on a wide variety of NLP tasks leads to a set of parameters that more easily adapt for other NLP tasks. In this paper, we examine whether a similar setup can be used in autoencoder language models … Cites: ‪Exploring and predicting transferability across nlp tasks‬</summary></entry><entry><title type="html">Classification Between Rumors and Explanations of Rumors Based on Common and Difference Subsequences of Sentences</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/378e6aa85d48903144af9a0708fd95be.html" rel="alternate" type="text/html" title="Classification Between Rumors and Explanations of Rumors Based on Common and Difference Subsequences of Sentences" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/378e6aa85d48903144af9a0708fd95be</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/378e6aa85d48903144af9a0708fd95be.html">&lt;p&gt;Preventing explosion of rumors on the Internet asks for a quick automatic detection mechanism that can detect rumors according to the given true information. Previous automatic rumors detection models are mainly built by training a supervised classification model on a labeled dataset containing rumor samples and true information samples. However, in many real cases, there is only one short piece of available true information sample given by an authority in form of an explanation or a … Cites: ‪Fact or fiction: Verifying scientific claims‬&lt;/p&gt;</content><author><name>X Sun, J Zhang, Y Sang - International Conference on Intelligent Information …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Preventing explosion of rumors on the Internet asks for a quick automatic detection mechanism that can detect rumors according to the given true information. Previous automatic rumors detection models are mainly built by training a supervised classification model on a labeled dataset containing rumor samples and true information samples. However, in many real cases, there is only one short piece of available true information sample given by an authority in form of an explanation or a … Cites: ‪Fact or fiction: Verifying scientific claims‬</summary></entry><entry><title type="html">Mutual match for semi-supervised online evolutive learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3ab91ff1d614ea107a3c9f675cf843b2.html" rel="alternate" type="text/html" title="Mutual match for semi-supervised online evolutive learning" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3ab91ff1d614ea107a3c9f675cf843b2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3ab91ff1d614ea107a3c9f675cf843b2.html">&lt;p&gt;Semi-supervised learning (SSL) can utilize a large amount of unlabeled data for self-training and continuous evolution with only a few annotations. This feature makes SSL a potential candidate for dealing with data from changing and real-time environments, where deep-learning models need to be adapting to evolving and nonstable (non-iid) data streams from the real world, ie, online evolutive scenarios. However, state-of-the-art SSL methods often have complex model design … Cites: ‪Meta pseudo labels‬&lt;/p&gt;</content><author><name>D Li, X Zhu, L Song - Applied Intelligence, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Semi-supervised learning (SSL) can utilize a large amount of unlabeled data for self-training and continuous evolution with only a few annotations. This feature makes SSL a potential candidate for dealing with data from changing and real-time environments, where deep-learning models need to be adapting to evolving and nonstable (non-iid) data streams from the real world, ie, online evolutive scenarios. However, state-of-the-art SSL methods often have complex model design … Cites: ‪Meta pseudo labels‬</summary></entry><entry><title type="html">Localization-based active learning (LOCAL) for object detection in 3D point clouds</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3cc1138607bf2767d18ee9451c3db13c.html" rel="alternate" type="text/html" title="Localization-based active learning (LOCAL) for object detection in 3D point clouds" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3cc1138607bf2767d18ee9451c3db13c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3cc1138607bf2767d18ee9451c3db13c.html">&lt;p&gt;Deep learning-based object detection and classification in 3D point clouds has numerous applications including defense, autonomous driving, and augmented reality. A challenge in applying deep learning to point clouds is the frequent scarcity of labeled data. Often, one must manually label a large quantity of data for the model to be useful in application. To overcome this challenge, active learning provides a means of minimizing the manual labeling required. The crux of active learning … Cites: ‪Margin-based active learning for structured output spaces‬&lt;/p&gt;</content><author><name>A Moses, S Jakkampudi, C Danner, D Biega - Geospatial Informatics XII, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning-based object detection and classification in 3D point clouds has numerous applications including defense, autonomous driving, and augmented reality. A challenge in applying deep learning to point clouds is the frequent scarcity of labeled data. Often, one must manually label a large quantity of data for the model to be useful in application. To overcome this challenge, active learning provides a means of minimizing the manual labeling required. The crux of active learning … Cites: ‪Margin-based active learning for structured output spaces‬</summary></entry><entry><title type="html">Journal: International Journal on Semantic Web and Information Systems, 2022, № 1, p. 1-20</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3ead481dbea4145f3a974fbf70067852.html" rel="alternate" type="text/html" title="Journal: International Journal on Semantic Web and Information Systems, 2022, № 1, p. 1-20" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3ead481dbea4145f3a974fbf70067852</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3ead481dbea4145f3a974fbf70067852.html">&lt;p&gt;Abstract Document Management Systems (DMS) are used for decades to store large amounts of information in textual form. Their technology paradigm is based on storing vast quantities of textual information enriched with metadata to support searchability. However, this exhibits limitations as it treats textual information as black box and is based exclusively on user-created metadata, a process that suffers from quality and completeness shortcomings. The use of knowledge graphs in DMS … Cites: ‪Multilingual autoregressive entity linking‬&lt;/p&gt;</content><author><name>N Stylianou, D Vlachava, I Konstantinidis… - International Journal on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Document Management Systems (DMS) are used for decades to store large amounts of information in textual form. Their technology paradigm is based on storing vast quantities of textual information enriched with metadata to support searchability. However, this exhibits limitations as it treats textual information as black box and is based exclusively on user-created metadata, a process that suffers from quality and completeness shortcomings. The use of knowledge graphs in DMS … Cites: ‪Multilingual autoregressive entity linking‬</summary></entry><entry><title type="html">Investigating Transfer Learning in Graph Neural Networks. Electronics 2022, 11, 1202</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3fc70a7b321f61477dcd8579b101f56c.html" rel="alternate" type="text/html" title="Investigating Transfer Learning in Graph Neural Networks. Electronics 2022, 11, 1202" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3fc70a7b321f61477dcd8579b101f56c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3fc70a7b321f61477dcd8579b101f56c.html">&lt;p&gt;Graph neural networks (GNNs) build on the success of deep learning models by extending them for use in graph spaces. Transfer learning has proven extremely successful for traditional deep learning problems, resulting in faster training and improved performance. Despite the increasing interest in GNNs and their use cases, there is little research on their transferability. This research demonstrates that transfer learning is effective with GNNs, and describes how source tasks and the choice of … Cites: ‪Strategies for pre-training graph neural networks‬&lt;/p&gt;</content><author><name>N Kooverjee, S James, T van Zyl - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Graph neural networks (GNNs) build on the success of deep learning models by extending them for use in graph spaces. Transfer learning has proven extremely successful for traditional deep learning problems, resulting in faster training and improved performance. Despite the increasing interest in GNNs and their use cases, there is little research on their transferability. This research demonstrates that transfer learning is effective with GNNs, and describes how source tasks and the choice of … Cites: ‪Strategies for pre-training graph neural networks‬</summary></entry><entry><title type="html">Wojood: Nested arabic named entity corpus and recognition using bert</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3fdbe1891e00c6f6c4b97c1de11f55f5.html" rel="alternate" type="text/html" title="Wojood: Nested arabic named entity corpus and recognition using bert" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3fdbe1891e00c6f6c4b97c1de11f55f5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/3fdbe1891e00c6f6c4b97c1de11f55f5.html">&lt;p&gt;This paper presents Wojood, a corpus for Arabic nested Named Entity Recognition (NER). Nested entities occur when one entity mention is embedded inside another entity mention. Wojood consists of about 550K Modern Standard Arabic (MSA) and dialect tokens that are manually annotated with 21 entity types including person, organization, location, event and date. More importantly, the corpus is annotated with nested entities instead of the more common flat annotations. The data contains about … Cites: ‪Bert: Pre-training of deep bidirectional transformers for language …‬&lt;/p&gt;</content><author><name>M Jarrar, M Khalilia, S Ghanem - Proceedings of the International Conference on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper presents Wojood, a corpus for Arabic nested Named Entity Recognition (NER). Nested entities occur when one entity mention is embedded inside another entity mention. Wojood consists of about 550K Modern Standard Arabic (MSA) and dialect tokens that are manually annotated with 21 entity types including person, organization, location, event and date. More importantly, the corpus is annotated with nested entities instead of the more common flat annotations. The data contains about … Cites: ‪Bert: Pre-training of deep bidirectional transformers for language …‬</summary></entry><entry><title type="html">Wire Point Cloud Instance Segmentation from RGBD Imagery with Mask R-CNN</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/468ae8dafbe0ff84b1775280ae494c78.html" rel="alternate" type="text/html" title="Wire Point Cloud Instance Segmentation from RGBD Imagery with Mask R-CNN" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/468ae8dafbe0ff84b1775280ae494c78</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/468ae8dafbe0ff84b1775280ae494c78.html">&lt;p&gt;Perception of the shapes of deforming objects like wires enables their monitoring and manipulation by autonomous robots. This paper presents detection, classification, and instance segmentation of deformable wires from a cluttered scene in RGBD imagery. This work uses the Detectron2 implementation of Mask R-CNN trained with the PointRend mask head on the UIUCWires dataset as the framework for wire instance segmentation on RGB imagery, a method demonstrated to perform … Cites: ‪Simple copy-paste is a strong data augmentation method for …‬&lt;/p&gt;</content><author><name>H Dinkel, J Xiang, H Zhao, B Coltin, T Smith, T Bretl</name></author><category term="jekyll" /><category term="update" /><summary type="html">Perception of the shapes of deforming objects like wires enables their monitoring and manipulation by autonomous robots. This paper presents detection, classification, and instance segmentation of deformable wires from a cluttered scene in RGBD imagery. This work uses the Detectron2 implementation of Mask R-CNN trained with the PointRend mask head on the UIUCWires dataset as the framework for wire instance segmentation on RGB imagery, a method demonstrated to perform … Cites: ‪Simple copy-paste is a strong data augmentation method for …‬</summary></entry><entry><title type="html">Multi-view data integration by linear and non-linear dimensionality reduction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/47fa75ea399b8def9eacff6463dd63cf.html" rel="alternate" type="text/html" title="Multi-view data integration by linear and non-linear dimensionality reduction" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/47fa75ea399b8def9eacff6463dd63cf</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/47fa75ea399b8def9eacff6463dd63cf.html">&lt;p&gt;Technological advancements and global data sharing allow for the collection of information from multiple sources on the same samples. Such data are usually referred to as multi-view data, and the dataset from each source as data-view. Statistical properties, such as heterogeneity and noise, make the analysis of multi-view data challenging. An integrative analysis of the different data-views, provides an improved and more accurate understanding of the data. In this thesis, both linear and … Cites: ‪Principles of data integration‬&lt;/p&gt;</content><author><name>T Rodosthenous - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Technological advancements and global data sharing allow for the collection of information from multiple sources on the same samples. Such data are usually referred to as multi-view data, and the dataset from each source as data-view. Statistical properties, such as heterogeneity and noise, make the analysis of multi-view data challenging. An integrative analysis of the different data-views, provides an improved and more accurate understanding of the data. In this thesis, both linear and … Cites: ‪Principles of data integration‬</summary></entry><entry><title type="html">A Systematic Review of Deep Learning Techniques for Semantic Image Segmentation: Methods, Future Directions, and Challenges</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/515c362dbe146f3c2c25bc003ecf99bc.html" rel="alternate" type="text/html" title="A Systematic Review of Deep Learning Techniques for Semantic Image Segmentation: Methods, Future Directions, and Challenges" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/515c362dbe146f3c2c25bc003ecf99bc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/515c362dbe146f3c2c25bc003ecf99bc.html">&lt;p&gt;The advancements in the methods and techniques in the field of computer vision have enabled numerous applications based on understanding and analysis of image data. Moreover, deep learning has brought a massive shift in image analysis, thereby attracting the attention of researchers worldwide. Many real-life application areas used the image segmentation techniques for the identification of different regions in an image and classify them into clusters depending upon the similarity. Many … Cites: ‪Espnet: Efficient spatial pyramid of dilated convolutions for …‬&lt;/p&gt;</content><author><name>AS Pall, N Sharma, KP Sharma, V Wadhwa - Handbook of Research on Machine Learning</name></author><category term="jekyll" /><category term="update" /><summary type="html">The advancements in the methods and techniques in the field of computer vision have enabled numerous applications based on understanding and analysis of image data. Moreover, deep learning has brought a massive shift in image analysis, thereby attracting the attention of researchers worldwide. Many real-life application areas used the image segmentation techniques for the identification of different regions in an image and classify them into clusters depending upon the similarity. Many … Cites: ‪Espnet: Efficient spatial pyramid of dilated convolutions for …‬</summary></entry><entry><title type="html">Knowledge-Based Dialogue System for the Ageing Support on Daily Activities</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/52c2f339fa755c23a66b9de514f1370b.html" rel="alternate" type="text/html" title="Knowledge-Based Dialogue System for the Ageing Support on Daily Activities" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/52c2f339fa755c23a66b9de514f1370b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/52c2f339fa755c23a66b9de514f1370b.html">&lt;p&gt;With the increasing digitalization of society, we need to use a wide range of digitalized services in our daily activities such as searching for events in a calendar, checking the weather forecast, receiving guidance for completing certain tasks or recommendations for certain topics. Assistance for digital services is often needed, and particularly in the ageing stages, support for these tasks from a coach can become valuable. We introduce our work on a dialogue system that is part of a digital … Cites: ‪Grounded conversation generation as guided traverses in …‬&lt;/p&gt;</content><author><name>J Vizcarra, K Jokinen - International Conference on Human-Computer …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">With the increasing digitalization of society, we need to use a wide range of digitalized services in our daily activities such as searching for events in a calendar, checking the weather forecast, receiving guidance for completing certain tasks or recommendations for certain topics. Assistance for digital services is often needed, and particularly in the ageing stages, support for these tasks from a coach can become valuable. We introduce our work on a dialogue system that is part of a digital … Cites: ‪Grounded conversation generation as guided traverses in …‬</summary></entry><entry><title type="html">Frontal face reconstruction based on detail identification, variable scale self-attention and flexible skip connection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/59a188e9e31769211079b4f8616f7d3b.html" rel="alternate" type="text/html" title="Frontal face reconstruction based on detail identification, variable scale self-attention and flexible skip connection" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/59a188e9e31769211079b4f8616f7d3b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/59a188e9e31769211079b4f8616f7d3b.html">&lt;p&gt;Reconstruction of the frontal face from the profile is of great significance for face recognition in complex scenes. The existing mainstream methods of face reconstruction, such as FF-GAN, CAPG-GAN, TP-GAN, etc., have made good progresses on improving the generator network, but fewer considerations on the identification of face details and the extraction of spatial context features. To address the problem, we propose the frontal face reconstruction based on the detail … Cites: ‪Neural machine translation by jointly learning to align and translate‬&lt;/p&gt;</content><author><name>H Luo, S Cen, Q Ding, X Chen - Neural Computing and Applications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Reconstruction of the frontal face from the profile is of great significance for face recognition in complex scenes. The existing mainstream methods of face reconstruction, such as FF-GAN, CAPG-GAN, TP-GAN, etc., have made good progresses on improving the generator network, but fewer considerations on the identification of face details and the extraction of spatial context features. To address the problem, we propose the frontal face reconstruction based on the detail … Cites: ‪Neural machine translation by jointly learning to align and translate‬</summary></entry><entry><title type="html">ARGOS: Adaptive Recognition and Gated Operation System for Real-Time Vision Applications</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/5eed6249ae8df3e4d468f00f9cb11265.html" rel="alternate" type="text/html" title="ARGOS: Adaptive Recognition and Gated Operation System for Real-Time Vision Applications" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/5eed6249ae8df3e4d468f00f9cb11265</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/5eed6249ae8df3e4d468f00f9cb11265.html">&lt;p&gt;Deep neural network-based methods have been proved to achieve outstanding performance on object detection and classification tasks. Deep neural networks follow the``deeper model with deeper confidence  belief to gain a higher recognition accuracy. However, reducing these networks  computational costs remains a challenge, which impedes their deployment on embedded devices. For instance, the intersection management of Connected Autonomous Vehicles (CAVs) requires … Cites: ‪Adaframe: Adaptive frame selection for fast video recognition‬&lt;/p&gt;</content><author><name>MF Bajestani - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep neural network-based methods have been proved to achieve outstanding performance on object detection and classification tasks. Deep neural networks follow the``deeper model with deeper confidence belief to gain a higher recognition accuracy. However, reducing these networks computational costs remains a challenge, which impedes their deployment on embedded devices. For instance, the intersection management of Connected Autonomous Vehicles (CAVs) requires … Cites: ‪Adaframe: Adaptive frame selection for fast video recognition‬</summary></entry><entry><title type="html">Weak Supervision for Information Extraction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/603b6cad8ffaebc15959104a4728c5be.html" rel="alternate" type="text/html" title="Weak Supervision for Information Extraction" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/603b6cad8ffaebc15959104a4728c5be</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/603b6cad8ffaebc15959104a4728c5be.html">&lt;p&gt;Deep learning models have gained much success in Information Extraction (IE) from text. Such models usually require a large number of labeled samples to train. Since human annotation can be difficult and time consuming, automatically generated weak supervision is widely leveraged. Cites: ‪Web-scale information extraction in knowitall: (preliminary results)‬&lt;/p&gt;</content><author><name>H Dai - 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning models have gained much success in Information Extraction (IE) from text. Such models usually require a large number of labeled samples to train. Since human annotation can be difficult and time consuming, automatically generated weak supervision is widely leveraged. Cites: ‪Web-scale information extraction in knowitall: (preliminary results)‬</summary></entry><entry><title type="html">CATEGORY: cs. AI [cs. AI, cs. CV, cs. LG] HIGHLIGHT: In this paper, we establish experimental baselines, protocols, and forward and backward transfer metrics to …</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/6808beeff7a0676d3140590ae56ae6bb.html" rel="alternate" type="text/html" title="CATEGORY: cs. AI [cs. AI, cs. CV, cs. LG] HIGHLIGHT: In this paper, we establish experimental baselines, protocols, and forward and backward transfer metrics to …" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/6808beeff7a0676d3140590ae56ae6bb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/6808beeff7a0676d3140590ae56ae6bb.html">&lt;p&gt;block lawrance - CSDN 精华内容 下载资源 问答 我要提问 计算机视觉论文-2021-03-10   千次阅读 2021-03-10 09:10:08 本专栏是计算机视觉方向论文收集积累，时间：2021年3月  9日，来源：paper digest 欢迎关注原创公众号 [计算机视觉联盟]，回复 [西瓜书手推笔记] 可  获取我的机器学习纯手推笔记！ 直达笔记地址：机器学习手推笔记（GitHub地址） 1, TITLE:   Selective Replay Enhances Learning in Online Continual Analogical Reasoning   AUTHORS: Tyler L. Hayes ; Christopher Kanan CATEGORY: cs.AI [cs.AI, cs.CV, cs.LG] … Cites: ‪Aspect level sentiment classification with deep memory network‬&lt;/p&gt;</content><author><name>T Hiippala, JA Bateman, Z Huang, TB Norris, P Wang</name></author><category term="jekyll" /><category term="update" /><summary type="html">block lawrance - CSDN 精华内容 下载资源 问答 我要提问 计算机视觉论文-2021-03-10 千次阅读 2021-03-10 09:10:08 本专栏是计算机视觉方向论文收集积累，时间：2021年3月 9日，来源：paper digest 欢迎关注原创公众号 [计算机视觉联盟]，回复 [西瓜书手推笔记] 可 获取我的机器学习纯手推笔记！ 直达笔记地址：机器学习手推笔记（GitHub地址） 1, TITLE: Selective Replay Enhances Learning in Online Continual Analogical Reasoning AUTHORS: Tyler L. Hayes ; Christopher Kanan CATEGORY: cs.AI [cs.AI, cs.CV, cs.LG] … Cites: ‪Aspect level sentiment classification with deep memory network‬</summary></entry><entry><title type="html">Are machines radically contextualist?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/6f7de65f19ba6dfc4d06e545a824bb03.html" rel="alternate" type="text/html" title="Are machines radically contextualist?" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/6f7de65f19ba6dfc4d06e545a824bb03</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/6f7de65f19ba6dfc4d06e545a824bb03.html">&lt;p&gt;In this article, I describe a novel position on the semantics of artificial intelligence. I present a problem for the current artificial neural networks used in machine learning, specifically with relation to natural language tasks. I then propose that from a metasemantic level, meaning in machines can best be interpreted as radically contextualist. Finally, I consider what this might mean for human‐level semantic competence from a comparative perspective. Cites: ‪Bringing machine learning and compositional semantics together‬&lt;/p&gt;</content><author><name>RM Nefdt - Mind &amp; Language, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this article, I describe a novel position on the semantics of artificial intelligence. I present a problem for the current artificial neural networks used in machine learning, specifically with relation to natural language tasks. I then propose that from a metasemantic level, meaning in machines can best be interpreted as radically contextualist. Finally, I consider what this might mean for human‐level semantic competence from a comparative perspective. Cites: ‪Bringing machine learning and compositional semantics together‬</summary></entry><entry><title type="html">User intent classification in noisy texts: an investigation on neural language models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/78479c86f4becca8998530d1b0ef98a8.html" rel="alternate" type="text/html" title="User intent classification in noisy texts: an investigation on neural language models" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/78479c86f4becca8998530d1b0ef98a8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/78479c86f4becca8998530d1b0ef98a8.html">&lt;p&gt;User-generated content is a fundamental source of information to aid the decision-making in several tasks, such as online marketing and follow-up intent response. Nonetheless, they also present several challenges, as the utterance sentences are short, noisy, lack proper grammar, and relate to multiple classes. Classification from texts has been widely addressed in the last years by extracting features from pretrained language models. However, because of the noisy nature of utterance … Cites: ‪Bert: Pre-training of deep bidirectional transformers for language …‬&lt;/p&gt;</content><author><name>P Blackman Sphaier, A Paes - Neural Computing and Applications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">User-generated content is a fundamental source of information to aid the decision-making in several tasks, such as online marketing and follow-up intent response. Nonetheless, they also present several challenges, as the utterance sentences are short, noisy, lack proper grammar, and relate to multiple classes. Classification from texts has been widely addressed in the last years by extracting features from pretrained language models. However, because of the noisy nature of utterance … Cites: ‪Bert: Pre-training of deep bidirectional transformers for language …‬</summary></entry><entry><title type="html">Explaining and Evaluating Deep Neural Networks in Natural Language Processing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/796f8238b911a6a2b8cc64268ea28099.html" rel="alternate" type="text/html" title="Explaining and Evaluating Deep Neural Networks in Natural Language Processing" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/796f8238b911a6a2b8cc64268ea28099</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/796f8238b911a6a2b8cc64268ea28099.html">&lt;p&gt;Abstract Deep Neural Networks such as Recurrent Neural Networks and Transformer models are widely adopted for their superior performance in many natural language processing (NLP) applications, but they remain largely black-box which can lead to unwanted bias and unrobust behaviors. To discover, diagnose and evaluate these issues, it is essential to make NLP systems accountable, reliable and most importantly, explainable. Explainability tools and methods can be leveraged by NLP … Cites: ‪Well-Read Students Learn Better: On the Importance of Pre …‬&lt;/p&gt;</content><author><name>K Lu - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Deep Neural Networks such as Recurrent Neural Networks and Transformer models are widely adopted for their superior performance in many natural language processing (NLP) applications, but they remain largely black-box which can lead to unwanted bias and unrobust behaviors. To discover, diagnose and evaluate these issues, it is essential to make NLP systems accountable, reliable and most importantly, explainable. Explainability tools and methods can be leveraged by NLP … Cites: ‪Well-Read Students Learn Better: On the Importance of Pre …‬</summary></entry><entry><title type="html">Anomaly Detection in Shared Spectrum</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/7dfb7670b26ee93cd262500defdf1e6e.html" rel="alternate" type="text/html" title="Anomaly Detection in Shared Spectrum" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/7dfb7670b26ee93cd262500defdf1e6e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/7dfb7670b26ee93cd262500defdf1e6e.html">&lt;p&gt;Demand for wireless communication devices has been growing relentlessly since the advent of mobile communication. Even though spectral efficiency and throughput keep increasing, consumer demand continues to seemingly outpace that growth. Spectrum sharing is becoming a more attractive solution to solving various capacity constraints as the resulting perceived spectrum scarcity can mostly be attributed to inefficient spectrum management. The observed shift from exclusivelylicensed … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/p&gt;</content><author><name>S Tschimben - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Demand for wireless communication devices has been growing relentlessly since the advent of mobile communication. Even though spectral efficiency and throughput keep increasing, consumer demand continues to seemingly outpace that growth. Spectrum sharing is becoming a more attractive solution to solving various capacity constraints as the resulting perceived spectrum scarcity can mostly be attributed to inefficient spectrum management. The observed shift from exclusivelylicensed … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">Taming Confusions in Software Engineering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/7f0a385dcfc13dfea403c7ea8b9890b8.html" rel="alternate" type="text/html" title="Taming Confusions in Software Engineering" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/7f0a385dcfc13dfea403c7ea8b9890b8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/7f0a385dcfc13dfea403c7ea8b9890b8.html">&lt;p&gt;Software Engineering (SE) researchers and practitioners struggle to learn effective quality assurance practices from project data. A repeated result is that data is processed poorly. As a result, developers make contradictory conclusions about what most effects (eg) defects to development time. Also, researchers keep relying on decades-old truisms about software development, even when data does not support those truisms. Cites: ‪The unreasonable effectiveness of data‬&lt;/p&gt;</content><author><name>SN Chandrasekaran - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Software Engineering (SE) researchers and practitioners struggle to learn effective quality assurance practices from project data. A repeated result is that data is processed poorly. As a result, developers make contradictory conclusions about what most effects (eg) defects to development time. Also, researchers keep relying on decades-old truisms about software development, even when data does not support those truisms. Cites: ‪The unreasonable effectiveness of data‬</summary></entry><entry><title type="html">Adversarial Defense with Secret Key</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/7f6a7b43fa1dca9fb4e65d41b1ee8df3.html" rel="alternate" type="text/html" title="Adversarial Defense with Secret Key" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/7f6a7b43fa1dca9fb4e65d41b1ee8df3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/7f6a7b43fa1dca9fb4e65d41b1ee8df3.html">&lt;p&gt;Adaptive attacks are known to defeat most adversarial defenses including state-of-the-art ones, so conventional defenses either reduce the classification accuracy or are completely broken. To overcome this problem, an encryption-inspired adversarial defense with a secret key was proposed motivated by image encryption methods. The adversarial defense with a secret key achieves high classification performance even when adaptive attacks were carried out. The adversarial defense was also … Cites: ‪Certified defenses against adversarial examples‬&lt;/p&gt;</content><author><name>MM April Pyone, H Kiya - Frontiers in Fake Media Generation and Detection, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Adaptive attacks are known to defeat most adversarial defenses including state-of-the-art ones, so conventional defenses either reduce the classification accuracy or are completely broken. To overcome this problem, an encryption-inspired adversarial defense with a secret key was proposed motivated by image encryption methods. The adversarial defense with a secret key achieves high classification performance even when adaptive attacks were carried out. The adversarial defense was also … Cites: ‪Certified defenses against adversarial examples‬</summary></entry><entry><title type="html">Implicitly Supervised Neural Question Answering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/7fa697e347481021fb3de2d6d136a102.html" rel="alternate" type="text/html" title="Implicitly Supervised Neural Question Answering" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/7fa697e347481021fb3de2d6d136a102</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/7fa697e347481021fb3de2d6d136a102.html">&lt;p&gt;How to teach a machine to understand natural language? This question is a long-standing challenge in Artificial Intelligence. Several tasks are designed to measure the progress of this challenge. Question Answering is one such task that evaluates a machine s ability to understand natural language, where it reads a passage of text or an image and answers comprehension questions. In recent years, the development of transformer-based language models and large-scale human-annotated datasets … Cites: ‪Improving question answering by commonsense-based pre-training‬&lt;/p&gt;</content><author><name>P Banerjee - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">How to teach a machine to understand natural language? This question is a long-standing challenge in Artificial Intelligence. Several tasks are designed to measure the progress of this challenge. Question Answering is one such task that evaluates a machine s ability to understand natural language, where it reads a passage of text or an image and answers comprehension questions. In recent years, the development of transformer-based language models and large-scale human-annotated datasets … Cites: ‪Improving question answering by commonsense-based pre-training‬</summary></entry><entry><title type="html">Sparse Oblique Decision Trees: A Tool to Interpret Natural Language Processing Datasets</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/86f43602d6b0e6d1c49e80864ea42094.html" rel="alternate" type="text/html" title="Sparse Oblique Decision Trees: A Tool to Interpret Natural Language Processing Datasets" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/86f43602d6b0e6d1c49e80864ea42094</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/86f43602d6b0e6d1c49e80864ea42094.html">&lt;p&gt;Natural language processing datasets, for example for document classification or sentiment analysis, are characterized by sparse, high-dimensional feature vectors, often based on bag-of-words approaches. Such datasets contain a wealth of information not just about the predictive task in question, but also about the language itself, and it is of interest to do data mining on such data. While one way to do this is to use standard exploratory data analysis techniques such as clustering or … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/p&gt;</content><author><name>SS Hada, MA Carreira-Perpinán</name></author><category term="jekyll" /><category term="update" /><summary type="html">Natural language processing datasets, for example for document classification or sentiment analysis, are characterized by sparse, high-dimensional feature vectors, often based on bag-of-words approaches. Such datasets contain a wealth of information not just about the predictive task in question, but also about the language itself, and it is of interest to do data mining on such data. While one way to do this is to use standard exploratory data analysis techniques such as clustering or … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">Heat-Induced Oxidative Stress in Plants: Consequences and Survival Mechanisms</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/8cabc7714344cfe8694e7638466d81d8.html" rel="alternate" type="text/html" title="Heat-Induced Oxidative Stress in Plants: Consequences and Survival Mechanisms" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/8cabc7714344cfe8694e7638466d81d8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/8cabc7714344cfe8694e7638466d81d8.html">&lt;p&gt;The United Nations has projected that the population across the globe would grow to 9.1 billion by 2050 at a rate of 34% from as-of-today 6.8 billion. To meet the food demand of the increasing population across the globe, it is important to increase the sustainable crop productivity under the changing climate conditions. Recently, the Intergovernmental Panel on Climate Change reported that abiotic stresses such as heat, salinity, water-logging, drought, heavy metals, cold, and ultraviolet rays are … Cites: ‪BRL1 and BRL3 are novel brassinosteroid receptors that function …‬&lt;/p&gt;</content><author><name>A Hossain, MN Alam, Z Chan, AEL Sabagh, S Fahad… - … of Plant Production in the Era of …</name></author><category term="jekyll" /><category term="update" /><summary type="html">The United Nations has projected that the population across the globe would grow to 9.1 billion by 2050 at a rate of 34% from as-of-today 6.8 billion. To meet the food demand of the increasing population across the globe, it is important to increase the sustainable crop productivity under the changing climate conditions. Recently, the Intergovernmental Panel on Climate Change reported that abiotic stresses such as heat, salinity, water-logging, drought, heavy metals, cold, and ultraviolet rays are … Cites: ‪BRL1 and BRL3 are novel brassinosteroid receptors that function …‬</summary></entry><entry><title type="html">A Framework for Automated Discovery and Analysis of Suspicious Trade Records</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/8df00516cc6033b6f3e7e7b35fae69bc.html" rel="alternate" type="text/html" title="A Framework for Automated Discovery and Analysis of Suspicious Trade Records" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/8df00516cc6033b6f3e7e7b35fae69bc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/8df00516cc6033b6f3e7e7b35fae69bc.html">&lt;p&gt;Illegal logging and timber trade presents a persistent threat to global biodiversity and national security due to its ties with illicit financial flows, and causes revenue loss. The scale of global commerce in timber and associated products, combined with the complexity and geographical spread of the supply chain entities present a non-trivial challenge in detecting such transactions. International shipment records, specifically those containing bill of lading is a key source of data which can be used to detect … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/p&gt;</content><author><name>D Datta - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Illegal logging and timber trade presents a persistent threat to global biodiversity and national security due to its ties with illicit financial flows, and causes revenue loss. The scale of global commerce in timber and associated products, combined with the complexity and geographical spread of the supply chain entities present a non-trivial challenge in detecting such transactions. International shipment records, specifically those containing bill of lading is a key source of data which can be used to detect … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">ASPECT-BASED SENTIMENT ANALYSIS ON TEXT-BASED REVIEWS USING DEEP NEURAL NETWORKS AND EMBEDDING MODELS</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/92d4b8aeed370ea08646e987415e5dcd.html" rel="alternate" type="text/html" title="ASPECT-BASED SENTIMENT ANALYSIS ON TEXT-BASED REVIEWS USING DEEP NEURAL NETWORKS AND EMBEDDING MODELS" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/92d4b8aeed370ea08646e987415e5dcd</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/92d4b8aeed370ea08646e987415e5dcd.html">&lt;p&gt;People are able to share and evaluate their opinion by using social media networks on the internet, a phenomenon that has taken off rapidly. The challenge is finding, monitoring, and extracting information manually from all opinion websites to help improve services or make decisions. A large section of each website is devoted to opinionated text. In addition, different experts hold different opinions. Computing the overall sentiment expressed for a particular product, service or event is a laborious … Cites: ‪Effective LSTMs for target-dependent sentiment classification‬&lt;/p&gt;</content><author><name>PM BARNAGHI</name></author><category term="jekyll" /><category term="update" /><summary type="html">People are able to share and evaluate their opinion by using social media networks on the internet, a phenomenon that has taken off rapidly. The challenge is finding, monitoring, and extracting information manually from all opinion websites to help improve services or make decisions. A large section of each website is devoted to opinionated text. In addition, different experts hold different opinions. Computing the overall sentiment expressed for a particular product, service or event is a laborious … Cites: ‪Effective LSTMs for target-dependent sentiment classification‬</summary></entry><entry><title type="html">Learning to Augment Data in Graphs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/948237c4e124e2f8c770c7b5d5891980.html" rel="alternate" type="text/html" title="Learning to Augment Data in Graphs" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/948237c4e124e2f8c770c7b5d5891980</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/948237c4e124e2f8c770c7b5d5891980.html">&lt;p&gt;Given the omnipresence of graph-structured data, graph machine learning has copious applications in multifarious fields such as social media, e-commerce platform, cyber-physical system, or chemical synthesis. Nonetheless, data driven models for graph data also face their unique challenges including over-smoothing caused by message passing-based graph neural networks, structural data sparsity brought by power-law distributions, lack of labelled data due to costly annotations … Cites: ‪Unsupervised data augmentation for consistency training‬&lt;/p&gt;</content><author><name>T Zhao - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Given the omnipresence of graph-structured data, graph machine learning has copious applications in multifarious fields such as social media, e-commerce platform, cyber-physical system, or chemical synthesis. Nonetheless, data driven models for graph data also face their unique challenges including over-smoothing caused by message passing-based graph neural networks, structural data sparsity brought by power-law distributions, lack of labelled data due to costly annotations … Cites: ‪Unsupervised data augmentation for consistency training‬</summary></entry><entry><title type="html">Accelerating Memory Intensive Algorithms and Applications Using In-Memory Computing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/94bbe95a48c993bb15b20fdc3fadd169.html" rel="alternate" type="text/html" title="Accelerating Memory Intensive Algorithms and Applications Using In-Memory Computing" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/94bbe95a48c993bb15b20fdc3fadd169</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/94bbe95a48c993bb15b20fdc3fadd169.html">&lt;p&gt;Data-intensive applications do not fully utilize the compute capabilities of Von Neumann architectures because of the memory bandwidth bottleneck. These memory-bandwidth limited applications can be accelerated by minimizing the data movement between the memory and the compute units through in-memory computing (IMC). Using IMC, this work accelerated four different types of applications and algorithms. Cites: ‪Xlnet: Generalized autoregressive pretraining for language …‬&lt;/p&gt;</content><author><name>AFB Laguna - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Data-intensive applications do not fully utilize the compute capabilities of Von Neumann architectures because of the memory bandwidth bottleneck. These memory-bandwidth limited applications can be accelerated by minimizing the data movement between the memory and the compute units through in-memory computing (IMC). Using IMC, this work accelerated four different types of applications and algorithms. Cites: ‪Xlnet: Generalized autoregressive pretraining for language …‬</summary></entry><entry><title type="html">Computer-aided diagnosis for breast cancer detection and classification using optimal region growing segmentation with MobileNet model</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/97af2d91ba852ac71ce501e069997edb.html" rel="alternate" type="text/html" title="Computer-aided diagnosis for breast cancer detection and classification using optimal region growing segmentation with MobileNet model" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/97af2d91ba852ac71ce501e069997edb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/97af2d91ba852ac71ce501e069997edb.html">&lt;p&gt;Globally, breast cancer is considered a major reason for women s morality. Earlier and accurate identification of breast cancer is essential to increase survival rates. Therefore, computer-aided diagnosis (CAD) models are developed to help radiologists in the detection of mammographic lesions. Presently, machine-learning (ML) and deep-learning (DL) models are widely employed in the disease diagnostic process. In this view, this paper designs a novel CAD using optimal region growing … Cites: ‪Deep neural networks improve radiologists’ performance in breast …‬&lt;/p&gt;</content><author><name>JD Rose, K VijayaKumar, L Singh, SK Sharma - … ENGINEERING-RESEARCH AND …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Globally, breast cancer is considered a major reason for women s morality. Earlier and accurate identification of breast cancer is essential to increase survival rates. Therefore, computer-aided diagnosis (CAD) models are developed to help radiologists in the detection of mammographic lesions. Presently, machine-learning (ML) and deep-learning (DL) models are widely employed in the disease diagnostic process. In this view, this paper designs a novel CAD using optimal region growing … Cites: ‪Deep neural networks improve radiologists’ performance in breast …‬</summary></entry><entry><title type="html">Comparación entre la cobertura de la prensa a campañas presidenciales y la agenda de los periodistas que conducen debates1</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/98c2ae8cea9ab1bf29dba33181fca50c.html" rel="alternate" type="text/html" title="Comparación entre la cobertura de la prensa a campañas presidenciales y la agenda de los periodistas que conducen debates1" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/98c2ae8cea9ab1bf29dba33181fca50c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/98c2ae8cea9ab1bf29dba33181fca50c.html">&lt;p&gt;La cobertura de campañas tendería a preferir temas de juego estratégico y personalización sobre propuestas de políticas públicas. En cambio, se espera que los debates electorales en televisión sean un momento diferenciador de la rutina periodística. Mediante un análisis de contenido, se compara la agenda de los periodistas en cuatro debates presidenciales chilenos con la de la prensa escrita en la cobertura de las respectivas campañas. Los resultados muestran que los … Cites: ‪Modeling topic control to detect influence in conversations using …‬&lt;/p&gt;</content><author><name>E NÚÑEZ-MUSSA, W PORATH - Comunicación y Sociedad, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">La cobertura de campañas tendería a preferir temas de juego estratégico y personalización sobre propuestas de políticas públicas. En cambio, se espera que los debates electorales en televisión sean un momento diferenciador de la rutina periodística. Mediante un análisis de contenido, se compara la agenda de los periodistas en cuatro debates presidenciales chilenos con la de la prensa escrita en la cobertura de las respectivas campañas. Los resultados muestran que los … Cites: ‪Modeling topic control to detect influence in conversations using …‬</summary></entry><entry><title type="html">Grounding in social media: An approach to building a chit-chat dialogue model</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/9d117c1fe61e9239e9493a5539bdf58a.html" rel="alternate" type="text/html" title="Grounding in social media: An approach to building a chit-chat dialogue model" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/9d117c1fe61e9239e9493a5539bdf58a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/9d117c1fe61e9239e9493a5539bdf58a.html">&lt;p&gt;Building open-domain dialogue systems capable of rich human-like conversational ability is one of the fundamental challenges in language generation. However, even with recent advancements in the field, existing open-domain generative models fail to capture and utilize external knowledge, leading to repetitive or generic responses to unseen utterances. Current work on knowledge-grounded dialogue generation primarily focuses on persona incorporation or searching a fact-based structured … Cites: ‪REALM: Retrieval-Augmented Language Model Pre-Training‬&lt;/p&gt;</content><author><name>R Choudhary, D Kawahara - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Building open-domain dialogue systems capable of rich human-like conversational ability is one of the fundamental challenges in language generation. However, even with recent advancements in the field, existing open-domain generative models fail to capture and utilize external knowledge, leading to repetitive or generic responses to unseen utterances. Current work on knowledge-grounded dialogue generation primarily focuses on persona incorporation or searching a fact-based structured … Cites: ‪REALM: Retrieval-Augmented Language Model Pre-Training‬</summary></entry><entry><title type="html">Face Attribute Analysis from Structured Light: An End-to-End Approach</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/9f9a8f019dd92c8c58fc770705004276.html" rel="alternate" type="text/html" title="Face Attribute Analysis from Structured Light: An End-to-End Approach" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/9f9a8f019dd92c8c58fc770705004276</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/9f9a8f019dd92c8c58fc770705004276.html">&lt;p&gt;In this work we explore the use of structured-light imaging for face analysis. Towards this and due to lack of a publicly available structured-light face dataset, we (a) firstly generate a synthetic structured-light face dataset constructed based on the RGB-dataset London Face and the RGB-D dataset Bosphorus 3D Face. We then (b) propose a conditional adversarial network for depth map estimation from generated synthetic data. Associated quantitative and qualitative results suggest the efficiency … Cites: ‪Convolutional-recursive deep learning for 3d object classification‬&lt;/p&gt;</content><author><name>V Thamizharasan, A Das, D Battaglino, F Bremond…</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this work we explore the use of structured-light imaging for face analysis. Towards this and due to lack of a publicly available structured-light face dataset, we (a) firstly generate a synthetic structured-light face dataset constructed based on the RGB-dataset London Face and the RGB-D dataset Bosphorus 3D Face. We then (b) propose a conditional adversarial network for depth map estimation from generated synthetic data. Associated quantitative and qualitative results suggest the efficiency … Cites: ‪Convolutional-recursive deep learning for 3d object classification‬</summary></entry><entry><title type="html">Tools for Research on Multimodal Perception and Interaction with Transformers</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/a030d12f5cfcd872e06dfa39b3bac269.html" rel="alternate" type="text/html" title="Tools for Research on Multimodal Perception and Interaction with Transformers" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/a030d12f5cfcd872e06dfa39b3bac269</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/a030d12f5cfcd872e06dfa39b3bac269.html">&lt;p&gt;Recent revolutionary progress in Machine Learning, Natural Language Processing, Computer Vision, and Spoken Language Understanding has been driven by three phenomena: 1) The continued growth of available computing power made possible with GPUs and ASICs freely available via cloud computing. 2) The availability of extremely large-scale data-sets of images, video, speech and natural language for training and testing freely available over the internet 3) A movement toward … Cites: ‪LXMERT: Learning Cross-Modality Encoder Representations from …‬&lt;/p&gt;</content><author><name>J Crowley</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent revolutionary progress in Machine Learning, Natural Language Processing, Computer Vision, and Spoken Language Understanding has been driven by three phenomena: 1) The continued growth of available computing power made possible with GPUs and ASICs freely available via cloud computing. 2) The availability of extremely large-scale data-sets of images, video, speech and natural language for training and testing freely available over the internet 3) A movement toward … Cites: ‪LXMERT: Learning Cross-Modality Encoder Representations from …‬</summary></entry><entry><title type="html">Identifying IoT Devices Behind a NAT by Using Empirical Data and Learning Methods</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/a3192344d53aa3edf1317ef66855f0ae.html" rel="alternate" type="text/html" title="Identifying IoT Devices Behind a NAT by Using Empirical Data and Learning Methods" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/a3192344d53aa3edf1317ef66855f0ae</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/a3192344d53aa3edf1317ef66855f0ae.html">&lt;p&gt;The explosive growth of the Internet-of-Things (IoT) paradigm has brought the rise of malicious activity targeting the Internet. Indeed, the lack of basic security protocols and measures in IoT devices is allowing attackers to use exploited Internet-scale IoT devices to organize malicious botnets, and cause significant damage to the Internet through Denial of Service (DoS) attacks, illicit scraping, and cryptojacking attacks. Such IoT botnets can be Internet-facing, or can also be deployed behind Network … Cites: ‪TaBERT: Pretraining for Joint Understanding of Textual and …‬&lt;/p&gt;</content><author><name>C Nader - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The explosive growth of the Internet-of-Things (IoT) paradigm has brought the rise of malicious activity targeting the Internet. Indeed, the lack of basic security protocols and measures in IoT devices is allowing attackers to use exploited Internet-scale IoT devices to organize malicious botnets, and cause significant damage to the Internet through Denial of Service (DoS) attacks, illicit scraping, and cryptojacking attacks. Such IoT botnets can be Internet-facing, or can also be deployed behind Network … Cites: ‪TaBERT: Pretraining for Joint Understanding of Textual and …‬</summary></entry><entry><title type="html">Heterogeneous data fusion and loss function design for tooth point cloud segmentation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/a5fc765c5be69d11f8393c02779e94a4.html" rel="alternate" type="text/html" title="Heterogeneous data fusion and loss function design for tooth point cloud segmentation" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/a5fc765c5be69d11f8393c02779e94a4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/a5fc765c5be69d11f8393c02779e94a4.html">&lt;p&gt;Tooth point cloud segmentation plays an important role in the digital dentistry, and has received much attention in the past decade. Recently, methods based on the graph neural network have made significant progress. However, the development has been hindered by two challenges:(1) the heterogeneous geometry data are analyzed separately or combined linearly which leads to a semantic gap in different streams;(2) there is mis-alignment between the loss function and evaluation metrics … Cites: ‪Regularized evolution for image classifier architecture search‬&lt;/p&gt;</content><author><name>D Liu, Y Tian, Y Zhang, J Gelernter, X Wang - Neural Computing and Applications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Tooth point cloud segmentation plays an important role in the digital dentistry, and has received much attention in the past decade. Recently, methods based on the graph neural network have made significant progress. However, the development has been hindered by two challenges:(1) the heterogeneous geometry data are analyzed separately or combined linearly which leads to a semantic gap in different streams;(2) there is mis-alignment between the loss function and evaluation metrics … Cites: ‪Regularized evolution for image classifier architecture search‬</summary></entry><entry><title type="html">Choose Your Lenses: Flaws in Gender Bias Evaluation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/a637606b0e1590ab41e457f7f9ea162a.html" rel="alternate" type="text/html" title="Choose Your Lenses: Flaws in Gender Bias Evaluation" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/a637606b0e1590ab41e457f7f9ea162a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/a637606b0e1590ab41e457f7f9ea162a.html">&lt;p&gt;Considerable efforts to measure and mitigate gender bias in recent years have led to the introduction of an abundance of tasks, datasets, and metrics used in this vein. In this position paper, we assess the current paradigm of gender bias evaluation and identify several flaws in it. First, we highlight the importance of extrinsic bias metrics that measure how a model s performance on some task is affected by gender, as opposed to intrinsic evaluations of model representations, which are less strongly … Cites: ‪Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis …‬&lt;/p&gt;</content><author><name>H Orgad, Y Belinkov</name></author><category term="jekyll" /><category term="update" /><summary type="html">Considerable efforts to measure and mitigate gender bias in recent years have led to the introduction of an abundance of tasks, datasets, and metrics used in this vein. In this position paper, we assess the current paradigm of gender bias evaluation and identify several flaws in it. First, we highlight the importance of extrinsic bias metrics that measure how a model s performance on some task is affected by gender, as opposed to intrinsic evaluations of model representations, which are less strongly … Cites: ‪Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis …‬</summary></entry><entry><title type="html">Machine Learning Assisted Security for Edge Computing Applications</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/abbb5da33846460da527dc02694a092d.html" rel="alternate" type="text/html" title="Machine Learning Assisted Security for Edge Computing Applications" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/abbb5da33846460da527dc02694a092d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/abbb5da33846460da527dc02694a092d.html">&lt;p&gt;Edge computing applications have recently gained prominence as the world of internet-of-things becomes increasingly embedded into people s lives. Performing computations at the edge addresses multiple issues, such as memory bandwidth-latency bottlenecks, exposure of sensitive data to external attackers, etc. It is important to protect the data collected and processed by edge devices, and also to prevent unauthorized access to such data. It is also important to ensure that the … Cites: ‪Smooth adversarial training‬&lt;/p&gt;</content><author><name>SK Cherupally - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Edge computing applications have recently gained prominence as the world of internet-of-things becomes increasingly embedded into people s lives. Performing computations at the edge addresses multiple issues, such as memory bandwidth-latency bottlenecks, exposure of sensitive data to external attackers, etc. It is important to protect the data collected and processed by edge devices, and also to prevent unauthorized access to such data. It is also important to ensure that the … Cites: ‪Smooth adversarial training‬</summary></entry><entry><title type="html">Partnering with immigrant families to promote language justice and equity in education</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/bdf5a45a921aad4c34b414eb88760d06.html" rel="alternate" type="text/html" title="Partnering with immigrant families to promote language justice and equity in education" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/bdf5a45a921aad4c34b414eb88760d06</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/bdf5a45a921aad4c34b414eb88760d06.html">&lt;p&gt;Despite US federal legislation mandates institutions to provide meaningful access and participation to students and families in educational settings, culturally and linguistically diverse (CLD) families and caregivers of children in special education experience cultural and linguistic barriers. A Community Advisory Team (CAT) of parents, advocates, community interpreters and translators, researchers, and teachers explored CLD families  experiences and advocacy efforts. Critical bifocality … Cites: ‪A set of recommendations for assessing human–machine parity in …‬&lt;/p&gt;</content><author><name>C Tang Yan, A Bachour, CJ Pérez, LP Ansaldo… - American Journal of Community …</name></author><category term="jekyll" /><category term="update" /><summary type="html">Despite US federal legislation mandates institutions to provide meaningful access and participation to students and families in educational settings, culturally and linguistically diverse (CLD) families and caregivers of children in special education experience cultural and linguistic barriers. A Community Advisory Team (CAT) of parents, advocates, community interpreters and translators, researchers, and teachers explored CLD families experiences and advocacy efforts. Critical bifocality … Cites: ‪A set of recommendations for assessing human–machine parity in …‬</summary></entry><entry><title type="html">The altered state of consciousness induced by Δ9-THC</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/bf1a47751527b025e219f656e93cb8e5.html" rel="alternate" type="text/html" title="The altered state of consciousness induced by Δ9-THC" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/bf1a47751527b025e219f656e93cb8e5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/bf1a47751527b025e219f656e93cb8e5.html">&lt;p&gt;Altered states of consciousness (ASC) provide an opportunity for researchers to study the neurophysiological basis of changes in phenomenal experience. Δ9-tetrahydrocannabinol (THC) is the primary psychoactive constituent of cannabis, however whether the effects of THC include ASC features that are shared with other ASC induction mechanisms, such as classical psychedelics, has not been systematically addressed. We used survey (11D-ASC; State Mindfulness), self-report … Cites: ‪Bert: Pre-training of deep bidirectional transformers for language …‬&lt;/p&gt;</content><author><name>CH Murray, B Srinivasa-Desikan - Consciousness and Cognition, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Altered states of consciousness (ASC) provide an opportunity for researchers to study the neurophysiological basis of changes in phenomenal experience. Δ9-tetrahydrocannabinol (THC) is the primary psychoactive constituent of cannabis, however whether the effects of THC include ASC features that are shared with other ASC induction mechanisms, such as classical psychedelics, has not been systematically addressed. We used survey (11D-ASC; State Mindfulness), self-report … Cites: ‪Bert: Pre-training of deep bidirectional transformers for language …‬</summary></entry><entry><title type="html">Adversarial Attacks and Defenses in Text Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/c9ede51801d5e8ed0418d816e1be301c.html" rel="alternate" type="text/html" title="Adversarial Attacks and Defenses in Text Classification" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/c9ede51801d5e8ed0418d816e1be301c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/c9ede51801d5e8ed0418d816e1be301c.html">&lt;p&gt;Deep learning models have achieved great success in solving a variety of natural language processing (NLP) problems. An ever-growing body of research, however, illustrates the vulnerability of deep neural networks (DNNs) to adversarial examples–inputs modified by introducing small perturbations to deliberately fool a target model into outputting incorrect results. The vulnerability to adversarial examples has become one of the main hurdles precluding neural network deployment into safety … Cites: ‪Paraphrasing revisited with neural machine translation‬&lt;/p&gt;</content><author><name>B Alshemali - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning models have achieved great success in solving a variety of natural language processing (NLP) problems. An ever-growing body of research, however, illustrates the vulnerability of deep neural networks (DNNs) to adversarial examples–inputs modified by introducing small perturbations to deliberately fool a target model into outputting incorrect results. The vulnerability to adversarial examples has become one of the main hurdles precluding neural network deployment into safety … Cites: ‪Paraphrasing revisited with neural machine translation‬</summary></entry><entry><title type="html">DEEP FEATURE EXTRACTION BASED ON DYNAMIC GRAPH CONVOLUTIONAL NETWORKS FOR ACCELERATED HYPERSPECTRAL IMAGE CLASSIFICATION</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/cc7315b2e58cb37930bc3d291db29c49.html" rel="alternate" type="text/html" title="DEEP FEATURE EXTRACTION BASED ON DYNAMIC GRAPH CONVOLUTIONAL NETWORKS FOR ACCELERATED HYPERSPECTRAL IMAGE CLASSIFICATION" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/cc7315b2e58cb37930bc3d291db29c49</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/cc7315b2e58cb37930bc3d291db29c49.html">&lt;p&gt;Deep learning has achieved impressive results on hyperspectral images (HSIs) classification. Among them, supervised learning convolutional neural networks (CNNs) and semi-supervised learning graph neural networks (GNNs) are the two main network frameworks. However, 1) the supervised learning CNN faces the problem of high model time complexity as the number of network layers deepens; 2) the semi-supervised learning GNN faces the problem of high spatial complexity due … Cites: ‪Graph neural networks: A review of methods and applications‬&lt;/p&gt;</content><author><name>Q Liu, Y Dong - ISPRS Annals of the Photogrammetry, Remote Sensing …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning has achieved impressive results on hyperspectral images (HSIs) classification. Among them, supervised learning convolutional neural networks (CNNs) and semi-supervised learning graph neural networks (GNNs) are the two main network frameworks. However, 1) the supervised learning CNN faces the problem of high model time complexity as the number of network layers deepens; 2) the semi-supervised learning GNN faces the problem of high spatial complexity due … Cites: ‪Graph neural networks: A review of methods and applications‬</summary></entry><entry><title type="html">A SECURITY-PRIVACY BASED MODEL FOR OPERATING SYSTEMS</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/d7f9496e6eeccadef6bc780a7599fe2a.html" rel="alternate" type="text/html" title="A SECURITY-PRIVACY BASED MODEL FOR OPERATING SYSTEMS" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/d7f9496e6eeccadef6bc780a7599fe2a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/d7f9496e6eeccadef6bc780a7599fe2a.html">&lt;p&gt;With good cause, there has been significant effort over the past decade by operating system developers focused on improving the security of operating systems. This has resulted in regular patching, various security-oriented operating system versions being spawned, and the re-architecture of various operating system components. Recently, significant concerns about individual and institutional privacy have risen in both the media and academic arenas. There is a strong interrelationship between … Cites: ‪The usable privacy policy project‬&lt;/p&gt;</content><author><name>M Mahmoud</name></author><category term="jekyll" /><category term="update" /><summary type="html">With good cause, there has been significant effort over the past decade by operating system developers focused on improving the security of operating systems. This has resulted in regular patching, various security-oriented operating system versions being spawned, and the re-architecture of various operating system components. Recently, significant concerns about individual and institutional privacy have risen in both the media and academic arenas. There is a strong interrelationship between … Cites: ‪The usable privacy policy project‬</summary></entry><entry><title type="html">A Photovoltaic System Fault Identification Method Based on Improved Deep Residual Shrinkage Networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/db53aec816d1de49684933e4b84fe5b2.html" rel="alternate" type="text/html" title="A Photovoltaic System Fault Identification Method Based on Improved Deep Residual Shrinkage Networks" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/db53aec816d1de49684933e4b84fe5b2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/db53aec816d1de49684933e4b84fe5b2.html">&lt;p&gt;With the increasing installed capacity of photovoltaic (PV) power generation, it has become a significant challenge to detect abnormalities and faults of PV modules in a timely manner. Considering that all the fault information of the PV module is contained in the current-voltage (IV) curve, this pioneering study takes the IV curve as the input and proposes a PV-fault identification method based on improved deep residual shrinkage networks (DRSN). This method can not only identify single faults … Cites: ‪Empirical evaluation of gated recurrent neural networks on …‬&lt;/p&gt;</content><author><name>F Cui, Y Tu, W Gao - Energies, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">With the increasing installed capacity of photovoltaic (PV) power generation, it has become a significant challenge to detect abnormalities and faults of PV modules in a timely manner. Considering that all the fault information of the PV module is contained in the current-voltage (IV) curve, this pioneering study takes the IV curve as the input and proposes a PV-fault identification method based on improved deep residual shrinkage networks (DRSN). This method can not only identify single faults … Cites: ‪Empirical evaluation of gated recurrent neural networks on …‬</summary></entry><entry><title type="html">Assessment of Using Machine Learning Methods in Analyzing Data from Renewable Integrated Power Systems</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/e0067dada0f9d0b73d01ba790c908adb.html" rel="alternate" type="text/html" title="Assessment of Using Machine Learning Methods in Analyzing Data from Renewable Integrated Power Systems" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/e0067dada0f9d0b73d01ba790c908adb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/e0067dada0f9d0b73d01ba790c908adb.html">&lt;p&gt;The high uncertainty of renewables introduces more dynamics to power systems. The conventional way of monitoring and controlling power systems is no longer reliable. New strategies are needed to ensure the stability and reliability of power systems. This work aims to assess the use of machine learning methods in analyzing data from renewable integrated power systems to aid the decision making of electricity market participants. Specifically, the work studies the cases of electricity … Cites: ‪An investigation of why overparameterization exacerbates …‬&lt;/p&gt;</content><author><name>S Luo - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The high uncertainty of renewables introduces more dynamics to power systems. The conventional way of monitoring and controlling power systems is no longer reliable. New strategies are needed to ensure the stability and reliability of power systems. This work aims to assess the use of machine learning methods in analyzing data from renewable integrated power systems to aid the decision making of electricity market participants. Specifically, the work studies the cases of electricity … Cites: ‪An investigation of why overparameterization exacerbates …‬</summary></entry><entry><title type="html">Video Captioning with Commonsense Knowledge Anchors</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/e0b1590f6b38fc049f0d17fdb8864741.html" rel="alternate" type="text/html" title="Video Captioning with Commonsense Knowledge Anchors" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/e0b1590f6b38fc049f0d17fdb8864741</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/e0b1590f6b38fc049f0d17fdb8864741.html">&lt;p&gt;It is not merely an aggregation of static entities that a video clip carries, but alsoa variety of interactions and relations among these entities. Challenges still remainfor a video captioning system to generate natural language descriptions focusing onthe prominent interest and aligning with the latent aspects beyond observations. Thiswork presents a Commonsense knowledge Anchored Video cAptioNing (dubbed asCAVAN) approach. CAVAN exploits inferential commonsense knowledge … Cites: ‪Ask me anything: Dynamic memory networks for natural language …‬&lt;/p&gt;</content><author><name>H Shao - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">It is not merely an aggregation of static entities that a video clip carries, but alsoa variety of interactions and relations among these entities. Challenges still remainfor a video captioning system to generate natural language descriptions focusing onthe prominent interest and aligning with the latent aspects beyond observations. Thiswork presents a Commonsense knowledge Anchored Video cAptioNing (dubbed asCAVAN) approach. CAVAN exploits inferential commonsense knowledge … Cites: ‪Ask me anything: Dynamic memory networks for natural language …‬</summary></entry><entry><title type="html">The Design of an Oncology Knowledge Base from an Online Health Forum</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/e0edf8a6efd79dfa8d94c0fb262aaf15.html" rel="alternate" type="text/html" title="The Design of an Oncology Knowledge Base from an Online Health Forum" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/e0edf8a6efd79dfa8d94c0fb262aaf15</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/e0edf8a6efd79dfa8d94c0fb262aaf15.html">&lt;p&gt;Knowledge base completion is an important task that allows scientists to reason over knowledge bases and discover new facts. In this thesis, a patient-centric knowledge base is designed and constructed using medical entities and relations extracted from the health forum r/cancer. The knowledge base stores information in binary relation triplets. It is enhanced with an is-a relation that is able to represent the hierarchical relationship between different medical entities. An enhanced Neural Tensor Network … Cites: ‪Learning Entity and Relation Embeddings for Knowledge Graph …‬&lt;/p&gt;</content><author><name>O Ramadan - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Knowledge base completion is an important task that allows scientists to reason over knowledge bases and discover new facts. In this thesis, a patient-centric knowledge base is designed and constructed using medical entities and relations extracted from the health forum r/cancer. The knowledge base stores information in binary relation triplets. It is enhanced with an is-a relation that is able to represent the hierarchical relationship between different medical entities. An enhanced Neural Tensor Network … Cites: ‪Learning Entity and Relation Embeddings for Knowledge Graph …‬</summary></entry><entry><title type="html">Verb-Particle Constructions in Arabic and English: A Contrastive Corpus Study of Learner and Native Language</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/e4b0d8cad88d1219b11a8453ed4820e0.html" rel="alternate" type="text/html" title="Verb-Particle Constructions in Arabic and English: A Contrastive Corpus Study of Learner and Native Language" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/e4b0d8cad88d1219b11a8453ed4820e0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/e4b0d8cad88d1219b11a8453ed4820e0.html">&lt;p&gt;The present study aimed to catalogue and compare usage patterns of verb-particle constructions (VPCs) in Modern Standard Arabic and English by native and learner writers. Building upon an analysis of a multi-genre monolingual Arabic corpus, use of both Arabic and English VPCs was explored in a bilingual L1 (first language) Arabic L2 (second language) English corpus containing essays written by the same authors in both languages. While Arabic usage was compared between the monolingual and … Cites: ‪Feature-rich part-of-speech tagging with a cyclic dependency …‬&lt;/p&gt;</content><author><name>S Creel - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The present study aimed to catalogue and compare usage patterns of verb-particle constructions (VPCs) in Modern Standard Arabic and English by native and learner writers. Building upon an analysis of a multi-genre monolingual Arabic corpus, use of both Arabic and English VPCs was explored in a bilingual L1 (first language) Arabic L2 (second language) English corpus containing essays written by the same authors in both languages. While Arabic usage was compared between the monolingual and … Cites: ‪Feature-rich part-of-speech tagging with a cyclic dependency …‬</summary></entry><entry><title type="html">A Comprehensive Survey of Techniques, Applications, and Challenges in Deep Learning: A Revolution in Machine Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/edd80d134e9b8fe7d712fac387a79f09.html" rel="alternate" type="text/html" title="A Comprehensive Survey of Techniques, Applications, and Challenges in Deep Learning: A Revolution in Machine Learning" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/edd80d134e9b8fe7d712fac387a79f09</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/edd80d134e9b8fe7d712fac387a79f09.html">&lt;p&gt;Deep learning (DL) is a hot topic in machine learning (ML). To limit the amount of time and money spent on supervised machine learning, we use DL. With a variety of methodologies and topographies, DL may be applied to address complicated problems in a variety of contexts. Features that illustrate or differentiate are learned in a layered manner. When it comes to effective security solutions, DL has made significant strides in a wide number of application domains. The best alternative for … Cites: ‪Unsupervised deep learning: A short review‬&lt;/p&gt;</content><author><name>TAS Srinivas, G Mahalaxmi, R Varaprasad, D Raziya</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning (DL) is a hot topic in machine learning (ML). To limit the amount of time and money spent on supervised machine learning, we use DL. With a variety of methodologies and topographies, DL may be applied to address complicated problems in a variety of contexts. Features that illustrate or differentiate are learned in a layered manner. When it comes to effective security solutions, DL has made significant strides in a wide number of application domains. The best alternative for … Cites: ‪Unsupervised deep learning: A short review‬</summary></entry><entry><title type="html">A New Artificial Intelligence Approach for the Radiographic Classification of Sacroiliitis</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/f2b043d7e917ca5e9d629b715aadaaaf.html" rel="alternate" type="text/html" title="A New Artificial Intelligence Approach for the Radiographic Classification of Sacroiliitis" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/f2b043d7e917ca5e9d629b715aadaaaf</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/f2b043d7e917ca5e9d629b715aadaaaf.html">&lt;p&gt;Radiographs of the sacroiliac joints are commonly used as the first imaging methods for the diagnosis of Sacroileitis in patients with back pain. This study aims to develop and validate a new artificial intelligence approach for the automatic classification of the grade of sacroiliitis on conventional radiographs. We included a total of 267 patients with chronic back pain and clinical suggestion of Axial Spondyloarthritis who presented in a specialized center. Radiographs of sacroiliac joints were evaluated by … Cites: ‪Efficientnetv2: Smaller models and faster training‬&lt;/p&gt;</content><author><name>E Fernandez, J Garrigos, JJ Martinez, I Cases… - Bio-inspired Systems and …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Radiographs of the sacroiliac joints are commonly used as the first imaging methods for the diagnosis of Sacroileitis in patients with back pain. This study aims to develop and validate a new artificial intelligence approach for the automatic classification of the grade of sacroiliitis on conventional radiographs. We included a total of 267 patients with chronic back pain and clinical suggestion of Axial Spondyloarthritis who presented in a specialized center. Radiographs of sacroiliac joints were evaluated by … Cites: ‪Efficientnetv2: Smaller models and faster training‬</summary></entry><entry><title type="html">Preserving Knowledge in Simulated Behavioral Action Loops</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/f60ccf72142f63a6e0fa0f9bbd239bc4.html" rel="alternate" type="text/html" title="Preserving Knowledge in Simulated Behavioral Action Loops" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/f60ccf72142f63a6e0fa0f9bbd239bc4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/f60ccf72142f63a6e0fa0f9bbd239bc4.html">&lt;p&gt;One basic goal of artificial learning systems is the ability to continually learn throughout that system s lifetime. Transitioning between tasks and re-deploying prior knowledge is thus a desired feature of artificial learning. However, in the deep-learning approaches, the problem of catastrophic forgetting of prior knowledge persists. As a field, we want to solve the catastrophic forgetting problem without requiring exponential computations or time, while demonstrating real-world … Cites: ‪Learn to grow: A continual structure learning framework for …‬&lt;/p&gt;</content><author><name>RS Clair - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">One basic goal of artificial learning systems is the ability to continually learn throughout that system s lifetime. Transitioning between tasks and re-deploying prior knowledge is thus a desired feature of artificial learning. However, in the deep-learning approaches, the problem of catastrophic forgetting of prior knowledge persists. As a field, we want to solve the catastrophic forgetting problem without requiring exponential computations or time, while demonstrating real-world … Cites: ‪Learn to grow: A continual structure learning framework for …‬</summary></entry><entry><title type="html">Commonsense Reasoning in Interpersonal Conflict</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/f63cd1f4db4fb52546ebfaecb092411c.html" rel="alternate" type="text/html" title="Commonsense Reasoning in Interpersonal Conflict" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/f63cd1f4db4fb52546ebfaecb092411c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/f63cd1f4db4fb52546ebfaecb092411c.html">&lt;p&gt;We propose to use the subreddit named r/AITA as the corpus for studying social commonsense reasoning. Compared to existing popular corpora, it contains social situations with more complex structures. We show that current NLP systems have worse performance on the subset of the corpus where humans have a lower agreement. We show that, across different subsets, RoBERTa outperforms BERT. Intermediate task finetuning only produces similar performance on the subsets with a … Cites: ‪Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis …‬&lt;/p&gt;</content><author><name>Z Cao - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose to use the subreddit named r/AITA as the corpus for studying social commonsense reasoning. Compared to existing popular corpora, it contains social situations with more complex structures. We show that current NLP systems have worse performance on the subset of the corpus where humans have a lower agreement. We show that, across different subsets, RoBERTa outperforms BERT. Intermediate task finetuning only produces similar performance on the subsets with a … Cites: ‪Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis …‬</summary></entry><entry><title type="html">Machine learning and deep learning based predictive quality in manufacturing: a systematic review</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/fb1a117cedb00283f9b0641b58ab3ee5.html" rel="alternate" type="text/html" title="Machine learning and deep learning based predictive quality in manufacturing: a systematic review" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/fb1a117cedb00283f9b0641b58ab3ee5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/fb1a117cedb00283f9b0641b58ab3ee5.html">&lt;p&gt;With the ongoing digitization of the manufacturing industry and the ability to bring together data from manufacturing processes and quality measurements, there is enormous potential to use machine learning and deep learning techniques for quality assurance. In this context, predictive quality enables manufacturing companies to make data-driven estimations about the product quality based on process data. In the current state of research, numerous approaches to predictive … Cites: ‪Graph neural networks: A review of methods and applications‬&lt;/p&gt;</content><author><name>H Tercan, T Meisen - Journal of Intelligent Manufacturing, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">With the ongoing digitization of the manufacturing industry and the ability to bring together data from manufacturing processes and quality measurements, there is enormous potential to use machine learning and deep learning techniques for quality assurance. In this context, predictive quality enables manufacturing companies to make data-driven estimations about the product quality based on process data. In the current state of research, numerous approaches to predictive … Cites: ‪Graph neural networks: A review of methods and applications‬</summary></entry><entry><title type="html">A mobile traffic load prediction based on recurrent neural network: A case of telecommunication in Afghanistan</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/fd4a5f6ea6e69e73f4c14d9116fb8f18.html" rel="alternate" type="text/html" title="A mobile traffic load prediction based on recurrent neural network: A case of telecommunication in Afghanistan" /><published>2022-06-01T23:51:30-04:00</published><updated>2022-06-01T23:51:30-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/fd4a5f6ea6e69e73f4c14d9116fb8f18</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/06/01/fd4a5f6ea6e69e73f4c14d9116fb8f18.html">&lt;p&gt;This paper investigates the prediction of mobile traffic load based on four variants of recurrent neural networks, which are the simple long short‐term memory (LSTM), stacked LSTM, gated recurrent unit (GRU) and bidirectional LSTM. In the considered schemes, the mobile traffic load of 15 min ahead of time is estimated based on the previous mobile traffic load data. The performance of the proposed scheme is verified using realistic traffic load data collected from the base station located in … Cites: ‪Learning Phrase Representations using RNN Encoder-Decoder …‬&lt;/p&gt;</content><author><name>FH Ahmadzai, W Lee - Electronics Letters</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper investigates the prediction of mobile traffic load based on four variants of recurrent neural networks, which are the simple long short‐term memory (LSTM), stacked LSTM, gated recurrent unit (GRU) and bidirectional LSTM. In the considered schemes, the mobile traffic load of 15 min ahead of time is estimated based on the previous mobile traffic load data. The performance of the proposed scheme is verified using realistic traffic load data collected from the base station located in … Cites: ‪Learning Phrase Representations using RNN Encoder-Decoder …‬</summary></entry><entry><title type="html">Dataset of solution-based inorganic materials synthesis procedures extracted from the scientific literature</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/004074c8a1b20b11444a1852382630d6.html" rel="alternate" type="text/html" title="Dataset of solution-based inorganic materials synthesis procedures extracted from the scientific literature" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/004074c8a1b20b11444a1852382630d6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/004074c8a1b20b11444a1852382630d6.html">&lt;p&gt;The development of a materials synthesis route is usually based on heuristics and experience. A possible new approach would be to apply data-driven approaches to learn the patterns of synthesis from past experience and use them to predict the syntheses of novel materials. However, this route is impeded by the lack of a large-scale database of synthesis formulations. In this work, we applied advanced machine learning and natural language processing techniques to construct a dataset of … Cites: ‪Bert: Pre-training of deep bidirectional transformers for language …‬&lt;/p&gt;</content><author><name>Z Wang, O Kononova, K Cruse, T He, H Huo, Y Fei… - Scientific Data, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The development of a materials synthesis route is usually based on heuristics and experience. A possible new approach would be to apply data-driven approaches to learn the patterns of synthesis from past experience and use them to predict the syntheses of novel materials. However, this route is impeded by the lack of a large-scale database of synthesis formulations. In this work, we applied advanced machine learning and natural language processing techniques to construct a dataset of … Cites: ‪Bert: Pre-training of deep bidirectional transformers for language …‬</summary></entry><entry><title type="html">Does Moral Code Have a Moral Code? Probing Delphi s Moral Philosophy</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/01e23924b4ca44e093712a65bca8c7c5.html" rel="alternate" type="text/html" title="Does Moral Code Have a Moral Code? Probing Delphi s Moral Philosophy" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/01e23924b4ca44e093712a65bca8c7c5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/01e23924b4ca44e093712a65bca8c7c5.html">&lt;p&gt;In an effort to guarantee that machine learning model outputs conform with human moral values, recent work has begun exploring the possibility of explicitly training models to learn the difference between right and wrong. This is typically done in a bottom-up fashion, by exposing the model to different scenarios, annotated with human moral judgements. One question, however, is whether the trained models actually learn any consistent, higher-level ethical principles from these datasets–and … Cites: ‪Delphi: Towards machine ethics and norms‬&lt;/p&gt;</content><author><name>KC Fraser, S Kiritchenko, E Balkir - arXiv preprint arXiv:2205.12771, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In an effort to guarantee that machine learning model outputs conform with human moral values, recent work has begun exploring the possibility of explicitly training models to learn the difference between right and wrong. This is typically done in a bottom-up fashion, by exposing the model to different scenarios, annotated with human moral judgements. One question, however, is whether the trained models actually learn any consistent, higher-level ethical principles from these datasets–and … Cites: ‪Delphi: Towards machine ethics and norms‬</summary></entry><entry><title type="html">Training Language Models with Memory Augmentation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/01f4184b6b8b51b92531b9c8265b3d51.html" rel="alternate" type="text/html" title="Training Language Models with Memory Augmentation" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/01f4184b6b8b51b92531b9c8265b3d51</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/01f4184b6b8b51b92531b9c8265b3d51.html">&lt;p&gt;Recent work has improved language models remarkably by equipping them with a non-parametric memory component. However, most existing approaches only introduce memories at testing time, or represent them using a separately trained encoder–resulting in sub-optimal training of the language model. In this work, we present TRIME, a novel yet simple training approach designed for training language models with memory augmentation. Our approach uses a training objective that … Cites: ‪REALM: Retrieval-Augmented Language Model Pre-Training‬&lt;/p&gt;</content><author><name>Z Zhong, T Lei, D Chen - arXiv preprint arXiv:2205.12674, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent work has improved language models remarkably by equipping them with a non-parametric memory component. However, most existing approaches only introduce memories at testing time, or represent them using a separately trained encoder–resulting in sub-optimal training of the language model. In this work, we present TRIME, a novel yet simple training approach designed for training language models with memory augmentation. Our approach uses a training objective that … Cites: ‪REALM: Retrieval-Augmented Language Model Pre-Training‬</summary></entry><entry><title type="html">Improving the Applicability of AI for Psychiatric Applications through Human-in-the-loop Methodologies</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/0b8e470437b893d40747b1a4687fd425.html" rel="alternate" type="text/html" title="Improving the Applicability of AI for Psychiatric Applications through Human-in-the-loop Methodologies" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/0b8e470437b893d40747b1a4687fd425</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/0b8e470437b893d40747b1a4687fd425.html">&lt;p&gt;Objectives Machine learning (ML) and natural language processing have great potential to improve efficiency and accuracy in diagnosis, treatment recommendations, predictive interventions, and scarce resource allocation within psychiatry. Researchers often conceptualize such an approach as operating in isolation without much need for human involvement, yet it remains crucial to harness human-in-the-loop practices when developing and implementing such techniques as … Cites: ‪Detecting formal thought disorder by deep contextualized word …‬&lt;/p&gt;</content><author><name>C Chandler, PW Foltz, B Elvevåg - Schizophrenia Bulletin, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Objectives Machine learning (ML) and natural language processing have great potential to improve efficiency and accuracy in diagnosis, treatment recommendations, predictive interventions, and scarce resource allocation within psychiatry. Researchers often conceptualize such an approach as operating in isolation without much need for human involvement, yet it remains crucial to harness human-in-the-loop practices when developing and implementing such techniques as … Cites: ‪Detecting formal thought disorder by deep contextualized word …‬</summary></entry><entry><title type="html">Selective Classification Via Neural Network Training Dynamics</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/0e6c335140dbe4a805a797acc48b980b.html" rel="alternate" type="text/html" title="Selective Classification Via Neural Network Training Dynamics" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/0e6c335140dbe4a805a797acc48b980b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/0e6c335140dbe4a805a797acc48b980b.html">&lt;p&gt;Selective classification is the task of rejecting inputs a model would predict incorrectly on through a trade-off between input space coverage and model accuracy. Current methods for selective classification impose constraints on either the model architecture or the loss function; this inhibits their usage in practice. In contrast to prior work, we show that state-of-the-art selective classification performance can be attained solely from studying the (discretized) training dynamics … Cites: ‪Selective classification can magnify disparities across groups‬&lt;/p&gt;</content><author><name>S Rabanser, A Thudi, K Hamidieh, A Dziedzic… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Selective classification is the task of rejecting inputs a model would predict incorrectly on through a trade-off between input space coverage and model accuracy. Current methods for selective classification impose constraints on either the model architecture or the loss function; this inhibits their usage in practice. In contrast to prior work, we show that state-of-the-art selective classification performance can be attained solely from studying the (discretized) training dynamics … Cites: ‪Selective classification can magnify disparities across groups‬</summary></entry><entry><title type="html">Overcoming Catastrophic Forgetting in Zero-Shot Cross-Lingual Generation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/0e6d48085c220a007332b0ecd4ca6dd3.html" rel="alternate" type="text/html" title="Overcoming Catastrophic Forgetting in Zero-Shot Cross-Lingual Generation" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/0e6d48085c220a007332b0ecd4ca6dd3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/0e6d48085c220a007332b0ecd4ca6dd3.html">&lt;p&gt;In this paper, we explore the challenging problem of performing a generative task (ie, summarization) in a target language when labeled data is only available in English. We assume a strict setting with no access to parallel data or machine translation. Prior work has shown, and we confirm, that standard transfer learning techniques struggle in this setting, as a generative multilingual model fine-tuned purely on English catastrophically forgets how to generate non-English. Given the recent rise of … Cites: ‪Metaicl: Learning to learn in context‬&lt;/p&gt;</content><author><name>T Vu, A Barua, B Lester, D Cer, M Iyyer, N Constant - arXiv preprint arXiv:2205.12647, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper, we explore the challenging problem of performing a generative task (ie, summarization) in a target language when labeled data is only available in English. We assume a strict setting with no access to parallel data or machine translation. Prior work has shown, and we confirm, that standard transfer learning techniques struggle in this setting, as a generative multilingual model fine-tuned purely on English catastrophically forgets how to generate non-English. Given the recent rise of … Cites: ‪Metaicl: Learning to learn in context‬</summary></entry><entry><title type="html">Intermediate Training on Question Answering Datasets Improves Generative Data Augmentation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/0f3cf062777d8a3e2d3e9a41fe640bd4.html" rel="alternate" type="text/html" title="Intermediate Training on Question Answering Datasets Improves Generative Data Augmentation" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/0f3cf062777d8a3e2d3e9a41fe640bd4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/0f3cf062777d8a3e2d3e9a41fe640bd4.html">&lt;p&gt;Manually annotating datasets requires domain experts to read through many documents and carefully label them, which is often expensive. Recently, pre-trained generative language models (GLMs) have demonstrated exceptional abilities in generating text which motivates to leverage them for generative data augmentation. We improve generative data augmentation by formulating the data generation as context generation task and use question answering (QA) datasets for intermediate … Cites: ‪Strata: Self-training with task augmentation for better few-shot …‬&lt;/p&gt;</content><author><name>D Mekala, T Vu, J Shang - arXiv preprint arXiv:2205.12604, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Manually annotating datasets requires domain experts to read through many documents and carefully label them, which is often expensive. Recently, pre-trained generative language models (GLMs) have demonstrated exceptional abilities in generating text which motivates to leverage them for generative data augmentation. We improve generative data augmentation by formulating the data generation as context generation task and use question answering (QA) datasets for intermediate … Cites: ‪Strata: Self-training with task augmentation for better few-shot …‬</summary></entry><entry><title type="html">Inception Transformer</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1036254bacb33c5971c3f68b0812ab69.html" rel="alternate" type="text/html" title="Inception Transformer" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1036254bacb33c5971c3f68b0812ab69</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1036254bacb33c5971c3f68b0812ab69.html">&lt;p&gt;Recent studies show that Transformer has strong capability of building long-range dependencies, yet is incompetent in capturing high frequencies that predominantly convey local information. To tackle this issue, we present a novel and general-purpose Inception Transformer, or iFormer for short, that effectively learns comprehensive features with both high-and low-frequency information in visual data. Specifically, we design an Inception mixer to explicitly graft the advantages of … Cites: ‪Palm: Scaling language modeling with pathways‬&lt;/p&gt;</content><author><name>C Si, W Yu, P Zhou, Y Zhou, X Wang, S Yan - arXiv preprint arXiv:2205.12956, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent studies show that Transformer has strong capability of building long-range dependencies, yet is incompetent in capturing high frequencies that predominantly convey local information. To tackle this issue, we present a novel and general-purpose Inception Transformer, or iFormer for short, that effectively learns comprehensive features with both high-and low-frequency information in visual data. Specifically, we design an Inception mixer to explicitly graft the advantages of … Cites: ‪Palm: Scaling language modeling with pathways‬</summary></entry><entry><title type="html">Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/10c3d78d81028f16e10886bcdac0a49d.html" rel="alternate" type="text/html" title="Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/10c3d78d81028f16e10886bcdac0a49d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/10c3d78d81028f16e10886bcdac0a49d.html">&lt;p&gt;Despite recent explosion in research interests, in-context learning and the precise impact of the quality of demonstrations remain elusive. While, based on current literature, it is expected that in-context learning shares a similar mechanism to supervised learning, Min et al.(2022) recently reported that, surprisingly, input-label correspondence is less important than other aspects of prompt demonstrations. Inspired by this counter-intuitive observation, we re-examine the importance of … Cites: ‪An Explanation of In-context Learning as Implicit Bayesian Inference‬&lt;/p&gt;</content><author><name>J Kim, HJ Kim, H Cho, H Jo, SW Lee, S Lee, KM Yoo… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Despite recent explosion in research interests, in-context learning and the precise impact of the quality of demonstrations remain elusive. While, based on current literature, it is expected that in-context learning shares a similar mechanism to supervised learning, Min et al.(2022) recently reported that, surprisingly, input-label correspondence is less important than other aspects of prompt demonstrations. Inspired by this counter-intuitive observation, we re-examine the importance of … Cites: ‪An Explanation of In-context Learning as Implicit Bayesian Inference‬</summary></entry><entry><title type="html">How explainable are adversarially-robust CNNs?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1123fea1fe37438a74af45dd60e128f0.html" rel="alternate" type="text/html" title="How explainable are adversarially-robust CNNs?" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1123fea1fe37438a74af45dd60e128f0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1123fea1fe37438a74af45dd60e128f0.html">&lt;p&gt;Three important criteria of existing convolutional neural networks (CNNs) are (1) test-set accuracy;(2) out-of-distribution accuracy; and (3) explainability. While these criteria have been studied independently, their relationship is unknown. For example, do CNNs that have a stronger out-of-distribution performance have also stronger explainability? Furthermore, most prior feature-importance studies only evaluate methods on 2-3 common vanilla ImageNet-trained CNNs, leaving it … Cites: ‪ERASER: A benchmark to evaluate rationalized NLP models‬&lt;/p&gt;</content><author><name>M Nourelahi, L Kotthoff, P Chen, A Nguyen - arXiv preprint arXiv:2205.13042, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Three important criteria of existing convolutional neural networks (CNNs) are (1) test-set accuracy;(2) out-of-distribution accuracy; and (3) explainability. While these criteria have been studied independently, their relationship is unknown. For example, do CNNs that have a stronger out-of-distribution performance have also stronger explainability? Furthermore, most prior feature-importance studies only evaluate methods on 2-3 common vanilla ImageNet-trained CNNs, leaving it … Cites: ‪ERASER: A benchmark to evaluate rationalized NLP models‬</summary></entry><entry><title type="html">Leveraging Causal Inference for Explainable Automatic Program Repair</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/12bcf5a210c62e3b32c1f6a94f9595c1.html" rel="alternate" type="text/html" title="Leveraging Causal Inference for Explainable Automatic Program Repair" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/12bcf5a210c62e3b32c1f6a94f9595c1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/12bcf5a210c62e3b32c1f6a94f9595c1.html">&lt;p&gt;Deep learning models have made significant progress in automatic program repair. However, the black-box nature of these methods has restricted their practical applications. To address this challenge, this paper presents an interpretable approach for program repair based on sequence-to-sequence models with causal inference and our method is called CPR, short for causal program repair. Our CPR can generate explanations in the process of decision making, which consists of … Cites: ‪Codebert: A pre-trained model for programming and natural …‬&lt;/p&gt;</content><author><name>J Wang, S Si, Z Zhu, X Qu, Z Hong, J Xiao - arXiv preprint arXiv:2205.13342, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning models have made significant progress in automatic program repair. However, the black-box nature of these methods has restricted their practical applications. To address this challenge, this paper presents an interpretable approach for program repair based on sequence-to-sequence models with causal inference and our method is called CPR, short for causal program repair. Our CPR can generate explanations in the process of decision making, which consists of … Cites: ‪Codebert: A pre-trained model for programming and natural …‬</summary></entry><entry><title type="html">VulBERTa: Simplified Source Code Pre-Training for Vulnerability Detection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1573576be83bf13b35c6d7509bc37b2a.html" rel="alternate" type="text/html" title="VulBERTa: Simplified Source Code Pre-Training for Vulnerability Detection" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1573576be83bf13b35c6d7509bc37b2a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1573576be83bf13b35c6d7509bc37b2a.html">&lt;p&gt;This paper presents VulBERTa, a deep learning approach to detect security vulnerabilities in source code. Our approach pre-trains a RoBERTa model with a custom tokenisation pipeline on real-world code from open-source C/C++ projects. The model learns a deep knowledge representation of the code syntax and semantics, which we leverage to train vulnerability detection classifiers. We evaluate our approach on binary and multi-class vulnerability detection tasks across several … Cites: ‪Codexglue: A machine learning benchmark dataset for code …‬&lt;/p&gt;</content><author><name>H Hanif, S Maffeis - arXiv preprint arXiv:2205.12424, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper presents VulBERTa, a deep learning approach to detect security vulnerabilities in source code. Our approach pre-trains a RoBERTa model with a custom tokenisation pipeline on real-world code from open-source C/C++ projects. The model learns a deep knowledge representation of the code syntax and semantics, which we leverage to train vulnerability detection classifiers. We evaluate our approach on binary and multi-class vulnerability detection tasks across several … Cites: ‪Codexglue: A machine learning benchmark dataset for code …‬</summary></entry><entry><title type="html">Symbolic Inference for Non-Horn Knowledge Bases With Fuzzy Predicates</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/16aabcf7caf280266b8fbfd39ee7df2f.html" rel="alternate" type="text/html" title="Symbolic Inference for Non-Horn Knowledge Bases With Fuzzy Predicates" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/16aabcf7caf280266b8fbfd39ee7df2f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/16aabcf7caf280266b8fbfd39ee7df2f.html">&lt;p&gt;This paper investigates non-Horn knowledge bases with fuzzy predicates. Inference from these knowledge bases excludes reasoning by contradiction, and it is characterized by means of substructural single-succedent sequent calculi with non-logical axioms expressing knowledge base rules and facts. A variety of truth functions can be used for the bodies of knowledge base rules and their contrapositives. Lower bounds of fuzzy truth values of ground literals are obtained by … Cites: ‪Neural logic machines‬&lt;/p&gt;</content><author><name>A Sakharov - Polynomial Computer Algebra, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper investigates non-Horn knowledge bases with fuzzy predicates. Inference from these knowledge bases excludes reasoning by contradiction, and it is characterized by means of substructural single-succedent sequent calculi with non-logical axioms expressing knowledge base rules and facts. A variety of truth functions can be used for the bodies of knowledge base rules and their contrapositives. Lower bounds of fuzzy truth values of ground literals are obtained by … Cites: ‪Neural logic machines‬</summary></entry><entry><title type="html">Train Flat, Then Compress: Sharpness-Aware Minimization Learns More Compressible Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/183f0a45934b9178dd578a552224dbc7.html" rel="alternate" type="text/html" title="Train Flat, Then Compress: Sharpness-Aware Minimization Learns More Compressible Models" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/183f0a45934b9178dd578a552224dbc7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/183f0a45934b9178dd578a552224dbc7.html">&lt;p&gt;Model compression by way of parameter pruning, quantization, or distillation has recently gained popularity as an approach for reducing the computational requirements of modern deep neural network models for NLP. Pruning unnecessary parameters has emerged as a simple and effective method for compressing large models that is compatible with a wide variety of contemporary off-the-shelf hardware (unlike quantization), and that requires little additional training (unlike distillation) … Cites: ‪Structured Pruning Learns Compact and Accurate Models‬&lt;/p&gt;</content><author><name>C Na, SV Mehta, E Strubell - arXiv preprint arXiv:2205.12694, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Model compression by way of parameter pruning, quantization, or distillation has recently gained popularity as an approach for reducing the computational requirements of modern deep neural network models for NLP. Pruning unnecessary parameters has emerged as a simple and effective method for compressing large models that is compatible with a wide variety of contemporary off-the-shelf hardware (unlike quantization), and that requires little additional training (unlike distillation) … Cites: ‪Structured Pruning Learns Compact and Accurate Models‬</summary></entry><entry><title type="html">How to manage a task-oriented virtual assistant software project: an experience report</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1c356d13eaa6b09cd858a34a7def0288.html" rel="alternate" type="text/html" title="How to manage a task-oriented virtual assistant software project: an experience report" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1c356d13eaa6b09cd858a34a7def0288</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1c356d13eaa6b09cd858a34a7def0288.html">&lt;p&gt;Task-oriented virtual assistants are software systems that provide users with a natural language interface to complete domain-specific tasks. With the recent technological advances in natural language processing and machine learning, an increasing number of task-oriented virtual assistants have been developed. However, due to the well-known complexity and difficulties of the natural language understanding problem, it is challenging to manage a task-oriented virtual assistant … Cites: ‪Model-based interactive semantic parsing: A unified framework …‬&lt;/p&gt;</content><author><name>S Li, J Guo, Y Gao, J Lou, D Yang, Y Xiao, Y Zhou… - Frontiers of Information …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Task-oriented virtual assistants are software systems that provide users with a natural language interface to complete domain-specific tasks. With the recent technological advances in natural language processing and machine learning, an increasing number of task-oriented virtual assistants have been developed. However, due to the well-known complexity and difficulties of the natural language understanding problem, it is challenging to manage a task-oriented virtual assistant … Cites: ‪Model-based interactive semantic parsing: A unified framework …‬</summary></entry><entry><title type="html">DisinfoMeme: A Multimodal Dataset for Detecting Meme Intentionally Spreading Out Disinformation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1ce65ba169832fbc27a8c53d6421ca81.html" rel="alternate" type="text/html" title="DisinfoMeme: A Multimodal Dataset for Detecting Meme Intentionally Spreading Out Disinformation" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1ce65ba169832fbc27a8c53d6421ca81</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1ce65ba169832fbc27a8c53d6421ca81.html">&lt;p&gt;Disinformation has become a serious problem on social media. In particular, given their short format, visual attraction, and humorous nature, memes have a significant advantage in dissemination among online communities, making them an effective vehicle for the spread of disinformation. We present DisinfoMeme to help detect disinformation memes. The dataset contains memes mined from Reddit covering three current topics: the COVID-19 pandemic, the Black Lives Matter movement, and … Cites: ‪Infosurgeon: Cross-media fine-grained information consistency …‬&lt;/p&gt;</content><author><name>J Qu, LH Li, J Zhao, S Dev, KW Chang - arXiv preprint arXiv:2205.12617, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Disinformation has become a serious problem on social media. In particular, given their short format, visual attraction, and humorous nature, memes have a significant advantage in dissemination among online communities, making them an effective vehicle for the spread of disinformation. We present DisinfoMeme to help detect disinformation memes. The dataset contains memes mined from Reddit covering three current topics: the COVID-19 pandemic, the Black Lives Matter movement, and … Cites: ‪Infosurgeon: Cross-media fine-grained information consistency …‬</summary></entry><entry><title type="html">Tailored Text Augmentation for sentiment analysis</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1e41c7fff6913d5ba544fb927226512a.html" rel="alternate" type="text/html" title="Tailored Text Augmentation for sentiment analysis" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1e41c7fff6913d5ba544fb927226512a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1e41c7fff6913d5ba544fb927226512a.html">&lt;p&gt;In synonym replacement-based data augmentation techniques for natural language processing tasks, words in a sentence are often sampled randomly with equal probability. In this paper, we propose a novel data augmentation technique named Tailored Text Argumentation (TTA) for sentiment analysis. It has two main operations. The first operation is the probabilistic word sampling for synonym replacement based on the discriminative power and relevance of the word to sentiment. The second … Cites: ‪SSMBA: Self-supervised manifold based data augmentation for …‬&lt;/p&gt;</content><author><name>Z Feng, H Zhou, Z Zhu, K Mao - Expert Systems with Applications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In synonym replacement-based data augmentation techniques for natural language processing tasks, words in a sentence are often sampled randomly with equal probability. In this paper, we propose a novel data augmentation technique named Tailored Text Argumentation (TTA) for sentiment analysis. It has two main operations. The first operation is the probabilistic word sampling for synonym replacement based on the discriminative power and relevance of the word to sentiment. The second … Cites: ‪SSMBA: Self-supervised manifold based data augmentation for …‬</summary></entry><entry><title type="html">Eliciting Transferability in Multi-task Learning with Task-level Mixture-of-Experts</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1ec76fb142ac3497fca6846b0fb2df2f.html" rel="alternate" type="text/html" title="Eliciting Transferability in Multi-task Learning with Task-level Mixture-of-Experts" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1ec76fb142ac3497fca6846b0fb2df2f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/1ec76fb142ac3497fca6846b0fb2df2f.html">&lt;p&gt;Recent work suggests that transformer models are capable of multi-task learning on diverse NLP tasks. However, the potential of these models may be limited as they use the same set of parameters for all tasks. In contrast, humans tackle tasks in a more flexible way, by making proper presumptions on what skills and knowledge are relevant and executing only the necessary computations. Inspired by this, we propose to use task-level mixture-of-expert models, which has a collection of … Cites: ‪MOCHA: A Dataset for Training and Evaluating Generative …‬&lt;/p&gt;</content><author><name>Q Ye, J Zha, X Ren - arXiv preprint arXiv:2205.12701, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent work suggests that transformer models are capable of multi-task learning on diverse NLP tasks. However, the potential of these models may be limited as they use the same set of parameters for all tasks. In contrast, humans tackle tasks in a more flexible way, by making proper presumptions on what skills and knowledge are relevant and executing only the necessary computations. Inspired by this, we propose to use task-level mixture-of-expert models, which has a collection of … Cites: ‪MOCHA: A Dataset for Training and Evaluating Generative …‬</summary></entry><entry><title type="html">RSTGen: Imbuing Fine-Grained Interpretable Control into Long-FormText Generators</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/20077787012dab8fbeb1a6527cb7fdd0.html" rel="alternate" type="text/html" title="RSTGen: Imbuing Fine-Grained Interpretable Control into Long-FormText Generators" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/20077787012dab8fbeb1a6527cb7fdd0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/20077787012dab8fbeb1a6527cb7fdd0.html">&lt;p&gt;In this paper, we study the task of improving the cohesion and coherence of long-form text generated by language models. To this end, we propose RSTGen, a framework that utilises Rhetorical Structure Theory (RST), a classical language theory, to control the discourse structure, semantics and topics of generated text. Firstly, we demonstrate our model s ability to control structural discourse and semantic features of generated text in open generation evaluation. Then we … Cites: ‪Neural Syntactic Preordering for Controlled Paraphrase Generation‬&lt;/p&gt;</content><author><name>RA Adewoyin, R Dutta, Y He - arXiv preprint arXiv:2205.12590, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper, we study the task of improving the cohesion and coherence of long-form text generated by language models. To this end, we propose RSTGen, a framework that utilises Rhetorical Structure Theory (RST), a classical language theory, to control the discourse structure, semantics and topics of generated text. Firstly, we demonstrate our model s ability to control structural discourse and semantic features of generated text in open generation evaluation. Then we … Cites: ‪Neural Syntactic Preordering for Controlled Paraphrase Generation‬</summary></entry><entry><title type="html">Logical Satisfiability of Counterfactuals for Faithful Explanations in NLI</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/22031469da8b19b1dfabe7827090c2f1.html" rel="alternate" type="text/html" title="Logical Satisfiability of Counterfactuals for Faithful Explanations in NLI" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/22031469da8b19b1dfabe7827090c2f1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/22031469da8b19b1dfabe7827090c2f1.html">&lt;p&gt;Evaluating an explanation s faithfulness is desired for many reasons such as trust, interpretability and diagnosing the sources of model s errors. In this work, which focuses on the NLI task, we introduce the methodology of Faithfulness-through-Counterfactuals, which first generates a counterfactual hypothesis based on the logical predicates expressed in the explanation, and then evaluates if the model s prediction on the counterfactual is consistent with that expressed logic (ie if the new … Cites: ‪Toward Code Generation: A Survey and Lessons from Semantic …‬&lt;/p&gt;</content><author><name>S Sia, A Belyy, A Almahairi, M Khabsa, L Zettlemoyer… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Evaluating an explanation s faithfulness is desired for many reasons such as trust, interpretability and diagnosing the sources of model s errors. In this work, which focuses on the NLI task, we introduce the methodology of Faithfulness-through-Counterfactuals, which first generates a counterfactual hypothesis based on the logical predicates expressed in the explanation, and then evaluates if the model s prediction on the counterfactual is consistent with that expressed logic (ie if the new … Cites: ‪Toward Code Generation: A Survey and Lessons from Semantic …‬</summary></entry><entry><title type="html">Textual Backdoor Attacks with Iterative Trigger Injection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/22f4b53a15e0833293d8524cae76967d.html" rel="alternate" type="text/html" title="Textual Backdoor Attacks with Iterative Trigger Injection" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/22f4b53a15e0833293d8524cae76967d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/22f4b53a15e0833293d8524cae76967d.html">&lt;p&gt;The backdoor attack has become an emerging threat for Natural Language Processing (NLP) systems. A victim model trained on poisoned data can be embedded with a  backdoor , making it predict the adversary-specified output (eg, the positive sentiment label) on inputs satisfying the trigger pattern (eg, containing a certain keyword). In this paper, we demonstrate that it s possible to design an effective and stealthy backdoor attack by iteratively injecting  triggers  into a small set … Cites: ‪Mind the Style of Text! Adversarial and Backdoor Attacks Based on …‬&lt;/p&gt;</content><author><name>J Yan, V Gupta, X Ren - arXiv preprint arXiv:2205.12700, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The backdoor attack has become an emerging threat for Natural Language Processing (NLP) systems. A victim model trained on poisoned data can be embedded with a backdoor , making it predict the adversary-specified output (eg, the positive sentiment label) on inputs satisfying the trigger pattern (eg, containing a certain keyword). In this paper, we demonstrate that it s possible to design an effective and stealthy backdoor attack by iteratively injecting triggers into a small set … Cites: ‪Mind the Style of Text! Adversarial and Backdoor Attacks Based on …‬</summary></entry><entry><title type="html">Asking the Right Questions in Low Resource Template Extraction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/233a2b3f4a7e837ea69578127f0fcc71.html" rel="alternate" type="text/html" title="Asking the Right Questions in Low Resource Template Extraction" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/233a2b3f4a7e837ea69578127f0fcc71</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/233a2b3f4a7e837ea69578127f0fcc71.html">&lt;p&gt;Information Extraction (IE) researchers are mapping tasks to Question Answering (QA) in order to leverage existing large QA resources, and thereby improve data efficiency. Especially in template extraction (TE), mapping an ontology to a set of questions can be more time-efficient than collecting labeled examples. We ask whether end users of TE systems can design these questions, and whether it is beneficial to involve an NLP practitioner in the process. We compare questions to … Cites: ‪Cutting down on prompts and parameters: Simple few-shot …‬&lt;/p&gt;</content><author><name>N Holzenberger, Y Chen, B Van Durme - arXiv preprint arXiv:2205.12643, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Information Extraction (IE) researchers are mapping tasks to Question Answering (QA) in order to leverage existing large QA resources, and thereby improve data efficiency. Especially in template extraction (TE), mapping an ontology to a set of questions can be more time-efficient than collecting labeled examples. We ask whether end users of TE systems can design these questions, and whether it is beneficial to involve an NLP practitioner in the process. We compare questions to … Cites: ‪Cutting down on prompts and parameters: Simple few-shot …‬</summary></entry><entry><title type="html">DialogZoo: Large-Scale Dialog-Oriented Task Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/25f9f6cdd8589ff6dca3732035564c22.html" rel="alternate" type="text/html" title="DialogZoo: Large-Scale Dialog-Oriented Task Learning" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/25f9f6cdd8589ff6dca3732035564c22</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/25f9f6cdd8589ff6dca3732035564c22.html">&lt;p&gt;Building unified conversational agents has been a long-standing goal of the dialogue research community. Most previous works only focus on a subset of various dialogue tasks. In this work, we aim to build a unified foundation model which can solve massive diverse dialogue tasks. To achieve this goal, we first collect a large-scale well-labeled dialogue dataset from 73 publicly available datasets. In addition to this dataset, we further propose two dialogue-oriented self-supervised tasks, and … Cites: ‪Coqa: A conversational question answering challenge‬&lt;/p&gt;</content><author><name>Z Chen, J Bao, L Chen, Y Liu, D Ma, B Chen, M Wu… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Building unified conversational agents has been a long-standing goal of the dialogue research community. Most previous works only focus on a subset of various dialogue tasks. In this work, we aim to build a unified foundation model which can solve massive diverse dialogue tasks. To achieve this goal, we first collect a large-scale well-labeled dialogue dataset from 73 publicly available datasets. In addition to this dataset, we further propose two dialogue-oriented self-supervised tasks, and … Cites: ‪Coqa: A conversational question answering challenge‬</summary></entry><entry><title type="html">Revisiting Calibration for Question Answering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/26b5f70f77737d7cfc87ad39979e3c52.html" rel="alternate" type="text/html" title="Revisiting Calibration for Question Answering" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/26b5f70f77737d7cfc87ad39979e3c52</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/26b5f70f77737d7cfc87ad39979e3c52.html">&lt;p&gt;Model calibration aims to adjust (calibrate) models  confidence so that they match expected accuracy. We argue that the traditional evaluation of calibration (expected calibration error; ECE) does not reflect usefulness of the model confidence. For example, after conventional temperature scaling, confidence scores become similar for all predictions, which makes it hard for users to distinguish correct predictions from wrong ones, even though it achieves low ECE. Building on those observations … Cites: ‪Can Explanations Be Useful for Calibrating Black Box Models?‬&lt;/p&gt;</content><author><name>C Si, C Zhao, S Min, J Boyd-Graber - arXiv preprint arXiv:2205.12507, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Model calibration aims to adjust (calibrate) models confidence so that they match expected accuracy. We argue that the traditional evaluation of calibration (expected calibration error; ECE) does not reflect usefulness of the model confidence. For example, after conventional temperature scaling, confidence scores become similar for all predictions, which makes it hard for users to distinguish correct predictions from wrong ones, even though it achieves low ECE. Building on those observations … Cites: ‪Can Explanations Be Useful for Calibrating Black Box Models?‬</summary></entry><entry><title type="html">FLUTE: Figurative Language Understanding and Textual Explanations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/28c2b6e21a697c69fdf4cc0aae506843.html" rel="alternate" type="text/html" title="FLUTE: Figurative Language Understanding and Textual Explanations" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/28c2b6e21a697c69fdf4cc0aae506843</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/28c2b6e21a697c69fdf4cc0aae506843.html">&lt;p&gt;In spite of the prevalence of figurative language, transformer-based models struggle to demonstrate an understanding of it. Meanwhile, even classical natural language inference (NLI) tasks have been plagued by spurious correlations and annotation artifacts. Datasets like eSNLI have been released, allowing to probe whether language models are right for the right reasons. Yet no such data exists for figurative language, making it harder to asses genuine understanding of such expressions. In … Cites: ‪Testing the Ability of Language Models to Interpret Figurative …‬&lt;/p&gt;</content><author><name>T Chakrabarty, A Saakyan, D Ghosh, S Muresan - arXiv preprint arXiv:2205.12404, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In spite of the prevalence of figurative language, transformer-based models struggle to demonstrate an understanding of it. Meanwhile, even classical natural language inference (NLI) tasks have been plagued by spurious correlations and annotation artifacts. Datasets like eSNLI have been released, allowing to probe whether language models are right for the right reasons. Yet no such data exists for figurative language, making it harder to asses genuine understanding of such expressions. In … Cites: ‪Testing the Ability of Language Models to Interpret Figurative …‬</summary></entry><entry><title type="html">Joint Modeling Based on Multi-task Learning for Aspect Term Extraction and Sentiment Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2a3fcd7bfd69eb1fb1b51641b3a02b2a.html" rel="alternate" type="text/html" title="Joint Modeling Based on Multi-task Learning for Aspect Term Extraction and Sentiment Classification" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2a3fcd7bfd69eb1fb1b51641b3a02b2a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2a3fcd7bfd69eb1fb1b51641b3a02b2a.html">&lt;p&gt;Fine-grained aspect-based sentiment analysis involves aspect term extraction and aspect sentiment classification. Most existing research methods address them in an independent fashion, which lack a mechanism to account for the relevant information between each other, and will also cause training redundancy and waste of resources. To solve the above problems, a joint model based on position embedding and graph convolutional network under the framework of multi-task learning is … Cites: ‪Effective LSTMs for target-dependent sentiment classification‬&lt;/p&gt;</content><author><name>M Tiantian, HAN Hu, WU Yuanhang - Journal of Frontiers of Computer Science &amp; Technology</name></author><category term="jekyll" /><category term="update" /><summary type="html">Fine-grained aspect-based sentiment analysis involves aspect term extraction and aspect sentiment classification. Most existing research methods address them in an independent fashion, which lack a mechanism to account for the relevant information between each other, and will also cause training redundancy and waste of resources. To solve the above problems, a joint model based on position embedding and graph convolutional network under the framework of multi-task learning is … Cites: ‪Effective LSTMs for target-dependent sentiment classification‬</summary></entry><entry><title type="html">Deep learning-based multi-label tissue segmentation and density assessment from mammograms</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2b29a5db8e8533d0b0d22348aa54f525.html" rel="alternate" type="text/html" title="Deep learning-based multi-label tissue segmentation and density assessment from mammograms" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2b29a5db8e8533d0b0d22348aa54f525</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2b29a5db8e8533d0b0d22348aa54f525.html">&lt;p&gt;Objectives: Breast cancer is the most commonly diagnosed type of cancer among women and a common cause of cancer-related deaths. Early diagnosis and treatment of breast cancer is critical in disease prognosis. Breast density is known to have a correlation with breast cancer. In recent years, there has been an increasing interest in the investigation of computer-aided methods for early diagnosis of breast cancer. In this study, a new fully-automated deep learning-based cascaded model … Cites: ‪Imagenet: A large-scale hierarchical image database, 2009‬&lt;/p&gt;</content><author><name>VM Tiryaki, V Kaplanoğlu - IRBM, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Objectives: Breast cancer is the most commonly diagnosed type of cancer among women and a common cause of cancer-related deaths. Early diagnosis and treatment of breast cancer is critical in disease prognosis. Breast density is known to have a correlation with breast cancer. In recent years, there has been an increasing interest in the investigation of computer-aided methods for early diagnosis of breast cancer. In this study, a new fully-automated deep learning-based cascaded model … Cites: ‪Imagenet: A large-scale hierarchical image database, 2009‬</summary></entry><entry><title type="html">Linear Connectivity Reveals Generalization Strategies</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2c292f5903b0051149b494da700f957d.html" rel="alternate" type="text/html" title="Linear Connectivity Reveals Generalization Strategies" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2c292f5903b0051149b494da700f957d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2c292f5903b0051149b494da700f957d.html">&lt;p&gt;It is widely accepted in the mode connectivity literature that when two neural networks are trained similarly on the same data, they are connected by a path through parameter space over which test set accuracy is maintained. Under some …&lt;/p&gt;</content><author><name>J Juneja, R Bansal, K Cho, J Sedoc, N Saphra - arXiv preprint arXiv:2205.12411, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">It is widely accepted in the mode connectivity literature that when two neural networks are trained similarly on the same data, they are connected by a path through parameter space over which test set accuracy is maintained. Under some …</summary></entry><entry><title type="html">BiT: Robustly Binarized Multi-distilled Transformer</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2db890fe8c8e8817545bf3f224391257.html" rel="alternate" type="text/html" title="BiT: Robustly Binarized Multi-distilled Transformer" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2db890fe8c8e8817545bf3f224391257</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2db890fe8c8e8817545bf3f224391257.html">&lt;p&gt;Modern pre-trained transformers have rapidly advanced the state-of-the-art in machine learning, but have also grown in parameters and computational complexity, making them increasingly difficult to deploy in resource-constrained environments …&lt;/p&gt;</content><author><name>Z Liu, B Oguz, A Pappu, L Xiao, S Yih, M Li… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Modern pre-trained transformers have rapidly advanced the state-of-the-art in machine learning, but have also grown in parameters and computational complexity, making them increasingly difficult to deploy in resource-constrained environments …</summary></entry><entry><title type="html">Constrained Sampling from Language Models via Langevin Dynamics in Embedding Spaces</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2eddc74981b2d486a9c6e3353cba9083.html" rel="alternate" type="text/html" title="Constrained Sampling from Language Models via Langevin Dynamics in Embedding Spaces" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2eddc74981b2d486a9c6e3353cba9083</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/2eddc74981b2d486a9c6e3353cba9083.html">&lt;p&gt;Large pre-trained language models are well-established for their ability to generate text seemingly indistinguishable from humans. In this work, we study the problem of constrained sampling from such language models. That is, generating text that satisfies user-defined constraints. Typical decoding strategies which generate samples left-to-right are not always conducive to imposing such constraints globally. Instead, we propose MuCoLa–a sampling procedure that combines the log … Cites: ‪COLD Decoding: Energy-based Constrained Text Generation with …‬&lt;/p&gt;</content><author><name>S Kumar, B Paria, Y Tsvetkov - arXiv preprint arXiv:2205.12558, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Large pre-trained language models are well-established for their ability to generate text seemingly indistinguishable from humans. In this work, we study the problem of constrained sampling from such language models. That is, generating text that satisfies user-defined constraints. Typical decoding strategies which generate samples left-to-right are not always conducive to imposing such constraints globally. Instead, we propose MuCoLa–a sampling procedure that combines the log … Cites: ‪COLD Decoding: Energy-based Constrained Text Generation with …‬</summary></entry><entry><title type="html">PLAtE: A Large-scale Dataset for List Page Web Extraction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/302ecf27abd7d27aee605a7e549ddb10.html" rel="alternate" type="text/html" title="PLAtE: A Large-scale Dataset for List Page Web Extraction" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/302ecf27abd7d27aee605a7e549ddb10</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/302ecf27abd7d27aee605a7e549ddb10.html">&lt;p&gt;Recently, neural models have been leveraged to significantly improve the performance of information extraction from semi-structured websites. However, a barrier for continued progress is the small number of datasets large enough to train these models. In this work, we introduce the PLAtE (Pages of Lists Attribute Extraction) dataset as a challenging new web extraction task. PLAtE focuses on shopping data, specifically extractions from product review pages with multiple items … Cites: ‪Ten years of webtables‬&lt;/p&gt;</content><author><name>A San, J Bakus, C Lockard, D Ciemiewicz, Y Ji, S Atluri… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recently, neural models have been leveraged to significantly improve the performance of information extraction from semi-structured websites. However, a barrier for continued progress is the small number of datasets large enough to train these models. In this work, we introduce the PLAtE (Pages of Lists Attribute Extraction) dataset as a challenging new web extraction task. PLAtE focuses on shopping data, specifically extractions from product review pages with multiple items … Cites: ‪Ten years of webtables‬</summary></entry><entry><title type="html">Tiered Reinforcement Learning: Pessimism in the Face of Uncertainty and Constant Regret</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/30835b3f246c8620fcce632c4b891607.html" rel="alternate" type="text/html" title="Tiered Reinforcement Learning: Pessimism in the Face of Uncertainty and Constant Regret" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/30835b3f246c8620fcce632c4b891607</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/30835b3f246c8620fcce632c4b891607.html">&lt;p&gt;We propose a new learning framework that captures the tiered structure of many real-world user-interaction applications, where the users can be divided into two groups based on their different tolerance on exploration risks and should be treated separately. In this setting, we simultaneously maintain two policies $\pi^{\text {O}} $ and $\pi^{\text {E}} $: $\pi^{\text {O}} $(  O  for  online ) interacts with more risk-tolerant users from the first tier and minimizes regret by balancing exploration and … Cites: ‪Breaking the curse of horizon: Infinite-horizon off-policy estimation‬&lt;/p&gt;</content><author><name>J Huang, L Zhao, T Qin, W Chen, N Jiang, TY Liu - arXiv preprint arXiv:2205.12418, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose a new learning framework that captures the tiered structure of many real-world user-interaction applications, where the users can be divided into two groups based on their different tolerance on exploration risks and should be treated separately. In this setting, we simultaneously maintain two policies $\pi^{\text {O}} $ and $\pi^{\text {E}} $: $\pi^{\text {O}} $( O for online ) interacts with more risk-tolerant users from the first tier and minimizes regret by balancing exploration and … Cites: ‪Breaking the curse of horizon: Infinite-horizon off-policy estimation‬</summary></entry><entry><title type="html">NaturalProver: Grounded Mathematical Proof Generation with Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/32e522fa2f4db70bee629049f13ed956.html" rel="alternate" type="text/html" title="NaturalProver: Grounded Mathematical Proof Generation with Language Models" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/32e522fa2f4db70bee629049f13ed956</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/32e522fa2f4db70bee629049f13ed956.html">&lt;p&gt;Theorem proving in natural mathematical language-the mixture of symbolic and natural language used by humans-plays a central role in mathematical advances and education, and tests aspects of reasoning that are core to intelligence. Yet it has …&lt;/p&gt;</content><author><name>S Welleck, J Liu, X Lu, H Hajishirzi, Y Choi - arXiv preprint arXiv:2205.12910, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Theorem proving in natural mathematical language-the mixture of symbolic and natural language used by humans-plays a central role in mathematical advances and education, and tests aspects of reasoning that are core to intelligence. Yet it has …</summary></entry><entry><title type="html">Multimodal Knowledge Alignment with Reinforcement Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/345c5ba42216048251a159acb581180b.html" rel="alternate" type="text/html" title="Multimodal Knowledge Alignment with Reinforcement Learning" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/345c5ba42216048251a159acb581180b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/345c5ba42216048251a159acb581180b.html">&lt;p&gt;Large language models readily adapt to novel settings, even without task-specific training data. Can their zero-shot capacity be extended to multimodal inputs? In this work, we propose ESPER which extends language-only zero-shot models to unseen …&lt;/p&gt;</content><author><name>Y Yu, J Chung, H Yun, J Hessel, JS Park, X Lu… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Large language models readily adapt to novel settings, even without task-specific training data. Can their zero-shot capacity be extended to multimodal inputs? In this work, we propose ESPER which extends language-only zero-shot models to unseen …</summary></entry><entry><title type="html">An Explainable Semantic Parser for End-User Development</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/35bc18a8fc6216ea609bbd8b79f49ad2.html" rel="alternate" type="text/html" title="An Explainable Semantic Parser for End-User Development" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/35bc18a8fc6216ea609bbd8b79f49ad2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/35bc18a8fc6216ea609bbd8b79f49ad2.html">&lt;p&gt;Programming is a key skill in a world where businesses are driven by digital transformations. Although many of the programming demand can be addressed by a simple set of instructions composing libraries and services available in the web, non-technical professionals, such as domain experts and analysts, are still unable to construct their own programs due to the intrinsic complexity of coding. Among other types of end-user development, natural language programming has emerged to … Cites: ‪A syntactic neural model for general-purpose code generation‬&lt;/p&gt;</content><author><name>N Sales, J Efson - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Programming is a key skill in a world where businesses are driven by digital transformations. Although many of the programming demand can be addressed by a simple set of instructions composing libraries and services available in the web, non-technical professionals, such as domain experts and analysts, are still unable to construct their own programs due to the intrinsic complexity of coding. Among other types of end-user development, natural language programming has emerged to … Cites: ‪A syntactic neural model for general-purpose code generation‬</summary></entry><entry><title type="html">AI in Arbitration and Courts</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/371ad6397ee6aa0f89748a26859d8687.html" rel="alternate" type="text/html" title="AI in Arbitration and Courts" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/371ad6397ee6aa0f89748a26859d8687</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/371ad6397ee6aa0f89748a26859d8687.html">&lt;p&gt;The litigation explosion had a destructive impact on the model of justice to which society was traditionally linked. Arbitration as a co-equal and independent to courts dispute mechanism is the resolution in present times. There are AI systems allowing not only improved prediction results but also deliver clients with powerful information management services. Legal decision-making entails cognitive and emotional capabilities that current AI does not possess. Blockchain applications for arbitrations … Cites: ‪The unreasonable effectiveness of data‬&lt;/p&gt;</content><author><name>GI Zekos - Advanced Artificial Intelligence and Robo-Justice, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The litigation explosion had a destructive impact on the model of justice to which society was traditionally linked. Arbitration as a co-equal and independent to courts dispute mechanism is the resolution in present times. There are AI systems allowing not only improved prediction results but also deliver clients with powerful information management services. Legal decision-making entails cognitive and emotional capabilities that current AI does not possess. Blockchain applications for arbitrations … Cites: ‪The unreasonable effectiveness of data‬</summary></entry><entry><title type="html">Nearest Neighbor Zero-Shot Inference</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/3afed0886c7a6cfc4807db4cea04b806.html" rel="alternate" type="text/html" title="Nearest Neighbor Zero-Shot Inference" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/3afed0886c7a6cfc4807db4cea04b806</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/3afed0886c7a6cfc4807db4cea04b806.html">&lt;p&gt;We introduce kNN-Prompt, a simple and effective technique to use k-nearest neighbor (kNN) retrieval augmentation (Khandelwal et al., 2021) for zero-shot inference with language models (LMs). Key to our approach is the introduction of fuzzy verbalizers which leverage the sparse kNN distribution for downstream tasks by automatically associating each classification label with a set of natural language tokens. Across eleven diverse end-tasks (spanning text classification, fact retrieval … Cites: ‪Efficient Nearest Neighbor Language Models‬&lt;/p&gt;</content><author><name>WSJMS Gururangan, L Zettlemoyer</name></author><category term="jekyll" /><category term="update" /><summary type="html">We introduce kNN-Prompt, a simple and effective technique to use k-nearest neighbor (kNN) retrieval augmentation (Khandelwal et al., 2021) for zero-shot inference with language models (LMs). Key to our approach is the introduction of fuzzy verbalizers which leverage the sparse kNN distribution for downstream tasks by automatically associating each classification label with a set of natural language tokens. Across eleven diverse end-tasks (spanning text classification, fact retrieval … Cites: ‪Efficient Nearest Neighbor Language Models‬</summary></entry><entry><title type="html">Teaching Broad Reasoning Skills via Decomposition-Guided Contexts</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/3bb317713ac1055dc5c6f2290f604479.html" rel="alternate" type="text/html" title="Teaching Broad Reasoning Skills via Decomposition-Guided Contexts" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/3bb317713ac1055dc5c6f2290f604479</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/3bb317713ac1055dc5c6f2290f604479.html">&lt;p&gt;Question-answering datasets require a broad set of reasoning skills. We show how to use question decompositions to teach language models these broad reasoning skills in a robust fashion. Specifically, we use widely available QDMR representations to programmatically create synthetic contexts for real questions in six multihop reasoning datasets. These contexts are carefully designed to avoid common reasoning shortcuts prevalent in real contexts that prevent models from … Cites: ‪Did aristotle use a laptop? a question answering benchmark with …‬&lt;/p&gt;</content><author><name>H Trivedi, N Balasubramanian, T Khot, A Sabharwal - arXiv preprint arXiv:2205.12496, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Question-answering datasets require a broad set of reasoning skills. We show how to use question decompositions to teach language models these broad reasoning skills in a robust fashion. Specifically, we use widely available QDMR representations to programmatically create synthetic contexts for real questions in six multihop reasoning datasets. These contexts are carefully designed to avoid common reasoning shortcuts prevalent in real contexts that prevent models from … Cites: ‪Did aristotle use a laptop? a question answering benchmark with …‬</summary></entry><entry><title type="html">To trust or not to trust? An assessment of trust in AI-based systems: Concerns, ethics and contexts</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/3de588483d91d455c79dcd1c71fe1550.html" rel="alternate" type="text/html" title="To trust or not to trust? An assessment of trust in AI-based systems: Concerns, ethics and contexts" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/3de588483d91d455c79dcd1c71fe1550</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/3de588483d91d455c79dcd1c71fe1550.html">&lt;p&gt;Artificial intelligence (AI) characterizes a new generation of technologies capable of interacting with the environment and aiming to simulate human intelligence. The success of integrating AI into organizations critically depends on workers  trust in AI technology. Trust is a central component of the interaction between people and AI, as incorrect levels of trust may cause misuse, abuse or disuse of the technology. The European Commission s High-level Expert Group on AI (HLEG) have adopted the … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/p&gt;</content><author><name>N Omrani, G Rivieccio, U Fiore, F Schiavone… - … Forecasting and Social …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Artificial intelligence (AI) characterizes a new generation of technologies capable of interacting with the environment and aiming to simulate human intelligence. The success of integrating AI into organizations critically depends on workers trust in AI technology. Trust is a central component of the interaction between people and AI, as incorrect levels of trust may cause misuse, abuse or disuse of the technology. The European Commission s High-level Expert Group on AI (HLEG) have adopted the … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/3f3e9105c2b10eccc775d9bfe0b0ef58.html" rel="alternate" type="text/html" title="PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/3f3e9105c2b10eccc775d9bfe0b0ef58</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/3f3e9105c2b10eccc775d9bfe0b0ef58.html">&lt;p&gt;Logical table-to-text generation is a task that involves generating logically faithful sentences from tables, which requires models to derive logical level facts from table records via logical inference. It raises a new challenge on the logical-level content planning of table-to-text models. However, directly learning the logical inference knowledge from table-text pairs is very difficult for neural models because of the ambiguity of natural language and the scarcity of parallel data. Hence even large … Cites: ‪UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge …‬&lt;/p&gt;</content><author><name>A Liu, H Dong, N Okazaki, S Han, D Zhang - arXiv preprint arXiv:2205.12697, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Logical table-to-text generation is a task that involves generating logically faithful sentences from tables, which requires models to derive logical level facts from table records via logical inference. It raises a new challenge on the logical-level content planning of table-to-text models. However, directly learning the logical inference knowledge from table-text pairs is very difficult for neural models because of the ambiguity of natural language and the scarcity of parallel data. Hence even large … Cites: ‪UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge …‬</summary></entry><entry><title type="html">BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird s-Eye View Representation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4305bd3d71fe76d1fe44a2d6449da1ef.html" rel="alternate" type="text/html" title="BEVFusion: Multi-Task Multi-Sensor Fusion with Unified Bird s-Eye View Representation" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4305bd3d71fe76d1fe44a2d6449da1ef</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4305bd3d71fe76d1fe44a2d6449da1ef.html">&lt;p&gt;Multi-sensor fusion is essential for an accurate and reliable autonomous driving system. Recent approaches are based on point-level fusion: augmenting the LiDAR point cloud with camera features. However, the camera-to-LiDAR projection throws away the semantic density of camera features, hindering the effectiveness of such methods, especially for semantic-oriented tasks (such as 3D scene segmentation). In this paper, we break this deeply-rooted convention with BEVFusion, an efficient and … Cites: ‪DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object …‬&lt;/p&gt;</content><author><name>Z Liu, H Tang, A Amini, X Yang, H Mao, D Rus, S Han - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Multi-sensor fusion is essential for an accurate and reliable autonomous driving system. Recent approaches are based on point-level fusion: augmenting the LiDAR point cloud with camera features. However, the camera-to-LiDAR projection throws away the semantic density of camera features, hindering the effectiveness of such methods, especially for semantic-oriented tasks (such as 3D scene segmentation). In this paper, we break this deeply-rooted convention with BEVFusion, an efficient and … Cites: ‪DeepFusion: Lidar-Camera Deep Fusion for Multi-Modal 3D Object …‬</summary></entry><entry><title type="html">QAMPARI:: An Open-domain Question Answering Benchmark for Questions with Many Answers from Multiple Paragraphs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4310a12aeb394e19aa2ea4efe3617e68.html" rel="alternate" type="text/html" title="QAMPARI:: An Open-domain Question Answering Benchmark for Questions with Many Answers from Multiple Paragraphs" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4310a12aeb394e19aa2ea4efe3617e68</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4310a12aeb394e19aa2ea4efe3617e68.html">&lt;p&gt;Existing benchmarks for open-domain question answering (ODQA) typically focus on questions whose answers can be extracted from a single paragraph. By contrast, many natural questions, such as  What players were drafted by the Brooklyn Nets?  …&lt;/p&gt;</content><author><name>SJAO Rubin, O Yoran, T Wolfson, J Herzig, J Berant - arXiv preprint arXiv:2205.12665, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Existing benchmarks for open-domain question answering (ODQA) typically focus on questions whose answers can be extracted from a single paragraph. By contrast, many natural questions, such as What players were drafted by the Brooklyn Nets? …</summary></entry><entry><title type="html">Using Expert Interpretation and Reasoning to Guide Model Selection in Machine Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4747bf55e7423f1a2f42a20548a4de56.html" rel="alternate" type="text/html" title="Using Expert Interpretation and Reasoning to Guide Model Selection in Machine Learning" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4747bf55e7423f1a2f42a20548a4de56</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4747bf55e7423f1a2f42a20548a4de56.html">&lt;p&gt;In using machine learning to train predictive models, training data often under-specify solutions due to limited sample size and/or the lack of diversity in samples. When selecting a solution (or model) for deployment, we must consider metrics beyond statistics calculated in distribution (ie, statistics on samples available in model learning such as training and validation error) so that we can identify and correct potential pitfalls of the learned model when applied to out of distribution … Cites: ‪Beyond Accuracy: Behavioral Testing of NLP Models with CheckList‬&lt;/p&gt;</content><author><name>J Wang - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In using machine learning to train predictive models, training data often under-specify solutions due to limited sample size and/or the lack of diversity in samples. When selecting a solution (or model) for deployment, we must consider metrics beyond statistics calculated in distribution (ie, statistics on samples available in model learning such as training and validation error) so that we can identify and correct potential pitfalls of the learned model when applied to out of distribution … Cites: ‪Beyond Accuracy: Behavioral Testing of NLP Models with CheckList‬</summary></entry><entry><title type="html">Detecting Label Errors using Pre-Trained Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4975368ccf755b7e18d16104e90d1d4e.html" rel="alternate" type="text/html" title="Detecting Label Errors using Pre-Trained Language Models" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4975368ccf755b7e18d16104e90d1d4e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4975368ccf755b7e18d16104e90d1d4e.html">&lt;p&gt;We show that large pre-trained language models are extremely capable of identifying label errors in datasets: simply verifying data points in descending order of out-of-distribution loss significantly outperforms more complex mechanisms for …&lt;/p&gt;</content><author><name>D Chong, J Hong, CD Manning - arXiv preprint arXiv:2205.12702, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We show that large pre-trained language models are extremely capable of identifying label errors in datasets: simply verifying data points in descending order of out-of-distribution loss significantly outperforms more complex mechanisms for …</summary></entry><entry><title type="html">Active Programming by Example with a Natural Language Prior</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4b85800b9cd2e812ac8a9bc34e8ec0d8.html" rel="alternate" type="text/html" title="Active Programming by Example with a Natural Language Prior" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4b85800b9cd2e812ac8a9bc34e8ec0d8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4b85800b9cd2e812ac8a9bc34e8ec0d8.html">&lt;p&gt;We introduce APEL, a new framework that enables non-programmers to indirectly annotate natural language utterances with executable meaning representations, such as SQL programs. Based on a natural language utterance, we first run a seed semantic parser to generate a prior over a list of candidate programs. To obtain information about which candidate is correct, we synthesize an input on which the more likely programs tend to produce different outputs, and ask an annotator which … Cites: ‪Constructing Expressive Relational Queries with Dual …‬&lt;/p&gt;</content><author><name>R Zhong, C Snell, D Klein, J Eisner - arXiv preprint arXiv:2205.12422, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We introduce APEL, a new framework that enables non-programmers to indirectly annotate natural language utterances with executable meaning representations, such as SQL programs. Based on a natural language utterance, we first run a seed semantic parser to generate a prior over a list of candidate programs. To obtain information about which candidate is correct, we synthesize an input on which the more likely programs tend to produce different outputs, and ask an annotator which … Cites: ‪Constructing Expressive Relational Queries with Dual …‬</summary></entry><entry><title type="html">Hypergraph Collaborative Network on Vertices and Hyperedges</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4c004c5c735ba4d94218d5ad05acca93.html" rel="alternate" type="text/html" title="Hypergraph Collaborative Network on Vertices and Hyperedges" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4c004c5c735ba4d94218d5ad05acca93</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4c004c5c735ba4d94218d5ad05acca93.html">&lt;p&gt;In many practical data sets, such as co-citation and co-authorship, relationships across the samples are more complex than pair-wise. Hypergraphs provide a flexible and natural representation for such complex correlations and thus obtain increasing attention in the machine learning and data mining communities. Existing deep-learning-based hypergraph approaches seek to learn the latent vertex representations based on either vertices or hyperedges from previous layers and … Cites: ‪Learning with hypergraphs: Clustering, classification, and …‬&lt;/p&gt;</content><author><name>H Wu, Y Yan, MK Ng - IEEE Transactions on Pattern Analysis and Machine …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In many practical data sets, such as co-citation and co-authorship, relationships across the samples are more complex than pair-wise. Hypergraphs provide a flexible and natural representation for such complex correlations and thus obtain increasing attention in the machine learning and data mining communities. Existing deep-learning-based hypergraph approaches seek to learn the latent vertex representations based on either vertices or hyperedges from previous layers and … Cites: ‪Learning with hypergraphs: Clustering, classification, and …‬</summary></entry><entry><title type="html">Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious Feature-Label Correlation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4d666b55523f4441093528d420fd43f0.html" rel="alternate" type="text/html" title="Less Learn Shortcut: Analyzing and Mitigating Learning of Spurious Feature-Label Correlation" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4d666b55523f4441093528d420fd43f0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4d666b55523f4441093528d420fd43f0.html">&lt;p&gt;Many recent works indicate that the deep neural networks tend to take dataset biases as shortcuts to make decision, rather than understand the tasks, which results in failures on the real-world applications. In this work, we focus on the spurious correlation between feature and label, which derive from the biased data distribution in the training data, and analyze it concretely. In particular, we define the word highly co-occurring with a specific label as biased word, and the example containing biased … Cites: ‪Avoiding the hypothesis-only bias in natural language inference …‬&lt;/p&gt;</content><author><name>Y Du, J Yan, Y Chen, J Liu, S Zhao, H Wu, H Wang… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Many recent works indicate that the deep neural networks tend to take dataset biases as shortcuts to make decision, rather than understand the tasks, which results in failures on the real-world applications. In this work, we focus on the spurious correlation between feature and label, which derive from the biased data distribution in the training data, and analyze it concretely. In particular, we define the word highly co-occurring with a specific label as biased word, and the example containing biased … Cites: ‪Avoiding the hypothesis-only bias in natural language inference …‬</summary></entry><entry><title type="html">Neighborhood Network for Aspect-Based Sentiment Analysis</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4d78544668377500570516d826e0408c.html" rel="alternate" type="text/html" title="Neighborhood Network for Aspect-Based Sentiment Analysis" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4d78544668377500570516d826e0408c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4d78544668377500570516d826e0408c.html">&lt;p&gt;Different aspects of a sentence may contain different sentiments, and sentiment descriptors for a given aspect exist in different places in the sentence, making it difficult to determine its sentiment polarity. Aiming at the above problems, a neighborhood network (Nenet) for aspect-based sentiment analysis is proposed. Firstly, the context information of the text is encoded, and the neighborhood information of the target aspect at the grammar level is extracted by using a graph … Cites: ‪Aspect level sentiment classification with deep memory network‬&lt;/p&gt;</content><author><name>H Liu, Q Dou - International Conference on Intelligent Information …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Different aspects of a sentence may contain different sentiments, and sentiment descriptors for a given aspect exist in different places in the sentence, making it difficult to determine its sentiment polarity. Aiming at the above problems, a neighborhood network (Nenet) for aspect-based sentiment analysis is proposed. Firstly, the context information of the text is encoded, and the neighborhood information of the target aspect at the grammar level is extracted by using a graph … Cites: ‪Aspect level sentiment classification with deep memory network‬</summary></entry><entry><title type="html">Are Large Pre-Trained Language Models Leaking Your Personal Information?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4ec5935309d3a37709c8ac303419f3e0.html" rel="alternate" type="text/html" title="Are Large Pre-Trained Language Models Leaking Your Personal Information?" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4ec5935309d3a37709c8ac303419f3e0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/4ec5935309d3a37709c8ac303419f3e0.html">&lt;p&gt;Large Pre-Trained Language Models (PLMs) have facilitated and dominated many NLP tasks in recent years. However, despite the great success of PLMs, there are also privacy concerns brought with PLMs. For example, recent studies show that PLMs memorize a lot of training data, including sensitive information, while the information may be leaked unintentionally and be utilized by malicious attackers. In this paper, we propose to measure whether PLMs are prone to leaking personal … Cites: ‪Large language models can be strong differentially private learners‬&lt;/p&gt;</content><author><name>J Huang, H Shao, KCC Chang - arXiv preprint arXiv:2205.12628, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Large Pre-Trained Language Models (PLMs) have facilitated and dominated many NLP tasks in recent years. However, despite the great success of PLMs, there are also privacy concerns brought with PLMs. For example, recent studies show that PLMs memorize a lot of training data, including sensitive information, while the information may be leaked unintentionally and be utilized by malicious attackers. In this paper, we propose to measure whether PLMs are prone to leaking personal … Cites: ‪Large language models can be strong differentially private learners‬</summary></entry><entry><title type="html">You Need to Read Again: Multi-granularity Perception Network for Moment Retrieval in Videos</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/51408476333505cedfea33eed7e4df8d.html" rel="alternate" type="text/html" title="You Need to Read Again: Multi-granularity Perception Network for Moment Retrieval in Videos" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/51408476333505cedfea33eed7e4df8d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/51408476333505cedfea33eed7e4df8d.html">&lt;p&gt;Moment retrieval in videos is a challenging task that aims to retrieve the most relevant video moment in an untrimmed video given a sentence description. Previous methods tend to perform self-modal learning and cross-modal interaction in a coarse manner, which neglect fine-grained clues contained in video content, query context, and their alignment. To this end, we propose a novel Multi-Granularity Perception Network (MGPN) that perceives intra-modality and inter-modality … Cites: ‪Evidence sentence extraction for machine reading comprehension‬&lt;/p&gt;</content><author><name>X Sun, X Wang, J Gao, Q Liu, X Zhou - arXiv preprint arXiv:2205.12886, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Moment retrieval in videos is a challenging task that aims to retrieve the most relevant video moment in an untrimmed video given a sentence description. Previous methods tend to perform self-modal learning and cross-modal interaction in a coarse manner, which neglect fine-grained clues contained in video content, query context, and their alignment. To this end, we propose a novel Multi-Granularity Perception Network (MGPN) that perceives intra-modality and inter-modality … Cites: ‪Evidence sentence extraction for machine reading comprehension‬</summary></entry><entry><title type="html">Towards More Realistic Generation of Information-Seeking Conversations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5161e7580fff5f3fa2e9d937b1485ab7.html" rel="alternate" type="text/html" title="Towards More Realistic Generation of Information-Seeking Conversations" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5161e7580fff5f3fa2e9d937b1485ab7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5161e7580fff5f3fa2e9d937b1485ab7.html">&lt;p&gt;In this paper, we introduce a novel framework SimSeek (simulating information-seeking conversation from unlabeled documents) and compare two variants of it to provide a deeper perspective into the information-seeking behavior. We first introduce a strong simulator for information-symmetric conversation, SimSeek-sym, where questioner and answerer share all knowledge when conversing with one another. Although it simulates reasonable conversations, we take a further step … Cites: ‪Natural questions: a benchmark for question answering research‬&lt;/p&gt;</content><author><name>G Kim, S Kim, KM Yoo, J Kang - arXiv preprint arXiv:2205.12609, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper, we introduce a novel framework SimSeek (simulating information-seeking conversation from unlabeled documents) and compare two variants of it to provide a deeper perspective into the information-seeking behavior. We first introduce a strong simulator for information-symmetric conversation, SimSeek-sym, where questioner and answerer share all knowledge when conversing with one another. Although it simulates reasonable conversations, we take a further step … Cites: ‪Natural questions: a benchmark for question answering research‬</summary></entry><entry><title type="html">Detection of source code in internet texts using automatically generated machine learning models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/52faa3cff55638b2759fe695fbecd9ab.html" rel="alternate" type="text/html" title="Detection of source code in internet texts using automatically generated machine learning models" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/52faa3cff55638b2759fe695fbecd9ab</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/52faa3cff55638b2759fe695fbecd9ab.html">&lt;p&gt;In the paper, the authors are presenting the outcome of web scraping software allowing for the automated classification of source code. The software system was prepared for a discussion forum for software developers to find fragments of source code that were published without marking them as code snippets. The analyzer software is using a Machine Learning binary classification model for differentiating between a programming language source code and highly technical text about … Cites: ‪Learning to mine aligned code and natural language pairs from …‬&lt;/p&gt;</content><author><name>M Badurowicz - Applied Computer Science, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In the paper, the authors are presenting the outcome of web scraping software allowing for the automated classification of source code. The software system was prepared for a discussion forum for software developers to find fragments of source code that were published without marking them as code snippets. The analyzer software is using a Machine Learning binary classification model for differentiating between a programming language source code and highly technical text about … Cites: ‪Learning to mine aligned code and natural language pairs from …‬</summary></entry><entry><title type="html">Loop Closure Prioritization for Efficient and Scalable Multi-Robot SLAM</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/552461d6bdee94bb301210c910d19b29.html" rel="alternate" type="text/html" title="Loop Closure Prioritization for Efficient and Scalable Multi-Robot SLAM" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/552461d6bdee94bb301210c910d19b29</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/552461d6bdee94bb301210c910d19b29.html">&lt;p&gt;Multi-robot SLAM systems in GPS-denied environments require loop closures to maintain a drift-free centralized map. With an increasing number of robots and size of the environment, checking and computing the transformation for all the loop closure candidates becomes computationally infeasible. In this work, we describe a loop closure module that is able to prioritize which loop closures to compute based on the underlying pose graph, the proximity to known beacons, and the characteristics of … Cites: ‪Graph neural networks: A review of methods and applications‬&lt;/p&gt;</content><author><name>CE Denniston, Y Chang, A Reinke, K Ebadi… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Multi-robot SLAM systems in GPS-denied environments require loop closures to maintain a drift-free centralized map. With an increasing number of robots and size of the environment, checking and computing the transformation for all the loop closure candidates becomes computationally infeasible. In this work, we describe a loop closure module that is able to prioritize which loop closures to compute based on the underlying pose graph, the proximity to known beacons, and the characteristics of … Cites: ‪Graph neural networks: A review of methods and applications‬</summary></entry><entry><title type="html">Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5705e96eb772a11716e7c976614db93a.html" rel="alternate" type="text/html" title="Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5705e96eb772a11716e7c976614db93a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5705e96eb772a11716e7c976614db93a.html">&lt;p&gt;Instruction tuning is an emergent paradigm in NLP wherein natural language instructions are leveraged with language models to induce zero-shot performance on unseen tasks. Instructions have been shown to enable good performance on unseen tasks and datasets in both large and small language models. Dialogue is an especially interesting area to explore instruction tuning because dialogue systems perform multiple kinds of tasks related to language (eg, natural language … Cites: ‪A simple language model for task-oriented dialogue‬&lt;/p&gt;</content><author><name>P Gupta, C Jiao, YT Yeh, S Mehri, M Eskenazi… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Instruction tuning is an emergent paradigm in NLP wherein natural language instructions are leveraged with language models to induce zero-shot performance on unseen tasks. Instructions have been shown to enable good performance on unseen tasks and datasets in both large and small language models. Dialogue is an especially interesting area to explore instruction tuning because dialogue systems perform multiple kinds of tasks related to language (eg, natural language … Cites: ‪A simple language model for task-oriented dialogue‬</summary></entry><entry><title type="html">Training Language Models with Language Feedback</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5869a6263c0ad5bdeece2082dcdefdab.html" rel="alternate" type="text/html" title="Training Language Models with Language Feedback" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5869a6263c0ad5bdeece2082dcdefdab</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5869a6263c0ad5bdeece2082dcdefdab.html">&lt;p&gt;Pretrained language models often do not perform tasks in ways that are in line with our preferences, eg, generating offensive text or factually incorrect summaries. Recent work approaches the above issue by learning from a simple form of human …&lt;/p&gt;</content><author><name>J Scheurer, JA Campos, JS Chan, A Chen, K Cho…</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pretrained language models often do not perform tasks in ways that are in line with our preferences, eg, generating offensive text or factually incorrect summaries. Recent work approaches the above issue by learning from a simple form of human …</summary></entry><entry><title type="html">ER-TEST: Evaluating Explanation Regularization Methods for NLP Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/599ddd79b304172633f82b1b3166f286.html" rel="alternate" type="text/html" title="ER-TEST: Evaluating Explanation Regularization Methods for NLP Models" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/599ddd79b304172633f82b1b3166f286</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/599ddd79b304172633f82b1b3166f286.html">&lt;p&gt;Neural language models (NLMs ) reasoning processes are notoriously hard to explain. Recently, there has been much progress in automatically generating machine rationales of NLM behavior, but less in utilizing the rationales to improve NLM behavior. For the latter, explanation regularization (ER) aims to improve NLM generalization by pushing the machine rationales to align with human rationales. Whereas prior works primarily evaluate such ER models via in-distribution (ID) … Cites: ‪Beyond Accuracy: Behavioral Testing of NLP Models with CheckList‬&lt;/p&gt;</content><author><name>B Joshi, A Chan, Z Liu, S Nie, M Sanjabi, H Firooz… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Neural language models (NLMs ) reasoning processes are notoriously hard to explain. Recently, there has been much progress in automatically generating machine rationales of NLM behavior, but less in utilizing the rationales to improve NLM behavior. For the latter, explanation regularization (ER) aims to improve NLM generalization by pushing the machine rationales to align with human rationales. Whereas prior works primarily evaluate such ER models via in-distribution (ID) … Cites: ‪Beyond Accuracy: Behavioral Testing of NLP Models with CheckList‬</summary></entry><entry><title type="html">TaCube: Pre-computing Data Cubes for Answering Numerical-Reasoning Questions over Tabular Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5a2864e63581c4634633d701daccae04.html" rel="alternate" type="text/html" title="TaCube: Pre-computing Data Cubes for Answering Numerical-Reasoning Questions over Tabular Data" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5a2864e63581c4634633d701daccae04</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5a2864e63581c4634633d701daccae04.html">&lt;p&gt;Existing auto-regressive pre-trained language models (PLMs) like T5 and BART, have been well applied to table question answering by UNIFIEDSKG and TAPEX, respectively, and demonstrated state-of-the-art results on multiple benchmarks. However, auto-regressive PLMs are challenged by recent emerging numerical reasoning datasets, such as TAT-QA, due to the error-prone implicit calculation. In this paper, we present TaCube, to pre-compute aggregation/arithmetic results for the … Cites: ‪Spreadsheetcoder: Formula prediction from semi-structured context‬&lt;/p&gt;</content><author><name>F Zhou, M Hu, H Dong, Z Cheng, S Han, D Zhang - arXiv preprint arXiv:2205.12682, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Existing auto-regressive pre-trained language models (PLMs) like T5 and BART, have been well applied to table question answering by UNIFIEDSKG and TAPEX, respectively, and demonstrated state-of-the-art results on multiple benchmarks. However, auto-regressive PLMs are challenged by recent emerging numerical reasoning datasets, such as TAT-QA, due to the error-prone implicit calculation. In this paper, we present TaCube, to pre-compute aggregation/arithmetic results for the … Cites: ‪Spreadsheetcoder: Formula prediction from semi-structured context‬</summary></entry><entry><title type="html">RELATE: Generating a linguistically inspired Knowledge Graph for fine-grained emotion classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5aa1bec11ca092e2ca29b74a7c48f371.html" rel="alternate" type="text/html" title="RELATE: Generating a linguistically inspired Knowledge Graph for fine-grained emotion classification" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5aa1bec11ca092e2ca29b74a7c48f371</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5aa1bec11ca092e2ca29b74a7c48f371.html">&lt;p&gt;Several existing resources are available for sentiment analysis (SA) tasks that are used for learning sentiment specific embedding (SSE) representations. These resources are either large, common-sense knowledge graphs (KG) that cover a limited amount of polarities/emotions or they are smaller in size, such as lexicons, which require costly human annotation and cover fine-grained emotions. Therefore using knowledge resources to learn SSE representations is either limited by the low … Cites: ‪Sentiment embeddings with applications to sentiment analysis‬&lt;/p&gt;</content><author><name>AM Schoene, N Dethlefs, S Ananiadou</name></author><category term="jekyll" /><category term="update" /><summary type="html">Several existing resources are available for sentiment analysis (SA) tasks that are used for learning sentiment specific embedding (SSE) representations. These resources are either large, common-sense knowledge graphs (KG) that cover a limited amount of polarities/emotions or they are smaller in size, such as lexicons, which require costly human annotation and cover fine-grained emotions. Therefore using knowledge resources to learn SSE representations is either limited by the low … Cites: ‪Sentiment embeddings with applications to sentiment analysis‬</summary></entry><entry><title type="html">ZeroGen $^+ $: Self-Guided High-Quality Data Generation in Efficient Zero-Shot Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5af79fd43e08856638cf5de81b3b83df.html" rel="alternate" type="text/html" title="ZeroGen $^+ $: Self-Guided High-Quality Data Generation in Efficient Zero-Shot Learning" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5af79fd43e08856638cf5de81b3b83df</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/5af79fd43e08856638cf5de81b3b83df.html">&lt;p&gt;Nowadays, owing to the superior capacity of the large pre-trained language models (PLM), the PLM-based zero-shot learning has shown promising performances on various natural language processing tasks. There are emerging interests in further exploring the zero-shot learning potential of PLMs. Among them, ZeroGen attempts to purely use PLM to generate data and train a tiny model without relying on any task-specific annotation. Despite its remarkable results, we observe that the synthesized … Cites: ‪How can we know what language models know?‬&lt;/p&gt;</content><author><name>J Gao, R Pi, Y Lin, H Xu, J Ye, Z Wu, X Liang, Z Li… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Nowadays, owing to the superior capacity of the large pre-trained language models (PLM), the PLM-based zero-shot learning has shown promising performances on various natural language processing tasks. There are emerging interests in further exploring the zero-shot learning potential of PLMs. Among them, ZeroGen attempts to purely use PLM to generate data and train a tiny model without relying on any task-specific annotation. Despite its remarkable results, we observe that the synthesized … Cites: ‪How can we know what language models know?‬</summary></entry><entry><title type="html">Software-Hardware Codesign for Efficient In-Memory Regular Pattern Matching</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/60e23bf5e8fe2f464c8aa5780c89b0b6.html" rel="alternate" type="text/html" title="Software-Hardware Codesign for Efficient In-Memory Regular Pattern Matching" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/60e23bf5e8fe2f464c8aa5780c89b0b6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/60e23bf5e8fe2f464c8aa5780c89b0b6.html">&lt;p&gt;Regular pattern matching is used in numerous application domains, including text processing, bioinformatics, and network security. Patterns are typically expressed with an extended syntax of regular expressions. This syntax includes the computationally challenging construct of bounded repetition or counting, which describes the repetition of a pattern a fixed number of times. We develop a specialized in-memory hardware architecture that integrates counter and bit vector … Cites: ‪HARE: Hardware accelerator for regular expressions‬&lt;/p&gt;</content><author><name>L Kong, Q Yu, A Chattopadhyay, A Le Glaunec… - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Regular pattern matching is used in numerous application domains, including text processing, bioinformatics, and network security. Patterns are typically expressed with an extended syntax of regular expressions. This syntax includes the computationally challenging construct of bounded repetition or counting, which describes the repetition of a pattern a fixed number of times. We develop a specialized in-memory hardware architecture that integrates counter and bit vector … Cites: ‪HARE: Hardware accelerator for regular expressions‬</summary></entry><entry><title type="html">Open Relation Extraction via Query-Based Span Prediction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/61ca910c325b8ad74becbd26ee675053.html" rel="alternate" type="text/html" title="Open Relation Extraction via Query-Based Span Prediction" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/61ca910c325b8ad74becbd26ee675053</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/61ca910c325b8ad74becbd26ee675053.html">&lt;p&gt;Open relation extraction (ORE) aims to assign semantic relationships between arguments, essential to the automatic construction of knowledge graphs. The previous methods either depend on external NLP tools (eg, PoS-taggers) and language-specific relation formations, or suffer from inherent problems in sequence representations, thus leading to unsatisfactory extraction in diverse languages and domains. To address the above problems, we propose a Query-based Open R … Cites: ‪Open information extraction from the web‬&lt;/p&gt;</content><author><name>H Yang, DW Li, Z Li, D Yang, J Qi, B Wu - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Open relation extraction (ORE) aims to assign semantic relationships between arguments, essential to the automatic construction of knowledge graphs. The previous methods either depend on external NLP tools (eg, PoS-taggers) and language-specific relation formations, or suffer from inherent problems in sequence representations, thus leading to unsatisfactory extraction in diverse languages and domains. To address the above problems, we propose a Query-based Open R … Cites: ‪Open information extraction from the web‬</summary></entry><entry><title type="html">Spatial-temporal interaction learning based two-stream network for action recognition</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/631cb7d1aa9888373536f6482ff8fb99.html" rel="alternate" type="text/html" title="Spatial-temporal interaction learning based two-stream network for action recognition" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/631cb7d1aa9888373536f6482ff8fb99</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/631cb7d1aa9888373536f6482ff8fb99.html">&lt;p&gt;Two-stream convolutional neural networks have been widely applied to action recognition. However, two-stream networks are usually adopted to capture spatial information and temporal information separately, which normally ignore the strong complementarity and correlation between spatial and temporal information in videos. To solve this problem, we propose a Spatial-Temporal Interaction Learning Two-stream network (STILT) for action recognition. Our proposed two-stream (ie, a spatial … Cites: ‪Long short-term memory-networks for machine reading‬&lt;/p&gt;</content><author><name>T Liu, Y Ma, W Yang, W Ji, R Wang, P Jiang - Information Sciences, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Two-stream convolutional neural networks have been widely applied to action recognition. However, two-stream networks are usually adopted to capture spatial information and temporal information separately, which normally ignore the strong complementarity and correlation between spatial and temporal information in videos. To solve this problem, we propose a Spatial-Temporal Interaction Learning Two-stream network (STILT) for action recognition. Our proposed two-stream (ie, a spatial … Cites: ‪Long short-term memory-networks for machine reading‬</summary></entry><entry><title type="html">Is a Question Decomposition Unit All We Need?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/64a60d4e65268456a9fb05c3f590a9bf.html" rel="alternate" type="text/html" title="Is a Question Decomposition Unit All We Need?" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/64a60d4e65268456a9fb05c3f590a9bf</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/64a60d4e65268456a9fb05c3f590a9bf.html">&lt;p&gt;Large Language Models (LMs) have achieved state-of-the-art performance on many Natural Language Processing (NLP) benchmarks. With the growing number of new benchmarks, we build bigger and more complex LMs. However, building new LMs may not be an ideal option owing to the cost, time and environmental impact associated with it. We explore an alternative route: can we modify data by expressing it in terms of the model s strengths, so that a question becomes easier for models to … Cites: ‪BoolQ: Exploring the surprising difficulty of natural yes/no questions‬&lt;/p&gt;</content><author><name>P Patel, S Mishra, M Parmar, C Baral - arXiv preprint arXiv:2205.12538, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Large Language Models (LMs) have achieved state-of-the-art performance on many Natural Language Processing (NLP) benchmarks. With the growing number of new benchmarks, we build bigger and more complex LMs. However, building new LMs may not be an ideal option owing to the cost, time and environmental impact associated with it. We explore an alternative route: can we modify data by expressing it in terms of the model s strengths, so that a question becomes easier for models to … Cites: ‪BoolQ: Exploring the surprising difficulty of natural yes/no questions‬</summary></entry><entry><title type="html">Your Transformer May Not be as Powerful as You Expect</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6617cdfb000e07288f74b695c1187b48.html" rel="alternate" type="text/html" title="Your Transformer May Not be as Powerful as You Expect" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6617cdfb000e07288f74b695c1187b48</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6617cdfb000e07288f74b695c1187b48.html">&lt;p&gt;Relative Positional Encoding (RPE), which encodes the relative distance between any pair of tokens, is one of the most successful modifications to the original Transformer. As far as we know, theoretical understanding of the RPE-based Transformers is largely unexplored. In this work, we mathematically analyze the power of RPE-based Transformers regarding whether the model is capable of approximating any continuous sequence-to-sequence functions. One may naturally … Cites: ‪Train short, test long: Attention with linear biases enables input …‬&lt;/p&gt;</content><author><name>S Luo, S Li, S Zheng, TY Liu, L Wang, D He - arXiv preprint arXiv:2205.13401, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Relative Positional Encoding (RPE), which encodes the relative distance between any pair of tokens, is one of the most successful modifications to the original Transformer. As far as we know, theoretical understanding of the RPE-based Transformers is largely unexplored. In this work, we mathematically analyze the power of RPE-based Transformers regarding whether the model is capable of approximating any continuous sequence-to-sequence functions. One may naturally … Cites: ‪Train short, test long: Attention with linear biases enables input …‬</summary></entry><entry><title type="html">Know Where You re Going: Meta-Learning for Parameter-Efficient Fine-tuning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6620b8ff3a5dd343232ba7be5dc4fea0.html" rel="alternate" type="text/html" title="Know Where You re Going: Meta-Learning for Parameter-Efficient Fine-tuning" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6620b8ff3a5dd343232ba7be5dc4fea0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6620b8ff3a5dd343232ba7be5dc4fea0.html">&lt;p&gt;A recent family of techniques, dubbed as lightweight fine-tuning methods, facilitates parameter-efficient transfer learning by updating only a small set of additional parameters while keeping the parameters of the pretrained language model frozen. While proven to be an effective method, there are no existing studies on if and how such knowledge of the downstream fine-tuning approach should affect the pretraining stage. In this work, we show that taking the ultimate choice of fine-tuning … Cites: ‪Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper …‬&lt;/p&gt;</content><author><name>M Gheini, X Ma, J May - arXiv preprint arXiv:2205.12453, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A recent family of techniques, dubbed as lightweight fine-tuning methods, facilitates parameter-efficient transfer learning by updating only a small set of additional parameters while keeping the parameters of the pretrained language model frozen. While proven to be an effective method, there are no existing studies on if and how such knowledge of the downstream fine-tuning approach should affect the pretraining stage. In this work, we show that taking the ultimate choice of fine-tuning … Cites: ‪Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper …‬</summary></entry><entry><title type="html">Leveraging Locality in Abstractive Text Summarization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6864435c52aea90275859ebdfdb50145.html" rel="alternate" type="text/html" title="Leveraging Locality in Abstractive Text Summarization" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6864435c52aea90275859ebdfdb50145</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6864435c52aea90275859ebdfdb50145.html">&lt;p&gt;Despite the successes of neural attention models for natural language generation tasks, the quadratic memory complexity of the self-attention module with respect to the input length hinders their applications in long text summarization. Instead of designing more efficient attention modules, we approach this problem by investigating if models with a restricted context can have competitive performance compared with the memory-efficient attention models that maintain a global context … Cites: ‪Discourse-Aware Neural Extractive Text Summarization‬&lt;/p&gt;</content><author><name>Y Liu, A Ni, L Nan, B Deb, C Zhu, AH Awadallah… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Despite the successes of neural attention models for natural language generation tasks, the quadratic memory complexity of the self-attention module with respect to the input length hinders their applications in long text summarization. Instead of designing more efficient attention modules, we approach this problem by investigating if models with a restricted context can have competitive performance compared with the memory-efficient attention models that maintain a global context … Cites: ‪Discourse-Aware Neural Extractive Text Summarization‬</summary></entry><entry><title type="html">Mutual Information Divergence: A Unified Metric for Multimodal Generative Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/69d826e069dc8506bccd76290b93dd82.html" rel="alternate" type="text/html" title="Mutual Information Divergence: A Unified Metric for Multimodal Generative Models" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/69d826e069dc8506bccd76290b93dd82</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/69d826e069dc8506bccd76290b93dd82.html">&lt;p&gt;Text-to-image generation and image captioning are recently emerged as a new experimental paradigm to assess machine intelligence. They predict continuous quantity accompanied by their sampling techniques in the generation, making evaluation complicated and intractable to get marginal distributions. Based on a recent trend that multimodal generative evaluations exploit a vison-and-language pre-trained model, we propose the negative Gaussian cross-mutual information … Cites: ‪DALL-Eval: Probing the Reasoning Skills and Social Biases of Text …‬&lt;/p&gt;</content><author><name>JH Kim, Y Kim, J Lee, KM Yoo, SW Lee - arXiv preprint arXiv:2205.13445, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Text-to-image generation and image captioning are recently emerged as a new experimental paradigm to assess machine intelligence. They predict continuous quantity accompanied by their sampling techniques in the generation, making evaluation complicated and intractable to get marginal distributions. Based on a recent trend that multimodal generative evaluations exploit a vison-and-language pre-trained model, we propose the negative Gaussian cross-mutual information … Cites: ‪DALL-Eval: Probing the Reasoning Skills and Social Biases of Text …‬</summary></entry><entry><title type="html">GisPy: A Tool for Measuring Gist Inference Score in Text</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6d2256a31e52db45bd52c83cbcf575c1.html" rel="alternate" type="text/html" title="GisPy: A Tool for Measuring Gist Inference Score in Text" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6d2256a31e52db45bd52c83cbcf575c1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6d2256a31e52db45bd52c83cbcf575c1.html">&lt;p&gt;Decision making theories such as Fuzzy-Trace Theory (FTT) suggest that individuals tend to rely on gist, or bottom-line meaning, in the text when making decisions. In this work, we delineate the process of developing GisPy, an open-source tool in Python for measuring the Gist Inference Score (GIS) in text. Evaluation of GisPy on documents in three benchmarks from the news and scientific text domains demonstrates that scores generated by our tool significantly distinguish low vs. high … Cites: ‪Automatic evaluation of text coherence: Models and representations‬&lt;/p&gt;</content><author><name>P Hosseini, CR Wolfe, M Diab, DA Broniatowski - arXiv preprint arXiv:2205.12484, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Decision making theories such as Fuzzy-Trace Theory (FTT) suggest that individuals tend to rely on gist, or bottom-line meaning, in the text when making decisions. In this work, we delineate the process of developing GisPy, an open-source tool in Python for measuring the Gist Inference Score (GIS) in text. Evaluation of GisPy on documents in three benchmarks from the news and scientific text domains demonstrates that scores generated by our tool significantly distinguish low vs. high … Cites: ‪Automatic evaluation of text coherence: Models and representations‬</summary></entry><entry><title type="html">RLPrompt: Optimizing Discrete Text Prompts With Reinforcement Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6e54863203f3eb7bb6cc51ceee014761.html" rel="alternate" type="text/html" title="RLPrompt: Optimizing Discrete Text Prompts With Reinforcement Learning" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6e54863203f3eb7bb6cc51ceee014761</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/6e54863203f3eb7bb6cc51ceee014761.html">&lt;p&gt;Prompting has shown impressive success in enabling large pretrained language models (LMs) to perform diverse NLP tasks, especially when only few downstream data are available. Automatically finding the optimal prompt for each task, however, is challenging. Most existing work resorts to tuning soft prompt (eg, embeddings) which falls short of interpretability, reusability across LMs, and applicability when gradients are not accessible. Discrete prompt, on the other hand, is difficult to … Cites: ‪Fantastically ordered prompts and where to find them: Overcoming …‬&lt;/p&gt;</content><author><name>M Deng, J Wang, CP Hsieh, Y Wang, H Guo, T Shu… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Prompting has shown impressive success in enabling large pretrained language models (LMs) to perform diverse NLP tasks, especially when only few downstream data are available. Automatically finding the optimal prompt for each task, however, is challenging. Most existing work resorts to tuning soft prompt (eg, embeddings) which falls short of interpretability, reusability across LMs, and applicability when gradients are not accessible. Discrete prompt, on the other hand, is difficult to … Cites: ‪Fantastically ordered prompts and where to find them: Overcoming …‬</summary></entry><entry><title type="html">Green Hierarchical Vision Transformer for Masked Image Modeling</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/704834b0e17e74920f1233cf681ea2e0.html" rel="alternate" type="text/html" title="Green Hierarchical Vision Transformer for Masked Image Modeling" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/704834b0e17e74920f1233cf681ea2e0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/704834b0e17e74920f1233cf681ea2e0.html">&lt;p&gt;We present an efficient approach for Masked Image Modeling (MIM) with hierarchical Vision Transformers (ViTs), eg, Swin Transformer, allowing the hierarchical ViTs to discard masked patches and operate only on the visible ones. Our approach consists of two key components. First, for the window attention, we design a Group Window Attention scheme following the Divide-and-Conquer strategy. To mitigate the quadratic complexity of the self-attention wrt the number of patches, group attention … Cites: ‪Green AI‬&lt;/p&gt;</content><author><name>L Huang, S You, M Zheng, F Wang, C Qian… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present an efficient approach for Masked Image Modeling (MIM) with hierarchical Vision Transformers (ViTs), eg, Swin Transformer, allowing the hierarchical ViTs to discard masked patches and operate only on the visible ones. Our approach consists of two key components. First, for the window attention, we design a Group Window Attention scheme following the Divide-and-Conquer strategy. To mitigate the quadratic complexity of the self-attention wrt the number of patches, group attention … Cites: ‪Green AI‬</summary></entry><entry><title type="html">Improving integration Platforms as a Service through the addition of enterprise data catalog features</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/72e112ca0bee2e01f6d3802c814e9752.html" rel="alternate" type="text/html" title="Improving integration Platforms as a Service through the addition of enterprise data catalog features" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/72e112ca0bee2e01f6d3802c814e9752</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/72e112ca0bee2e01f6d3802c814e9752.html">&lt;p&gt;This research evaluates two software solutions for organizations and possible opportunities in combining them. These are the integration Platform as a Service (iPaaS) and the enterprise data catalog. An iPaaS provides a platform for organizations to create integrations between different systems, whereas an enterprise data catalog focuses on making data of an organization visible and usable to all employees who need it. This research is focused on applying the features of an … Cites: ‪Goods: Organizing google s datasets‬&lt;/p&gt;</content><author><name>JJ Smits - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This research evaluates two software solutions for organizations and possible opportunities in combining them. These are the integration Platform as a Service (iPaaS) and the enterprise data catalog. An iPaaS provides a platform for organizations to create integrations between different systems, whereas an enterprise data catalog focuses on making data of an organization visible and usable to all employees who need it. This research is focused on applying the features of an … Cites: ‪Goods: Organizing google s datasets‬</summary></entry><entry><title type="html">Learning Action Conditions from Instructional Manuals for Instruction Understanding</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/730e612708f6d73a34374a73fd496518.html" rel="alternate" type="text/html" title="Learning Action Conditions from Instructional Manuals for Instruction Understanding" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/730e612708f6d73a34374a73fd496518</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/730e612708f6d73a34374a73fd496518.html">&lt;p&gt;The ability to infer pre-and postconditions of an action is vital for comprehending complex instructions, and is essential for applications such as autonomous instruction-guided agents and assistive AI that supports humans to perform physical tasks. In this work, we propose a task dubbed action condition inference, and collecting a high-quality, human annotated dataset of preconditions and postconditions of actions in instructional manuals. We propose a weakly supervised … Cites: ‪ESTER: A Machine Reading Comprehension Dataset for Event …‬&lt;/p&gt;</content><author><name>TL Wu, C Zhang, Q Hu, A Spangher, N Peng - arXiv preprint arXiv:2205.12420, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The ability to infer pre-and postconditions of an action is vital for comprehending complex instructions, and is essential for applications such as autonomous instruction-guided agents and assistive AI that supports humans to perform physical tasks. In this work, we propose a task dubbed action condition inference, and collecting a high-quality, human annotated dataset of preconditions and postconditions of actions in instructional manuals. We propose a weakly supervised … Cites: ‪ESTER: A Machine Reading Comprehension Dataset for Event …‬</summary></entry><entry><title type="html">Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/75b4cf74c6da33c2a192d5872bb5deae.html" rel="alternate" type="text/html" title="Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/75b4cf74c6da33c2a192d5872bb5deae</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/75b4cf74c6da33c2a192d5872bb5deae.html">&lt;p&gt;Scaling multilingual representation learning beyond the hundred most frequent languages is challenging, in particular to cover the long tail of low-resource languages. A promising approach has been to train one-for-all multilingual models capable of cross-lingual transfer, but these models often suffer from insufficient capacity and interference between unrelated languages. Instead, we move away from this approach and focus on training multiple language (family) specific … Cites: ‪Extending multilingual BERT to low-resource languages‬&lt;/p&gt;</content><author><name>K Heffernan, O Çelebi, H Schwenk - arXiv preprint arXiv:2205.12654, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Scaling multilingual representation learning beyond the hundred most frequent languages is challenging, in particular to cover the long tail of low-resource languages. A promising approach has been to train one-for-all multilingual models capable of cross-lingual transfer, but these models often suffer from insufficient capacity and interference between unrelated languages. Instead, we move away from this approach and focus on training multiple language (family) specific … Cites: ‪Extending multilingual BERT to low-resource languages‬</summary></entry><entry><title type="html">Multimodal Learning Approach for Multi-topic Twitter Summarization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/77b2050cf7099cebc0eebbf61d123252.html" rel="alternate" type="text/html" title="Multimodal Learning Approach for Multi-topic Twitter Summarization" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/77b2050cf7099cebc0eebbf61d123252</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/77b2050cf7099cebc0eebbf61d123252.html">&lt;p&gt;Twitter summary is designed to filter out the content summary from lots of noisy tweets, which can be used for Twitter search, public opinion analysis, hot topic discovery, etc. But the existing Twitter summary methods mostly focus on individual topics or hot events, and there are few studies on Twitter summary with multi-topic posts. For the sake of resolve this problem, we propose a Twitter summary method based on social network information and manifold learning, which can extract tweets … Cites: ‪Sentence centrality revisited for unsupervised summarization‬&lt;/p&gt;</content><author><name>Y Cao, YM Wu, JL Qi, Z Chen - 2022 7th International Conference on Cloud …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Twitter summary is designed to filter out the content summary from lots of noisy tweets, which can be used for Twitter search, public opinion analysis, hot topic discovery, etc. But the existing Twitter summary methods mostly focus on individual topics or hot events, and there are few studies on Twitter summary with multi-topic posts. For the sake of resolve this problem, we propose a Twitter summary method based on social network information and manifold learning, which can extract tweets … Cites: ‪Sentence centrality revisited for unsupervised summarization‬</summary></entry><entry><title type="html">EDIN: An End-to-end Benchmark and Pipeline for Unknown Entity Discovery and Indexing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/7be22ffae07e24772a583f331d326cf6.html" rel="alternate" type="text/html" title="EDIN: An End-to-end Benchmark and Pipeline for Unknown Entity Discovery and Indexing" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/7be22ffae07e24772a583f331d326cf6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/7be22ffae07e24772a583f331d326cf6.html">&lt;p&gt;Existing work on Entity Linking mostly assumes that the reference knowledge base is complete, and therefore all mentions can be linked. In practice this is hardly ever the case, as knowledge bases are incomplete and because novel concepts arise constantly. This paper created the Unknown Entity Discovery and Indexing (EDIN) benchmark where unknown entities, that is entities without a description in the knowledge base and labeled mentions, have to be integrated into an existing entity … Cites: ‪Zero-shot entity linking by reading entity descriptions‬&lt;/p&gt;</content><author><name>N Kassner, F Petroni, M Plekhanov, S Riedel… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Existing work on Entity Linking mostly assumes that the reference knowledge base is complete, and therefore all mentions can be linked. In practice this is hardly ever the case, as knowledge bases are incomplete and because novel concepts arise constantly. This paper created the Unknown Entity Discovery and Indexing (EDIN) benchmark where unknown entities, that is entities without a description in the knowledge base and labeled mentions, have to be integrated into an existing entity … Cites: ‪Zero-shot entity linking by reading entity descriptions‬</summary></entry><entry><title type="html">Deep Multi-Attributed-View Graph Representation Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8068385700490d38df5272f3e0c27183.html" rel="alternate" type="text/html" title="Deep Multi-Attributed-View Graph Representation Learning" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8068385700490d38df5272f3e0c27183</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8068385700490d38df5272f3e0c27183.html">&lt;p&gt;Graph representation learning aims at mapping a graph into a lower-dimensional feature space. Deep attributed graph representation, utilizing deep learning models on the graph structure and attributes, shows its significance in mining complex relational data. Most existing deep attributed graph representation models assume graph attributes in a single-attributed view. However, rich information in real-world applications demands the ability to handle multiple attributed views. For example, in … Cites: ‪Adaptive Graph Encoder for Attributed Graph Embedding‬&lt;/p&gt;</content><author><name>X Ma, S Xue, J Wu, J Yang, C Paris, S Nepal… - IEEE Transactions on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Graph representation learning aims at mapping a graph into a lower-dimensional feature space. Deep attributed graph representation, utilizing deep learning models on the graph structure and attributes, shows its significance in mining complex relational data. Most existing deep attributed graph representation models assume graph attributes in a single-attributed view. However, rich information in real-world applications demands the ability to handle multiple attributed views. For example, in … Cites: ‪Adaptive Graph Encoder for Attributed Graph Embedding‬</summary></entry><entry><title type="html">Threats to Training: A Survey of Poisoning Attacks and Defenses on Machine Learning Systems</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8179eff6253feb68273b8b447e62c07f.html" rel="alternate" type="text/html" title="Threats to Training: A Survey of Poisoning Attacks and Defenses on Machine Learning Systems" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8179eff6253feb68273b8b447e62c07f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8179eff6253feb68273b8b447e62c07f.html">&lt;p&gt;Machine learning (ML) has been universally adopted for automated decisions in a variety of fields, including recognition and classification applications, recommendation systems, natural language processing, etc. However, in the light of high expenses on training data and computing resources, recent years have witnessed a rapid increase in outsourced ML training, either partially or completely, which provides vulnerabilities for adversaries to exploit. A prime threat in training … Cites: ‪Stronger data poisoning attacks break data sanitization defenses‬&lt;/p&gt;</content><author><name>Z Wang, J Ma, X Wang, J Hu, Z Qin, K Ren - ACM Journal of the ACM (JACM), 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Machine learning (ML) has been universally adopted for automated decisions in a variety of fields, including recognition and classification applications, recommendation systems, natural language processing, etc. However, in the light of high expenses on training data and computing resources, recent years have witnessed a rapid increase in outsourced ML training, either partially or completely, which provides vulnerabilities for adversaries to exploit. A prime threat in training … Cites: ‪Stronger data poisoning attacks break data sanitization defenses‬</summary></entry><entry><title type="html">Active Labeling: Streaming Stochastic Gradients</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/82befc133c202f1efdf8579bf2d458bc.html" rel="alternate" type="text/html" title="Active Labeling: Streaming Stochastic Gradients" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/82befc133c202f1efdf8579bf2d458bc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/82befc133c202f1efdf8579bf2d458bc.html">&lt;p&gt;The workhorse of machine learning is stochastic gradient descent. To access stochastic gradients, it is common to consider iteratively input/output pairs of a training dataset. Interestingly, it appears that one does not need full supervision to access stochastic gradients, which is the main motivation of this paper. After formalizing the  active labeling  problem, which generalizes active learning based on partial supervision, we provide a streaming technique that provably minimizes the … Cites: ‪Crowdsourcing systems on the world-wide web‬&lt;/p&gt;</content><author><name>V Cabannes, F Bach, V Perchet, A Rudi - arXiv preprint arXiv:2205.13255, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The workhorse of machine learning is stochastic gradient descent. To access stochastic gradients, it is common to consider iteratively input/output pairs of a training dataset. Interestingly, it appears that one does not need full supervision to access stochastic gradients, which is the main motivation of this paper. After formalizing the active labeling problem, which generalizes active learning based on partial supervision, we provide a streaming technique that provably minimizes the … Cites: ‪Crowdsourcing systems on the world-wide web‬</summary></entry><entry><title type="html">End-to-End Multimodal Fact-Checking and Explanation Generation: A Challenging Dataset and Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8361b4160c042cbfb019192addb32db5.html" rel="alternate" type="text/html" title="End-to-End Multimodal Fact-Checking and Explanation Generation: A Challenging Dataset and Models" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8361b4160c042cbfb019192addb32db5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8361b4160c042cbfb019192addb32db5.html">&lt;p&gt;We propose the end-to-end multimodal fact-checking and explanation generation, where the input is a claim and a large collection of web sources, including articles, images, videos, and tweets, and the goal is to assess the truthfulness of the claim by retrieving relevant evidence and predicting a truthfulness label (ie, support, refute and not enough information), and generate a rationalization statement to explain the reasoning and ruling process. To support this research, we construct Mocheg, a … Cites: ‪Generating fact checking briefs‬&lt;/p&gt;</content><author><name>BM Yao, A Shah, L Sun, JH Cho, L Huang - arXiv preprint arXiv:2205.12487, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose the end-to-end multimodal fact-checking and explanation generation, where the input is a claim and a large collection of web sources, including articles, images, videos, and tweets, and the goal is to assess the truthfulness of the claim by retrieving relevant evidence and predicting a truthfulness label (ie, support, refute and not enough information), and generate a rationalization statement to explain the reasoning and ruling process. To support this research, we construct Mocheg, a … Cites: ‪Generating fact checking briefs‬</summary></entry><entry><title type="html">Memorization in NLP Fine-tuning Methods</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/839ca2baaf7806b7e080ba040610d93b.html" rel="alternate" type="text/html" title="Memorization in NLP Fine-tuning Methods" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/839ca2baaf7806b7e080ba040610d93b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/839ca2baaf7806b7e080ba040610d93b.html">&lt;p&gt;Large language models are shown to present privacy risks through memorization of training data, and several recent works have studied such risks for the pre-training phase. Little attention, however, has been given to the fine-tuning phase and it is not well understood how different fine-tuning methods (such as fine-tuning the full model, the model head, and adapter) compare in terms of memorization risk. This presents increasing concern as the  pre-train and fine-tune  paradigm proliferates. In this … Cites: ‪Documenting the english colossal clean crawled corpus‬&lt;/p&gt;</content><author><name>F Mireshghallah, A Uniyal, T Wang, D Evans… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Large language models are shown to present privacy risks through memorization of training data, and several recent works have studied such risks for the pre-training phase. Little attention, however, has been given to the fine-tuning phase and it is not well understood how different fine-tuning methods (such as fine-tuning the full model, the model head, and adapter) compare in terms of memorization risk. This presents increasing concern as the pre-train and fine-tune paradigm proliferates. In this … Cites: ‪Documenting the english colossal clean crawled corpus‬</summary></entry><entry><title type="html">Structured Prompt Tuning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/83ce9d6c22f2d2b88d81c80ed204bcdc.html" rel="alternate" type="text/html" title="Structured Prompt Tuning" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/83ce9d6c22f2d2b88d81c80ed204bcdc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/83ce9d6c22f2d2b88d81c80ed204bcdc.html">&lt;p&gt;We propose structured prompt tuning, a simple and effective method to improve prompt tuning. Instead of prepending a sequence of tunable embeddings to the input, we generate the soft prompt embeddings through a hypernetwork. Our approach subsumes the standard prompt tuning, allows more flexibility in model design and can be applied to both single-task and multi-task training settings. Empirically, structured prompt tuning shows a gain of+ 1.2$~ 1.5 points on the GLUE … Cites: ‪Factual Probing Is [MASK]: Learning vs. Learning to Recall‬&lt;/p&gt;</content><author><name>CL Liu, H Lee, W Yih - arXiv preprint arXiv:2205.12309, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose structured prompt tuning, a simple and effective method to improve prompt tuning. Instead of prepending a sequence of tunable embeddings to the input, we generate the soft prompt embeddings through a hypernetwork. Our approach subsumes the standard prompt tuning, allows more flexibility in model design and can be applied to both single-task and multi-task training settings. Empirically, structured prompt tuning shows a gain of+ 1.2$~ 1.5 points on the GLUE … Cites: ‪Factual Probing Is [MASK]: Learning vs. Learning to Recall‬</summary></entry><entry><title type="html">R2D2: Robust Data-to-Text with Replacement Detection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8489f8b0b6aacc60a065e4dea4c547ab.html" rel="alternate" type="text/html" title="R2D2: Robust Data-to-Text with Replacement Detection" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8489f8b0b6aacc60a065e4dea4c547ab</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8489f8b0b6aacc60a065e4dea4c547ab.html">&lt;p&gt;Unfaithful text generation is a common problem for text generation systems. In the case of Data-to-Text (D2T) systems, the factuality of the generated text is particularly crucial for any real-world applications. We introduce R2D2, a training framework that addresses unfaithful Data-to-Text generation by training a system both as a generator and a faithfulness discriminator with additional replacement detection and unlikelihood learning tasks. To facilitate such training, we propose two methods for … Cites: ‪BRIO: Bringing Order to Abstractive Summarization‬&lt;/p&gt;</content><author><name>L Nan, LJY Flores, Y Zhao, Y Liu, L Benson, W Zou… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Unfaithful text generation is a common problem for text generation systems. In the case of Data-to-Text (D2T) systems, the factuality of the generated text is particularly crucial for any real-world applications. We introduce R2D2, a training framework that addresses unfaithful Data-to-Text generation by training a system both as a generator and a faithfulness discriminator with additional replacement detection and unlikelihood learning tasks. To facilitate such training, we propose two methods for … Cites: ‪BRIO: Bringing Order to Abstractive Summarization‬</summary></entry><entry><title type="html">On the Evolution of AI and Machine Learning: Towards Measuring and Understanding Impact, Influence, and Leadership at Premier AI Conferences</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8d72d23b36fd4b8c16b94c48ecdb24d6.html" rel="alternate" type="text/html" title="On the Evolution of AI and Machine Learning: Towards Measuring and Understanding Impact, Influence, and Leadership at Premier AI Conferences" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8d72d23b36fd4b8c16b94c48ecdb24d6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8d72d23b36fd4b8c16b94c48ecdb24d6.html">&lt;p&gt;Artificial Intelligence is now recognized as a general-purpose technology with ample impact on human life. In this work, we aim to understand the evolution of AI and Machine learning over the years by analyzing researchers  impact, influence, and leadership over the last decades. This work also intends to shed new light on the history and evolution of AI by exploring the dynamics involved in the field s evolution through the lenses of the papers published on AI conferences since the first … Cites: ‪BERT: pre-training of deep bidirectional transformers for language …‬&lt;/p&gt;</content><author><name>RB Audibert, H Lemos, P Avelar, AR Tavares, LC Lamb - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Artificial Intelligence is now recognized as a general-purpose technology with ample impact on human life. In this work, we aim to understand the evolution of AI and Machine learning over the years by analyzing researchers impact, influence, and leadership over the last decades. This work also intends to shed new light on the history and evolution of AI by exploring the dynamics involved in the field s evolution through the lenses of the papers published on AI conferences since the first … Cites: ‪BERT: pre-training of deep bidirectional transformers for language …‬</summary></entry><entry><title type="html">Sparse Mixers: Combining MoE and Mixing to build a more efficient BERT</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8d79b281ab0d0b37b85c69280d871a99.html" rel="alternate" type="text/html" title="Sparse Mixers: Combining MoE and Mixing to build a more efficient BERT" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8d79b281ab0d0b37b85c69280d871a99</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8d79b281ab0d0b37b85c69280d871a99.html">&lt;p&gt;We combine the capacity of sparsely gated Mixture-of-Experts (MoE) with the speed and stability of linear, mixing transformations to design the Sparse Mixer encoder model. The Sparse Mixer slightly outperforms (&amp;lt; 1%) BERT on GLUE and SuperGLUE, but more importantly trains 65% faster and runs inference 61% faster. We also present a faster variant, prosaically named Fast Sparse Mixer, that marginally underperforms (&amp;lt; 0.2%) BERT on SuperGLUE, but trains and runs nearly … Cites: ‪Electra: Pre-training text encoders as discriminators rather than …‬&lt;/p&gt;</content><author><name>J Lee-Thorp, J Ainslie - arXiv preprint arXiv:2205.12399, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We combine the capacity of sparsely gated Mixture-of-Experts (MoE) with the speed and stability of linear, mixing transformations to design the Sparse Mixer encoder model. The Sparse Mixer slightly outperforms (&amp;lt; 1%) BERT on GLUE and SuperGLUE, but more importantly trains 65% faster and runs inference 61% faster. We also present a faster variant, prosaically named Fast Sparse Mixer, that marginally underperforms (&amp;lt; 0.2%) BERT on SuperGLUE, but trains and runs nearly … Cites: ‪Electra: Pre-training text encoders as discriminators rather than …‬</summary></entry><entry><title type="html">Uncovering Synergy and Dysergy in Consumer Reviews: A Machine Learning Approach</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8e0b365009deebb8e52cc0bfd8a4bde6.html" rel="alternate" type="text/html" title="Uncovering Synergy and Dysergy in Consumer Reviews: A Machine Learning Approach" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8e0b365009deebb8e52cc0bfd8a4bde6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/8e0b365009deebb8e52cc0bfd8a4bde6.html">&lt;p&gt;Massive online text reviews can be a powerful market research tool for understanding consumer experiences and helping firms improve and innovate. This research exploits the rich semantic properties of text reviews and proposes a novel machine learning modeling framework that can reliably and efficiently extract consumer opinions and uncover potential interaction effects across these opinions, thereby identifying hidden and nuanced areas for product and service improvement … Cites: ‪Subjective databases‬&lt;/p&gt;</content><author><name>Z Zhang, K Yang, JZ Zhang, RW Palmatier - Management Science, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Massive online text reviews can be a powerful market research tool for understanding consumer experiences and helping firms improve and innovate. This research exploits the rich semantic properties of text reviews and proposes a novel machine learning modeling framework that can reliably and efficiently extract consumer opinions and uncover potential interaction effects across these opinions, thereby identifying hidden and nuanced areas for product and service improvement … Cites: ‪Subjective databases‬</summary></entry><entry><title type="html">A text mining framework for screening catalysts and critical process parameters from scientific literature-a study on Hydrogen production from alcohol</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/904f881bf5611d06685e95d5e1b9f4d2.html" rel="alternate" type="text/html" title="A text mining framework for screening catalysts and critical process parameters from scientific literature-a study on Hydrogen production from alcohol" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/904f881bf5611d06685e95d5e1b9f4d2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/904f881bf5611d06685e95d5e1b9f4d2.html">&lt;p&gt;Hydrogen production is an active area of research with a vast amount of available scientific literature. However, this data is unstructured and scattered, making its utilization difficult from an academic and industrial point of view. This work aims to develop a recommendation system to identify optimal process conditions and catalyst information using Natural Language Processing (NLP) tools. To this end, full-text articles were extracted using the Elsevier API key followed by a custom XML … Cites: ‪Reading tea leaves: How humans interpret topic models‬&lt;/p&gt;</content><author><name>A Kumar, S Ganesh, D Gupta, H Kodamana - Chemical Engineering Research and …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Hydrogen production is an active area of research with a vast amount of available scientific literature. However, this data is unstructured and scattered, making its utilization difficult from an academic and industrial point of view. This work aims to develop a recommendation system to identify optimal process conditions and catalyst information using Natural Language Processing (NLP) tools. To this end, full-text articles were extracted using the Elsevier API key followed by a custom XML … Cites: ‪Reading tea leaves: How humans interpret topic models‬</summary></entry><entry><title type="html">An analysis of machine learning models for sentiment analysis of Tamil code-mixed data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/908b02d8ef88ecbbf2f70b16b9a656aa.html" rel="alternate" type="text/html" title="An analysis of machine learning models for sentiment analysis of Tamil code-mixed data" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/908b02d8ef88ecbbf2f70b16b9a656aa</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/908b02d8ef88ecbbf2f70b16b9a656aa.html">&lt;p&gt;Nowadays, more and more people are sharing and expressing their feelings through social media platforms such as Twitter, Facebook and YouTube. Sentiment analysis is a process that explores, identifies and categorizes content. People that belong to multilingual communities tend to communicate through multiple regional languages. This type of text is represented using different languages and is known as code-mixed data. The proposed system utilizes a code-mixed data set of Tamil–English … Cites: ‪Kristina, Toutanova‬&lt;/p&gt;</content><author><name>K Shanmugavadivel, SH Sampath, P Nandhakumar… - Computer Speech &amp; …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Nowadays, more and more people are sharing and expressing their feelings through social media platforms such as Twitter, Facebook and YouTube. Sentiment analysis is a process that explores, identifies and categorizes content. People that belong to multilingual communities tend to communicate through multiple regional languages. This type of text is represented using different languages and is known as code-mixed data. The proposed system utilizes a code-mixed data set of Tamil–English … Cites: ‪Kristina, Toutanova‬</summary></entry><entry><title type="html">QAMPARI:: An Open-domain Question Answering Benchmark for Questions with Many Answers from Multiple Paragraphs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/954cd71ba67b15fe35392b30fb94a0d0.html" rel="alternate" type="text/html" title="QAMPARI:: An Open-domain Question Answering Benchmark for Questions with Many Answers from Multiple Paragraphs" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/954cd71ba67b15fe35392b30fb94a0d0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/954cd71ba67b15fe35392b30fb94a0d0.html">&lt;p&gt;Existing benchmarks for open-domain question answering (ODQA) typically focus on questions whose answers can be extracted from a single paragraph. By contrast, many natural questions, such as  What players were drafted by the Brooklyn Nets?  …&lt;/p&gt;</content><author><name>SJ Amouyal, O Rubin, O Yoran, T Wolfson, J Herzig… - arXiv e-prints, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Existing benchmarks for open-domain question answering (ODQA) typically focus on questions whose answers can be extracted from a single paragraph. By contrast, many natural questions, such as What players were drafted by the Brooklyn Nets? …</summary></entry><entry><title type="html">Reasoning over Logically Interacted Conditions for Question Answering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/95515b896debbc1a50a80eebdf960c79.html" rel="alternate" type="text/html" title="Reasoning over Logically Interacted Conditions for Question Answering" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/95515b896debbc1a50a80eebdf960c79</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/95515b896debbc1a50a80eebdf960c79.html">&lt;p&gt;Some questions have multiple answers that are not equally correct, ie answers are different under different conditions. Conditions are used to distinguish answers as well as to provide additional information to support them. In this paper, we study a more challenging task where answers are constrained by a list of conditions that logically interact, which requires performing logical reasoning over the conditions to determine the correctness of the answers. Even more challenging, we only provide … Cites: ‪Explicit memory tracker with coarse-to-fine reasoning for …‬&lt;/p&gt;</content><author><name>H Sun, WW Cohen, R Salakhutdinov - arXiv preprint arXiv:2205.12898, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Some questions have multiple answers that are not equally correct, ie answers are different under different conditions. Conditions are used to distinguish answers as well as to provide additional information to support them. In this paper, we study a more challenging task where answers are constrained by a list of conditions that logically interact, which requires performing logical reasoning over the conditions to determine the correctness of the answers. Even more challenging, we only provide … Cites: ‪Explicit memory tracker with coarse-to-fine reasoning for …‬</summary></entry><entry><title type="html">Towards Understanding Label Regularization for Fine-tuning Pre-trained Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/976e877c32165c0cd74efaf5bdab3a14.html" rel="alternate" type="text/html" title="Towards Understanding Label Regularization for Fine-tuning Pre-trained Language Models" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/976e877c32165c0cd74efaf5bdab3a14</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/976e877c32165c0cd74efaf5bdab3a14.html">&lt;p&gt;Knowledge Distillation (KD) is a prominent neural model compression technique which heavily relies on teacher network predictions to guide the training of a student model. Considering the ever-growing size of pre-trained language models (PLMs), KD is often adopted in many NLP tasks involving PLMs. However, it is evident that in KD, deploying the teacher network during training adds to the memory and computational requirements of training. In the computer vision literature, the … Cites: ‪Well-Read Students Learn Better: On the Importance of Pre …‬&lt;/p&gt;</content><author><name>I Kobyzev, A Jafari, M Rezagholizadeh, T Li, A Do-Omri… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Knowledge Distillation (KD) is a prominent neural model compression technique which heavily relies on teacher network predictions to guide the training of a student model. Considering the ever-growing size of pre-trained language models (PLMs), KD is often adopted in many NLP tasks involving PLMs. However, it is evident that in KD, deploying the teacher network during training adds to the memory and computational requirements of training. In the computer vision literature, the … Cites: ‪Well-Read Students Learn Better: On the Importance of Pre …‬</summary></entry><entry><title type="html">Mitigating Bias in Search Results Through Contextual Document Reranking and Neutrality Regularization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/977dda4fc8e6d56f1d0af1c79aa91ef8.html" rel="alternate" type="text/html" title="Mitigating Bias in Search Results Through Contextual Document Reranking and Neutrality Regularization" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/977dda4fc8e6d56f1d0af1c79aa91ef8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/977dda4fc8e6d56f1d0af1c79aa91ef8.html">&lt;p&gt;Societal biases can influence Information Retrieval system results, and conversely, search results can potentially reinforce existing societal biases. Recent research has therefore focused on developing methods for quantifying and mitigating bias in search results and applied them to contemporary retrieval systems that leverage transformer-based language models. In the present work, we expand this direction of research by considering bias mitigation within a framework for contextual document … Cites: ‪Sparse, dense, and attentional representations for text retrieval‬&lt;/p&gt;</content><author><name>G Zerveas, N Rekabsaz, D Cohen, C Eickhoff - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Societal biases can influence Information Retrieval system results, and conversely, search results can potentially reinforce existing societal biases. Recent research has therefore focused on developing methods for quantifying and mitigating bias in search results and applied them to contemporary retrieval systems that leverage transformer-based language models. In the present work, we expand this direction of research by considering bias mitigation within a framework for contextual document … Cites: ‪Sparse, dense, and attentional representations for text retrieval‬</summary></entry><entry><title type="html">Regulation of tomato fruit elongation by transcription factor BZR1. 7 through promotion of SUN gene expression</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/97a6a0b7bf7b9a672091e15f9dfa030c.html" rel="alternate" type="text/html" title="Regulation of tomato fruit elongation by transcription factor BZR1. 7 through promotion of SUN gene expression" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/97a6a0b7bf7b9a672091e15f9dfa030c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/97a6a0b7bf7b9a672091e15f9dfa030c.html">&lt;p&gt;Fruit shape is an important biological trait that is also of special commercial value in tomato. The SUN gene has been known as a key regulator of tomato fruit elongation for years, but the molecular mechanisms underlying its transcriptional regulation remain little understood. Here, a unique BZR1-like transcription factor, BZR1. 7, was identified as a trans-acting factor of the SUN gene promoter that bound to the conserved E-box of the promoter to promoted SUN gene expression. Overexpression … Cites: ‪BRL1 and BRL3 are novel brassinosteroid receptors that function …‬&lt;/p&gt;</content><author><name>T Yu, G Ai, Q Xie, W Wang, J Song, J Wang, J Tao… - Horticulture Research, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Fruit shape is an important biological trait that is also of special commercial value in tomato. The SUN gene has been known as a key regulator of tomato fruit elongation for years, but the molecular mechanisms underlying its transcriptional regulation remain little understood. Here, a unique BZR1-like transcription factor, BZR1. 7, was identified as a trans-acting factor of the SUN gene promoter that bound to the conserved E-box of the promoter to promoted SUN gene expression. Overexpression … Cites: ‪BRL1 and BRL3 are novel brassinosteroid receptors that function …‬</summary></entry><entry><title type="html">Generating Natural Language Proofs with Verifier-Guided Search</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/97dbc601160acdaaa867ec2f2e15ce48.html" rel="alternate" type="text/html" title="Generating Natural Language Proofs with Verifier-Guided Search" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/97dbc601160acdaaa867ec2f2e15ce48</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/97dbc601160acdaaa867ec2f2e15ce48.html">&lt;p&gt;Deductive reasoning (drawing conclusions from assumptions) is a challenging problem in NLP. In this work, we focus on proof generation: given a hypothesis and a set of supporting facts in natural language, the model generates a proof tree indicating how to deduce the hypothesis from supporting facts. Instead of generating the entire proof in one shot, prior work has demonstrated the promise of stepwise generation but achieved limited success on real-world data. Existing stepwise … Cites: ‪Natural Language Deduction through Search over Statement …‬&lt;/p&gt;</content><author><name>K Yang, J Deng, D Chen - arXiv preprint arXiv:2205.12443, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deductive reasoning (drawing conclusions from assumptions) is a challenging problem in NLP. In this work, we focus on proof generation: given a hypothesis and a set of supporting facts in natural language, the model generates a proof tree indicating how to deduce the hypothesis from supporting facts. Instead of generating the entire proof in one shot, prior work has demonstrated the promise of stepwise generation but achieved limited success on real-world data. Existing stepwise … Cites: ‪Natural Language Deduction through Search over Statement …‬</summary></entry><entry><title type="html">A review of deep learning-based recommender system in e-learning environments</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/980e99494a50c1e93b977c6dd94a3843.html" rel="alternate" type="text/html" title="A review of deep learning-based recommender system in e-learning environments" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/980e99494a50c1e93b977c6dd94a3843</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/980e99494a50c1e93b977c6dd94a3843.html">&lt;p&gt;While the recent emergence of a large number of online course resources has made life more convenient for many people, it has also caused information overload. According to a user s situation and behavior, course recommendation systems can recommend courses of interest to the user, so that the user can quickly sift through a massive amount of information to find courses that meet his or her needs. This paper provide a systematic review of deep learning-based recommendation systems in e … Cites: ‪MOOCCube: a large-scale data repository for NLP applications in …‬&lt;/p&gt;</content><author><name>T Liu, Q Wu, L Chang, T Gu - Artificial Intelligence Review, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">While the recent emergence of a large number of online course resources has made life more convenient for many people, it has also caused information overload. According to a user s situation and behavior, course recommendation systems can recommend courses of interest to the user, so that the user can quickly sift through a massive amount of information to find courses that meet his or her needs. This paper provide a systematic review of deep learning-based recommendation systems in e … Cites: ‪MOOCCube: a large-scale data repository for NLP applications in …‬</summary></entry><entry><title type="html">Learning a Better Initialization for Soft Prompts via Meta-Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/9a33ed89a28d13e981052fdc48f8915f.html" rel="alternate" type="text/html" title="Learning a Better Initialization for Soft Prompts via Meta-Learning" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/9a33ed89a28d13e981052fdc48f8915f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/9a33ed89a28d13e981052fdc48f8915f.html">&lt;p&gt;Prompt tuning (PT) is an effective approach to adapting pre-trained language models to downstream tasks. Without a good initialization, prompt tuning doesn t perform well under few-shot settings. So pre-trained prompt tuning (PPT) is proposed to initialize prompts by leveraging pre-training data. We propose MetaPT (Meta-learned Prompt Tuning) to further improve PPT s initialization by considering latent structure within the pre-training data. Specifically, we introduce the structure by first clustering pre … Cites: ‪BERTese: Learning to Speak to BERT‬&lt;/p&gt;</content><author><name>Y Huang, K Qian, Z Yu - arXiv preprint arXiv:2205.12471, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Prompt tuning (PT) is an effective approach to adapting pre-trained language models to downstream tasks. Without a good initialization, prompt tuning doesn t perform well under few-shot settings. So pre-trained prompt tuning (PPT) is proposed to initialize prompts by leveraging pre-training data. We propose MetaPT (Meta-learned Prompt Tuning) to further improve PPT s initialization by considering latent structure within the pre-training data. Specifically, we introduce the structure by first clustering pre … Cites: ‪BERTese: Learning to Speak to BERT‬</summary></entry><entry><title type="html">Recent trends in movement ecology of animals and human mobility</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/9d881eab32ec5026254b3f1e8441b54f.html" rel="alternate" type="text/html" title="Recent trends in movement ecology of animals and human mobility" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/9d881eab32ec5026254b3f1e8441b54f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/9d881eab32ec5026254b3f1e8441b54f.html">&lt;p&gt;Movement is fundamental to life, shaping population dynamics, biodiversity patterns, and ecosystem structure. In 2008, the movement ecology framework (MEF Nathan et al. in PNAS 105 (49): 19052–19059, 2008) introduced an integrative theory of organismal movement—linking internal state, motion capacity, and navigation capacity to external factors—which has been recognized as a milestone in the field. Since then, the study of movement experienced a technological boom, which … Cites: ‪Reading tea leaves: How humans interpret topic models‬&lt;/p&gt;</content><author><name>R Joo, S Picardi, ME Boone, TA Clay, SC Patrick… - Movement Ecology, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Movement is fundamental to life, shaping population dynamics, biodiversity patterns, and ecosystem structure. In 2008, the movement ecology framework (MEF Nathan et al. in PNAS 105 (49): 19052–19059, 2008) introduced an integrative theory of organismal movement—linking internal state, motion capacity, and navigation capacity to external factors—which has been recognized as a milestone in the field. Since then, the study of movement experienced a technological boom, which … Cites: ‪Reading tea leaves: How humans interpret topic models‬</summary></entry><entry><title type="html">Does Your Model Classify Entities Reasonably? Diagnosing and Mitigating Spurious Correlations in Entity Typing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/9def347d0f31c93cb3869f069ec09b6d.html" rel="alternate" type="text/html" title="Does Your Model Classify Entities Reasonably? Diagnosing and Mitigating Spurious Correlations in Entity Typing" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/9def347d0f31c93cb3869f069ec09b6d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/9def347d0f31c93cb3869f069ec09b6d.html">&lt;p&gt;The entity typing task aims at predicting one or more words or phrases that describe the type (s) of a specific mention in a sentence. Due to shortcuts from surface patterns to annotated entity labels and biased training, existing entity typing models are subject to the problem of spurious correlations. To comprehensively investigate the faithfulness and reliability of entity typing methods, we first systematically define distinct kinds of model biases that are reflected mainly from spurious correlations … Cites: ‪Modeling fine-grained entity types with box embeddings‬&lt;/p&gt;</content><author><name>N Xu, F Wang, B Li, M Dong, M Chen - arXiv preprint arXiv:2205.12640, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The entity typing task aims at predicting one or more words or phrases that describe the type (s) of a specific mention in a sentence. Due to shortcuts from surface patterns to annotated entity labels and biased training, existing entity typing models are subject to the problem of spurious correlations. To comprehensively investigate the faithfulness and reliability of entity typing methods, we first systematically define distinct kinds of model biases that are reflected mainly from spurious correlations … Cites: ‪Modeling fine-grained entity types with box embeddings‬</summary></entry><entry><title type="html">Improving aspect term extraction via span-level tag data augmentation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/9fdd60e6c4bd3d478de6d6124893d428.html" rel="alternate" type="text/html" title="Improving aspect term extraction via span-level tag data augmentation" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/9fdd60e6c4bd3d478de6d6124893d428</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/9fdd60e6c4bd3d478de6d6124893d428.html">&lt;p&gt;Aspect term extraction (ATE), a fundamental subtask in aspect-based sentiment analysis, aims to extract explicit aspect term from reviewers  expressed opinions. However, the distribution of samples containing different numbers of aspect terms is long-tailed. Due to the scarcity of long-tailed samples and the existence of multiple variable-length aspect terms inside each sample, most ATE models converge to an inferior state because they have difficulty capturing features. Popular data … Cites: ‪A simple and effective model for answering multi-span questions‬&lt;/p&gt;</content><author><name>B Liu, T Lin, M Li - Applied Intelligence, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Aspect term extraction (ATE), a fundamental subtask in aspect-based sentiment analysis, aims to extract explicit aspect term from reviewers expressed opinions. However, the distribution of samples containing different numbers of aspect terms is long-tailed. Due to the scarcity of long-tailed samples and the existence of multiple variable-length aspect terms inside each sample, most ATE models converge to an inferior state because they have difficulty capturing features. Popular data … Cites: ‪A simple and effective model for answering multi-span questions‬</summary></entry><entry><title type="html">An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/a09233db2d2429204cf8e1ff795d7590.html" rel="alternate" type="text/html" title="An Evolutionary Approach to Dynamic Introduction of Tasks in Large-scale Multitask Learning Systems" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/a09233db2d2429204cf8e1ff795d7590</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/a09233db2d2429204cf8e1ff795d7590.html">&lt;p&gt;Multitask learning assumes that models capable of learning from multiple tasks can achieve better quality and efficiency via knowledge transfer, a key feature of human learning. Though, state of the art ML models rely on high customization for each task and leverage size and data scale rather than scaling the number of tasks. Also, continual learning, that adds the temporal aspect to multitask, is often focused to the study of common pitfalls such as catastrophic forgetting instead of being studied at a … Cites: ‪GLaM: Efficient Scaling of Language Models with Mixture-of-Experts‬&lt;/p&gt;</content><author><name>A Gesmundo, J Dean - arXiv preprint arXiv:2205.12755, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Multitask learning assumes that models capable of learning from multiple tasks can achieve better quality and efficiency via knowledge transfer, a key feature of human learning. Though, state of the art ML models rely on high customization for each task and leverage size and data scale rather than scaling the number of tasks. Also, continual learning, that adds the temporal aspect to multitask, is often focused to the study of common pitfalls such as catastrophic forgetting instead of being studied at a … Cites: ‪GLaM: Efficient Scaling of Language Models with Mixture-of-Experts‬</summary></entry><entry><title type="html">Transcormer: Transformer for Sentence Scoring with Sliding Language Modeling</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/a1636998a7878ae9df7eb0e8d3d41f84.html" rel="alternate" type="text/html" title="Transcormer: Transformer for Sentence Scoring with Sliding Language Modeling" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/a1636998a7878ae9df7eb0e8d3d41f84</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/a1636998a7878ae9df7eb0e8d3d41f84.html">&lt;p&gt;Sentence scoring aims at measuring the likelihood score of a sentence and is widely used in many natural language processing scenarios, like reranking, which is to select the best sentence from multiple candidates. Previous works on sentence scoring mainly adopted either causal language modeling (CLM) like GPT or masked language modeling (MLM) like BERT, which have some limitations: 1) CLM only utilizes unidirectional information for the probability estimation of a sentence without … Cites: ‪Energy-based reranking: Improving neural machine translation …‬&lt;/p&gt;</content><author><name>K Song, Y Leng, X Tan, Y Zou, T Qin, D Li - arXiv preprint arXiv:2205.12986, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Sentence scoring aims at measuring the likelihood score of a sentence and is widely used in many natural language processing scenarios, like reranking, which is to select the best sentence from multiple candidates. Previous works on sentence scoring mainly adopted either causal language modeling (CLM) like GPT or masked language modeling (MLM) like BERT, which have some limitations: 1) CLM only utilizes unidirectional information for the probability estimation of a sentence without … Cites: ‪Energy-based reranking: Improving neural machine translation …‬</summary></entry><entry><title type="html">Deep Intra-Class Similarity Measured Semi-Supervised Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/abb33c392bfa7e64bbb7fb6020cc31c0.html" rel="alternate" type="text/html" title="Deep Intra-Class Similarity Measured Semi-Supervised Learning" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/abb33c392bfa7e64bbb7fb6020cc31c0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/abb33c392bfa7e64bbb7fb6020cc31c0.html">&lt;p&gt;Recently, how to handle the situation where only a few samples in the dataset are labeled has become a hot academic topic. Semi-Supervised Learning (SSL) has shown its great capacity and potential in this topic. However, existing methods tend to focus more on the relationship between unlabeled samples and labeled samples or focus on unlabeled samples  information while rarely exploring the hidden information between unlabeled data of the same category. To address this … Cites: ‪Learning with Local and Global Consistency.‬&lt;/p&gt;</content><author><name>Y Yang - 2022 7th International Conference on Intelligent …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recently, how to handle the situation where only a few samples in the dataset are labeled has become a hot academic topic. Semi-Supervised Learning (SSL) has shown its great capacity and potential in this topic. However, existing methods tend to focus more on the relationship between unlabeled samples and labeled samples or focus on unlabeled samples information while rarely exploring the hidden information between unlabeled data of the same category. To address this … Cites: ‪Learning with Local and Global Consistency.‬</summary></entry><entry><title type="html">Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/ad8491b623bf44dd063de31c58ec68dc.html" rel="alternate" type="text/html" title="Understanding Factual Errors in Summarization: Errors, Summarizers, Datasets, Error Detectors" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/ad8491b623bf44dd063de31c58ec68dc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/ad8491b623bf44dd063de31c58ec68dc.html">&lt;p&gt;The propensity of abstractive summarization systems to make factual errors has been the subject of significant study, including work on models to detect factual errors and annotation of errors in current systems  outputs. However, the ever-evolving nature of summarization systems, error detectors, and annotated benchmarks make factuality evaluation a moving target; it is hard to get a clear picture of how techniques compare. In this work, we collect labeled factuality errors from across nine datasets of … Cites: ‪Optimizing the factual correctness of a summary: A study of …‬&lt;/p&gt;</content><author><name>L Tang, T Goyal, AR Fabbri, P Laban, J Xu, S Yahvuz… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The propensity of abstractive summarization systems to make factual errors has been the subject of significant study, including work on models to detect factual errors and annotation of errors in current systems outputs. However, the ever-evolving nature of summarization systems, error detectors, and annotated benchmarks make factuality evaluation a moving target; it is hard to get a clear picture of how techniques compare. In this work, we collect labeled factuality errors from across nine datasets of … Cites: ‪Optimizing the factual correctness of a summary: A study of …‬</summary></entry><entry><title type="html">First Contact: Unsupervised Human-Machine Co-Adaptation via Mutual Information Maximization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b2d725546b7235a7c3e827ff649286d2.html" rel="alternate" type="text/html" title="First Contact: Unsupervised Human-Machine Co-Adaptation via Mutual Information Maximization" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b2d725546b7235a7c3e827ff649286d2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b2d725546b7235a7c3e827ff649286d2.html">&lt;p&gt;How can we train an assistive human-machine interface (eg, an electromyography-based limb prosthesis) to translate a user s raw command signals into the actions of a robot or computer when there is no prior mapping, we cannot ask the user for supervision in the form of action labels or reward feedback, and we do not have prior knowledge of the tasks the user is trying to accomplish? The key idea in this paper is that, regardless of the task, when an interface is more intuitive, the user s commands … Cites: ‪Learning adaptive language interfaces through decomposition‬&lt;/p&gt;</content><author><name>S Reddy, S Levine, AD Dragan - arXiv preprint arXiv:2205.12381, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">How can we train an assistive human-machine interface (eg, an electromyography-based limb prosthesis) to translate a user s raw command signals into the actions of a robot or computer when there is no prior mapping, we cannot ask the user for supervision in the form of action labels or reward feedback, and we do not have prior knowledge of the tasks the user is trying to accomplish? The key idea in this paper is that, regardless of the task, when an interface is more intuitive, the user s commands … Cites: ‪Learning adaptive language interfaces through decomposition‬</summary></entry><entry><title type="html">Fine-grained image captioning with clip reward</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b3591544874878118282043abf15dcd7.html" rel="alternate" type="text/html" title="Fine-grained image captioning with clip reward" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b3591544874878118282043abf15dcd7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b3591544874878118282043abf15dcd7.html">&lt;p&gt;Modern image captioning models are usually trained with text similarity objectives. However, since reference captions in public datasets often describe the most salient common objects, models trained with text similarity objectives tend to ignore specific and detailed aspects of an image that distinguish it from others. Toward more descriptive and distinctive caption generation, we propose using CLIP, a multimodal encoder trained on huge image-text pairs from web, to calculate multimodal similarity … Cites: ‪Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis …‬&lt;/p&gt;</content><author><name>J Cho, S Yoon, A Kale, F Dernoncourt, T Bui, M Bansal - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Modern image captioning models are usually trained with text similarity objectives. However, since reference captions in public datasets often describe the most salient common objects, models trained with text similarity objectives tend to ignore specific and detailed aspects of an image that distinguish it from others. Toward more descriptive and distinctive caption generation, we propose using CLIP, a multimodal encoder trained on huge image-text pairs from web, to calculate multimodal similarity … Cites: ‪Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis …‬</summary></entry><entry><title type="html">Dynamic topic modeling of twitter data during the COVID-19 pandemic</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b4f2aff2cb427cc01d085fdd816c9c32.html" rel="alternate" type="text/html" title="Dynamic topic modeling of twitter data during the COVID-19 pandemic" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b4f2aff2cb427cc01d085fdd816c9c32</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b4f2aff2cb427cc01d085fdd816c9c32.html">&lt;p&gt;In an effort to gauge the global pandemic s impact on social thoughts and behavior, it is important to answer the following questions:(1) What kinds of topics are individuals and groups vocalizing in relation to the pandemic?(2) Are there any noticeable topic trends and if so how do these topics change over time and in response to major events? In this paper, through the advanced Sequential Latent Dirichlet Allocation model, we identified twelve of the most popular topics present in a Twitter dataset … Cites: ‪Zika discourse in the Americas: A multilingual topic analysis of Twitter‬&lt;/p&gt;</content><author><name>A Bogdanowicz, CH Guan - PloS one, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In an effort to gauge the global pandemic s impact on social thoughts and behavior, it is important to answer the following questions:(1) What kinds of topics are individuals and groups vocalizing in relation to the pandemic?(2) Are there any noticeable topic trends and if so how do these topics change over time and in response to major events? In this paper, through the advanced Sequential Latent Dirichlet Allocation model, we identified twelve of the most popular topics present in a Twitter dataset … Cites: ‪Zika discourse in the Americas: A multilingual topic analysis of Twitter‬</summary></entry><entry><title type="html">A knowledge graph of clinical trials ([… formula…])</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b53bc43fcbb85e66a1488f23c6d16f58.html" rel="alternate" type="text/html" title="A knowledge graph of clinical trials ([… formula…])" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b53bc43fcbb85e66a1488f23c6d16f58</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b53bc43fcbb85e66a1488f23c6d16f58.html">&lt;p&gt;Effective and successful clinical trials are essential in developing new drugs and advancing new treatments. However, clinical trials are very expensive and easy to fail. The high cost and low success rate of clinical trials motivate research on inferring knowledge from existing clinical trials in innovative ways for designing future clinical trials. In this manuscript, we present our efforts on constructing the first publicly available Clinical Trials Knowledge Graph, denoted as CTKG. CTKG includes nodes … Cites: ‪Biomedical and clinical English model packages in the Stanza …‬&lt;/p&gt;</content><author><name>Z Chen, B Peng, VN Ioannidis, M Li, G Karypis, X Ning - Scientific Reports, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Effective and successful clinical trials are essential in developing new drugs and advancing new treatments. However, clinical trials are very expensive and easy to fail. The high cost and low success rate of clinical trials motivate research on inferring knowledge from existing clinical trials in innovative ways for designing future clinical trials. In this manuscript, we present our efforts on constructing the first publicly available Clinical Trials Knowledge Graph, denoted as CTKG. CTKG includes nodes … Cites: ‪Biomedical and clinical English model packages in the Stanza …‬</summary></entry><entry><title type="html">Would You Ask it that Way? Measuring and Improving Question Naturalness for Knowledge Graph Question Answering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b60bc7354418a7ba24735b2858723692.html" rel="alternate" type="text/html" title="Would You Ask it that Way? Measuring and Improving Question Naturalness for Knowledge Graph Question Answering" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b60bc7354418a7ba24735b2858723692</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/b60bc7354418a7ba24735b2858723692.html">&lt;p&gt;Knowledge graph question answering (KGQA) facilitates information access by leveraging structured data without requiring formal query language expertise from the user. Instead, users can express their information needs by simply asking their questions in natural language (NL). Datasets used to train KGQA models that would provide such a service are expensive to construct, both in terms of expert and crowdsourced labor. Typically, crowdsourced labor is used to improve template … Cites: ‪The web as a knowledge-base for answering complex questions‬&lt;/p&gt;</content><author><name>T Linjordet, K Balog - arXiv preprint arXiv:2205.12768, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Knowledge graph question answering (KGQA) facilitates information access by leveraging structured data without requiring formal query language expertise from the user. Instead, users can express their information needs by simply asking their questions in natural language (NL). Datasets used to train KGQA models that would provide such a service are expensive to construct, both in terms of expert and crowdsourced labor. Typically, crowdsourced labor is used to improve template … Cites: ‪The web as a knowledge-base for answering complex questions‬</summary></entry><entry><title type="html">A model for automatized data integration in hadoop-based data lakes</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/bff7956709a47fd8539d7e98cd481681.html" rel="alternate" type="text/html" title="A model for automatized data integration in hadoop-based data lakes" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/bff7956709a47fd8539d7e98cd481681</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/bff7956709a47fd8539d7e98cd481681.html">&lt;p&gt;The massive amount of data currently generated by our computing systems and devices, known as big data, require specific technologies to be stored, processed, and distributed. Data lakes are architectures to store data of various formats to be queried when necessary, without needing a predefined schema. Data lakes aim to manage big data ecosystems, and most are currently created based on the Hadoop framework. A known challenge related to data lakes is integrating data from different … Cites: ‪Towards Data Discovery by Example‬&lt;/p&gt;</content><author><name>JMC Couto - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The massive amount of data currently generated by our computing systems and devices, known as big data, require specific technologies to be stored, processed, and distributed. Data lakes are architectures to store data of various formats to be queried when necessary, without needing a predefined schema. Data lakes aim to manage big data ecosystems, and most are currently created based on the Hadoop framework. A known challenge related to data lakes is integrating data from different … Cites: ‪Towards Data Discovery by Example‬</summary></entry><entry><title type="html">ORCA: Interpreting Prompted Language Models via Locating Supporting Data Evidence in the Ocean of Pretraining Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c2775385a882b02a1c3f2fac229b558f.html" rel="alternate" type="text/html" title="ORCA: Interpreting Prompted Language Models via Locating Supporting Data Evidence in the Ocean of Pretraining Data" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c2775385a882b02a1c3f2fac229b558f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c2775385a882b02a1c3f2fac229b558f.html">&lt;p&gt;Large pretrained language models have been performing increasingly well in a variety of downstream tasks via prompting. However, it remains unclear from where the model learns the task-specific knowledge, especially in a zero-shot setup. In this work, we want to find evidence of the model s task-specific competence from pretraining and are specifically interested in locating a very small subset of pretraining data that directly supports the model in the task. We call such a subset … Cites: ‪Mauve: Measuring the gap between neural text and human text …‬&lt;/p&gt;</content><author><name>X Han, Y Tsvetkov - arXiv preprint arXiv:2205.12600, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Large pretrained language models have been performing increasingly well in a variety of downstream tasks via prompting. However, it remains unclear from where the model learns the task-specific knowledge, especially in a zero-shot setup. In this work, we want to find evidence of the model s task-specific competence from pretraining and are specifically interested in locating a very small subset of pretraining data that directly supports the model in the task. We call such a subset … Cites: ‪Mauve: Measuring the gap between neural text and human text …‬</summary></entry><entry><title type="html">Guiding Visual Question Answering with Attention Priors</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c32717b7ad5f5bc53401373982beb983.html" rel="alternate" type="text/html" title="Guiding Visual Question Answering with Attention Priors" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c32717b7ad5f5bc53401373982beb983</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c32717b7ad5f5bc53401373982beb983.html">&lt;p&gt;The current success of modern visual reasoning systems is arguably attributed to cross-modality attention mechanisms. However, in deliberative reasoning such as in VQA, attention is unconstrained at each step, and thus may serve as a statistical pooling mechanism rather than a semantic operation intended to select information relevant to inference. This is because at training time, attention is only guided by a very sparse signal (ie the answer label) at the end of the inference chain. This … Cites: ‪Learning by abstraction: The neural state machine‬&lt;/p&gt;</content><author><name>TM Le, V Le, S Gupta, S Venkatesh, T Tran - arXiv preprint arXiv:2205.12616, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The current success of modern visual reasoning systems is arguably attributed to cross-modality attention mechanisms. However, in deliberative reasoning such as in VQA, attention is unconstrained at each step, and thus may serve as a statistical pooling mechanism rather than a semantic operation intended to select information relevant to inference. This is because at training time, attention is only guided by a very sparse signal (ie the answer label) at the end of the inference chain. This … Cites: ‪Learning by abstraction: The neural state machine‬</summary></entry><entry><title type="html">Refining Query Representations for Dense Retrieval at Test Time</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c38067e09129d2d55c9b4e102dfad34d.html" rel="alternate" type="text/html" title="Refining Query Representations for Dense Retrieval at Test Time" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c38067e09129d2d55c9b4e102dfad34d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c38067e09129d2d55c9b4e102dfad34d.html">&lt;p&gt;Dense retrieval uses a contrastive learning framework to learn dense representations of queries and contexts. Trained encoders are directly used for each test query, but they often fail to accurately represent out-of-domain queries. In this paper, we introduce a framework that refines instance-level query representations at test time, with only the signals coming from the intermediate retrieval results. We optimize the query representation based on the retrieval result similar to pseudo … Cites: ‪Latent retrieval for weakly supervised open domain question …‬&lt;/p&gt;</content><author><name>M Sung, J Park, J Kang, D Chen, J Lee - arXiv preprint arXiv:2205.12680, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Dense retrieval uses a contrastive learning framework to learn dense representations of queries and contexts. Trained encoders are directly used for each test query, but they often fail to accurately represent out-of-domain queries. In this paper, we introduce a framework that refines instance-level query representations at test time, with only the signals coming from the intermediate retrieval results. We optimize the query representation based on the retrieval result similar to pseudo … Cites: ‪Latent retrieval for weakly supervised open domain question …‬</summary></entry><entry><title type="html">An Empirical Study on Distribution Shift Robustness From the Perspective of Pre-Training and Data Augmentation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c71a0dcf6a6a3b36863591dab472b72f.html" rel="alternate" type="text/html" title="An Empirical Study on Distribution Shift Robustness From the Perspective of Pre-Training and Data Augmentation" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c71a0dcf6a6a3b36863591dab472b72f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c71a0dcf6a6a3b36863591dab472b72f.html">&lt;p&gt;The performance of machine learning models under distribution shift has been the focus of the community in recent years. Most of current methods have been proposed to improve the robustness to distribution shift from the algorithmic perspective, ie, designing better training algorithms to help the generalization in shifted test distributions. This paper studies the distribution shift problem from the perspective of pre-training and data augmentation, two important factors in the practice of deep … Cites: ‪Examining and Combating Spurious Features under Distribution Shift‬&lt;/p&gt;</content><author><name>Z Liu, Y Xu, Y Xu, Q Qian, H Li, R Jin, X Ji, AB Chan - arXiv preprint arXiv:2205.12753, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The performance of machine learning models under distribution shift has been the focus of the community in recent years. Most of current methods have been proposed to improve the robustness to distribution shift from the algorithmic perspective, ie, designing better training algorithms to help the generalization in shifted test distributions. This paper studies the distribution shift problem from the perspective of pre-training and data augmentation, two important factors in the practice of deep … Cites: ‪Examining and Combating Spurious Features under Distribution Shift‬</summary></entry><entry><title type="html">LEPUS: Prompt-based Unsupervised Multi-hop Reranking for Open-domain QA</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c76f7969637ed5323841f1db38bc01d0.html" rel="alternate" type="text/html" title="LEPUS: Prompt-based Unsupervised Multi-hop Reranking for Open-domain QA" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c76f7969637ed5323841f1db38bc01d0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c76f7969637ed5323841f1db38bc01d0.html">&lt;p&gt;We study unsupervised multi-hop reranking for multi-hop QA (MQA) with open-domain questions. Since MQA requires piecing information from multiple documents, the main challenge thus resides in retrieving and reranking chains of passages that support the reasoning process. Our approach relies on LargE models with Prompt-Utilizing reranking Strategy (LEPUS): we construct an instruction-like prompt based on a candidate document path and compute a relevance score of the path as the … Cites: ‪Calibration of Pre-trained Transformers‬&lt;/p&gt;</content><author><name>M Khalifa, L Logeswaran, M Lee, H Lee, L Wang - arXiv preprint arXiv:2205.12650, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We study unsupervised multi-hop reranking for multi-hop QA (MQA) with open-domain questions. Since MQA requires piecing information from multiple documents, the main challenge thus resides in retrieving and reranking chains of passages that support the reasoning process. Our approach relies on LargE models with Prompt-Utilizing reranking Strategy (LEPUS): we construct an instruction-like prompt based on a candidate document path and compute a relevance score of the path as the … Cites: ‪Calibration of Pre-trained Transformers‬</summary></entry><entry><title type="html">Federated Split BERT for Heterogeneous Text Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c91b035bb5cfd38f790ebf93b9027827.html" rel="alternate" type="text/html" title="Federated Split BERT for Heterogeneous Text Classification" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c91b035bb5cfd38f790ebf93b9027827</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c91b035bb5cfd38f790ebf93b9027827.html">&lt;p&gt;Pre-trained BERT models have achieved impressive performance in many natural language processing (NLP) tasks. However, in many real-world situations, textual data are usually decentralized over many clients and unable to be uploaded to a central server due to privacy protection and regulations. Federated learning (FL) enables multiple clients collaboratively to train a global model while keeping the local data privacy. A few researches have investigated BERT in federated learning … Cites: ‪Texthide: Tackling Data Privacy in Language Understanding Tasks‬&lt;/p&gt;</content><author><name>Z Li, S Si, J Wang, J Xiao - arXiv preprint arXiv:2205.13299, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pre-trained BERT models have achieved impressive performance in many natural language processing (NLP) tasks. However, in many real-world situations, textual data are usually decentralized over many clients and unable to be uploaded to a central server due to privacy protection and regulations. Federated learning (FL) enables multiple clients collaboratively to train a global model while keeping the local data privacy. A few researches have investigated BERT in federated learning … Cites: ‪Texthide: Tackling Data Privacy in Language Understanding Tasks‬</summary></entry><entry><title type="html">Segmentation and classification of breast cancer using novel deep learning architecture</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c9919351e41276829c20ee87604fc859.html" rel="alternate" type="text/html" title="Segmentation and classification of breast cancer using novel deep learning architecture" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c9919351e41276829c20ee87604fc859</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c9919351e41276829c20ee87604fc859.html">&lt;p&gt;Breast cancer is one of the most frequent cancers in women, and it has a higher mortality rate than other cancers. As a result, early detection is critical. In computer-assisted disease diagnosis, accurate segmentation of the region of interest is a vital concept. The segmentation techniques have been widely used by doctors and physicians to locate the pathology, identify the abnormality, compute the tissue volume, analyze the anatomical structures, and provide treatment. Cancer diagnostic … Cites: ‪An interpretable classifier for high-resolution breast cancer …‬&lt;/p&gt;</content><author><name>S Ramesh, S Sasikala, S Gomathi, V Geetha… - Neural Computing and …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Breast cancer is one of the most frequent cancers in women, and it has a higher mortality rate than other cancers. As a result, early detection is critical. In computer-assisted disease diagnosis, accurate segmentation of the region of interest is a vital concept. The segmentation techniques have been widely used by doctors and physicians to locate the pathology, identify the abnormality, compute the tissue volume, analyze the anatomical structures, and provide treatment. Cancer diagnostic … Cites: ‪An interpretable classifier for high-resolution breast cancer …‬</summary></entry><entry><title type="html">SCS-Gan: Learning Functionality-Agnostic Stylometric Representations for Source Code Authorship Verification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c9c5ce392a544a127318131588086074.html" rel="alternate" type="text/html" title="SCS-Gan: Learning Functionality-Agnostic Stylometric Representations for Source Code Authorship Verification" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c9c5ce392a544a127318131588086074</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/c9c5ce392a544a127318131588086074.html">&lt;p&gt;In recent years, the number of anonymous script-based fileless malware attacks, software copyright disputes, and code plagiarism issues has increased rapidly. In the literature, automated Code Authorship Analysis (CAA) techniques have been proposed to reduce the manual effort in identifying those attacks and issues. Most CAA techniques aim to solve the task of Authorship Attribution (AA), ie, identifying the actual author of a source code fragment from a given set of candidate authors … Cites: ‪Codebert: A pre-trained model for programming and natural …‬&lt;/p&gt;</content><author><name>W Ou, SHH Ding, Y Tian, L Song - IEEE Transactions on Software Engineering, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In recent years, the number of anonymous script-based fileless malware attacks, software copyright disputes, and code plagiarism issues has increased rapidly. In the literature, automated Code Authorship Analysis (CAA) techniques have been proposed to reduce the manual effort in identifying those attacks and issues. Most CAA techniques aim to solve the task of Authorship Attribution (AA), ie, identifying the actual author of a source code fragment from a given set of candidate authors … Cites: ‪Codebert: A pre-trained model for programming and natural …‬</summary></entry><entry><title type="html">Maschinelles Lernen für Sprachverarbeitung</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/ce104a0cc10364eeb9244f1c0102583f.html" rel="alternate" type="text/html" title="Maschinelles Lernen für Sprachverarbeitung" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/ce104a0cc10364eeb9244f1c0102583f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/ce104a0cc10364eeb9244f1c0102583f.html">&lt;p&gt;Zusammenfassung In diesem Kapitel werden Aspekte des maschinellen Lernens behandelt, welche für die Verarbeitung von Text relevant sind. Im maschinellen Lernen erfolgt die Repräsentation sprachlicher Objekte wie Wörter oder Dokumente mit Merkmalen (Features). Auf Basis dieser Merkmale können Objekte geclustert werden, um deren natürliche Gruppierung sichtbar zu machen. Wir illustrieren Clustering, auch unüberwachtes Lernen genannt, an einigen Beispielen mit einem … Cites: ‪Multilingual topic models for unaligned text‬&lt;/p&gt;</content><author><name>C Biemann, G Heyer, U Quasthoff - Wissensrohstoff Text, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Zusammenfassung In diesem Kapitel werden Aspekte des maschinellen Lernens behandelt, welche für die Verarbeitung von Text relevant sind. Im maschinellen Lernen erfolgt die Repräsentation sprachlicher Objekte wie Wörter oder Dokumente mit Merkmalen (Features). Auf Basis dieser Merkmale können Objekte geclustert werden, um deren natürliche Gruppierung sichtbar zu machen. Wir illustrieren Clustering, auch unüberwachtes Lernen genannt, an einigen Beispielen mit einem … Cites: ‪Multilingual topic models for unaligned text‬</summary></entry><entry><title type="html">Orthogonal Multi-view Tensor-based Learning for Clustering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d12ef6cb20cbb05938511620fd7db2d9.html" rel="alternate" type="text/html" title="Orthogonal Multi-view Tensor-based Learning for Clustering" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d12ef6cb20cbb05938511620fd7db2d9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d12ef6cb20cbb05938511620fd7db2d9.html">&lt;p&gt;Multi-view spectral clustering aims to improve the performance of spectral clustering through multi-view data. Many multi-view spectral clustering methods have been proposed recently and achieved promising performance. Among these methods, most of them are designed to pursue numerical consistency in multi-view similarity matrices. However, each similarity matrix has its unique statistic distribution, which makes it not appropriate to seek numerical consistency in multi-view similarity … Cites: ‪Spectral clustering and transductive learning with multiple views‬&lt;/p&gt;</content><author><name>S Ma, Y Liu, G Liu, Q Zheng, C Zhang - Neurocomputing, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Multi-view spectral clustering aims to improve the performance of spectral clustering through multi-view data. Many multi-view spectral clustering methods have been proposed recently and achieved promising performance. Among these methods, most of them are designed to pursue numerical consistency in multi-view similarity matrices. However, each similarity matrix has its unique statistic distribution, which makes it not appropriate to seek numerical consistency in multi-view similarity … Cites: ‪Spectral clustering and transductive learning with multiple views‬</summary></entry><entry><title type="html">A Unified Framework for Anomaly and Concept Drift Detection with Explainability</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d24ba14ad9bbb8a61796dd9c261d1b9b.html" rel="alternate" type="text/html" title="A Unified Framework for Anomaly and Concept Drift Detection with Explainability" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d24ba14ad9bbb8a61796dd9c261d1b9b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d24ba14ad9bbb8a61796dd9c261d1b9b.html">&lt;p&gt;Data-driven applications typically rely on data streams for different machine learning tasks. Inevitably, rare and peculiar events such as concept drifts and anomalies exist within real-world data streams. Identifying such events is of crucial importance as they are the major causes of the deterioration of the performance of machine learning algorithms. The accurate identification of these events remains challenging, particularly because of the characteristics of the real-world streaming data:(1) … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬&lt;/p&gt;</content><author><name>CH Tan - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Data-driven applications typically rely on data streams for different machine learning tasks. Inevitably, rare and peculiar events such as concept drifts and anomalies exist within real-world data streams. Identifying such events is of crucial importance as they are the major causes of the deterioration of the performance of machine learning algorithms. The accurate identification of these events remains challenging, particularly because of the characteristics of the real-world streaming data:(1) … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬</summary></entry><entry><title type="html">МЕТОДЫ ГЛУБОКОГО ОБУЧЕНИЯ ДЛЯ ОБРАБОТКИ ТЕКСТОВ НА ЕСТЕСТВЕННОМ ЯЗЫКЕ</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d371b4fa9a5e6a7d1b43c926ce5dfbaf.html" rel="alternate" type="text/html" title="МЕТОДЫ ГЛУБОКОГО ОБУЧЕНИЯ ДЛЯ ОБРАБОТКИ ТЕКСТОВ НА ЕСТЕСТВЕННОМ ЯЗЫКЕ" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d371b4fa9a5e6a7d1b43c926ce5dfbaf</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d371b4fa9a5e6a7d1b43c926ce5dfbaf.html">&lt;p&gt;Представлен анализ подходов, основанных на глубоком обучении (DL), к задачам обработки естественного языка (NLP). Исследование охватывает различные задачи NLP, реализованные с помощью искусственных нейронных сетей (ANNs), сверточных нейронных сетей (CNNs) и рекуррентных нейронных сетей (RNNs). Эти архитектуры позволяют решать широкий спектр задач обработки естественного языка, ранее не поддававшихся эффективному … Cites: ‪A neural network for factoid question answering over paragraphs‬&lt;/p&gt;</content><author><name>ВВ Курейчик, СИ Родзин, ВВ Бова - Известия ЮФУ. Технические науки., 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Представлен анализ подходов, основанных на глубоком обучении (DL), к задачам обработки естественного языка (NLP). Исследование охватывает различные задачи NLP, реализованные с помощью искусственных нейронных сетей (ANNs), сверточных нейронных сетей (CNNs) и рекуррентных нейронных сетей (RNNs). Эти архитектуры позволяют решать широкий спектр задач обработки естественного языка, ранее не поддававшихся эффективному … Cites: ‪A neural network for factoid question answering over paragraphs‬</summary></entry><entry><title type="html">Transcendental Logic-Based Formalism for Semantic Representation of Software Project Requirements Architecture</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d565b6ab0b3c4e600aa62fadbaff1ee9.html" rel="alternate" type="text/html" title="Transcendental Logic-Based Formalism for Semantic Representation of Software Project Requirements Architecture" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d565b6ab0b3c4e600aa62fadbaff1ee9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d565b6ab0b3c4e600aa62fadbaff1ee9.html">&lt;p&gt;This article is devoted to the analysis of the situation that has arisen in the practice of using artificial intelligence methods for software development. Nowadays there are many disparate approaches, models, and practices based on the use of narrow intelligence for decision-making at different stages of the life cycle of software products, and an almost complete lack of solutions brought to wide practical use. The article provides a comprehensive overview of the main reasons for the lack of the … Cites: ‪Building a neural semantic parser from a domain ontology‬&lt;/p&gt;</content><author><name>OV Moroz, OO Pysarchuk, TI Konrad - Computer and Information Science, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This article is devoted to the analysis of the situation that has arisen in the practice of using artificial intelligence methods for software development. Nowadays there are many disparate approaches, models, and practices based on the use of narrow intelligence for decision-making at different stages of the life cycle of software products, and an almost complete lack of solutions brought to wide practical use. The article provides a comprehensive overview of the main reasons for the lack of the … Cites: ‪Building a neural semantic parser from a domain ontology‬</summary></entry><entry><title type="html">MaskEval: Weighted MLM-Based Evaluation for Text Summarization and Simplification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d5f176b17babd2a21c8c9ee995673478.html" rel="alternate" type="text/html" title="MaskEval: Weighted MLM-Based Evaluation for Text Summarization and Simplification" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d5f176b17babd2a21c8c9ee995673478</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d5f176b17babd2a21c8c9ee995673478.html">&lt;p&gt;In text summarization and simplification, system outputs must be evaluated along multiple dimensions such as relevance, factual consistency, fluency, and grammaticality, and a wide range of possible outputs could be of high quality. These properties make the development of an adaptable, reference-less evaluation metric both necessary and challenging. We introduce MaskEval, a reference-less metric for text summarization and simplification that operates by performing masked language … Cites: ‪BARTScore: Evaluating Generated Text as Text Generation‬&lt;/p&gt;</content><author><name>YL Liu, R Bawden, T Scaliom, B Sagot, JCK Cheung - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In text summarization and simplification, system outputs must be evaluated along multiple dimensions such as relevance, factual consistency, fluency, and grammaticality, and a wide range of possible outputs could be of high quality. These properties make the development of an adaptable, reference-less evaluation metric both necessary and challenging. We introduce MaskEval, a reference-less metric for text summarization and simplification that operates by performing masked language … Cites: ‪BARTScore: Evaluating Generated Text as Text Generation‬</summary></entry><entry><title type="html">Counterfactual Data Augmentation improves Factuality of Abstractive Summarization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d9873a2e52381fc8bb1711aa63ac768f.html" rel="alternate" type="text/html" title="Counterfactual Data Augmentation improves Factuality of Abstractive Summarization" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d9873a2e52381fc8bb1711aa63ac768f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/d9873a2e52381fc8bb1711aa63ac768f.html">&lt;p&gt;Abstractive summarization systems based on pretrained language models often generate coherent but factually inconsistent sentences. In this paper, we present a counterfactual data augmentation approach where we augment data with perturbed summaries that increase the training data diversity. Specifically, we present three augmentation approaches based on replacing (i) entities from other and the same category and (ii) nouns with their corresponding WordNet hypernyms. We show that … Cites: ‪Don t give me the details, just the summary! topic-aware …‬&lt;/p&gt;</content><author><name>D Rajagopal, S Shakeri, CN Santos, E Hovy… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstractive summarization systems based on pretrained language models often generate coherent but factually inconsistent sentences. In this paper, we present a counterfactual data augmentation approach where we augment data with perturbed summaries that increase the training data diversity. Specifically, we present three augmentation approaches based on replacing (i) entities from other and the same category and (ii) nouns with their corresponding WordNet hypernyms. We show that … Cites: ‪Don t give me the details, just the summary! topic-aware …‬</summary></entry><entry><title type="html">Multimodal and Embodied Learning with Language as the Anchor</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/dab7f2d2c6417657583c62d5e88b3837.html" rel="alternate" type="text/html" title="Multimodal and Embodied Learning with Language as the Anchor" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/dab7f2d2c6417657583c62d5e88b3837</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/dab7f2d2c6417657583c62d5e88b3837.html">&lt;p&gt;Since most worldly phenomena can be expressed via language, language is a crucial medium for transferring information and integrating multiple information sources. For example, humans can describe what they see, hear and feel, and also explain how they move with words. Conversely, humans can imagine scenes, sounds, and feelings, and move their body from language descriptions. Therefore, language plays an important role in solving machine learning (ML) and artificial … Cites: ‪CAISE: Conversational Agent for Image Search and Editing‬&lt;/p&gt;</content><author><name>H Kim - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Since most worldly phenomena can be expressed via language, language is a crucial medium for transferring information and integrating multiple information sources. For example, humans can describe what they see, hear and feel, and also explain how they move with words. Conversely, humans can imagine scenes, sounds, and feelings, and move their body from language descriptions. Therefore, language plays an important role in solving machine learning (ML) and artificial … Cites: ‪CAISE: Conversational Agent for Image Search and Editing‬</summary></entry><entry><title type="html">Undersampling is a Minimax Optimal Robustness Intervention in Nonparametric Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e538ea77af8eebf065b2a7bcddb1e860.html" rel="alternate" type="text/html" title="Undersampling is a Minimax Optimal Robustness Intervention in Nonparametric Classification" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e538ea77af8eebf065b2a7bcddb1e860</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e538ea77af8eebf065b2a7bcddb1e860.html">&lt;p&gt;While a broad range of techniques have been proposed to tackle distribution shift, the simple baseline of training on an $\textit {undersampled} $ dataset often achieves close to state-of-the-art-accuracy across several popular benchmarks. This is rather surprising, since undersampling algorithms discard excess majority group data. To understand this phenomenon, we ask if learning is fundamentally constrained by a lack of minority group samples. We prove that this is indeed the case in the setting of … Cites: ‪Just train twice: Improving group robustness without training group …‬&lt;/p&gt;</content><author><name>NS Chatterji, S Haque, T Hashimoto - arXiv preprint arXiv:2205.13094, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">While a broad range of techniques have been proposed to tackle distribution shift, the simple baseline of training on an $\textit {undersampled} $ dataset often achieves close to state-of-the-art-accuracy across several popular benchmarks. This is rather surprising, since undersampling algorithms discard excess majority group data. To understand this phenomenon, we ask if learning is fundamentally constrained by a lack of minority group samples. We prove that this is indeed the case in the setting of … Cites: ‪Just train twice: Improving group robustness without training group …‬</summary></entry><entry><title type="html">Deep Unsupervised Domain Adaptation: A Review of Recent Advances and Perspectives</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e7674cddb3162ce6a356f07ad054c7da.html" rel="alternate" type="text/html" title="Deep Unsupervised Domain Adaptation: A Review of Recent Advances and Perspectives" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e7674cddb3162ce6a356f07ad054c7da</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e7674cddb3162ce6a356f07ad054c7da.html">&lt;p&gt;Deep learning has become the method of choice to tackle real-world problems in different domains, partly because of its ability to learn from data and achieve impressive performance on a wide range of applications. However, its success usually relies on two assumptions:(i) vast troves of labeled datasets are required for accurate model fitting, and (ii) training and testing data are independent and identically distributed. Its performance on unseen target domains, thus, is not … Cites: ‪On the opportunities and risks of foundation models‬&lt;/p&gt;</content><author><name>X Liua, C Yoob, F Xinga, H Ohb, G El Fakhria…</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning has become the method of choice to tackle real-world problems in different domains, partly because of its ability to learn from data and achieve impressive performance on a wide range of applications. However, its success usually relies on two assumptions:(i) vast troves of labeled datasets are required for accurate model fitting, and (ii) training and testing data are independent and identically distributed. Its performance on unseen target domains, thus, is not … Cites: ‪On the opportunities and risks of foundation models‬</summary></entry><entry><title type="html">Automated video analysis of emotion and dystonia in epileptic seizures</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e7bec918dd610cc0a88a55d4cbe2e901.html" rel="alternate" type="text/html" title="Automated video analysis of emotion and dystonia in epileptic seizures" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e7bec918dd610cc0a88a55d4cbe2e901</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e7bec918dd610cc0a88a55d4cbe2e901.html">&lt;p&gt;Objective To investigate the accuracy of deep learning methods applied to seizure video data, in discriminating individual semiologic features of dystonia and emotion in epileptic seizures. Methods A dataset of epileptic seizure videos was used from patients explored with stereo-EEG for focal pharmacoresistant epilepsy. All patients had hyperkinetic (HKN) seizures according to ILAE definition. Presence or absence of (1) dystonia and (2) emotional features in each seizure was documented by an … Cites: ‪Deep learning-enabled medical computer vision‬&lt;/p&gt;</content><author><name>JC Hou, M Thonnat, F Bartolomei, A McGonigal - Epilepsy Research, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Objective To investigate the accuracy of deep learning methods applied to seizure video data, in discriminating individual semiologic features of dystonia and emotion in epileptic seizures. Methods A dataset of epileptic seizure videos was used from patients explored with stereo-EEG for focal pharmacoresistant epilepsy. All patients had hyperkinetic (HKN) seizures according to ILAE definition. Presence or absence of (1) dystonia and (2) emotional features in each seizure was documented by an … Cites: ‪Deep learning-enabled medical computer vision‬</summary></entry><entry><title type="html">Identification of opinion trends using sentiment analysis of airlines passengers reviews</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e905e3741c50724624e483bc484d7bdf.html" rel="alternate" type="text/html" title="Identification of opinion trends using sentiment analysis of airlines passengers reviews" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e905e3741c50724624e483bc484d7bdf</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e905e3741c50724624e483bc484d7bdf.html">&lt;p&gt;Receiving customer opinions on products and services provided by companies is one of the main needs of company managers to improve products and services. Today, it is common to use social networks, messengers, and review websites to receive data from customer opinions. But analyzing the data received from these sources due to their huge volume requires an efficient tool. In this study, textual data obtained from the reviews of passengers of the top 10 airlines in the Middle East … Cites: ‪Interactive topic modeling‬&lt;/p&gt;</content><author><name>S Farzadnia, IR Vanani - Journal of Air Transport Management, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Receiving customer opinions on products and services provided by companies is one of the main needs of company managers to improve products and services. Today, it is common to use social networks, messengers, and review websites to receive data from customer opinions. But analyzing the data received from these sources due to their huge volume requires an efficient tool. In this study, textual data obtained from the reviews of passengers of the top 10 airlines in the Middle East … Cites: ‪Interactive topic modeling‬</summary></entry><entry><title type="html">ProsocialDialog: A Prosocial Backbone for Conversational Agents</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e955113410240a29b32338f50c5a144a.html" rel="alternate" type="text/html" title="ProsocialDialog: A Prosocial Backbone for Conversational Agents" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e955113410240a29b32338f50c5a144a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e955113410240a29b32338f50c5a144a.html">&lt;p&gt;Most existing dialogue systems fail to respond properly to potentially unsafe user utterances by either ignoring or passively agreeing with them. To address this issue, we introduce ProsocialDialog, the first large-scale multi-turn dialogue dataset to …&lt;/p&gt;</content><author><name>H Kim, Y Yu, L Jiang, X Lu, D Khashabi, G Kim, Y Choi… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Most existing dialogue systems fail to respond properly to potentially unsafe user utterances by either ignoring or passively agreeing with them. To address this issue, we introduce ProsocialDialog, the first large-scale multi-turn dialogue dataset to …</summary></entry><entry><title type="html">Certified Robustness Against Natural Language Attacks by Causal Intervention</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e982860ffb3d7b3834437d8e931c59ec.html" rel="alternate" type="text/html" title="Certified Robustness Against Natural Language Attacks by Causal Intervention" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e982860ffb3d7b3834437d8e931c59ec</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/e982860ffb3d7b3834437d8e931c59ec.html">&lt;table&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;Deep learning models have achieved great success in many fields, yet they are vulnerable to adversarial examples. This paper follows a causal perspective to look into the adversarial vulnerability and proposes Causal Intervention by Semantic Smoothing (CISS), a novel framework towards robustness against natural language attacks. Instead of merely fitting observational data, CISS learns causal effects p (y&lt;/td&gt;
      &lt;td&gt;do (x)) by smoothing in the latent semantic space to make robust predictions, which … Cites: ‪Semantically Equivalent Adversarial Rules for Debugging NLP …‬&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;</content><author><name>H Zhao, C Ma, X Dong, AT Luu, ZH Deng, H Zhang - arXiv preprint arXiv:2205.12331, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning models have achieved great success in many fields, yet they are vulnerable to adversarial examples. This paper follows a causal perspective to look into the adversarial vulnerability and proposes Causal Intervention by Semantic Smoothing (CISS), a novel framework towards robustness against natural language attacks. Instead of merely fitting observational data, CISS learns causal effects p (y do (x)) by smoothing in the latent semantic space to make robust predictions, which … Cites: ‪Semantically Equivalent Adversarial Rules for Debugging NLP …‬</summary></entry><entry><title type="html">Sequence to Sequence Learning for Joint Extraction of Entities and Relations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/ebce0df77dfb4a41e658c8c60828be96.html" rel="alternate" type="text/html" title="Sequence to Sequence Learning for Joint Extraction of Entities and Relations" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/ebce0df77dfb4a41e658c8c60828be96</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/ebce0df77dfb4a41e658c8c60828be96.html">&lt;p&gt;The relations of two entities contained in the sentence are often complicated. There exists multiple relation tuples which owns one or both the same entities among them. Extracting those overlapped multiple relation tuples faces great challenges. Most existing works employ the famous Seq2Seq model for joint extraction of entities and relations, which cannot handle the multiple relations properly due to the missing of graph structure information of the relations and entities in a sentence. In this paper … Cites: ‪Exploiting syntactico-semantic structures for relation extraction‬&lt;/p&gt;</content><author><name>Z Liang, J Du - Neurocomputing, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The relations of two entities contained in the sentence are often complicated. There exists multiple relation tuples which owns one or both the same entities among them. Extracting those overlapped multiple relation tuples faces great challenges. Most existing works employ the famous Seq2Seq model for joint extraction of entities and relations, which cannot handle the multiple relations properly due to the missing of graph structure information of the relations and entities in a sentence. In this paper … Cites: ‪Exploiting syntactico-semantic structures for relation extraction‬</summary></entry><entry><title type="html">Perturbation Augmentation for Fairer NLP</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/eeea83cacfccd8019031de18c3cd443d.html" rel="alternate" type="text/html" title="Perturbation Augmentation for Fairer NLP" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/eeea83cacfccd8019031de18c3cd443d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/eeea83cacfccd8019031de18c3cd443d.html">&lt;p&gt;Unwanted and often harmful social biases are becoming ever more salient in NLP research, affecting both models and datasets. In this work, we ask: does training on demographically perturbed data lead to more fair language models? We collect a large dataset of human annotated text perturbations and train an automatic perturber on it, which we show to outperform heuristic alternatives. We find:(i) Language models (LMs) pre-trained on demographically perturbed corpora are more fair, at … Cites: ‪Tailor: Generating and Perturbing Text with Semantic Controls‬&lt;/p&gt;</content><author><name>R Qian, C Ross, J Fernandes, E Smith, D Kiela… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Unwanted and often harmful social biases are becoming ever more salient in NLP research, affecting both models and datasets. In this work, we ask: does training on demographically perturbed data lead to more fair language models? We collect a large dataset of human annotated text perturbations and train an automatic perturber on it, which we show to outperform heuristic alternatives. We find:(i) Language models (LMs) pre-trained on demographically perturbed corpora are more fair, at … Cites: ‪Tailor: Generating and Perturbing Text with Semantic Controls‬</summary></entry><entry><title type="html">AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/ef8acfed66f3e0fec4fc98ad40c53016.html" rel="alternate" type="text/html" title="AdaptFormer: Adapting Vision Transformers for Scalable Visual Recognition" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/ef8acfed66f3e0fec4fc98ad40c53016</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/ef8acfed66f3e0fec4fc98ad40c53016.html">&lt;p&gt;Although the pre-trained Vision Transformers (ViTs) achieved great success in computer vision, adapting a ViT to various image and video tasks is challenging because of its heavy computation and storage burdens, where each model needs to be independently and comprehensively fine-tuned to different tasks, limiting its transferability in different domains. To address this challenge, we propose an effective adaptation approach for Transformer, namely AdaptFormer, which can … Cites: ‪Towards a unified view of parameter-efficient transfer learning‬&lt;/p&gt;</content><author><name>S Chen, C Ge, Z Tong, J Wang, Y Song, J Wang, P Luo - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Although the pre-trained Vision Transformers (ViTs) achieved great success in computer vision, adapting a ViT to various image and video tasks is challenging because of its heavy computation and storage burdens, where each model needs to be independently and comprehensively fine-tuned to different tasks, limiting its transferability in different domains. To address this challenge, we propose an effective adaptation approach for Transformer, namely AdaptFormer, which can … Cites: ‪Towards a unified view of parameter-efficient transfer learning‬</summary></entry><entry><title type="html">Large Language Models are Zero-Shot Clinical Information Extractors</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/f088e36b3430cc87ee7e0669ce419b9e.html" rel="alternate" type="text/html" title="Large Language Models are Zero-Shot Clinical Information Extractors" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/f088e36b3430cc87ee7e0669ce419b9e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/f088e36b3430cc87ee7e0669ce419b9e.html">&lt;p&gt;We show that large language models, such as GPT-3, perform well at zero-shot information extraction from clinical text despite not being trained specifically for the clinical domain. We present several examples showing how to use these models as tools for the diverse tasks of (i) concept disambiguation,(ii) evidence extraction,(iii) coreference resolution, and (iv) concept extraction, all on clinical text. The key to good performance is the use of simple task-specific programs that map from the … Cites: ‪Pre-train, prompt, and predict: A systematic survey of prompting …‬&lt;/p&gt;</content><author><name>M Agrawal, S Hegselmann, H Lang, Y Kim, D Sontag - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We show that large language models, such as GPT-3, perform well at zero-shot information extraction from clinical text despite not being trained specifically for the clinical domain. We present several examples showing how to use these models as tools for the diverse tasks of (i) concept disambiguation,(ii) evidence extraction,(iii) coreference resolution, and (iv) concept extraction, all on clinical text. The key to good performance is the use of simple task-specific programs that map from the … Cites: ‪Pre-train, prompt, and predict: A systematic survey of prompting …‬</summary></entry><entry><title type="html">Charting Past, Present, and Future Research in the Semantic Web and Interoperability</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/f14e2285dafe8509729ffec956b672b4.html" rel="alternate" type="text/html" title="Charting Past, Present, and Future Research in the Semantic Web and Interoperability" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/f14e2285dafe8509729ffec956b672b4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/f14e2285dafe8509729ffec956b672b4.html">&lt;p&gt;Huge advances in peer-to-peer systems and attempts to develop the semantic web have revealed a critical issue in information systems across multiple domains: the absence of semantic interoperability. Today, businesses operating in a digital environment require increased supply-chain automation, interoperability, and data governance. While research on the semantic web and interoperability has recently received much attention, a dearth of studies investigates the relationship between … Cites: ‪Piazza: Data management infrastructure for semantic web …‬&lt;/p&gt;</content><author><name>A Rejeb, JG Keogh, W Martindale, D Dooley, E Smart… - Future Internet, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Huge advances in peer-to-peer systems and attempts to develop the semantic web have revealed a critical issue in information systems across multiple domains: the absence of semantic interoperability. Today, businesses operating in a digital environment require increased supply-chain automation, interoperability, and data governance. While research on the semantic web and interoperability has recently received much attention, a dearth of studies investigates the relationship between … Cites: ‪Piazza: Data management infrastructure for semantic web …‬</summary></entry><entry><title type="html">Language Anisotropic Cross-Lingual Model Editing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/f735fe7df8f070c1d4d9c50335794582.html" rel="alternate" type="text/html" title="Language Anisotropic Cross-Lingual Model Editing" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/f735fe7df8f070c1d4d9c50335794582</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/f735fe7df8f070c1d4d9c50335794582.html">&lt;p&gt;Pre-trained language models learn large amounts of knowledge from their training corpus, while the memorized facts could become outdated over a few years. Model editing aims to make post-hoc updates on specific facts in a model while leaving irrelevant knowledge unchanged. However, existing work studies only the monolingual scenario. In this paper, we focus on cross-lingual model editing. Firstly, we propose the definition and metrics of the cross-lingual model editing, where … Cites: ‪Fast model editing at scale‬&lt;/p&gt;</content><author><name>Y Xu, Y Hou, W Che - arXiv preprint arXiv:2205.12677, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pre-trained language models learn large amounts of knowledge from their training corpus, while the memorized facts could become outdated over a few years. Model editing aims to make post-hoc updates on specific facts in a model while leaving irrelevant knowledge unchanged. However, existing work studies only the monolingual scenario. In this paper, we focus on cross-lingual model editing. Firstly, we propose the definition and metrics of the cross-lingual model editing, where … Cites: ‪Fast model editing at scale‬</summary></entry><entry><title type="html">A distantly supervised approach for recognizing product mentions in user-generated content</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/f99654ae35a8a668b679d9d92cf8b288.html" rel="alternate" type="text/html" title="A distantly supervised approach for recognizing product mentions in user-generated content" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/f99654ae35a8a668b679d9d92cf8b288</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/f99654ae35a8a668b679d9d92cf8b288.html">&lt;p&gt;As online purchasing becomes more popular, users trust more information published on social media than on advertisement content. Opinion mining is often applied to social media, and opinion target extraction is one of its main sub-tasks. In this paper, we focus on recognizing target entities related to electronic products. We propose a method called ProdSpot, for training a named entity extractor to identify product mentions in user text based on the distant supervision paradigm. ProdSpot relies … Cites: ‪Design challenges and misconceptions in named entity recognition‬&lt;/p&gt;</content><author><name>HS Vieira, AS Silva, P Calado, ES de Moura - Journal of Intelligent Information …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As online purchasing becomes more popular, users trust more information published on social media than on advertisement content. Opinion mining is often applied to social media, and opinion target extraction is one of its main sub-tasks. In this paper, we focus on recognizing target entities related to electronic products. We propose a method called ProdSpot, for training a named entity extractor to identify product mentions in user text based on the distant supervision paradigm. ProdSpot relies … Cites: ‪Design challenges and misconceptions in named entity recognition‬</summary></entry><entry><title type="html">Dynamically Relative Position Encoding-Based Transformer for Automatic Code Edit</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/fccdecb3dd1c303679f54aa2f597c128.html" rel="alternate" type="text/html" title="Dynamically Relative Position Encoding-Based Transformer for Automatic Code Edit" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/fccdecb3dd1c303679f54aa2f597c128</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/fccdecb3dd1c303679f54aa2f597c128.html">&lt;p&gt;Adapting Deep Learning (DL) techniques to automate non-trivial coding activities, such as code documentation and defect detection, has been intensively studied recently. Learning to predict code changes is one of the popular and essential investigations. Prior studies have shown that DL techniques such as Neural Machine Translation (NMT) can benefit meaningful code changes, including bug fixing and code refactoring. However, NMT models may encounter bottleneck when modeling … Cites: ‪Graphcodebert: Pre-training code representations with data flow‬&lt;/p&gt;</content><author><name>S Qi, Y Li, C Gao, X Su, S Gao, Z Zheng, C Liu - arXiv preprint arXiv:2205.13522, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Adapting Deep Learning (DL) techniques to automate non-trivial coding activities, such as code documentation and defect detection, has been intensively studied recently. Learning to predict code changes is one of the popular and essential investigations. Prior studies have shown that DL techniques such as Neural Machine Translation (NMT) can benefit meaningful code changes, including bug fixing and code refactoring. However, NMT models may encounter bottleneck when modeling … Cites: ‪Graphcodebert: Pre-training code representations with data flow‬</summary></entry><entry><title type="html">Align Representations with Base: A New Approach to Self-Supervised Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/fe02ae0f91a228b84cc92e1df9c710fd.html" rel="alternate" type="text/html" title="Align Representations with Base: A New Approach to Self-Supervised Learning" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/fe02ae0f91a228b84cc92e1df9c710fd</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/fe02ae0f91a228b84cc92e1df9c710fd.html">&lt;p&gt;Existing symmetric contrastive learning methods suffer from collapses (complete and dimensional) or quadratic complexity of objectives. Departure from these methods which maximize mutual information of two generated views, along either instance or feature dimension, the proposed paradigm introduces intermediate variables at the feature level, and maximizes the consistency between variables and representations of each view. Specifically, the proposed intermediate variables are the nearest group … Cites: ‪Towards domain-agnostic contrastive learning‬&lt;/p&gt;</content><author><name>S Zhang, L Qiu, F Zhu, J Yan, H Zhang, R Zhao, H Li…</name></author><category term="jekyll" /><category term="update" /><summary type="html">Existing symmetric contrastive learning methods suffer from collapses (complete and dimensional) or quadratic complexity of objectives. Departure from these methods which maximize mutual information of two generated views, along either instance or feature dimension, the proposed paradigm introduces intermediate variables at the feature level, and maximizes the consistency between variables and representations of each view. Specifically, the proposed intermediate variables are the nearest group … Cites: ‪Towards domain-agnostic contrastive learning‬</summary></entry><entry><title type="html">LingMess: Linguistically Informed Multi Expert Scorers for Coreference Resolution</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/fe2b31f777194dd797c0e95a39bf8d46.html" rel="alternate" type="text/html" title="LingMess: Linguistically Informed Multi Expert Scorers for Coreference Resolution" /><published>2022-05-30T22:20:45-04:00</published><updated>2022-05-30T22:20:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/fe2b31f777194dd797c0e95a39bf8d46</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/30/fe2b31f777194dd797c0e95a39bf8d46.html">&lt;p&gt;While coreference resolution typically involves various linguistic challenges, recent models are based on a single pairwise scorer for all types of pairs. We present LingMess, a new coreference model that defines different categories of coreference cases and optimize multiple pairwise scorers, where each scorer learns a specific set of linguistic challenges. Our model substantially improves pairwise scores for most categories and outperforms cluster-level performance on Ontonotes. Our model is … Cites: ‪SpanBERT: Improving Pre-training by Representing and Predicting …‬&lt;/p&gt;</content><author><name>S Otmazgin, A Cattan, Y Goldberg - arXiv preprint arXiv:2205.12644, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">While coreference resolution typically involves various linguistic challenges, recent models are based on a single pairwise scorer for all types of pairs. We present LingMess, a new coreference model that defines different categories of coreference cases and optimize multiple pairwise scorers, where each scorer learns a specific set of linguistic challenges. Our model substantially improves pairwise scores for most categories and outperforms cluster-level performance on Ontonotes. Our model is … Cites: ‪SpanBERT: Improving Pre-training by Representing and Predicting …‬</summary></entry><entry><title type="html">Attributing AUC-ROC to Analyze Binary Classifier Performance</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/005fb0ac216257a4b9b00c8ac16bd1b8.html" rel="alternate" type="text/html" title="Attributing AUC-ROC to Analyze Binary Classifier Performance" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/005fb0ac216257a4b9b00c8ac16bd1b8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/005fb0ac216257a4b9b00c8ac16bd1b8.html">&lt;p&gt;Area Under the Receiver Operating Characteristic Curve (AUC-ROC) is a popular evaluation metric for binary classifiers. In this paper, we discuss techniques to segment the AUC-ROC along human-interpretable dimensions. AUC-ROC is not an additive/linear function over the data samples, therefore such segmenting the overall AUC-ROC is different from tabulating the AUC-ROC of data segments. To segment the overall AUC-ROC, we must first solve an\emph {attribution} problem to identify … Cites: ‪Beyond Accuracy: Behavioral Testing of NLP Models with CheckList‬&lt;/p&gt;</content><author><name>A Tafvizi, B Avci, M Sundararajan - arXiv preprint arXiv:2205.11781, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Area Under the Receiver Operating Characteristic Curve (AUC-ROC) is a popular evaluation metric for binary classifiers. In this paper, we discuss techniques to segment the AUC-ROC along human-interpretable dimensions. AUC-ROC is not an additive/linear function over the data samples, therefore such segmenting the overall AUC-ROC is different from tabulating the AUC-ROC of data segments. To segment the overall AUC-ROC, we must first solve an\emph {attribution} problem to identify … Cites: ‪Beyond Accuracy: Behavioral Testing of NLP Models with CheckList‬</summary></entry><entry><title type="html">Explanatory machine learning for sequential human teaching</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/01e5144896eec157768069fd03359958.html" rel="alternate" type="text/html" title="Explanatory machine learning for sequential human teaching" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/01e5144896eec157768069fd03359958</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/01e5144896eec157768069fd03359958.html">&lt;p&gt;The topic of comprehensibility of machine-learned theories has recently drawn increasing attention. Inductive Logic Programming (ILP) uses logic programming to derive logic theories from small data based on abduction and induction techniques. Learned theories are represented in the form of rules as declarative descriptions of obtained knowledge. In earlier work, the authors provided the first evidence of a measurable increase in human comprehension based on machine-learned logic … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬&lt;/p&gt;</content><author><name>L Ai, J Langer, SH Muggleton, U Schmid - arXiv preprint arXiv:2205.10250, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The topic of comprehensibility of machine-learned theories has recently drawn increasing attention. Inductive Logic Programming (ILP) uses logic programming to derive logic theories from small data based on abduction and induction techniques. Learned theories are represented in the form of rules as declarative descriptions of obtained knowledge. In earlier work, the authors provided the first evidence of a measurable increase in human comprehension based on machine-learned logic … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬</summary></entry><entry><title type="html">Revisiting Pre-trained Language Models and their Evaluation for Arabic Natural Language Understanding</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/0289be1ce5493911e52e973c295978a5.html" rel="alternate" type="text/html" title="Revisiting Pre-trained Language Models and their Evaluation for Arabic Natural Language Understanding" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/0289be1ce5493911e52e973c295978a5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/0289be1ce5493911e52e973c295978a5.html">&lt;p&gt;There is a growing body of work in recent years to develop pre-trained language models (PLMs) for the Arabic language. This work concerns addressing two major problems in existing Arabic PLMs which constraint progress of the Arabic NLU and NLG fields. First, existing Arabic PLMs are not well-explored and their pre-trainig can be improved significantly using a more methodical approach. Second, there is a lack of systematic and reproducible evaluation of these models in the literature. In this … Cites: ‪Palm: Scaling language modeling with pathways‬&lt;/p&gt;</content><author><name>A Ghaddar, Y Wu, S Bagga, A Rashid, K Bibi… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">There is a growing body of work in recent years to develop pre-trained language models (PLMs) for the Arabic language. This work concerns addressing two major problems in existing Arabic PLMs which constraint progress of the Arabic NLU and NLG fields. First, existing Arabic PLMs are not well-explored and their pre-trainig can be improved significantly using a more methodical approach. Second, there is a lack of systematic and reproducible evaluation of these models in the literature. In this … Cites: ‪Palm: Scaling language modeling with pathways‬</summary></entry><entry><title type="html">Can Foundation Models Wrangle Your Data?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/034a1cc70b3f70609bf4e09e7f14f894.html" rel="alternate" type="text/html" title="Can Foundation Models Wrangle Your Data?" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/034a1cc70b3f70609bf4e09e7f14f894</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/034a1cc70b3f70609bf4e09e7f14f894.html">&lt;p&gt;Foundation Models (FMs) are models trained on large corpora of data that, at very large scale, can generalize to new tasks without any task-specific finetuning. As these models continue to grow in size, innovations continue to push the boundaries of what these models can do on language and image tasks. This paper aims to understand an underexplored area of FMs: classical data tasks like cleaning and integration. As a proof-of-concept, we cast three data cleaning and integration tasks … Cites: ‪WANLI: Worker and AI Collaboration for Natural Language …‬&lt;/p&gt;</content><author><name>A Narayan, I Chami, L Orr, C Ré - arXiv preprint arXiv:2205.09911, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Foundation Models (FMs) are models trained on large corpora of data that, at very large scale, can generalize to new tasks without any task-specific finetuning. As these models continue to grow in size, innovations continue to push the boundaries of what these models can do on language and image tasks. This paper aims to understand an underexplored area of FMs: classical data tasks like cleaning and integration. As a proof-of-concept, we cast three data cleaning and integration tasks … Cites: ‪WANLI: Worker and AI Collaboration for Natural Language …‬</summary></entry><entry><title type="html">Neural Subgraph Explorer: Reducing Noisy Information via Target-Oriented Syntax Graph Pruning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/04795ec33e0a14efe84ebbe5a4384447.html" rel="alternate" type="text/html" title="Neural Subgraph Explorer: Reducing Noisy Information via Target-Oriented Syntax Graph Pruning" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/04795ec33e0a14efe84ebbe5a4384447</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/04795ec33e0a14efe84ebbe5a4384447.html">&lt;p&gt;Recent years have witnessed the emerging success of leveraging syntax graphs for the target sentiment classification task. However, we discover that existing syntax-based models suffer from two issues: noisy information aggregation and loss of distant correlations. In this paper, we propose a novel model termed Neural Subgraph Explorer, which (1) reduces the noisy information via pruning target-irrelevant nodes on the syntax graph;(2) introduces beneficial first-order connections … Cites: ‪Effective LSTMs for target-dependent sentiment classification‬&lt;/p&gt;</content><author><name>B Xing, IW Tsang - arXiv preprint arXiv:2205.10970, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent years have witnessed the emerging success of leveraging syntax graphs for the target sentiment classification task. However, we discover that existing syntax-based models suffer from two issues: noisy information aggregation and loss of distant correlations. In this paper, we propose a novel model termed Neural Subgraph Explorer, which (1) reduces the noisy information via pruning target-irrelevant nodes on the syntax graph;(2) introduces beneficial first-order connections … Cites: ‪Effective LSTMs for target-dependent sentiment classification‬</summary></entry><entry><title type="html">WCATN: Unsupervised deep learning to classify weather conditions from outdoor images</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/088d865c5fbcc12a1d61b12508f6c969.html" rel="alternate" type="text/html" title="WCATN: Unsupervised deep learning to classify weather conditions from outdoor images" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/088d865c5fbcc12a1d61b12508f6c969</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/088d865c5fbcc12a1d61b12508f6c969.html">&lt;p&gt;Weather classification from single images is significant for many outdoor computer vision applications, while it has not been thoroughly studied. Existing methods view it as a supervised task under the guidance of weather labels. Though these methods have made great success, they are not applicable to real-world applications because of their reliance on massive human-annotated weather images. In this paper, we take the initial attempt to treat weather classification as an unsupervised task, ie to classify … Cites: ‪Randaugment: Practical automated data augmentation with a …‬&lt;/p&gt;</content><author><name>K Xie, L Huang, Z Wei, W Zhang, Q Qin - Engineering Applications of Artificial …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Weather classification from single images is significant for many outdoor computer vision applications, while it has not been thoroughly studied. Existing methods view it as a supervised task under the guidance of weather labels. Though these methods have made great success, they are not applicable to real-world applications because of their reliance on massive human-annotated weather images. In this paper, we take the initial attempt to treat weather classification as an unsupervised task, ie to classify … Cites: ‪Randaugment: Practical automated data augmentation with a …‬</summary></entry><entry><title type="html">Discovering Entity Columns of Web Tables Effectively and Efficiently.</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/09339e516519853c0bd670dd20d571eb.html" rel="alternate" type="text/html" title="Discovering Entity Columns of Web Tables Effectively and Efficiently." /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/09339e516519853c0bd670dd20d571eb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/09339e516519853c0bd670dd20d571eb.html">&lt;p&gt;Compared with traditional relational tables, web tables have no designated key attributes or entity columns, which make them difficult for machines to understand. The effectiveness of existing methods for entity column detection usually depends on the coverage of knowledge base, and efficiency of traversing knowledge base is low. In this paper, we propose a novel framework for discovering entity columns in web tables based on approximate primary functional dependency. We build the table … Cites: ‪Ten years of webtables‬&lt;/p&gt;</content><author><name>SIYU CHEN, N WANG - Journal of Information Science &amp; Engineering, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Compared with traditional relational tables, web tables have no designated key attributes or entity columns, which make them difficult for machines to understand. The effectiveness of existing methods for entity column detection usually depends on the coverage of knowledge base, and efficiency of traversing knowledge base is low. In this paper, we propose a novel framework for discovering entity columns in web tables based on approximate primary functional dependency. We build the table … Cites: ‪Ten years of webtables‬</summary></entry><entry><title type="html">Penguins Don t Fly: Reasoning about Generics through Instantiations and Exceptions</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/0a26416bc497faeff0a3a5860a47cfba.html" rel="alternate" type="text/html" title="Penguins Don t Fly: Reasoning about Generics through Instantiations and Exceptions" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/0a26416bc497faeff0a3a5860a47cfba</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/0a26416bc497faeff0a3a5860a47cfba.html">&lt;p&gt;Generics express generalizations about the world (eg,  birds can fly ). However, they are not universally true–while sparrows and penguins are both birds, only sparrows can fly and penguins cannot. Commonsense knowledge bases, which are used extensively in many NLP tasks as a source of world-knowledge, can often encode generic knowledge but, by-design, cannot encode such exceptions. Therefore, it is crucial to realize the specific instances when a generic statement is true or false. In … Cites: ‪NeuroLogic A* esque Decoding: Constrained Text Generation with …‬&lt;/p&gt;</content><author><name>E Allaway, JD Hwang, C Bhagavatula, K McKeown… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Generics express generalizations about the world (eg, birds can fly ). However, they are not universally true–while sparrows and penguins are both birds, only sparrows can fly and penguins cannot. Commonsense knowledge bases, which are used extensively in many NLP tasks as a source of world-knowledge, can often encode generic knowledge but, by-design, cannot encode such exceptions. Therefore, it is crucial to realize the specific instances when a generic statement is true or false. In … Cites: ‪NeuroLogic A* esque Decoding: Constrained Text Generation with …‬</summary></entry><entry><title type="html">SAIBench: Benchmarking AI for Science</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/0c02c53cda828274ead672c1cdcc3bf9.html" rel="alternate" type="text/html" title="SAIBench: Benchmarking AI for Science" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/0c02c53cda828274ead672c1cdcc3bf9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/0c02c53cda828274ead672c1cdcc3bf9.html">&lt;p&gt;Scientific research communities are embracing AI-based solutions to target tractable scientific tasks and improve research work-flows. However, the development and evaluation of such solutions are scattered across multiple disciplines. We formalize the problem of scientific AI benchmarking, and propose a system called SAIBench in the hope of unifying the efforts and enabling low-friction on-boarding of new disciplines. The system approaches this goal with SAIL, a domain-specific language … Cites: ‪Codexglue: A machine learning benchmark dataset for code …‬&lt;/p&gt;</content><author><name>Y Li, J Zhan - BenchCouncil Transactions on Benchmarks, Standards …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Scientific research communities are embracing AI-based solutions to target tractable scientific tasks and improve research work-flows. However, the development and evaluation of such solutions are scattered across multiple disciplines. We formalize the problem of scientific AI benchmarking, and propose a system called SAIBench in the hope of unifying the efforts and enabling low-friction on-boarding of new disciplines. The system approaches this goal with SAIL, a domain-specific language … Cites: ‪Codexglue: A machine learning benchmark dataset for code …‬</summary></entry><entry><title type="html">Depicting Places in Information Systems</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/0fddfc384de9d77c9adabc4d06d57524.html" rel="alternate" type="text/html" title="Depicting Places in Information Systems" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/0fddfc384de9d77c9adabc4d06d57524</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/0fddfc384de9d77c9adabc4d06d57524.html">&lt;p&gt;Places are more than just locations on a map—they are centers of meaning and lived experience that play essential roles in how people interact with and make sense of the world. Over the last three decades, as computing has grown more powerful, more ubiquitous, and more deeply entwined with society, the ways people encounter and experience places are increasingly mediated by information systems such as digital maps, information overlays, social media, augmented reality, and local guides … Cites: ‪Automatic construction of travel itineraries using social breadcrumbs‬&lt;/p&gt;</content><author><name>J Cranshaw - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Places are more than just locations on a map—they are centers of meaning and lived experience that play essential roles in how people interact with and make sense of the world. Over the last three decades, as computing has grown more powerful, more ubiquitous, and more deeply entwined with society, the ways people encounter and experience places are increasingly mediated by information systems such as digital maps, information overlays, social media, augmented reality, and local guides … Cites: ‪Automatic construction of travel itineraries using social breadcrumbs‬</summary></entry><entry><title type="html">UVA Resources for the Biomedical Vocabulary Alignment at Scale in the UMLS Metathesaurus</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/11bfda957cf8a7fe7bd8d804585ed586.html" rel="alternate" type="text/html" title="UVA Resources for the Biomedical Vocabulary Alignment at Scale in the UMLS Metathesaurus" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/11bfda957cf8a7fe7bd8d804585ed586</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/11bfda957cf8a7fe7bd8d804585ed586.html">&lt;p&gt;The construction and maintenance process of the UMLS (Unified Medical Language System) Metathesaurus is time-consuming, costly, and error-prone as it relies on (1) the lexical and semantic processing for suggesting synonymous terms, and (2) the expertise of UMLS editors for curating the suggestions. For improving the UMLS Metathesaurus construction process, our research group has defined a new task called UVA (UMLS Vocabulary Alignment) and generated a dataset for evaluating … Cites: ‪Ontology matching: A machine learning approach‬&lt;/p&gt;</content><author><name>V Nguyen, O Bodenreider - arXiv preprint arXiv:2205.10575, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The construction and maintenance process of the UMLS (Unified Medical Language System) Metathesaurus is time-consuming, costly, and error-prone as it relies on (1) the lexical and semantic processing for suggesting synonymous terms, and (2) the expertise of UMLS editors for curating the suggestions. For improving the UMLS Metathesaurus construction process, our research group has defined a new task called UVA (UMLS Vocabulary Alignment) and generated a dataset for evaluating … Cites: ‪Ontology matching: A machine learning approach‬</summary></entry><entry><title type="html">Detecting fake news using Natural Language Processing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/12acf0aa1660ef5ff5a52fbf09d3cedf.html" rel="alternate" type="text/html" title="Detecting fake news using Natural Language Processing" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/12acf0aa1660ef5ff5a52fbf09d3cedf</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/12acf0aa1660ef5ff5a52fbf09d3cedf.html">&lt;p&gt;The enormous dissemination of data and information enabled by the Internet has brought great freedom of expression and information to almost the entire world population. However, at the same time the spread of information also brings with it the spread of false information, known in the field as  Fake news  or  misinformation . This phenomenon has led the scientific community to become interested in and develop solutions that can curb the problem: a fundamental building block is Natural … Cites: ‪Database reasoning over text‬&lt;/p&gt;</content><author><name>G ALFARANO</name></author><category term="jekyll" /><category term="update" /><summary type="html">The enormous dissemination of data and information enabled by the Internet has brought great freedom of expression and information to almost the entire world population. However, at the same time the spread of information also brings with it the spread of false information, known in the field as Fake news or misinformation . This phenomenon has led the scientific community to become interested in and develop solutions that can curb the problem: a fundamental building block is Natural … Cites: ‪Database reasoning over text‬</summary></entry><entry><title type="html">Learning and Evaluating the Geometric Structure of Representation Spaces</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/15f15c5dc5702d6fddee8dbca082e08b.html" rel="alternate" type="text/html" title="Learning and Evaluating the Geometric Structure of Representation Spaces" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/15f15c5dc5702d6fddee8dbca082e08b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/15f15c5dc5702d6fddee8dbca082e08b.html">&lt;p&gt;Efficient representations of observed input data have been shown to significantly accelerate the performance of subsequent learning tasks in numerous domains. To obtain such representations automatically, we need to design both i) models that identify useful patterns in the input data and encode them into structured low dimensional representations, and ii) evaluation measures that accurately assess the quality of the resulting representations. In this thesis, we present work that addresses … Cites: ‪Spherical latent spaces for stable variational autoencoders‬&lt;/p&gt;</content><author><name>P Poklukar - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Efficient representations of observed input data have been shown to significantly accelerate the performance of subsequent learning tasks in numerous domains. To obtain such representations automatically, we need to design both i) models that identify useful patterns in the input data and encode them into structured low dimensional representations, and ii) evaluation measures that accurately assess the quality of the resulting representations. In this thesis, we present work that addresses … Cites: ‪Spherical latent spaces for stable variational autoencoders‬</summary></entry><entry><title type="html">On the Paradox of Learning to Reason from Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/1755b05679ec265397489d3abdc91183.html" rel="alternate" type="text/html" title="On the Paradox of Learning to Reason from Data" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/1755b05679ec265397489d3abdc91183</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/1755b05679ec265397489d3abdc91183.html">&lt;p&gt;Logical reasoning is needed in a wide range of NLP tasks. Can a BERT model be trained end-to-end to solve logical reasoning problems presented in natural language? We attempt to answer this question in a confined problem space where there exists a set of parameters that perfectly simulates logical reasoning. We make observations that seem to contradict each other: BERT attains near-perfect accuracy on in-distribution test examples while failing to generalize to other data distributions … Cites: ‪Back to Square One: Artifact Detection, Training and …‬&lt;/p&gt;</content><author><name>H Zhang, LH Li, T Meng, KW Chang, GV Broeck - arXiv preprint arXiv:2205.11502, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Logical reasoning is needed in a wide range of NLP tasks. Can a BERT model be trained end-to-end to solve logical reasoning problems presented in natural language? We attempt to answer this question in a confined problem space where there exists a set of parameters that perfectly simulates logical reasoning. We make observations that seem to contradict each other: BERT attains near-perfect accuracy on in-distribution test examples while failing to generalize to other data distributions … Cites: ‪Back to Square One: Artifact Detection, Training and …‬</summary></entry><entry><title type="html">Pre-training Data Quality and Quantity for a Low-Resource Language: New Corpus and BERT Models for Maltese</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/1a33820b92fdbb12e68aab4feb0e2f05.html" rel="alternate" type="text/html" title="Pre-training Data Quality and Quantity for a Low-Resource Language: New Corpus and BERT Models for Maltese" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/1a33820b92fdbb12e68aab4feb0e2f05</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/1a33820b92fdbb12e68aab4feb0e2f05.html">&lt;p&gt;Multilingual language models such as mBERT have seen impressive cross-lingual transfer to a variety of languages, but many languages remain excluded from these models. In this paper, we analyse the effect of pre-training with monolingual data for a low-resource language that is not included in mBERT–Maltese–with a range of pre-training set ups. We conduct evaluations with the newly pre-trained models on three morphosyntactic tasks–dependency parsing, part-of-speech tagging, and named … Cites: ‪Specializing Multilingual Language Models: An Empirical Study‬&lt;/p&gt;</content><author><name>K Micallef, A Gatt, M Tanti, L van der Plas, C Borg - arXiv preprint arXiv:2205.10517, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Multilingual language models such as mBERT have seen impressive cross-lingual transfer to a variety of languages, but many languages remain excluded from these models. In this paper, we analyse the effect of pre-training with monolingual data for a low-resource language that is not included in mBERT–Maltese–with a range of pre-training set ups. We conduct evaluations with the newly pre-trained models on three morphosyntactic tasks–dependency parsing, part-of-speech tagging, and named … Cites: ‪Specializing Multilingual Language Models: An Empirical Study‬</summary></entry><entry><title type="html">Deep Learning Methods for Semantic Parsing and Question Answering over Knowledge Graphs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/1eac8a901c9efc13949d09f73a57a1bc.html" rel="alternate" type="text/html" title="Deep Learning Methods for Semantic Parsing and Question Answering over Knowledge Graphs" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/1eac8a901c9efc13949d09f73a57a1bc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/1eac8a901c9efc13949d09f73a57a1bc.html">&lt;p&gt;Recently, the advances in deep learning have lead to a surge in research on semantic parsing and question answering over knowledge graphs (KGQA). Significant improvements in these fields and in natural language processing (NLP) in general have been achieved thanks to the use and better understanding of training neural-networks-based models. Particularly important in training any model for any task is their generalization ability. While the generalization ability of machine … Cites: ‪TaBERT: Pretraining for Joint Understanding of Textual and …‬&lt;/p&gt;</content><author><name>D Lukovnikov - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recently, the advances in deep learning have lead to a surge in research on semantic parsing and question answering over knowledge graphs (KGQA). Significant improvements in these fields and in natural language processing (NLP) in general have been achieved thanks to the use and better understanding of training neural-networks-based models. Particularly important in training any model for any task is their generalization ability. While the generalization ability of machine … Cites: ‪TaBERT: Pretraining for Joint Understanding of Textual and …‬</summary></entry><entry><title type="html">Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/219d7e1c396527f2361ff1ffded75894.html" rel="alternate" type="text/html" title="Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/219d7e1c396527f2361ff1ffded75894</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/219d7e1c396527f2361ff1ffded75894.html">&lt;p&gt;Prompt Tuning (PT) has been largely successful as a parameter-efficient way of conditioning large-scale pre-trained language models towards a downstream task. More recently, soft prompt tuning has aimed to learn a fixed set of task-specific continuous vectors, ie, soft tokens that remain static across the task samples. However, a fixed prompt may not generalize well to the diverse kinds of inputs the task comprises. With this motivation, we propose a novel way of prompting, Vector … Cites: ‪BERTese: Learning to Speak to BERT‬&lt;/p&gt;</content><author><name>R Bhardwaj, A Saha, SCH Hoi - arXiv preprint arXiv:2205.11024, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Prompt Tuning (PT) has been largely successful as a parameter-efficient way of conditioning large-scale pre-trained language models towards a downstream task. More recently, soft prompt tuning has aimed to learn a fixed set of task-specific continuous vectors, ie, soft tokens that remain static across the task samples. However, a fixed prompt may not generalize well to the diverse kinds of inputs the task comprises. With this motivation, we propose a novel way of prompting, Vector … Cites: ‪BERTese: Learning to Speak to BERT‬</summary></entry><entry><title type="html">Prompt-and-Rerank: A Method for Zero-Shot and Few-Shot Arbitrary Textual Style Transfer with Small Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/2262fce0ad060364b754d43f702b4287.html" rel="alternate" type="text/html" title="Prompt-and-Rerank: A Method for Zero-Shot and Few-Shot Arbitrary Textual Style Transfer with Small Language Models" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/2262fce0ad060364b754d43f702b4287</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/2262fce0ad060364b754d43f702b4287.html">&lt;p&gt;We propose a method for arbitrary textual style transfer (TST)–the task of transforming a text into any given style–utilizing general-purpose pre-trained language models. Our method, Prompt-and-Rerank, is based on a mathematical formulation of the TST task, decomposing it into three constituent components: textual similarity, target style strength, and fluency. Specifically, our method first uses zero-shot or few-shot prompting to obtain a set of candidate generations in the target … Cites: ‪Reformulating Unsupervised Style Transfer as Paraphrase …‬&lt;/p&gt;</content><author><name>M Suzgun, L Melas-Kyriazi, D Jurafsky - arXiv preprint arXiv:2205.11503, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose a method for arbitrary textual style transfer (TST)–the task of transforming a text into any given style–utilizing general-purpose pre-trained language models. Our method, Prompt-and-Rerank, is based on a mathematical formulation of the TST task, decomposing it into three constituent components: textual similarity, target style strength, and fluency. Specifically, our method first uses zero-shot or few-shot prompting to obtain a set of candidate generations in the target … Cites: ‪Reformulating Unsupervised Style Transfer as Paraphrase …‬</summary></entry><entry><title type="html">How do different types and landscape attributes of urban parks affect visitors positive emotions?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/271543d75a2b7a3550e92e1788a4c6f9.html" rel="alternate" type="text/html" title="How do different types and landscape attributes of urban parks affect visitors positive emotions?" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/271543d75a2b7a3550e92e1788a4c6f9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/271543d75a2b7a3550e92e1788a4c6f9.html">&lt;p&gt;Improving the positive emotions of urban populations is essential for meeting the United Nations Sustainable Development Goals (SDGs) of “good health and well-being” and “sustainable cities and communities”. Urban parks generally may enhance people s positive sentiments, but little is known about explicitly linking the landscape composition and configuration of urban parks directly with visitors  sentiments based on social media data. The main objective of this study, therefore … Cites: ‪Twitter sentiment in New York City parks as measure of well-being‬&lt;/p&gt;</content><author><name>L Kong, Z Liu, X Pan, Y Wang, X Guo, J Wu - Landscape and Urban Planning, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Improving the positive emotions of urban populations is essential for meeting the United Nations Sustainable Development Goals (SDGs) of “good health and well-being” and “sustainable cities and communities”. Urban parks generally may enhance people s positive sentiments, but little is known about explicitly linking the landscape composition and configuration of urban parks directly with visitors sentiments based on social media data. The main objective of this study, therefore … Cites: ‪Twitter sentiment in New York City parks as measure of well-being‬</summary></entry><entry><title type="html">Learning to Ignore Adversarial Attacks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/273f531e1ebd4f305887332c285ef971.html" rel="alternate" type="text/html" title="Learning to Ignore Adversarial Attacks" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/273f531e1ebd4f305887332c285ef971</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/273f531e1ebd4f305887332c285ef971.html">&lt;p&gt;Despite the strong performance of current NLP models, they can be brittle against adversarial attacks. To enable effective learning against adversarial inputs, we introduce the use of rationale models that can explicitly learn to ignore attack tokens. We find that the rationale models can successfully ignore over 90\% of attack tokens. This approach leads to consistent sizable improvements ($\sim $10\%) over baseline models in robustness on three datasets for both BERT and RoBERTa, and also … Cites: ‪When Can Models Learn From Explanations? A Formal …‬&lt;/p&gt;</content><author><name>Y Zhang, Y Zhou, S Carton, C Tan - arXiv preprint arXiv:2205.11551, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Despite the strong performance of current NLP models, they can be brittle against adversarial attacks. To enable effective learning against adversarial inputs, we introduce the use of rationale models that can explicitly learn to ignore attack tokens. We find that the rationale models can successfully ignore over 90\% of attack tokens. This approach leads to consistent sizable improvements ($\sim $10\%) over baseline models in robustness on three datasets for both BERT and RoBERTa, and also … Cites: ‪When Can Models Learn From Explanations? A Formal …‬</summary></entry><entry><title type="html">Collaborative Adversarial Training</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/28b9a832e4a35789feb370315e0e37bb.html" rel="alternate" type="text/html" title="Collaborative Adversarial Training" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/28b9a832e4a35789feb370315e0e37bb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/28b9a832e4a35789feb370315e0e37bb.html">&lt;p&gt;The vulnerability of deep neural networks (DNNs) to adversarial examples has attracted great attention in the machine learning community. The problem is related to local non-smoothness and steepness of normally obtained loss landscapes. Training augmented with adversarial examples (aka, adversarial training) is considered as an effective remedy. In this paper, we highlight that some collaborative examples, nearly perceptually indistinguishable from both adversarial and benign … Cites: ‪Unlabeled data improves adversarial robustness‬&lt;/p&gt;</content><author><name>Q Li, Y Guo, W Zuo, H Chen - arXiv preprint arXiv:2205.11156, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The vulnerability of deep neural networks (DNNs) to adversarial examples has attracted great attention in the machine learning community. The problem is related to local non-smoothness and steepness of normally obtained loss landscapes. Training augmented with adversarial examples (aka, adversarial training) is considered as an effective remedy. In this paper, we highlight that some collaborative examples, nearly perceptually indistinguishable from both adversarial and benign … Cites: ‪Unlabeled data improves adversarial robustness‬</summary></entry><entry><title type="html">Tracing Knowledge in Language Models Back to the Training Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/294bbf1b076e6d1677e25b6c0754d01f.html" rel="alternate" type="text/html" title="Tracing Knowledge in Language Models Back to the Training Data" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/294bbf1b076e6d1677e25b6c0754d01f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/294bbf1b076e6d1677e25b6c0754d01f.html">&lt;p&gt;Neural language models (LMs) have been shown to memorize a great deal of factual knowledge. But when an LM generates an assertion, it is often difficult to determine where it learned this information and whether it is true. In this paper, we introduce a new benchmark for fact tracing: tracing language models  assertions back to the training examples that provided evidence for those predictions. Prior work has suggested that dataset-level\emph {influence methods} might offer an effective … Cites: ‪Explaining and improving model behavior with k nearest neighbor …‬&lt;/p&gt;</content><author><name>E Akyürek, T Bolukbasi, F Liu, B Xiong, I Tenney… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Neural language models (LMs) have been shown to memorize a great deal of factual knowledge. But when an LM generates an assertion, it is often difficult to determine where it learned this information and whether it is true. In this paper, we introduce a new benchmark for fact tracing: tracing language models assertions back to the training examples that provided evidence for those predictions. Prior work has suggested that dataset-level\emph {influence methods} might offer an effective … Cites: ‪Explaining and improving model behavior with k nearest neighbor …‬</summary></entry><entry><title type="html">Community Question Answering Entity Linking via Leveraging Auxiliary Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/295e91e694e578eb7ffce7605e54e05d.html" rel="alternate" type="text/html" title="Community Question Answering Entity Linking via Leveraging Auxiliary Data" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/295e91e694e578eb7ffce7605e54e05d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/295e91e694e578eb7ffce7605e54e05d.html">&lt;p&gt;Community Question Answering (CQA) platforms contain plenty of CQA texts (ie, questions and answers corresponding to the question) where named entities appear ubiquitously. In this paper, we define a new task of CQA entity linking (CQAEL) as linking the textual entity mentions detected from CQA texts with their corresponding entities in a knowledge base. This task can facilitate many downstream applications including expert finding and knowledge base enrichment. Traditional entity linking … Cites: ‪Zero-Shot Entity Linking by Reading Entity Descriptions‬&lt;/p&gt;</content><author><name>Y Li, W Shen, J Gao, Y Wang - arXiv preprint arXiv:2205.11917, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Community Question Answering (CQA) platforms contain plenty of CQA texts (ie, questions and answers corresponding to the question) where named entities appear ubiquitously. In this paper, we define a new task of CQA entity linking (CQAEL) as linking the textual entity mentions detected from CQA texts with their corresponding entities in a knowledge base. This task can facilitate many downstream applications including expert finding and knowledge base enrichment. Traditional entity linking … Cites: ‪Zero-Shot Entity Linking by Reading Entity Descriptions‬</summary></entry><entry><title type="html">Robust Task-Oriented Dialogue Generation with Contrastive Pre-training and Adversarial Filtering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/314ce50417fa14e2189a6fbaae245801.html" rel="alternate" type="text/html" title="Robust Task-Oriented Dialogue Generation with Contrastive Pre-training and Adversarial Filtering" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/314ce50417fa14e2189a6fbaae245801</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/314ce50417fa14e2189a6fbaae245801.html">&lt;p&gt;Data artifacts incentivize machine learning models to learn non-transferable generalizations by taking advantage of shortcuts in the data, and there is growing evidence that data artifacts play a role for the strong results that deep learning models achieve in recent natural language processing benchmarks. In this paper, we focus on task-oriented dialogue and investigate whether popular datasets such as MultiWOZ contain such data artifacts. We found that by only keeping frequent … Cites: ‪Are we modeling the task or the annotator? an investigation of …‬&lt;/p&gt;</content><author><name>S Yang, X Huang, JH Lau, S Erfani - arXiv preprint arXiv:2205.10363, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Data artifacts incentivize machine learning models to learn non-transferable generalizations by taking advantage of shortcuts in the data, and there is growing evidence that data artifacts play a role for the strong results that deep learning models achieve in recent natural language processing benchmarks. In this paper, we focus on task-oriented dialogue and investigate whether popular datasets such as MultiWOZ contain such data artifacts. We found that by only keeping frequent … Cites: ‪Are we modeling the task or the annotator? an investigation of …‬</summary></entry><entry><title type="html">HyperLogLogLog: Cardinality Estimation With One Log More</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/327a2462e4df317327ad0ab07ab21ea3.html" rel="alternate" type="text/html" title="HyperLogLogLog: Cardinality Estimation With One Log More" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/327a2462e4df317327ad0ab07ab21ea3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/327a2462e4df317327ad0ab07ab21ea3.html">&lt;p&gt;We present HyperLogLogLog, a practical compression of the HyperLogLog sketch that compresses the sketch from $ O (m\log\log n) $ bits down to $ m\log_2\log_2\log_2 m+ O (m+\log\log n) $ bits for estimating the number of distinct elements~ $ n $ using $ m $~ registers. The algorithm works as a drop-in replacement that preserves all estimation properties of the HyperLogLog sketch, it is possible to convert back and forth between the compressed and uncompressed … Cites: ‪Goods: Organizing google s datasets‬&lt;/p&gt;</content><author><name>M Karppa, R Pagh - arXiv preprint arXiv:2205.11327, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present HyperLogLogLog, a practical compression of the HyperLogLog sketch that compresses the sketch from $ O (m\log\log n) $ bits down to $ m\log_2\log_2\log_2 m+ O (m+\log\log n) $ bits for estimating the number of distinct elements~ $ n $ using $ m $~ registers. The algorithm works as a drop-in replacement that preserves all estimation properties of the HyperLogLog sketch, it is possible to convert back and forth between the compressed and uncompressed … Cites: ‪Goods: Organizing google s datasets‬</summary></entry><entry><title type="html">SQuALITY: Building a Long-Document Summarization Dataset the Hard Way</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/334d42d494b9d9db7ffa54256d5556cc.html" rel="alternate" type="text/html" title="SQuALITY: Building a Long-Document Summarization Dataset the Hard Way" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/334d42d494b9d9db7ffa54256d5556cc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/334d42d494b9d9db7ffa54256d5556cc.html">&lt;p&gt;Summarization datasets are often assembled either by scraping naturally occurring public-domain summaries–which are nearly always in difficult-to-work-with technical domains–or by using approximate heuristics to extract them from everyday text–which frequently yields unfaithful summaries. In this work, we turn to a slower but more straightforward approach to developing summarization benchmark data: We hire highly-qualified contractors to read stories and write original summaries from … Cites: ‪Neural text summarization: A critical evaluation‬&lt;/p&gt;</content><author><name>A Wang, RY Pang, A Chen, J Phang, SR Bowman - arXiv preprint arXiv:2205.11465, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Summarization datasets are often assembled either by scraping naturally occurring public-domain summaries–which are nearly always in difficult-to-work-with technical domains–or by using approximate heuristics to extract them from everyday text–which frequently yields unfaithful summaries. In this work, we turn to a slower but more straightforward approach to developing summarization benchmark data: We hire highly-qualified contractors to read stories and write original summaries from … Cites: ‪Neural text summarization: A critical evaluation‬</summary></entry><entry><title type="html">rgpdOS: GDPR Enforcement By The Operating System</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/34a6f440ccfce1933edb43d52775fec9.html" rel="alternate" type="text/html" title="rgpdOS: GDPR Enforcement By The Operating System" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/34a6f440ccfce1933edb43d52775fec9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/34a6f440ccfce1933edb43d52775fec9.html">&lt;p&gt;The General Data Protection Regulation (GDPR) forces IT companies to comply with a number of principles when dealing with European citizens  personal data. Non-compliant companies are exposed to penalties which may represent up to 4% of their turnover. Currently, it is very hard for companies driven by personal data to make their applications GDPR-compliant, especially if those applications were developed before the GDPR was established. We present rgpdOS, a GDPR-aware operating … Cites: ‪Dbos: A proposal for a data-centric operating system‬&lt;/p&gt;</content><author><name>A Tchana, R Colin, V Berger, B Combemale, N Crooks… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The General Data Protection Regulation (GDPR) forces IT companies to comply with a number of principles when dealing with European citizens personal data. Non-compliant companies are exposed to penalties which may represent up to 4% of their turnover. Currently, it is very hard for companies driven by personal data to make their applications GDPR-compliant, especially if those applications were developed before the GDPR was established. We present rgpdOS, a GDPR-aware operating … Cites: ‪Dbos: A proposal for a data-centric operating system‬</summary></entry><entry><title type="html">Markedness in Visual Semantic AI</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/39322d349d6171c59ad2c527dfaa9860.html" rel="alternate" type="text/html" title="Markedness in Visual Semantic AI" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/39322d349d6171c59ad2c527dfaa9860</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/39322d349d6171c59ad2c527dfaa9860.html">&lt;p&gt;We evaluate the state-of-the-art multimodal  visual semantic  model CLIP (  Contrastive Language Image Pretraining ) for biases related to the marking of age, gender, and race or ethnicity. Given the option to label an image as  a photo of a person  or to select a label denoting race or ethnicity, CLIP chooses the  person  label 47.9% of the time for White individuals, compared with 5.0% or less for individuals who are Black, East Asian, Southeast Asian, Indian, or Latino or Hispanic … Cites: ‪Contrastive learning of medical visual representations from paired …‬&lt;/p&gt;</content><author><name>R Wolfe, A Caliskan - arXiv preprint arXiv:2205.11378, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We evaluate the state-of-the-art multimodal visual semantic model CLIP ( Contrastive Language Image Pretraining ) for biases related to the marking of age, gender, and race or ethnicity. Given the option to label an image as a photo of a person or to select a label denoting race or ethnicity, CLIP chooses the person label 47.9% of the time for White individuals, compared with 5.0% or less for individuals who are Black, East Asian, Southeast Asian, Indian, or Latino or Hispanic … Cites: ‪Contrastive learning of medical visual representations from paired …‬</summary></entry><entry><title type="html">BanglaNLG: Benchmarks and Resources for Evaluating Low-Resource Natural Language Generation in Bangla</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3944b15fbb428989ca235595fd736dcc.html" rel="alternate" type="text/html" title="BanglaNLG: Benchmarks and Resources for Evaluating Low-Resource Natural Language Generation in Bangla" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3944b15fbb428989ca235595fd736dcc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3944b15fbb428989ca235595fd736dcc.html">&lt;p&gt;This work presents BanglaNLG, a comprehensive benchmark for evaluating natural language generation (NLG) models in Bangla, a widely spoken yet low-resource language in the web domain. We aggregate three challenging conditional text generation tasks under the BanglaNLG benchmark. Then, using a clean corpus of 27.5 GB of Bangla data, we pretrain BanglaT5, a sequence-to-sequence Transformer model for Bangla. BanglaT5 achieves state-of-the-art performance in all of these … Cites: ‪Coqa: A conversational question answering challenge‬&lt;/p&gt;</content><author><name>A Bhattacharjee, T Hasan, WU Ahmad, R Shahriyar - arXiv preprint arXiv:2205.11081, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This work presents BanglaNLG, a comprehensive benchmark for evaluating natural language generation (NLG) models in Bangla, a widely spoken yet low-resource language in the web domain. We aggregate three challenging conditional text generation tasks under the BanglaNLG benchmark. Then, using a clean corpus of 27.5 GB of Bangla data, we pretrain BanglaT5, a sequence-to-sequence Transformer model for Bangla. BanglaT5 achieves state-of-the-art performance in all of these … Cites: ‪Coqa: A conversational question answering challenge‬</summary></entry><entry><title type="html">Local Byte Fusion for Neural Machine Translation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3ac02ff33ec4778fc01819b9f0558acc.html" rel="alternate" type="text/html" title="Local Byte Fusion for Neural Machine Translation" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3ac02ff33ec4778fc01819b9f0558acc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3ac02ff33ec4778fc01819b9f0558acc.html">&lt;p&gt;Subword tokenization schemes are the dominant technique used in current NLP models. However, such schemes can be rigid and tokenizers built on one corpus do not adapt well to other parallel corpora. It has also been observed that in multilingual corpora, subword tokenization schemes over-segment low-resource languages leading to a drop in translation performance. A simple alternative to subword tokenizers is byte-based methods ie tokenization into byte sequences using … Cites: ‪Byte Pair Encoding is Suboptimal for Language Model Pretraining‬&lt;/p&gt;</content><author><name>MN Sreedhar, X Wan, Y Cheng, J Hu - arXiv preprint arXiv:2205.11490, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Subword tokenization schemes are the dominant technique used in current NLP models. However, such schemes can be rigid and tokenizers built on one corpus do not adapt well to other parallel corpora. It has also been observed that in multilingual corpora, subword tokenization schemes over-segment low-resource languages leading to a drop in translation performance. A simple alternative to subword tokenizers is byte-based methods ie tokenization into byte sequences using … Cites: ‪Byte Pair Encoding is Suboptimal for Language Model Pretraining‬</summary></entry><entry><title type="html">Challenges in Information-Mining the Materials Literature: A Case Study and Perspective</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3b01ffce88f913f092fce0014bdaf7bb.html" rel="alternate" type="text/html" title="Challenges in Information-Mining the Materials Literature: A Case Study and Perspective" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3b01ffce88f913f092fce0014bdaf7bb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3b01ffce88f913f092fce0014bdaf7bb.html">&lt;p&gt;The rapid development and application of machine learning (ML) techniques in materials science have led to new tools for machine-enabled and autonomous/high-throughput materials design and discovery. Alongside, efforts to extract data from traditional experiments in the published literature with natural language processing (NLP) algorithms provide opportunities to develop tremendous data troves for these in silico design and discovery endeavors. While NLP is used in all aspects of society … Cites: ‪BERT: Pre-training of deep bidirectional transformers for language …‬&lt;/p&gt;</content><author><name>A Smith, V Bhat, Q Ai, C Risko - Chemistry of Materials, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The rapid development and application of machine learning (ML) techniques in materials science have led to new tools for machine-enabled and autonomous/high-throughput materials design and discovery. Alongside, efforts to extract data from traditional experiments in the published literature with natural language processing (NLP) algorithms provide opportunities to develop tremendous data troves for these in silico design and discovery endeavors. While NLP is used in all aspects of society … Cites: ‪BERT: Pre-training of deep bidirectional transformers for language …‬</summary></entry><entry><title type="html">Heterformer: A Transformer Architecture for Node Representation Learning on Heterogeneous Text-Rich Networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3b674bff92176ff15ec89770e6a22ef3.html" rel="alternate" type="text/html" title="Heterformer: A Transformer Architecture for Node Representation Learning on Heterogeneous Text-Rich Networks" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3b674bff92176ff15ec89770e6a22ef3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3b674bff92176ff15ec89770e6a22ef3.html">&lt;p&gt;We study node representation learning on heterogeneous text-rich networks, where nodes and edges are multi-typed and some types of nodes are associated with text information. Although recent studies on graph neural networks (GNNs) and pretrained language models (PLMs) have demonstrated their power in encoding network and text signals, respectively, less focus has been given to delicately coupling these two types of models on heterogeneous text-rich networks … Cites: ‪Fine-grained fact verification with kernel graph attention network‬&lt;/p&gt;</content><author><name>B Jin, Y Zhang, Q Zhu, J Han - arXiv preprint arXiv:2205.10282, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We study node representation learning on heterogeneous text-rich networks, where nodes and edges are multi-typed and some types of nodes are associated with text information. Although recent studies on graph neural networks (GNNs) and pretrained language models (PLMs) have demonstrated their power in encoding network and text signals, respectively, less focus has been given to delicately coupling these two types of models on heterogeneous text-rich networks … Cites: ‪Fine-grained fact verification with kernel graph attention network‬</summary></entry><entry><title type="html">Machine Learning for Combinatorial Optimisation of Partially-Specified Problems: Regret Minimisation as a Unifying Lens</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3c52c92cd1edc9e7632c955a899b4a29.html" rel="alternate" type="text/html" title="Machine Learning for Combinatorial Optimisation of Partially-Specified Problems: Regret Minimisation as a Unifying Lens" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3c52c92cd1edc9e7632c955a899b4a29</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3c52c92cd1edc9e7632c955a899b4a29.html">&lt;p&gt;It is increasingly common to solve combinatorial optimisation problems that are partially-specified. We survey the case where the objective function or the relations between variables are not known or are only partially specified. The challenge is to learn them from available data, while taking into account a set of hard constraints that a solution must satisfy, and that solving the optimisation problem (esp. during learning) is computationally very demanding. This paper overviews four seemingly … Cites: ‪Learning and inference for structured prediction: A unifying …‬&lt;/p&gt;</content><author><name>S Teso, L Bliek, A Borghesi, M Lombardi… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">It is increasingly common to solve combinatorial optimisation problems that are partially-specified. We survey the case where the objective function or the relations between variables are not known or are only partially specified. The challenge is to learn them from available data, while taking into account a set of hard constraints that a solution must satisfy, and that solving the optimisation problem (esp. during learning) is computationally very demanding. This paper overviews four seemingly … Cites: ‪Learning and inference for structured prediction: A unifying …‬</summary></entry><entry><title type="html">A Survey of Trustworthy Graph Learning: Reliability, Explainability, and Privacy Protection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3e203b1b1c73daf8654029ec93af0a37.html" rel="alternate" type="text/html" title="A Survey of Trustworthy Graph Learning: Reliability, Explainability, and Privacy Protection" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3e203b1b1c73daf8654029ec93af0a37</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/3e203b1b1c73daf8654029ec93af0a37.html">&lt;p&gt;Deep graph learning has achieved remarkable progresses in both business and scientific areas ranging from finance and e-commerce, to drug and advanced material discovery. Despite these progresses, how to ensure various deep graph learning algorithms behave in a socially responsible manner and meet regulatory compliance requirements becomes an emerging problem, especially in risk-sensitive domains. Trustworthy graph learning (TwGL) aims to solve the above problems from … Cites: ‪Adaptive recursive neural network for target-dependent twitter …‬&lt;/p&gt;</content><author><name>B Wu, J Li, J Yu, Y Bian, H Zhang, CH Chen, C Hou… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep graph learning has achieved remarkable progresses in both business and scientific areas ranging from finance and e-commerce, to drug and advanced material discovery. Despite these progresses, how to ensure various deep graph learning algorithms behave in a socially responsible manner and meet regulatory compliance requirements becomes an emerging problem, especially in risk-sensitive domains. Trustworthy graph learning (TwGL) aims to solve the above problems from … Cites: ‪Adaptive recursive neural network for target-dependent twitter …‬</summary></entry><entry><title type="html">A Fine-grained Interpretability Evaluation Benchmark for Neural NLP</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/40ec872c672e251c4b2607828e18189c.html" rel="alternate" type="text/html" title="A Fine-grained Interpretability Evaluation Benchmark for Neural NLP" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/40ec872c672e251c4b2607828e18189c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/40ec872c672e251c4b2607828e18189c.html">&lt;p&gt;While there is increasing concern about the interpretability of neural models, the evaluation of interpretability remains an open problem, due to the lack of proper evaluation datasets and metrics. In this paper, we present a novel benchmark to evaluate the interpretability of both neural models and saliency methods. This benchmark covers three representative NLP tasks: sentiment analysis, textual similarity and reading comprehension, each provided with both English and Chinese … Cites: ‪Fact or fiction: Verifying scientific claims‬&lt;/p&gt;</content><author><name>L Wang, Y Shen, S Peng, S Zhang, X Xiao, H Liu… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">While there is increasing concern about the interpretability of neural models, the evaluation of interpretability remains an open problem, due to the lack of proper evaluation datasets and metrics. In this paper, we present a novel benchmark to evaluate the interpretability of both neural models and saliency methods. This benchmark covers three representative NLP tasks: sentiment analysis, textual similarity and reading comprehension, each provided with both English and Chinese … Cites: ‪Fact or fiction: Verifying scientific claims‬</summary></entry><entry><title type="html">On the Trade-off between Redundancy and Local Coherence in Summarization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/45a22829d59a8f5cc9bfc5259f24bed1.html" rel="alternate" type="text/html" title="On the Trade-off between Redundancy and Local Coherence in Summarization" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/45a22829d59a8f5cc9bfc5259f24bed1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/45a22829d59a8f5cc9bfc5259f24bed1.html">&lt;p&gt;Extractive summarization systems are known to produce poorly coherent and, if not accounted for, highly redundant text. In this work, we tackle the problem of summary redundancy in unsupervised extractive summarization of long, highly-redundant documents. For this, we leverage a psycholinguistic theory of human reading comprehension which directly models local coherence and redundancy. Implementing this theory, our system operates at the proposition level and exploits … Cites: ‪Aspect-controllable opinion summarization‬&lt;/p&gt;</content><author><name>R Cardenas, M Galle, SB Cohen - arXiv preprint arXiv:2205.10192, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Extractive summarization systems are known to produce poorly coherent and, if not accounted for, highly redundant text. In this work, we tackle the problem of summary redundancy in unsupervised extractive summarization of long, highly-redundant documents. For this, we leverage a psycholinguistic theory of human reading comprehension which directly models local coherence and redundancy. Implementing this theory, our system operates at the proposition level and exploits … Cites: ‪Aspect-controllable opinion summarization‬</summary></entry><entry><title type="html">Robust Text Perturbation using Sequence-to-Sequence Pre-Training</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/46f085c5fc53f6097672b08ebcabeb72.html" rel="alternate" type="text/html" title="Robust Text Perturbation using Sequence-to-Sequence Pre-Training" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/46f085c5fc53f6097672b08ebcabeb72</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/46f085c5fc53f6097672b08ebcabeb72.html">&lt;p&gt;Large Transformer-based models have shown great performance in sequence-tosequence tasks such as machine translation, text summarization etc. While these models perform well on the original task they have been trained on, it is hard to use them for a new but related task. We propose CASPer, a framework to perturb the input-output behavior of the original pre-trained sequence-to-sequence model. CASPer learns a perturbation parameter at test time to modify the behavior of pre … Cites: ‪Polyjuice: Automated, general-purpose counterfactual generation‬&lt;/p&gt;</content><author><name>N Madaan, D Saha, S Bedathur</name></author><category term="jekyll" /><category term="update" /><summary type="html">Large Transformer-based models have shown great performance in sequence-tosequence tasks such as machine translation, text summarization etc. While these models perform well on the original task they have been trained on, it is hard to use them for a new but related task. We propose CASPer, a framework to perturb the input-output behavior of the original pre-trained sequence-to-sequence model. CASPer learns a perturbation parameter at test time to modify the behavior of pre … Cites: ‪Polyjuice: Automated, general-purpose counterfactual generation‬</summary></entry><entry><title type="html">Unintended memorisation of unique features in neural networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4a22365515f2897ffc8ebb967e76290e.html" rel="alternate" type="text/html" title="Unintended memorisation of unique features in neural networks" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4a22365515f2897ffc8ebb967e76290e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4a22365515f2897ffc8ebb967e76290e.html">&lt;p&gt;Neural networks pose a privacy risk due to their propensity to memorise and leak training data. We show that unique features occurring only once in training data are memorised by discriminative multi-layer perceptrons and convolutional neural networks trained on benchmark imaging datasets. We design our method for settings where sensitive training data is not available, for example medical imaging. Our setting knows the unique feature, but not the training data, model weights or the … Cites: ‪Just train twice: Improving group robustness without training group …‬&lt;/p&gt;</content><author><name>J Hartley, SA Tsaftaris - arXiv preprint arXiv:2205.10079, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Neural networks pose a privacy risk due to their propensity to memorise and leak training data. We show that unique features occurring only once in training data are memorised by discriminative multi-layer perceptrons and convolutional neural networks trained on benchmark imaging datasets. We design our method for settings where sensitive training data is not available, for example medical imaging. Our setting knows the unique feature, but not the training data, model weights or the … Cites: ‪Just train twice: Improving group robustness without training group …‬</summary></entry><entry><title type="html">Table Retrieval May Not Necessitate Table-specific Model Design</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4cdd93a444519e558b979d96cad9abb5.html" rel="alternate" type="text/html" title="Table Retrieval May Not Necessitate Table-specific Model Design" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4cdd93a444519e558b979d96cad9abb5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4cdd93a444519e558b979d96cad9abb5.html">&lt;p&gt;Tables are an important form of structured data for both human and machine readers alike, providing answers to questions that cannot, or cannot easily, be found in texts. Recent work has designed special models and training paradigms for table-related tasks such as table-based question answering and table retrieval. Though effective, they add complexity in both modeling and data acquisition compared to generic text solutions and obscure which elements are truly beneficial. In this work, we focus on … Cites: ‪UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge …‬&lt;/p&gt;</content><author><name>Z Wang, Z Jiang, E Nyberg, G Neubig - arXiv preprint arXiv:2205.09843, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Tables are an important form of structured data for both human and machine readers alike, providing answers to questions that cannot, or cannot easily, be found in texts. Recent work has designed special models and training paradigms for table-related tasks such as table-based question answering and table retrieval. Though effective, they add complexity in both modeling and data acquisition compared to generic text solutions and obscure which elements are truly beneficial. In this work, we focus on … Cites: ‪UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge …‬</summary></entry><entry><title type="html">SELECTIVELY GENERATING EXPANDED RESPONSES THAT GUIDE CONTINUANCE OF A HUMAN-TO-COMPUTER DIALOG</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4dae0cfe88f733863fa4ec182f62f2bb.html" rel="alternate" type="text/html" title="SELECTIVELY GENERATING EXPANDED RESPONSES THAT GUIDE CONTINUANCE OF A HUMAN-TO-COMPUTER DIALOG" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4dae0cfe88f733863fa4ec182f62f2bb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4dae0cfe88f733863fa4ec182f62f2bb.html">&lt;p&gt;Generating expanded responses that guide continuance of a human-to computer dialog that is facilitated by a client device and that is between at least one user and an automated assistant. The expanded responses are generated by the automated …&lt;/p&gt;</content><author><name>M Fink, V Vuskovic, SO Salant, D Cohen, A Revach… - US Patent App. 17/587,478, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Generating expanded responses that guide continuance of a human-to computer dialog that is facilitated by a client device and that is between at least one user and an automated assistant. The expanded responses are generated by the automated …</summary></entry><entry><title type="html">A Dataset for Sentence Retrieval for Open-Ended Dialogues</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4fb2659e6f6537a503a8270c30730fe9.html" rel="alternate" type="text/html" title="A Dataset for Sentence Retrieval for Open-Ended Dialogues" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4fb2659e6f6537a503a8270c30730fe9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4fb2659e6f6537a503a8270c30730fe9.html">&lt;p&gt;We address the task of sentence retrieval for open-ended dialogues. The goal is to retrieve sentences from a document corpus that contain information useful for generating the next turn in a given dialogue. Prior work on dialogue-based retrieval focused on specific types of dialogues: either conversational QA or conversational search. To address a broader scope of this task where any type of dialogue can be used, we constructed a dataset that includes open-ended dialogues from Reddit … Cites: ‪Dataset and baselines for sequential open-domain question …‬&lt;/p&gt;</content><author><name>I Harel, H Taitelbaum, I Szpektor, O Kurland - arXiv preprint arXiv:2205.11685, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We address the task of sentence retrieval for open-ended dialogues. The goal is to retrieve sentences from a document corpus that contain information useful for generating the next turn in a given dialogue. Prior work on dialogue-based retrieval focused on specific types of dialogues: either conversational QA or conversational search. To address a broader scope of this task where any type of dialogue can be used, we constructed a dataset that includes open-ended dialogues from Reddit … Cites: ‪Dataset and baselines for sequential open-domain question …‬</summary></entry><entry><title type="html">Deep Learning Meets Software Engineering: A Survey on Pre-Trained Models of Source Code</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4fd79195c13b15bfbbf53e2bddd4f010.html" rel="alternate" type="text/html" title="Deep Learning Meets Software Engineering: A Survey on Pre-Trained Models of Source Code" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4fd79195c13b15bfbbf53e2bddd4f010</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/4fd79195c13b15bfbbf53e2bddd4f010.html">&lt;p&gt;Recent years have seen the successful application of deep learning to software engineering (SE). In particular, the development and use of pre-trained models of source code has enabled state-of-the-art results to be achieved on a wide variety of SE tasks. This paper provides an overview of this rapidly advancing field of research and reflects on future research directions. Cites: ‪Dawn Drain‬&lt;/p&gt;</content><author><name>C Niu, C Li, B Luo, V Ng - arXiv preprint arXiv:2205.11739, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent years have seen the successful application of deep learning to software engineering (SE). In particular, the development and use of pre-trained models of source code has enabled state-of-the-art results to be achieved on a wide variety of SE tasks. This paper provides an overview of this rapidly advancing field of research and reflects on future research directions. Cites: ‪Dawn Drain‬</summary></entry><entry><title type="html">Heterogeneous Graph Neural Network for Key Player Identification in Underground Forums</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/52abbdb146cd18e16d9de89d6b027ab2.html" rel="alternate" type="text/html" title="Heterogeneous Graph Neural Network for Key Player Identification in Underground Forums" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/52abbdb146cd18e16d9de89d6b027ab2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/52abbdb146cd18e16d9de89d6b027ab2.html">&lt;p&gt;In recent years, underground forums have played a more significant role in trading illicit crimeware and disseminating crime services. To combat its imperils to our cybersecurity, in this thesis, we develop an intelligent framework to identify the key players on Hack Forums to better monitor and trace the distribution of crimeware on the market. We first introduce a heterogeneous information network to model the intricate ecosystem based on the extracted entity and relations. Then we propose a … Cites: ‪Tools for Automated Analysis of Cybercriminal Markets‬&lt;/p&gt;</content><author><name>Q Peng - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In recent years, underground forums have played a more significant role in trading illicit crimeware and disseminating crime services. To combat its imperils to our cybersecurity, in this thesis, we develop an intelligent framework to identify the key players on Hack Forums to better monitor and trace the distribution of crimeware on the market. We first introduce a heterogeneous information network to model the intricate ecosystem based on the extracted entity and relations. Then we propose a … Cites: ‪Tools for Automated Analysis of Cybercriminal Markets‬</summary></entry><entry><title type="html">Bachelor s Thesis</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/53a18581fe6927d8ec9b263a06791df1.html" rel="alternate" type="text/html" title="Bachelor s Thesis" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/53a18581fe6927d8ec9b263a06791df1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/53a18581fe6927d8ec9b263a06791df1.html">&lt;p&gt;Article retrieval is a topic widely studied in computer science. Many unique approaches have been developed to retrieve articles for a given query. This work describes, implements, evaluates, and compares three different approaches to retrieve related articles on Wikipedia. The keyquery approach incorporates a search engine to find a query that will retrieve a set of documents. The graph approach creates a graph from Wikipedias  structure and finds similar articles based on its … Cites: ‪Deep unordered composition rivals syntactic methods for text …‬&lt;/p&gt;</content><author><name>J Stahlhut, JPDM Potthast, W Kircheis</name></author><category term="jekyll" /><category term="update" /><summary type="html">Article retrieval is a topic widely studied in computer science. Many unique approaches have been developed to retrieve articles for a given query. This work describes, implements, evaluates, and compares three different approaches to retrieve related articles on Wikipedia. The keyquery approach incorporates a search engine to find a query that will retrieve a set of documents. The graph approach creates a graph from Wikipedias structure and finds similar articles based on its … Cites: ‪Deep unordered composition rivals syntactic methods for text …‬</summary></entry><entry><title type="html">Decoder Denoising Pretraining for Semantic Segmentation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/549fcd10023daac9ec3b41cd3f8369ea.html" rel="alternate" type="text/html" title="Decoder Denoising Pretraining for Semantic Segmentation" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/549fcd10023daac9ec3b41cd3f8369ea</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/549fcd10023daac9ec3b41cd3f8369ea.html">&lt;p&gt;Semantic segmentation labels are expensive and time consuming to acquire. Hence, pretraining is commonly used to improve the label-efficiency of segmentation models. Typically, the encoder of a segmentation model is pretrained as a classifier and the decoder is randomly initialized. Here, we argue that random initialization of the decoder can be suboptimal, especially when few labeled examples are available. We propose a decoder pretraining approach based on denoising, which … Cites: ‪Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis …‬&lt;/p&gt;</content><author><name>EB Asiedu, S Kornblith, T Chen, N Parmar, M Minderer… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Semantic segmentation labels are expensive and time consuming to acquire. Hence, pretraining is commonly used to improve the label-efficiency of segmentation models. Typically, the encoder of a segmentation model is pretrained as a classifier and the decoder is randomly initialized. Here, we argue that random initialization of the decoder can be suboptimal, especially when few labeled examples are available. We propose a decoder pretraining approach based on denoising, which … Cites: ‪Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis …‬</summary></entry><entry><title type="html">Constructing Knowledge Graph for Business Environment</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/55381c492ced4572e023602676c9604c.html" rel="alternate" type="text/html" title="Constructing Knowledge Graph for Business Environment" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/55381c492ced4572e023602676c9604c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/55381c492ced4572e023602676c9604c.html">&lt;p&gt;[Objective] This paper builds knowledge graph for business environment to improve the utilization of resources, aiming to discover the internal entity relationship of development factors, and analyze government decision-making.[Methods] We constructed the knowledge graph based on business environment policy of Beijing, and proposed a knowledge extraction method integrating dependency syntax analysis and semantic role annotation. Then, we constructed a combined classifier to … Cites: ‪Web-scale information extraction in knowitall: (preliminary results)‬&lt;/p&gt;</content><author><name>L Kan, X Qinya, Y Lu - Data Analysis and Knowledge Discovery, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">[Objective] This paper builds knowledge graph for business environment to improve the utilization of resources, aiming to discover the internal entity relationship of development factors, and analyze government decision-making.[Methods] We constructed the knowledge graph based on business environment policy of Beijing, and proposed a knowledge extraction method integrating dependency syntax analysis and semantic role annotation. Then, we constructed a combined classifier to … Cites: ‪Web-scale information extraction in knowitall: (preliminary results)‬</summary></entry><entry><title type="html">Attentional Mixtures of Soft Prompt Tuning for Parameter-efficient Multi-task Knowledge Sharing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/590f5924be5646ef5123279db470f745.html" rel="alternate" type="text/html" title="Attentional Mixtures of Soft Prompt Tuning for Parameter-efficient Multi-task Knowledge Sharing" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/590f5924be5646ef5123279db470f745</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/590f5924be5646ef5123279db470f745.html">&lt;p&gt;This work introduces ATTEMPT (Attentional Mixture of Prompt Tuning), a new modular, multi-task, and parameter-efficient language model (LM) tuning approach that combines knowledge transferred across different tasks via a mixture of soft prompts while keeping original LM unchanged. ATTEMPT interpolates a set of prompts trained on large-scale source tasks and a newly initialized target task prompt using instance-wise attention computed by a lightweight sub-network trained … Cites: ‪Palm: Scaling language modeling with pathways‬&lt;/p&gt;</content><author><name>A Asai, M Salehi, ME Peters, H Hajishirzi - arXiv preprint arXiv:2205.11961, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This work introduces ATTEMPT (Attentional Mixture of Prompt Tuning), a new modular, multi-task, and parameter-efficient language model (LM) tuning approach that combines knowledge transferred across different tasks via a mixture of soft prompts while keeping original LM unchanged. ATTEMPT interpolates a set of prompts trained on large-scale source tasks and a newly initialized target task prompt using instance-wise attention computed by a lightweight sub-network trained … Cites: ‪Palm: Scaling language modeling with pathways‬</summary></entry><entry><title type="html">A SURVEY ON SEMANTIC ANNOTATION TOOLS FOR KNOWLEDGE MANAGEMENT</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/597323b5f64460c8490f723bd7def34a.html" rel="alternate" type="text/html" title="A SURVEY ON SEMANTIC ANNOTATION TOOLS FOR KNOWLEDGE MANAGEMENT" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/597323b5f64460c8490f723bd7def34a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/597323b5f64460c8490f723bd7def34a.html">&lt;p&gt;Support for information and knowledge exchange is a key issue in the information society. To reduce the time wasted in searching and to reduce associated user frustration much more selective user access is needed. This is possible by semantic information processing of online documents. Knowledge management in an organisation are used for managing knowledge resources in order to facilitate access and reuse of knowledge. Semantic annotation is about assigning to the … Cites: ‪Mangrove: Enticing ordinary people onto the semantic web via …‬&lt;/p&gt;</content><author><name>P Kherwa</name></author><category term="jekyll" /><category term="update" /><summary type="html">Support for information and knowledge exchange is a key issue in the information society. To reduce the time wasted in searching and to reduce associated user frustration much more selective user access is needed. This is possible by semantic information processing of online documents. Knowledge management in an organisation are used for managing knowledge resources in order to facilitate access and reuse of knowledge. Semantic annotation is about assigning to the … Cites: ‪Mangrove: Enticing ordinary people onto the semantic web via …‬</summary></entry><entry><title type="html">Visualizing CoAtNet Predictions for Aiding Melanoma Detection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/59e98f9b7e9977e0b820ffd6bea75f5a.html" rel="alternate" type="text/html" title="Visualizing CoAtNet Predictions for Aiding Melanoma Detection" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/59e98f9b7e9977e0b820ffd6bea75f5a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/59e98f9b7e9977e0b820ffd6bea75f5a.html">&lt;p&gt;Melanoma is considered to be the most aggressive form of skin cancer. Due to the similar shape of malignant and benign cancerous lesions, doctors spend considerably more time when diagnosing these findings. At present, the evaluation of malignancy is performed primarily by invasive histological examination of the suspicious lesion. Developing an accurate classifier for early and efficient detection can minimize and monitor the harmful effects of skin cancer and increase patient … Cites: ‪Coatnet: Marrying convolution and attention for all data sizes‬&lt;/p&gt;</content><author><name>D Kvak - arXiv preprint arXiv:2205.10515, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Melanoma is considered to be the most aggressive form of skin cancer. Due to the similar shape of malignant and benign cancerous lesions, doctors spend considerably more time when diagnosing these findings. At present, the evaluation of malignancy is performed primarily by invasive histological examination of the suspicious lesion. Developing an accurate classifier for early and efficient detection can minimize and monitor the harmful effects of skin cancer and increase patient … Cites: ‪Coatnet: Marrying convolution and attention for all data sizes‬</summary></entry><entry><title type="html">FedNoiL: A Simple Two-Level Sampling Method for Federated Learning with Noisy Labels</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/5a1a2ca574f457e42135011d2d47079e.html" rel="alternate" type="text/html" title="FedNoiL: A Simple Two-Level Sampling Method for Federated Learning with Noisy Labels" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/5a1a2ca574f457e42135011d2d47079e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/5a1a2ca574f457e42135011d2d47079e.html">&lt;p&gt;Federated learning (FL) aims at training a global model on the server side while the training data are collected and located at the local devices. Hence, the labels in practice are usually annotated by clients of varying expertise or criteria and thus contain different amounts of noises. Local training on noisy labels can easily result in overfitting to noisy labels, which is devastating to the global model through aggregation. Although recent robust FL methods take malicious clients into account … Cites: ‪Dividemix: Learning with noisy labels as semi-supervised learning‬&lt;/p&gt;</content><author><name>Z Wang, T Zhou, G Long, B Han, J Jiang - arXiv preprint arXiv:2205.10110, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Federated learning (FL) aims at training a global model on the server side while the training data are collected and located at the local devices. Hence, the labels in practice are usually annotated by clients of varying expertise or criteria and thus contain different amounts of noises. Local training on noisy labels can easily result in overfitting to noisy labels, which is devastating to the global model through aggregation. Although recent robust FL methods take malicious clients into account … Cites: ‪Dividemix: Learning with noisy labels as semi-supervised learning‬</summary></entry><entry><title type="html">ARNN-QA: Adaptive Recurrent Neural Network with feature optimization for incremental learning-based Question Answering system</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/5d0bfaf729600419cc3b1b0b877dfbe3.html" rel="alternate" type="text/html" title="ARNN-QA: Adaptive Recurrent Neural Network with feature optimization for incremental learning-based Question Answering system" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/5d0bfaf729600419cc3b1b0b877dfbe3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/5d0bfaf729600419cc3b1b0b877dfbe3.html">&lt;p&gt;The evolution of internet services has raised many information retrieval systems, and the use of intelligent services for the Question Answering (QA) systems has been on ascending. QA system identifies the accurate answers briefly, and the answers are identified through natural language expressions. Developing intelligent techniques for QA has been an abiding issue, and it has been studied for over years. Though, different QA models focus on common-sense and general questions in open fields … Cites: ‪QA Dataset Explosion: A Taxonomy of NLP Resources for …‬&lt;/p&gt;</content><author><name>M Therasa, G Mathivanan - Applied Soft Computing, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The evolution of internet services has raised many information retrieval systems, and the use of intelligent services for the Question Answering (QA) systems has been on ascending. QA system identifies the accurate answers briefly, and the answers are identified through natural language expressions. Developing intelligent techniques for QA has been an abiding issue, and it has been studied for over years. Though, different QA models focus on common-sense and general questions in open fields … Cites: ‪QA Dataset Explosion: A Taxonomy of NLP Resources for …‬</summary></entry><entry><title type="html">Test-Time Robust Personalization for Federated Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/5df478ee51893805b2427466a4785368.html" rel="alternate" type="text/html" title="Test-Time Robust Personalization for Federated Learning" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/5df478ee51893805b2427466a4785368</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/5df478ee51893805b2427466a4785368.html">&lt;p&gt;Federated Learning (FL) is a machine learning paradigm where many clients collaboratively learn a shared global model with decentralized training data. Personalization on FL model additionally adapts the global model to different clients, achieving promising results on consistent local training &amp;amp; test distributions. However, for real-world personalized FL applications, it is crucial to go one step further: robustifying FL models under evolving local test set during deployment, where … Cites: ‪Robust fine-tuning of zero-shot models‬&lt;/p&gt;</content><author><name>L Jiang, T Lin - arXiv preprint arXiv:2205.10920, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Federated Learning (FL) is a machine learning paradigm where many clients collaboratively learn a shared global model with decentralized training data. Personalization on FL model additionally adapts the global model to different clients, achieving promising results on consistent local training &amp;amp; test distributions. However, for real-world personalized FL applications, it is crucial to go one step further: robustifying FL models under evolving local test set during deployment, where … Cites: ‪Robust fine-tuning of zero-shot models‬</summary></entry><entry><title type="html">Question Generation for Reading Comprehension Test Complying with Types of Question.</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/5e89d6ed5b0b0c9b907e57a8e1de4a82.html" rel="alternate" type="text/html" title="Question Generation for Reading Comprehension Test Complying with Types of Question." /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/5e89d6ed5b0b0c9b907e57a8e1de4a82</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/5e89d6ed5b0b0c9b907e57a8e1de4a82.html">&lt;p&gt;In this paper, we proposed a method to generate two different types of reading comprehension questions complying with types of question for language learning tests with the Transformer model and the seq2seq method. In recent years, many approaches have showed good results by treating question generation as a seq2seq task. These approaches were implemented with a question-answering (QA) dataset; however, few studies have considered a reading comprehension-based dataset … Cites: ‪Question generation for question answering‬&lt;/p&gt;</content><author><name>J SHAN, Y NISHIHARA, A MAEDA, R YAMANISHI - Journal of Information Science &amp; …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper, we proposed a method to generate two different types of reading comprehension questions complying with types of question for language learning tests with the Transformer model and the seq2seq method. In recent years, many approaches have showed good results by treating question generation as a seq2seq task. These approaches were implemented with a question-answering (QA) dataset; however, few studies have considered a reading comprehension-based dataset … Cites: ‪Question generation for question answering‬</summary></entry><entry><title type="html">How Machine Learning Classification Accuracy Changes in a Happiness Dataset with Different Demographic Groups</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/60bd8c195d35ddba3989e04416e3e1e1.html" rel="alternate" type="text/html" title="How Machine Learning Classification Accuracy Changes in a Happiness Dataset with Different Demographic Groups" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/60bd8c195d35ddba3989e04416e3e1e1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/60bd8c195d35ddba3989e04416e3e1e1.html">&lt;p&gt;This study aims to explore how machine learning classification accuracy changes with different demographic groups. The HappyDB is a dataset that contains over 100,000 happy statements, incorporating demographic information that includes marital status, gender, age, and parenthood status. Using the happiness category field, we test different types of machine learning classifiers to predict what category of happiness the statements belong to, for example, whether they indicate happiness … Cites: ‪Happydb: A corpus of 100,000 crowdsourced happy moments‬&lt;/p&gt;</content><author><name>C Sweeney, E Ennis, M Mulvenna, R Bond, S O Neill - Computers, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This study aims to explore how machine learning classification accuracy changes with different demographic groups. The HappyDB is a dataset that contains over 100,000 happy statements, incorporating demographic information that includes marital status, gender, age, and parenthood status. Using the happiness category field, we test different types of machine learning classifiers to predict what category of happiness the statements belong to, for example, whether they indicate happiness … Cites: ‪Happydb: A corpus of 100,000 crowdsourced happy moments‬</summary></entry><entry><title type="html">Exploring Input Modalities for Collaborative Storytelling</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/631f0fb8f50b37b4b52554b46c2039a4.html" rel="alternate" type="text/html" title="Exploring Input Modalities for Collaborative Storytelling" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/631f0fb8f50b37b4b52554b46c2039a4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/631f0fb8f50b37b4b52554b46c2039a4.html">&lt;p&gt;Joint storytelling is a collaborative activity with multiple benefits, such as improved language development for children. Many studies have created AI-supported tools for collaborative storytelling with varying input mechanisms. Very little research has compared the differing quality of different input methods. We built a collaborative storytelling prototype with multiple input methods to compare which method works best and engages the children. KEY WORDS Human-Computer Interaction, Child-AI … Cites: ‪StoryBuddy: A Human-AI Collaborative Chatbot for Parent-Child …‬&lt;/p&gt;</content><author><name>Z Havens, R Thiessen</name></author><category term="jekyll" /><category term="update" /><summary type="html">Joint storytelling is a collaborative activity with multiple benefits, such as improved language development for children. Many studies have created AI-supported tools for collaborative storytelling with varying input mechanisms. Very little research has compared the differing quality of different input methods. We built a collaborative storytelling prototype with multiple input methods to compare which method works best and engages the children. KEY WORDS Human-Computer Interaction, Child-AI … Cites: ‪StoryBuddy: A Human-AI Collaborative Chatbot for Parent-Child …‬</summary></entry><entry><title type="html">Housekeep: Tidying Virtual Households using Commonsense Reasoning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/6466e522a17a3770b33ae45c760de467.html" rel="alternate" type="text/html" title="Housekeep: Tidying Virtual Households using Commonsense Reasoning" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/6466e522a17a3770b33ae45c760de467</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/6466e522a17a3770b33ae45c760de467.html">&lt;p&gt;We introduce Housekeep, a benchmark to evaluate commonsense reasoning in the home for embodied AI. In Housekeep, an embodied agent must tidy a house by rearranging misplaced objects without explicit instructions specifying which objects need to be rearranged. Instead, the agent must learn from and is evaluated against human preferences of which objects belong where in a tidy house. Specifically, we collect a dataset of where humans typically place objects in tidy and untidy houses … Cites: ‪Abductive commonsense reasoning‬&lt;/p&gt;</content><author><name>Y Kant, A Ramachandran, S Yenamandra… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We introduce Housekeep, a benchmark to evaluate commonsense reasoning in the home for embodied AI. In Housekeep, an embodied agent must tidy a house by rearranging misplaced objects without explicit instructions specifying which objects need to be rearranged. Instead, the agent must learn from and is evaluated against human preferences of which objects belong where in a tidy house. Specifically, we collect a dataset of where humans typically place objects in tidy and untidy houses … Cites: ‪Abductive commonsense reasoning‬</summary></entry><entry><title type="html">Explainable Data for AI</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/6d9997beaf605d990bb3d88396d69f7c.html" rel="alternate" type="text/html" title="Explainable Data for AI" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/6d9997beaf605d990bb3d88396d69f7c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/6d9997beaf605d990bb3d88396d69f7c.html">&lt;p&gt;Knowledge In - Wisdom Out Explainable Data for AI Page 1 Knowledge In - Wisdom   Out Explainable Data for AI Kaushik Roy, Usha Lokala, Manas Gaur, Amit Sheth   Spread the word! Tweet your insights, screenshots, and questions #KiWo2021 #ICWSM2021   #ExplainableData #ExplainableAI #KG4Explainability Check Tutorial site for latest   slides: https://aiisc.ai/kiwo-icwsm Page 2 Team Presentation Amit Sheth Director   Artificial Intelligence Institute, University of South Carolina Manas Gaur Ph.D. Student … Cites: ‪Beyond Accuracy: Behavioral Testing of NLP Models with CheckList‬&lt;/p&gt;</content><author><name>K Roy, U Lokala, M Gaur, A Sheth</name></author><category term="jekyll" /><category term="update" /><summary type="html">Knowledge In - Wisdom Out Explainable Data for AI Page 1 Knowledge In - Wisdom Out Explainable Data for AI Kaushik Roy, Usha Lokala, Manas Gaur, Amit Sheth Spread the word! Tweet your insights, screenshots, and questions #KiWo2021 #ICWSM2021 #ExplainableData #ExplainableAI #KG4Explainability Check Tutorial site for latest slides: https://aiisc.ai/kiwo-icwsm Page 2 Team Presentation Amit Sheth Director Artificial Intelligence Institute, University of South Carolina Manas Gaur Ph.D. Student … Cites: ‪Beyond Accuracy: Behavioral Testing of NLP Models with CheckList‬</summary></entry><entry><title type="html">All Birds with One Stone: Multi-task Text Classification for Efficient Inference with One Forward Pass</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/6dee8574e7f3b226cc185bfbaf77f824.html" rel="alternate" type="text/html" title="All Birds with One Stone: Multi-task Text Classification for Efficient Inference with One Forward Pass" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/6dee8574e7f3b226cc185bfbaf77f824</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/6dee8574e7f3b226cc185bfbaf77f824.html">&lt;p&gt;Multi-Task Learning (MTL) models have shown their robustness, effectiveness, and efficiency for transferring learned knowledge across tasks. In real industrial applications such as web content classification, multiple classification tasks are …&lt;/p&gt;</content><author><name>J Huang, T Liu, J Liu, AD Lelkes, C Yu, J Han - arXiv preprint arXiv:2205.10744, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Multi-Task Learning (MTL) models have shown their robustness, effectiveness, and efficiency for transferring learned knowledge across tasks. In real industrial applications such as web content classification, multiple classification tasks are …</summary></entry><entry><title type="html">Cross-lingual Lifelong Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/6f21b698385ca73e8557b553f5604b6b.html" rel="alternate" type="text/html" title="Cross-lingual Lifelong Learning" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/6f21b698385ca73e8557b553f5604b6b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/6f21b698385ca73e8557b553f5604b6b.html">&lt;p&gt;The longstanding goal of multi-lingual learning has been to develop a universal cross-lingual model that can withstand the changes in multi-lingual data distributions. However, most existing models assume full access to the target languages in advance, whereas in realistic scenarios this is not often the case, as new languages can be incorporated later on. In this paper, we present the Cross-lingual Lifelong Learning (CLL) challenge, where a model is continually fine-tuned to adapt to … Cites: ‪Adapterhub: A framework for adapting transformers‬&lt;/p&gt;</content><author><name>M M hamdi, X Ren, J May - arXiv preprint arXiv:2205.11152, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The longstanding goal of multi-lingual learning has been to develop a universal cross-lingual model that can withstand the changes in multi-lingual data distributions. However, most existing models assume full access to the target languages in advance, whereas in realistic scenarios this is not often the case, as new languages can be incorporated later on. In this paper, we present the Cross-lingual Lifelong Learning (CLL) challenge, where a model is continually fine-tuned to adapt to … Cites: ‪Adapterhub: A framework for adapting transformers‬</summary></entry><entry><title type="html">Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/75bdaef7bcc9f4608afc8c92a649b9ec.html" rel="alternate" type="text/html" title="Memorization Without Overfitting: Analyzing the Training Dynamics of Large Language Models" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/75bdaef7bcc9f4608afc8c92a649b9ec</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/75bdaef7bcc9f4608afc8c92a649b9ec.html">&lt;p&gt;Despite their wide adoption, the underlying training and memorization dynamics of very large language models is not well understood. We empirically study exact memorization in causal and masked language modeling, across model sizes and throughout the training process. We measure the effects of dataset size, learning rate, and model size on memorization, finding that larger language models memorize training data faster across all settings. Surprisingly, we show that larger models can … Cites: ‪Palm: Scaling language modeling with pathways‬&lt;/p&gt;</content><author><name>K Tirumala, AH Markosyan, L Zettlemoyer… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Despite their wide adoption, the underlying training and memorization dynamics of very large language models is not well understood. We empirically study exact memorization in causal and masked language modeling, across model sizes and throughout the training process. We measure the effects of dataset size, learning rate, and model size on memorization, finding that larger language models memorize training data faster across all settings. Surprisingly, we show that larger models can … Cites: ‪Palm: Scaling language modeling with pathways‬</summary></entry><entry><title type="html">A review: development of named entity recognition (NER) technology for aeronautical information intelligence</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7634cf4894662d4fbc6f0d771ff5860b.html" rel="alternate" type="text/html" title="A review: development of named entity recognition (NER) technology for aeronautical information intelligence" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7634cf4894662d4fbc6f0d771ff5860b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7634cf4894662d4fbc6f0d771ff5860b.html">&lt;p&gt;The rapid development of data and artificial intelligence technology has introduced new opportunities and challenges to aeronautical information intelligence. However, there are many obstacles in the sharing, reasoning and reusing aeronautical data due to the disunity of norms, the opacity of sharing and semantic ambiguity. To a large extent, as a basic method for processing, storing and deducing aeronautical data in the future, NER provides a new idea for the natural language processing of … Cites: ‪Generalized Data Augmentation for Low-Resource Translation‬&lt;/p&gt;</content><author><name>M Baigang, F Yi - Artificial Intelligence Review, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The rapid development of data and artificial intelligence technology has introduced new opportunities and challenges to aeronautical information intelligence. However, there are many obstacles in the sharing, reasoning and reusing aeronautical data due to the disunity of norms, the opacity of sharing and semantic ambiguity. To a large extent, as a basic method for processing, storing and deducing aeronautical data in the future, NER provides a new idea for the natural language processing of … Cites: ‪Generalized Data Augmentation for Low-Resource Translation‬</summary></entry><entry><title type="html">Utilizing Language-Image Pretraining for Efficient and Robust Bilingual Word Alignment</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/78cf7813e1aece12eb9834728d9e9ea7.html" rel="alternate" type="text/html" title="Utilizing Language-Image Pretraining for Efficient and Robust Bilingual Word Alignment" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/78cf7813e1aece12eb9834728d9e9ea7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/78cf7813e1aece12eb9834728d9e9ea7.html">&lt;p&gt;Word translation without parallel corpora has become feasible, rivaling the performance of supervised methods. Recent findings have shown that the accuracy and robustness of unsupervised word translation (UWT) can be improved by making use of visual observations, which are universal representations across languages. In this work, we investigate the potential of using not only visual observations but also pretrained language-image models for enabling a more efficient and robust UWT … Cites: ‪XTREME: A massively multilingual multi-task benchmark for …‬&lt;/p&gt;</content><author><name>T Dinh, J Sohn, S Rajput, T Ossowski, Y Ming, J Hu… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Word translation without parallel corpora has become feasible, rivaling the performance of supervised methods. Recent findings have shown that the accuracy and robustness of unsupervised word translation (UWT) can be improved by making use of visual observations, which are universal representations across languages. In this work, we investigate the potential of using not only visual observations but also pretrained language-image models for enabling a more efficient and robust UWT … Cites: ‪XTREME: A massively multilingual multi-task benchmark for …‬</summary></entry><entry><title type="html">A Review of Safe Reinforcement Learning: Methods, Theory and Applications</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7cb56252d358356fc691b062dad59065.html" rel="alternate" type="text/html" title="A Review of Safe Reinforcement Learning: Methods, Theory and Applications" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7cb56252d358356fc691b062dad59065</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7cb56252d358356fc691b062dad59065.html">&lt;p&gt;Reinforcement learning has achieved tremendous success in many complex decision making tasks. When it comes to deploying RL in the real world, safety concerns are usually raised, leading to a growing demand for safe reinforcement learning algorithms, such as in autonomous driving and robotics scenarios. While safety control has a long history, the study of safe RL algorithms is still in the early stages. To establish a good foundation for future research in this thread, in this … Cites: ‪Doubly robust bias reduction in infinite horizon off-policy estimation‬&lt;/p&gt;</content><author><name>S Gu, L Yang, Y Du, G Chen, F Walter, J Wang, Y Yang… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Reinforcement learning has achieved tremendous success in many complex decision making tasks. When it comes to deploying RL in the real world, safety concerns are usually raised, leading to a growing demand for safe reinforcement learning algorithms, such as in autonomous driving and robotics scenarios. While safety control has a long history, the study of safe RL algorithms is still in the early stages. To establish a good foundation for future research in this thread, in this … Cites: ‪Doubly robust bias reduction in infinite horizon off-policy estimation‬</summary></entry><entry><title type="html">DKG: A Descriptive Knowledge Graph for Explaining Relationships between Entities</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7e2648add8be298e5b30814f97bdc67b.html" rel="alternate" type="text/html" title="DKG: A Descriptive Knowledge Graph for Explaining Relationships between Entities" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7e2648add8be298e5b30814f97bdc67b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7e2648add8be298e5b30814f97bdc67b.html">&lt;p&gt;In this paper, we propose Descriptive Knowledge Graph (DKG)-an open and interpretable form of modeling relationships between entities. In DKGs, relationships between entities are represented by relation descriptions. For instance, the relationship between entities of machine learning and algorithm can be described as  Machine learning explores the study and construction of algorithms that can learn from and make predictions on data.  To construct DKGs, we propose a self … Cites: ‪Open information extraction from the web‬&lt;/p&gt;</content><author><name>J Huang, K Zhu, KCC Chang, J Xiong, W Hwu - arXiv preprint arXiv:2205.10479, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper, we propose Descriptive Knowledge Graph (DKG)-an open and interpretable form of modeling relationships between entities. In DKGs, relationships between entities are represented by relation descriptions. For instance, the relationship between entities of machine learning and algorithm can be described as Machine learning explores the study and construction of algorithms that can learn from and make predictions on data. To construct DKGs, we propose a self … Cites: ‪Open information extraction from the web‬</summary></entry><entry><title type="html">Asynchronous Digital Participation in Urban Design Processes: Qualitative Data Exploration and Analysis With Natural Language Processing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7e72e01df13462103ad2fa2ff601c25b.html" rel="alternate" type="text/html" title="Asynchronous Digital Participation in Urban Design Processes: Qualitative Data Exploration and Analysis With Natural Language Processing" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7e72e01df13462103ad2fa2ff601c25b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7e72e01df13462103ad2fa2ff601c25b.html">&lt;p&gt;This paper aims to improve the usability of qualitative urban big data sources by utilizing Natural Language Processing (NLP) as a promising AI-based technique. In this research, we designed a digital participation experiment by deploying an open-source and customizable asynchronous participation tool,  Consul Project ‚, with 47 participants in the campus transformation process of the Singapore University of Technology and Design (SUTD). At the end of the data collection process with … Cites: ‪Reading tea leaves: How humans interpret topic models‬&lt;/p&gt;</content><author><name>C Ataman, B Tuncer, S Perrault - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper aims to improve the usability of qualitative urban big data sources by utilizing Natural Language Processing (NLP) as a promising AI-based technique. In this research, we designed a digital participation experiment by deploying an open-source and customizable asynchronous participation tool, Consul Project ‚, with 47 participants in the campus transformation process of the Singapore University of Technology and Design (SUTD). At the end of the data collection process with … Cites: ‪Reading tea leaves: How humans interpret topic models‬</summary></entry><entry><title type="html">FlexiBERT: Are Current Transformer Architectures too Homogeneous and Rigid?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7e79d7ff427591ef46806d7e3a6bb4c7.html" rel="alternate" type="text/html" title="FlexiBERT: Are Current Transformer Architectures too Homogeneous and Rigid?" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7e79d7ff427591ef46806d7e3a6bb4c7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/7e79d7ff427591ef46806d7e3a6bb4c7.html">&lt;p&gt;The existence of a plethora of language models makes the problem of selecting the best one for a custom task challenging. Most state-of-the-art methods leverage transformer-based models (eg, BERT) or their variants. Training such models and exploring their hyperparameter space, however, is computationally expensive. Prior work proposes several neural architecture search (NAS) methods that employ performance predictors (eg, surrogate models) to address this issue; however … Cites: ‪Searching for Efficient Transformers for Language Modeling‬&lt;/p&gt;</content><author><name>S Tuli, B Dedhia, S Tuli, NK Jha - arXiv preprint arXiv:2205.11656, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The existence of a plethora of language models makes the problem of selecting the best one for a custom task challenging. Most state-of-the-art methods leverage transformer-based models (eg, BERT) or their variants. Training such models and exploring their hyperparameter space, however, is computationally expensive. Prior work proposes several neural architecture search (NAS) methods that employ performance predictors (eg, surrogate models) to address this issue; however … Cites: ‪Searching for Efficient Transformers for Language Modeling‬</summary></entry><entry><title type="html">Context Matters for Image Descriptions for Accessibility: Challenges for Referenceless Evaluation Metrics</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/808e3acf157325af827d838b43250080.html" rel="alternate" type="text/html" title="Context Matters for Image Descriptions for Accessibility: Challenges for Referenceless Evaluation Metrics" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/808e3acf157325af827d838b43250080</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/808e3acf157325af827d838b43250080.html">&lt;p&gt;Few images on the Web receive alt-text descriptions that would make them accessible to blind and low vision (BLV) users. Image-based NLG systems have progressed to the point where they can begin to address this persistent societal problem, but these systems will not be fully successful unless we evaluate them on metrics that guide their development correctly. Here, we argue against current referenceless metrics–those that don t rely on human-generated ground-truth … Cites: ‪Bidimensional Leaderboards: Generate and Evaluate Language …‬&lt;/p&gt;</content><author><name>E Kreiss, C Bennett, S Hooshmand, E Zelikman… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Few images on the Web receive alt-text descriptions that would make them accessible to blind and low vision (BLV) users. Image-based NLG systems have progressed to the point where they can begin to address this persistent societal problem, but these systems will not be fully successful unless we evaluate them on metrics that guide their development correctly. Here, we argue against current referenceless metrics–those that don t rely on human-generated ground-truth … Cites: ‪Bidimensional Leaderboards: Generate and Evaluate Language …‬</summary></entry><entry><title type="html">Mutually reinforced network embedding: An integrated approach to research paper recommendation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/8479bfa182940661a6b1a62a1748d6c6.html" rel="alternate" type="text/html" title="Mutually reinforced network embedding: An integrated approach to research paper recommendation" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/8479bfa182940661a6b1a62a1748d6c6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/8479bfa182940661a6b1a62a1748d6c6.html">&lt;p&gt;With the rapid growth of research publications, it has become time-consuming and cumbersome for researchers to find research papers relevant to their research. Research paper recommendation, which provides a reference list for a given manuscript, providing convenience for researchers. In the past, researchers embedded papers into a low-dimensional vector space through textual information and network structure to obtain paper embeddings, and then made … Cites: ‪Learning with Local and Global Consistency.‬&lt;/p&gt;</content><author><name>X Mei, X Cai, S Xu, W Li, S Pan, L Yang - Expert Systems with Applications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">With the rapid growth of research publications, it has become time-consuming and cumbersome for researchers to find research papers relevant to their research. Research paper recommendation, which provides a reference list for a given manuscript, providing convenience for researchers. In the past, researchers embedded papers into a low-dimensional vector space through textual information and network structure to obtain paper embeddings, and then made … Cites: ‪Learning with Local and Global Consistency.‬</summary></entry><entry><title type="html">muNet: Evolving Pretrained Deep Neural Networks into Scalable Auto-tuning Multitask Systems</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/84da51e523bbe93a541e4c89203f8fc1.html" rel="alternate" type="text/html" title="muNet: Evolving Pretrained Deep Neural Networks into Scalable Auto-tuning Multitask Systems" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/84da51e523bbe93a541e4c89203f8fc1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/84da51e523bbe93a541e4c89203f8fc1.html">&lt;p&gt;Most uses of machine learning today involve training a model from scratch for a particular task, or sometimes starting with a model pretrained on a related task and then fine-tuning on a downstream task. Both approaches offer limited knowledge transfer between different tasks, time-consuming human-driven customization to individual tasks and high computational costs especially when starting from randomly initialized models. We propose a method that uses the layers of a … Cites: ‪Chip placement with deep reinforcement learning‬&lt;/p&gt;</content><author><name>A Gesmundo, J Dean - arXiv preprint arXiv:2205.10937, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Most uses of machine learning today involve training a model from scratch for a particular task, or sometimes starting with a model pretrained on a related task and then fine-tuning on a downstream task. Both approaches offer limited knowledge transfer between different tasks, time-consuming human-driven customization to individual tasks and high computational costs especially when starting from randomly initialized models. We propose a method that uses the layers of a … Cites: ‪Chip placement with deep reinforcement learning‬</summary></entry><entry><title type="html">From Chip Design to Chip Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/84df181b1c97d2c599f947160602014a.html" rel="alternate" type="text/html" title="From Chip Design to Chip Learning" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/84df181b1c97d2c599f947160602014a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/84df181b1c97d2c599f947160602014a.html">&lt;p&gt;Chip is the foundation of the modern information society. As the world is entering a new era of human-cyber-physical ternary computing, with diverse intelligent applications over trillions of devices, chip with specialized architecture will be heavily demanded in both numbers and types. However, chip design is very costly, which usually requires a long design cycle, complicated process, and high professional developers. Hence, there is a large gap between the need of tremendous chips and … Cites: ‪A graph placement methodology for fast chip design‬&lt;/p&gt;</content><author><name>Y CHEN, Z DU, Q GUO, W LI, Y TAN - Bulletin of Chinese Academy of Sciences …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Chip is the foundation of the modern information society. As the world is entering a new era of human-cyber-physical ternary computing, with diverse intelligent applications over trillions of devices, chip with specialized architecture will be heavily demanded in both numbers and types. However, chip design is very costly, which usually requires a long design cycle, complicated process, and high professional developers. Hence, there is a large gap between the need of tremendous chips and … Cites: ‪A graph placement methodology for fast chip design‬</summary></entry><entry><title type="html">QASem Parsing: Text-to-text Modeling of QA-based Semantics</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/869e21cf92e0c58fa24f0d52509237f3.html" rel="alternate" type="text/html" title="QASem Parsing: Text-to-text Modeling of QA-based Semantics" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/869e21cf92e0c58fa24f0d52509237f3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/869e21cf92e0c58fa24f0d52509237f3.html">&lt;p&gt;Several recent works have suggested to represent semantic relations with questions and answers, decomposing textual information into separate interrogative natural language statements. In this paper, we consider three QA-based semantic tasks-namely, QA-SRL, QANom and QADiscourse, each targeting a certain type of predication-and propose to regard them as jointly providing a comprehensive representation of textual information. To promote this goal, we investigate how to … Cites: ‪Efficiently Summarizing Text and Graph Encodings of Multi …‬&lt;/p&gt;</content><author><name>A Klein, E Hirsch, R Eliav, V Pyatkin, A Caciularu… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Several recent works have suggested to represent semantic relations with questions and answers, decomposing textual information into separate interrogative natural language statements. In this paper, we consider three QA-based semantic tasks-namely, QA-SRL, QANom and QADiscourse, each targeting a certain type of predication-and propose to regard them as jointly providing a comprehensive representation of textual information. To promote this goal, we investigate how to … Cites: ‪Efficiently Summarizing Text and Graph Encodings of Multi …‬</summary></entry><entry><title type="html">Conditional Supervised Contrastive Learning for Fair Text Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/8804e681230af72250db853d4a68f0b2.html" rel="alternate" type="text/html" title="Conditional Supervised Contrastive Learning for Fair Text Classification" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/8804e681230af72250db853d4a68f0b2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/8804e681230af72250db853d4a68f0b2.html">&lt;p&gt;Contrastive representation learning has gained much attention due to its superior performance in learning representations from both image and sequential data. However, the learned representations could potentially lead to performance disparities in downstream tasks, such as increased silencing of underrepresented groups in toxicity comment classification. In light of this challenge, in this work, we study learning fair representations that satisfy a notion of fairness known as … Cites: ‪Wilds: A benchmark of in-the-wild distribution shifts‬&lt;/p&gt;</content><author><name>J Chi, W Shand, Y Yu, KW Chang, H Zhao, Y Tian - arXiv preprint arXiv:2205.11485, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Contrastive representation learning has gained much attention due to its superior performance in learning representations from both image and sequential data. However, the learned representations could potentially lead to performance disparities in downstream tasks, such as increased silencing of underrepresented groups in toxicity comment classification. In light of this challenge, in this work, we study learning fair representations that satisfy a notion of fairness known as … Cites: ‪Wilds: A benchmark of in-the-wild distribution shifts‬</summary></entry><entry><title type="html">Automated Scoring for Reading Comprehension via In-context BERT Tuning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/88a3d10869e2c51577a755eabb96c463.html" rel="alternate" type="text/html" title="Automated Scoring for Reading Comprehension via In-context BERT Tuning" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/88a3d10869e2c51577a755eabb96c463</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/88a3d10869e2c51577a755eabb96c463.html">&lt;p&gt;Automated scoring of open-ended student responses has the potential to significantly reduce human grader effort. Recent advances in automated scoring often leverage textual representations based on pre-trained language models such as BERT and GPT as input to scoring models. Most existing approaches train a separate model for each item/question, which is suitable for scenarios such as essay scoring where items can be quite different from one another. However, these … Cites: ‪Metaicl: Learning to learn in context‬&lt;/p&gt;</content><author><name>N Fernandez, A Ghosh, N Liu, Z Wang, B Choffin… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Automated scoring of open-ended student responses has the potential to significantly reduce human grader effort. Recent advances in automated scoring often leverage textual representations based on pre-trained language models such as BERT and GPT as input to scoring models. Most existing approaches train a separate model for each item/question, which is suitable for scenarios such as essay scoring where items can be quite different from one another. However, these … Cites: ‪Metaicl: Learning to learn in context‬</summary></entry><entry><title type="html">An Empirical Investigation of Commonsense Self-Supervision with Knowledge Graphs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/89097f5880b91e2ea2b9dcd9858b4fbd.html" rel="alternate" type="text/html" title="An Empirical Investigation of Commonsense Self-Supervision with Knowledge Graphs" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/89097f5880b91e2ea2b9dcd9858b4fbd</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/89097f5880b91e2ea2b9dcd9858b4fbd.html">&lt;p&gt;Self-supervision based on the information extracted from large knowledge graphs has been shown to improve the generalization of language models, in zero-shot evaluation on various downstream language reasoning tasks. Since these improvements are reported in aggregate, however, little is known about (i) how to select the appropriate knowledge for solid performance across tasks,(ii) how to combine this knowledge with neural language models, and (iii) how these pairings … Cites: ‪Prompting contrastive explanations for commonsense reasoning …‬&lt;/p&gt;</content><author><name>J Zhang, F Ilievski, K Ma, J Francis, A Oltramari - arXiv preprint arXiv:2205.10661, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Self-supervision based on the information extracted from large knowledge graphs has been shown to improve the generalization of language models, in zero-shot evaluation on various downstream language reasoning tasks. Since these improvements are reported in aggregate, however, little is known about (i) how to select the appropriate knowledge for solid performance across tasks,(ii) how to combine this knowledge with neural language models, and (iii) how these pairings … Cites: ‪Prompting contrastive explanations for commonsense reasoning …‬</summary></entry><entry><title type="html">Partial-input baselines show that NLI models can ignore context, but they don t</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/92dcf1247fb1880a744f993064bcd2d9.html" rel="alternate" type="text/html" title="Partial-input baselines show that NLI models can ignore context, but they don t" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/92dcf1247fb1880a744f993064bcd2d9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/92dcf1247fb1880a744f993064bcd2d9.html">&lt;p&gt;When strong partial-input baselines reveal artifacts in crowdsourced NLI datasets, the performance of full-input models trained on such datasets is often dismissed as reliance on spurious correlations. We investigate whether state-of-the-art NLI models are capable of overriding default inferences made by a partial-input baseline. We introduce an evaluation set of 600 examples consisting of perturbed premises to examine a RoBERTa model s sensitivity to edited contexts. Our results indicate that … Cites: ‪Misleading failures of partial-input baselines‬&lt;/p&gt;</content><author><name>N Srikanth, R Rudinger - arXiv preprint arXiv:2205.12181, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">When strong partial-input baselines reveal artifacts in crowdsourced NLI datasets, the performance of full-input models trained on such datasets is often dismissed as reliance on spurious correlations. We investigate whether state-of-the-art NLI models are capable of overriding default inferences made by a partial-input baseline. We introduce an evaluation set of 600 examples consisting of perturbed premises to examine a RoBERTa model s sensitivity to edited contexts. Our results indicate that … Cites: ‪Misleading failures of partial-input baselines‬</summary></entry><entry><title type="html">Blackbird s language matrices (BLMs): a new benchmark to investigate disentangled generalisation in neural networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/942c613ac5b4ffb05c3bc4ed1dc18b60.html" rel="alternate" type="text/html" title="Blackbird s language matrices (BLMs): a new benchmark to investigate disentangled generalisation in neural networks" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/942c613ac5b4ffb05c3bc4ed1dc18b60</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/942c613ac5b4ffb05c3bc4ed1dc18b60.html">&lt;p&gt;Current successes of machine learning architectures are based on computationally expensive algorithms and prohibitively large amounts of data. We need to develop tasks and data to train networks to reach more complex and more compositional skills. In this paper, we illustrate Blackbird s language matrices (BLMs), a novel grammatical dataset developed to test a linguistic variant of Raven s progressive matrices, an intelligence test usually based on visual stimuli. The dataset consists of … Cites: ‪Disentangled Sequence to Sequence Learning for Compositional …‬&lt;/p&gt;</content><author><name>P Merlo, A An, MA Rodriguez - arXiv preprint arXiv:2205.10866, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Current successes of machine learning architectures are based on computationally expensive algorithms and prohibitively large amounts of data. We need to develop tasks and data to train networks to reach more complex and more compositional skills. In this paper, we illustrate Blackbird s language matrices (BLMs), a novel grammatical dataset developed to test a linguistic variant of Raven s progressive matrices, an intelligence test usually based on visual stimuli. The dataset consists of … Cites: ‪Disentangled Sequence to Sequence Learning for Compositional …‬</summary></entry><entry><title type="html">Generative Steganography Based on Long Readable Text Generation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/943d1ab6369bf9bfa0a901332f0ad721.html" rel="alternate" type="text/html" title="Generative Steganography Based on Long Readable Text Generation" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/943d1ab6369bf9bfa0a901332f0ad721</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/943d1ab6369bf9bfa0a901332f0ad721.html">&lt;p&gt;Text steganography has received a lot of attention in the application of covert communication. How to ensure desirable capacity and imperceptibility has become a key issue in text steganography. There are two typical approaches, ie, text-selection-based steganography and text-generation-based steganography. However, the text-selection-based approaches generally have the very low hidden capacity and are not applicable in practical scenarios. Although the text-generation-based … Cites: ‪Word n-gram attention models for sentence similarity and inference‬&lt;/p&gt;</content><author><name>Y Cao, Z Zhou, C Chakraborty, M Wang, QMJ Wu… - IEEE Transactions on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Text steganography has received a lot of attention in the application of covert communication. How to ensure desirable capacity and imperceptibility has become a key issue in text steganography. There are two typical approaches, ie, text-selection-based steganography and text-generation-based steganography. However, the text-selection-based approaches generally have the very low hidden capacity and are not applicable in practical scenarios. Although the text-generation-based … Cites: ‪Word n-gram attention models for sentence similarity and inference‬</summary></entry><entry><title type="html">A Quadrature Rule combining Control Variates and Adaptive Importance Sampling</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/94a26f6530efd050df9f50eabc59fe59.html" rel="alternate" type="text/html" title="A Quadrature Rule combining Control Variates and Adaptive Importance Sampling" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/94a26f6530efd050df9f50eabc59fe59</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/94a26f6530efd050df9f50eabc59fe59.html">&lt;p&gt;Driven by several successful applications such as in stochastic gradient descent or in Bayesian computation, control variates have become a major tool for Monte Carlo integration. However, standard methods do not allow the distribution of the particles to evolve during the algorithm, as is the case in sequential simulation methods. Within the standard adaptive importance sampling framework, a simple weighted least squares approach is proposed to improve the procedure with control variates … Cites: ‪Action-depedent Control Variates for Policy Optimization via Stein s …‬&lt;/p&gt;</content><author><name>R Leluc, F Portier, J Segers, A Zhuman - arXiv preprint arXiv:2205.11890, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Driven by several successful applications such as in stochastic gradient descent or in Bayesian computation, control variates have become a major tool for Monte Carlo integration. However, standard methods do not allow the distribution of the particles to evolve during the algorithm, as is the case in sequential simulation methods. Within the standard adaptive importance sampling framework, a simple weighted least squares approach is proposed to improve the procedure with control variates … Cites: ‪Action-depedent Control Variates for Policy Optimization via Stein s …‬</summary></entry><entry><title type="html">CORAL: Contextual Response Retrievability Loss Function for Training Dialog Generation Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/98d62422a6a7625e3a476ce9fc6d0a42.html" rel="alternate" type="text/html" title="CORAL: Contextual Response Retrievability Loss Function for Training Dialog Generation Models" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/98d62422a6a7625e3a476ce9fc6d0a42</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/98d62422a6a7625e3a476ce9fc6d0a42.html">&lt;p&gt;Natural Language Generation (NLG) represents a large collection of tasks in the field of NLP. While many of these tasks have been tackled well by the cross-entropy (CE) loss, the task of dialog generation poses a few unique challenges for this loss function. First, CE loss assumes that for any given input, the only possible output is the one available as the ground truth in the training dataset. In general, this is not true for any task, as there can be multiple semantically equivalent sentences, each … Cites: ‪MultiTalk: A Highly-Branching Dialog Testbed for Diverse …‬&lt;/p&gt;</content><author><name>B Santra, R Ghadia, A Dwivedi, M Gupta, P Goyal - arXiv preprint arXiv:2205.10558, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Natural Language Generation (NLG) represents a large collection of tasks in the field of NLP. While many of these tasks have been tackled well by the cross-entropy (CE) loss, the task of dialog generation poses a few unique challenges for this loss function. First, CE loss assumes that for any given input, the only possible output is the one available as the ground truth in the training dataset. In general, this is not true for any task, as there can be multiple semantically equivalent sentences, each … Cites: ‪MultiTalk: A Highly-Branching Dialog Testbed for Diverse …‬</summary></entry><entry><title type="html">Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/9954580fa4f16a03ff1fa1dcf9a9fb75.html" rel="alternate" type="text/html" title="Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/9954580fa4f16a03ff1fa1dcf9a9fb75</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/9954580fa4f16a03ff1fa1dcf9a9fb75.html">&lt;p&gt;Despite their impressive capabilities, large pre-trained language models (LMs) struggle with consistent reasoning; recently, prompting LMs to generate explanations that self-guide the inference has emerged as a promising direction to amend this. However, these approaches are fundamentally bounded by the correctness of explanations, which themselves are often noisy and inconsistent. In this work, we develop Maieutic Prompting, which infers a correct answer to a question even from … Cites: ‪Palm: Scaling language modeling with pathways‬&lt;/p&gt;</content><author><name>J Jung, L Qin, S Welleck, F Brahman, C Bhagavatula… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Despite their impressive capabilities, large pre-trained language models (LMs) struggle with consistent reasoning; recently, prompting LMs to generate explanations that self-guide the inference has emerged as a promising direction to amend this. However, these approaches are fundamentally bounded by the correctness of explanations, which themselves are often noisy and inconsistent. In this work, we develop Maieutic Prompting, which infers a correct answer to a question even from … Cites: ‪Palm: Scaling language modeling with pathways‬</summary></entry><entry><title type="html">Set-based Meta-Interpolation for Few-Task Meta-Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/9ccead1cd72eac53bee0b8cf52cf6a4c.html" rel="alternate" type="text/html" title="Set-based Meta-Interpolation for Few-Task Meta-Learning" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/9ccead1cd72eac53bee0b8cf52cf6a4c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/9ccead1cd72eac53bee0b8cf52cf6a4c.html">&lt;p&gt;Meta-learning approaches enable machine learning systems to adapt to new tasks given few examples by leveraging knowledge from related tasks. However, a large number of meta-training tasks are still required for generalization to unseen tasks during meta-testing, which introduces a critical bottleneck for real-world problems that come with only few tasks, due to various reasons including the difficulty and cost of constructing tasks. Recently, several task augmentation methods have been … Cites: ‪DReCa: A general task augmentation strategy for few-shot natural …‬&lt;/p&gt;</content><author><name>S Lee, B Andreis, K Kawaguchi, J Lee, SJ Hwang - arXiv preprint arXiv:2205.09990, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Meta-learning approaches enable machine learning systems to adapt to new tasks given few examples by leveraging knowledge from related tasks. However, a large number of meta-training tasks are still required for generalization to unseen tasks during meta-testing, which introduces a critical bottleneck for real-world problems that come with only few tasks, due to various reasons including the difficulty and cost of constructing tasks. Recently, several task augmentation methods have been … Cites: ‪DReCa: A general task augmentation strategy for few-shot natural …‬</summary></entry><entry><title type="html">HiVLP: Hierarchical Vision-Language Pre-Training for Fast Image-Text Retrieval</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/9ea52e6bf59f5cc0c9940260bf6fb824.html" rel="alternate" type="text/html" title="HiVLP: Hierarchical Vision-Language Pre-Training for Fast Image-Text Retrieval" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/9ea52e6bf59f5cc0c9940260bf6fb824</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/9ea52e6bf59f5cc0c9940260bf6fb824.html">&lt;p&gt;In the past few years, the emergence of vision-language pre-training (VLP) has brought cross-modal retrieval to a new era. However, due to the latency and computation demand, it is commonly challenging to apply VLP in a real-time online retrieval system. To alleviate the defect, this paper proposes a\textbf {Hi} erarchical\textbf {V} ision-\textbf {} Language\textbf {P} re-Training (\textbf {HiVLP}) for fast Image-Text Retrieval (ITR). Specifically, we design a novel hierarchical retrieval … Cites: ‪How Much Can CLIP Benefit Vision-and-Language Tasks?‬&lt;/p&gt;</content><author><name>F Chen, X Chen, J Shi, D Zhang, J Chang, Q Tian - arXiv preprint arXiv:2205.12105, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In the past few years, the emergence of vision-language pre-training (VLP) has brought cross-modal retrieval to a new era. However, due to the latency and computation demand, it is commonly challenging to apply VLP in a real-time online retrieval system. To alleviate the defect, this paper proposes a\textbf {Hi} erarchical\textbf {V} ision-\textbf {} Language\textbf {P} re-Training (\textbf {HiVLP}) for fast Image-Text Retrieval (ITR). Specifically, we design a novel hierarchical retrieval … Cites: ‪How Much Can CLIP Benefit Vision-and-Language Tasks?‬</summary></entry><entry><title type="html">BBTv2: Pure Black-Box Optimization Can Be Comparable to Gradient Descent for Few-Shot Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/9ffde3656b97c8cc0503ebd6551e676e.html" rel="alternate" type="text/html" title="BBTv2: Pure Black-Box Optimization Can Be Comparable to Gradient Descent for Few-Shot Learning" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/9ffde3656b97c8cc0503ebd6551e676e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/9ffde3656b97c8cc0503ebd6551e676e.html">&lt;p&gt;Black-Box Tuning (BBT) is a derivative-free approach to optimize continuous prompt tokens prepended to the input of language models. Although BBT has achieved comparable performance to full model tuning on simple classification tasks under few-shot settings, it requires pre-trained prompt embedding to match model tuning on hard tasks (eg, entailment tasks), and therefore does not completely get rid of the dependence on gradients. In this paper we present BBTv2, a pure black-box … Cites: ‪Cpm-2: Large-scale cost-effective pre-trained language models‬&lt;/p&gt;</content><author><name>T Sun, Z He, H Qian, X Huang, X Qiu - arXiv preprint arXiv:2205.11200, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Black-Box Tuning (BBT) is a derivative-free approach to optimize continuous prompt tokens prepended to the input of language models. Although BBT has achieved comparable performance to full model tuning on simple classification tasks under few-shot settings, it requires pre-trained prompt embedding to match model tuning on hard tasks (eg, entailment tasks), and therefore does not completely get rid of the dependence on gradients. In this paper we present BBTv2, a pure black-box … Cites: ‪Cpm-2: Large-scale cost-effective pre-trained language models‬</summary></entry><entry><title type="html">A Template-based Method for Constrained Neural Machine Translation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/a2a4c5d04557dfd231e8e4ff4dc476f9.html" rel="alternate" type="text/html" title="A Template-based Method for Constrained Neural Machine Translation" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/a2a4c5d04557dfd231e8e4ff4dc476f9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/a2a4c5d04557dfd231e8e4ff4dc476f9.html">&lt;p&gt;Machine translation systems are expected to cope with various types of constraints in many practical scenarios. While neural machine translation (NMT) has achieved strong performance in unconstrained cases, it is non-trivial to impose pre-specified constraints into the translation process of NMT models. Although many approaches have been proposed to address this issue, most existing methods can not satisfy the following three desiderata at the same time:(1) high translation quality,(2) high match … Cites: ‪A high-quality multilingual dataset for structured documentation …‬&lt;/p&gt;</content><author><name>S Wang, P Li, Z Tan, Z Tu, M Sun, Y Liu - arXiv preprint arXiv:2205.11255, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Machine translation systems are expected to cope with various types of constraints in many practical scenarios. While neural machine translation (NMT) has achieved strong performance in unconstrained cases, it is non-trivial to impose pre-specified constraints into the translation process of NMT models. Although many approaches have been proposed to address this issue, most existing methods can not satisfy the following three desiderata at the same time:(1) high translation quality,(2) high match … Cites: ‪A high-quality multilingual dataset for structured documentation …‬</summary></entry><entry><title type="html">Summarization as Indirect Supervision for Relation Extraction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/a33c306e8b176e150c07278309809ac5.html" rel="alternate" type="text/html" title="Summarization as Indirect Supervision for Relation Extraction" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/a33c306e8b176e150c07278309809ac5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/a33c306e8b176e150c07278309809ac5.html">&lt;p&gt;Relation extraction (RE) models have been challenged by their reliance on training data with expensive annotations. Considering that summarization tasks aim at acquiring concise expressions of synoptical information from the longer context, these tasks naturally align with the objective of RE, ie, extracting a kind of synoptical information that describes the relation of entity mentions. We present SuRE, which converts RE into a summarization formulation. SuRE leads to more precise and … Cites: ‪Universal natural language processing with limited annotations …‬&lt;/p&gt;</content><author><name>K Lu, I Hsu, W Zhou, MD Ma, M Chen - arXiv preprint arXiv:2205.09837, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Relation extraction (RE) models have been challenged by their reliance on training data with expensive annotations. Considering that summarization tasks aim at acquiring concise expressions of synoptical information from the longer context, these tasks naturally align with the objective of RE, ie, extracting a kind of synoptical information that describes the relation of entity mentions. We present SuRE, which converts RE into a summarization formulation. SuRE leads to more precise and … Cites: ‪Universal natural language processing with limited annotations …‬</summary></entry><entry><title type="html">Few-shot learning with language models: Learning from instructions and contexts</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/aaede62b81b67c324697ebe12d6f593d.html" rel="alternate" type="text/html" title="Few-shot learning with language models: Learning from instructions and contexts" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/aaede62b81b67c324697ebe12d6f593d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/aaede62b81b67c324697ebe12d6f593d.html">&lt;p&gt;Pretraining deep neural networks to perform language modeling–that is, to reconstruct missing words from incomplete pieces of text–has brought large improvements throughout natural language processing (NLP). However, even pretrained models typically do not achieve satisfactory performance in few-shot settings, where only a limited number of examples is available. This is an important issue not only because the need to annotate thousands of examples is a barrier to … Cites: ‪Noisy channel language model prompting for few-shot text …‬&lt;/p&gt;</content><author><name>T Schick - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pretraining deep neural networks to perform language modeling–that is, to reconstruct missing words from incomplete pieces of text–has brought large improvements throughout natural language processing (NLP). However, even pretrained models typically do not achieve satisfactory performance in few-shot settings, where only a limited number of examples is available. This is an important issue not only because the need to annotate thousands of examples is a barrier to … Cites: ‪Noisy channel language model prompting for few-shot text …‬</summary></entry><entry><title type="html">IMPROVED METHODS TO AID UNSUPERVISED EVIDENCE-BASED FACT CHECKING FOR ONLINE HEALTH NEWS</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ab2ab848f9139952a46ab79737eb13ed.html" rel="alternate" type="text/html" title="IMPROVED METHODS TO AID UNSUPERVISED EVIDENCE-BASED FACT CHECKING FOR ONLINE HEALTH NEWS" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ab2ab848f9139952a46ab79737eb13ed</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ab2ab848f9139952a46ab79737eb13ed.html">&lt;p&gt;False information in the domain of online health related articles is of great concern, which has been witnessed abundantly in the current pandemic situation of Covid-19. Recent advancements in the field of Machine Learning and Natural Language Processing can be leveraged to aid people in distinguishing false information from the truth in the domain of online health articles. Whilst there has been substantial progress in this space over the years, research in this area has mainly focused on … Cites: ‪LongChecker: Improving scientific claim verification by modeling …‬&lt;/p&gt;</content><author><name>P DEKA, A JUREK-LOUGHREY, P DEEPAK - Journal of Data Intelligence, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">False information in the domain of online health related articles is of great concern, which has been witnessed abundantly in the current pandemic situation of Covid-19. Recent advancements in the field of Machine Learning and Natural Language Processing can be leveraged to aid people in distinguishing false information from the truth in the domain of online health articles. Whilst there has been substantial progress in this space over the years, research in this area has mainly focused on … Cites: ‪LongChecker: Improving scientific claim verification by modeling …‬</summary></entry><entry><title type="html">On the SDEs and Scaling Rules for Adaptive Gradient Algorithms</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/acab68de4ff803d5583ff161017b4fc3.html" rel="alternate" type="text/html" title="On the SDEs and Scaling Rules for Adaptive Gradient Algorithms" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/acab68de4ff803d5583ff161017b4fc3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/acab68de4ff803d5583ff161017b4fc3.html">&lt;p&gt;Approximating Stochastic Gradient Descent (SGD) as a Stochastic Differential Equation (SDE) has allowed researchers to enjoy the benefits of studying a continuous optimization trajectory while carefully preserving the stochasticity of SGD. Analogous study of adaptive gradient methods, such as RMSprop and Adam, has been challenging because there were no rigorously proven SDE approximations for these methods. This paper derives the SDE approximations for RMSprop and Adam … Cites: ‪Should You Mask 15% in Masked Language Modeling?‬&lt;/p&gt;</content><author><name>S Malladi, K Lyu, A Panigrahi, S Arora - arXiv preprint arXiv:2205.10287, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Approximating Stochastic Gradient Descent (SGD) as a Stochastic Differential Equation (SDE) has allowed researchers to enjoy the benefits of studying a continuous optimization trajectory while carefully preserving the stochasticity of SGD. Analogous study of adaptive gradient methods, such as RMSprop and Adam, has been challenging because there were no rigorously proven SDE approximations for these methods. This paper derives the SDE approximations for RMSprop and Adam … Cites: ‪Should You Mask 15% in Masked Language Modeling?‬</summary></entry><entry><title type="html">An Extensive Assessment of Network Embedding in PPI Network Alignment</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ad4e0a21aa7adf4b57dcfb32e394a279.html" rel="alternate" type="text/html" title="An Extensive Assessment of Network Embedding in PPI Network Alignment" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ad4e0a21aa7adf4b57dcfb32e394a279</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ad4e0a21aa7adf4b57dcfb32e394a279.html">&lt;p&gt;Network alignment is a fundamental task in network analysis. In the biological field, where the protein–protein interaction (PPI) is represented as a graph, network alignment allowed the discovery of underlying biological knowledge such as conserved evolutionary pathways and functionally conserved proteins throughout different species. A recent trend in network science concerns network embedding, ie, the modelling of nodes in a network as a low-dimensional feature vector. In this … Cites: ‪A regularization framework for learning from graph data‬&lt;/p&gt;</content><author><name>M Milano, C Zucco, M Settino, M Cannataro - Entropy, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Network alignment is a fundamental task in network analysis. In the biological field, where the protein–protein interaction (PPI) is represented as a graph, network alignment allowed the discovery of underlying biological knowledge such as conserved evolutionary pathways and functionally conserved proteins throughout different species. A recent trend in network science concerns network embedding, ie, the modelling of nodes in a network as a low-dimensional feature vector. In this … Cites: ‪A regularization framework for learning from graph data‬</summary></entry><entry><title type="html">On the Role of Bidirectionality in Language Model Pre-Training</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ad6668f3d36979456a947aa420212d86.html" rel="alternate" type="text/html" title="On the Role of Bidirectionality in Language Model Pre-Training" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ad6668f3d36979456a947aa420212d86</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ad6668f3d36979456a947aa420212d86.html">&lt;p&gt;Prior work on language model pre-training has explored different architectures and learning objectives, but differences in data, hyperparameters and evaluation make a principled comparison difficult. In this work, we focus on bidirectionality as a key …&lt;/p&gt;</content><author><name>M Artetxe, J Du, N Goyal, L Zettlemoyer, V Stoyanov - arXiv preprint arXiv:2205.11726, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Prior work on language model pre-training has explored different architectures and learning objectives, but differences in data, hyperparameters and evaluation make a principled comparison difficult. In this work, we focus on bidirectionality as a key …</summary></entry><entry><title type="html">A benchmark and comprehensive survey on knowledge graph entity alignment via representation learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ad88799c824ed74fded7be8691faf8e2.html" rel="alternate" type="text/html" title="A benchmark and comprehensive survey on knowledge graph entity alignment via representation learning" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ad88799c824ed74fded7be8691faf8e2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ad88799c824ed74fded7be8691faf8e2.html">&lt;p&gt;In the last few years, the interest in knowledge bases has grown exponentially in both the research community and the industry due to their essential role in AI applications. Entity alignment is an important task for enriching knowledge bases. This paper provides a comprehensive tutorial-type survey on representative entity alignment techniques that use the new approach of representation learning. We present a framework for capturing the key characteristics of these techniques … Cites: ‪Exploring and Evaluating Attributes, Values, and Structures for …‬&lt;/p&gt;</content><author><name>R Zhang, BD Trisedya, M Li, Y Jiang, J Qi - The VLDB Journal, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In the last few years, the interest in knowledge bases has grown exponentially in both the research community and the industry due to their essential role in AI applications. Entity alignment is an important task for enriching knowledge bases. This paper provides a comprehensive tutorial-type survey on representative entity alignment techniques that use the new approach of representation learning. We present a framework for capturing the key characteristics of these techniques … Cites: ‪Exploring and Evaluating Attributes, Values, and Structures for …‬</summary></entry><entry><title type="html">Learning Context-Aware Service Representation for Service Recommendation in Workflow Composition</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/adc07b41c63a38d69686884213f99802.html" rel="alternate" type="text/html" title="Learning Context-Aware Service Representation for Service Recommendation in Workflow Composition" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/adc07b41c63a38d69686884213f99802</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/adc07b41c63a38d69686884213f99802.html">&lt;p&gt;As increasingly more software services have been published onto the Internet, it remains a significant challenge to recommend suitable services to facilitate scientific workflow composition. This paper proposes a novel NLP-inspired approach to recommending services throughout a workflow development process, based on incrementally learning latent service representation from workflow provenance. A workflow composition process is formalized as a step-wise, context-aware service … Cites: ‪Representation Learning for the Semantic Web‬&lt;/p&gt;</content><author><name>X Xie, J Zhang, R Ramachandran, TJ Lee, S Lee - arXiv preprint arXiv:2205.11771, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As increasingly more software services have been published onto the Internet, it remains a significant challenge to recommend suitable services to facilitate scientific workflow composition. This paper proposes a novel NLP-inspired approach to recommending services throughout a workflow development process, based on incrementally learning latent service representation from workflow provenance. A workflow composition process is formalized as a step-wise, context-aware service … Cites: ‪Representation Learning for the Semantic Web‬</summary></entry><entry><title type="html">Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ae4afd6995caf090c43ff91b73dbaaec.html" rel="alternate" type="text/html" title="Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ae4afd6995caf090c43ff91b73dbaaec</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ae4afd6995caf090c43ff91b73dbaaec.html">&lt;p&gt;Despite their strong performance on many tasks, pre-trained language models have been shown to struggle on out-of-distribution compositional generalization. Meanwhile, recent work has shown considerable improvements on many NLP tasks from model scaling. Can scaling up model size also improve compositional generalization in semantic parsing? We evaluate encoder-decoder models up to 11B parameters and decoder-only models up to 540B parameters, and compare model … Cites: ‪Rethinking the Role of Demonstrations: What Makes In-Context …‬&lt;/p&gt;</content><author><name>L Qiu, P Shaw, P Pasupat, T Shi, J Herzig, E Pitler… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Despite their strong performance on many tasks, pre-trained language models have been shown to struggle on out-of-distribution compositional generalization. Meanwhile, recent work has shown considerable improvements on many NLP tasks from model scaling. Can scaling up model size also improve compositional generalization in semantic parsing? We evaluate encoder-decoder models up to 11B parameters and decoder-only models up to 540B parameters, and compare model … Cites: ‪Rethinking the Role of Demonstrations: What Makes In-Context …‬</summary></entry><entry><title type="html">Many-Class Text Classification with Matching</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b19f4a5715fd41868d2cedc3e743ab2a.html" rel="alternate" type="text/html" title="Many-Class Text Classification with Matching" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b19f4a5715fd41868d2cedc3e743ab2a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b19f4a5715fd41868d2cedc3e743ab2a.html">&lt;p&gt;In this work, we formulate\textbf {T} ext\textbf {C} lassification as a\textbf {M} atching problem between the text and the labels, and propose a simple yet effective framework named TCM. Compared with previous text classification approaches, TCM takes advantage of the fine-grained semantic information of the classification labels, which helps distinguish each class better when the class number is large, especially in low-resource scenarios. TCM is also easy to implement and is … Cites: ‪PPT: Pre-trained Prompt Tuning for Few-shot Learning‬&lt;/p&gt;</content><author><name>Y Song, Y Gu, M Huang - arXiv preprint arXiv:2205.11409, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this work, we formulate\textbf {T} ext\textbf {C} lassification as a\textbf {M} atching problem between the text and the labels, and propose a simple yet effective framework named TCM. Compared with previous text classification approaches, TCM takes advantage of the fine-grained semantic information of the classification labels, which helps distinguish each class better when the class number is large, especially in low-resource scenarios. TCM is also easy to implement and is … Cites: ‪PPT: Pre-trained Prompt Tuning for Few-shot Learning‬</summary></entry><entry><title type="html">Logical Reasoning with Span Predictions: Span-level Logical Atoms for Interpretable and Robust NLI Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b1e67000bfb81565f06edb7dd1368498.html" rel="alternate" type="text/html" title="Logical Reasoning with Span Predictions: Span-level Logical Atoms for Interpretable and Robust NLI Models" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b1e67000bfb81565f06edb7dd1368498</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b1e67000bfb81565f06edb7dd1368498.html">&lt;p&gt;Current Natural Language Inference (NLI) models achieve impressive results, sometimes outperforming humans when evaluating on in-distribution test sets. However, as these models are known to learn from annotation artefacts and dataset biases, it is unclear to what extent the models are learning the task of NLI instead of learning from shallow heuristics in their training data. We address this issue by introducing a logical reasoning framework for NLI, creating highly transparent model … Cites: ‪Leap-Of-Thought: Teaching Pre-Trained Models to Systematically …‬&lt;/p&gt;</content><author><name>J Stacey, P Minervini, H Dubossarsky, M Rei - arXiv preprint arXiv:2205.11432, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Current Natural Language Inference (NLI) models achieve impressive results, sometimes outperforming humans when evaluating on in-distribution test sets. However, as these models are known to learn from annotation artefacts and dataset biases, it is unclear to what extent the models are learning the task of NLI instead of learning from shallow heuristics in their training data. We address this issue by introducing a logical reasoning framework for NLI, creating highly transparent model … Cites: ‪Leap-Of-Thought: Teaching Pre-Trained Models to Systematically …‬</summary></entry><entry><title type="html">What Makes Data-to-Text Generation Hard for Pretrained Language Models?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b5307c630ef2f89c459417895101e61b.html" rel="alternate" type="text/html" title="What Makes Data-to-Text Generation Hard for Pretrained Language Models?" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b5307c630ef2f89c459417895101e61b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b5307c630ef2f89c459417895101e61b.html">&lt;p&gt;Expressing natural language descriptions of structured facts or relations–data-to-text generation (D2T)–increases the accessibility of structured knowledge repositories. Previous work shows that pre-trained language models (PLMs) perform remarkably well on this task after fine-tuning on a significant amount of task-specific training data. On the other hand, while auto-regressive PLMs can generalize from a few task examples, their efficacy at D2T is largely unexplored. Furthermore, we have an … Cites: ‪Do Massively Pretrained Language Models Make Better Storytellers?‬&lt;/p&gt;</content><author><name>M Keymanesh, A Benton, M Dredze - arXiv preprint arXiv:2205.11505, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Expressing natural language descriptions of structured facts or relations–data-to-text generation (D2T)–increases the accessibility of structured knowledge repositories. Previous work shows that pre-trained language models (PLMs) perform remarkably well on this task after fine-tuning on a significant amount of task-specific training data. On the other hand, while auto-regressive PLMs can generalize from a few task examples, their efficacy at D2T is largely unexplored. Furthermore, we have an … Cites: ‪Do Massively Pretrained Language Models Make Better Storytellers?‬</summary></entry><entry><title type="html">Business Meeting Summarisation System</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b583fe5bfd68237cb034123b6f334e18.html" rel="alternate" type="text/html" title="Business Meeting Summarisation System" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b583fe5bfd68237cb034123b6f334e18</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b583fe5bfd68237cb034123b6f334e18.html">&lt;p&gt;As the economy expands, so does the quantity of production and sales in a firm; as a result, a substantial number of business meetings are conducted day-to-day to make crucial choices. The importance of business meetings cannot be overstated. It enables you to maintain track of the organization s processes and operations to achieve the organization s goals and objectives. The business meeting findings must be kept up to date by a large number of individuals. Conventionally, people had to … Cites: ‪Sentence centrality revisited for unsupervised summarization‬&lt;/p&gt;</content><author><name>P Lodhi, S Kharche, D Kambri, S Khan - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As the economy expands, so does the quantity of production and sales in a firm; as a result, a substantial number of business meetings are conducted day-to-day to make crucial choices. The importance of business meetings cannot be overstated. It enables you to maintain track of the organization s processes and operations to achieve the organization s goals and objectives. The business meeting findings must be kept up to date by a large number of individuals. Conventionally, people had to … Cites: ‪Sentence centrality revisited for unsupervised summarization‬</summary></entry><entry><title type="html">ItemSage: Learning Product Embeddings for Shopping Recommendations at Pinterest</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b58f81805b869c87bcec457728abebc6.html" rel="alternate" type="text/html" title="ItemSage: Learning Product Embeddings for Shopping Recommendations at Pinterest" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b58f81805b869c87bcec457728abebc6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b58f81805b869c87bcec457728abebc6.html">&lt;p&gt;Learned embeddings for products are an important building block for web-scale e-commerce recommendation systems. At Pinterest, we build a single set of product embeddings called ItemSage to provide relevant recommendations in all shopping use cases including user, image and search based recommendations. This approach has led to significant improvements in engagement and conversion metrics, while reducing both infrastructure and maintenance cost. While most prior … Cites: ‪LXMERT: Learning Cross-Modality Encoder Representations from …‬&lt;/p&gt;</content><author><name>P Baltescu, H Chen, N Pancha, A Zhai, J Leskovec… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Learned embeddings for products are an important building block for web-scale e-commerce recommendation systems. At Pinterest, we build a single set of product embeddings called ItemSage to provide relevant recommendations in all shopping use cases including user, image and search based recommendations. This approach has led to significant improvements in engagement and conversion metrics, while reducing both infrastructure and maintenance cost. While most prior … Cites: ‪LXMERT: Learning Cross-Modality Encoder Representations from …‬</summary></entry><entry><title type="html">TempLM: Distilling Language Models into Template-Based Generators</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b626fd33c01b6cf12b2f98b7f438ccc2.html" rel="alternate" type="text/html" title="TempLM: Distilling Language Models into Template-Based Generators" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b626fd33c01b6cf12b2f98b7f438ccc2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b626fd33c01b6cf12b2f98b7f438ccc2.html">&lt;p&gt;While pretrained language models (PLMs) have greatly improved text generation, they have also been known to produce unfaithful or inappropriate content. In contrast, classic template-based systems provide strong guarantees of faithfulness at the cost of fluency. We propose TempLM, which achieves the best of both worlds by distilling a PLM into a template-based generator. On the E2E and SynthBio data-to-text datasets, we show that TempLM is more faithful than the original PLM and is … Cites: ‪Data-to-text generation with content selection and planning‬&lt;/p&gt;</content><author><name>T Zhang, M Lee, L Li, E Shen, TB Hashimoto - arXiv preprint arXiv:2205.11055, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">While pretrained language models (PLMs) have greatly improved text generation, they have also been known to produce unfaithful or inappropriate content. In contrast, classic template-based systems provide strong guarantees of faithfulness at the cost of fluency. We propose TempLM, which achieves the best of both worlds by distilling a PLM into a template-based generator. On the E2E and SynthBio data-to-text datasets, we show that TempLM is more faithful than the original PLM and is … Cites: ‪Data-to-text generation with content selection and planning‬</summary></entry><entry><title type="html">A spatio-temporal LSTM model to forecast across multiple temporal and spatial scales</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b75a09f080346383f32ebdbaacaae6e4.html" rel="alternate" type="text/html" title="A spatio-temporal LSTM model to forecast across multiple temporal and spatial scales" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b75a09f080346383f32ebdbaacaae6e4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/b75a09f080346383f32ebdbaacaae6e4.html">&lt;p&gt;This paper presents a novel spatio-temporal LSTM (SPATIAL) architecture for time series forecasting applied to environmental datasets. The framework was applied for three different ocean datasets: current speed, temperature, and dissolved oxygen. Network implementation proceeded in two directions that are nominally separated but connected as part of a natural environmental system–across the spatial (between individual sensors) and temporal dimensions of the sensor data. Data from twenty … Cites: ‪AlphaD3M: Machine learning pipeline synthesis‬&lt;/p&gt;</content><author><name>F O Donncha, Y Hu, P Palmes, M Burke, R Filgueira… - Ecological Informatics, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper presents a novel spatio-temporal LSTM (SPATIAL) architecture for time series forecasting applied to environmental datasets. The framework was applied for three different ocean datasets: current speed, temperature, and dissolved oxygen. Network implementation proceeded in two directions that are nominally separated but connected as part of a natural environmental system–across the spatial (between individual sensors) and temporal dimensions of the sensor data. Data from twenty … Cites: ‪AlphaD3M: Machine learning pipeline synthesis‬</summary></entry><entry><title type="html">Generating Content-Preserving and Semantics-Flipping Adversarial Text</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ba5179cd5575daa569356a44c92955da.html" rel="alternate" type="text/html" title="Generating Content-Preserving and Semantics-Flipping Adversarial Text" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ba5179cd5575daa569356a44c92955da</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ba5179cd5575daa569356a44c92955da.html">&lt;p&gt;ABSTRACT Natural Language Processing (NLP) models are often vulnerable to semantics-preserving adversarial attacks. That is, they make different semantic predictions on input instances with similar content and semantics. However, it remains unclear to which extent modern NLP models are vulnerable to content-preserving and semantics-flipping (CPSF) adversarial attacks. That is, they would make the same semantic prediction on input instances with similar content but … Cites: ‪Adversarial Example Generation with Syntactically Controlled …‬&lt;/p&gt;</content><author><name>W Pei, C Yue - Proceedings of the 2022 ACM on Asia Conference on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">ABSTRACT Natural Language Processing (NLP) models are often vulnerable to semantics-preserving adversarial attacks. That is, they make different semantic predictions on input instances with similar content and semantics. However, it remains unclear to which extent modern NLP models are vulnerable to content-preserving and semantics-flipping (CPSF) adversarial attacks. That is, they would make the same semantic prediction on input instances with similar content but … Cites: ‪Adversarial Example Generation with Syntactically Controlled …‬</summary></entry><entry><title type="html">Chunk-based Nearest Neighbor Machine Translation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/c098366e56e3bfc72346ba2e896029c1.html" rel="alternate" type="text/html" title="Chunk-based Nearest Neighbor Machine Translation" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/c098366e56e3bfc72346ba2e896029c1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/c098366e56e3bfc72346ba2e896029c1.html">&lt;p&gt;Semi-parametric models, which augment generation with retrieval, have led to impressive results in language modeling and machine translation, due to their ability to leverage information retrieved from a datastore of examples. One of the most prominent approaches, $ k $ NN-MT, has an outstanding performance on domain adaptation by retrieving tokens from a domain-specific datastore\citep {khandelwal2020nearest}. However, $ k $ NN-MT requires retrieval for every single … Cites: ‪Topic models for dynamic translation model adaptation‬&lt;/p&gt;</content><author><name>PH Martins, Z Marinho, AFT Martins - arXiv preprint arXiv:2205.12230, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Semi-parametric models, which augment generation with retrieval, have led to impressive results in language modeling and machine translation, due to their ability to leverage information retrieved from a datastore of examples. One of the most prominent approaches, $ k $ NN-MT, has an outstanding performance on domain adaptation by retrieving tokens from a domain-specific datastore\citep {khandelwal2020nearest}. However, $ k $ NN-MT requires retrieval for every single … Cites: ‪Topic models for dynamic translation model adaptation‬</summary></entry><entry><title type="html">Geometric Signal Processing with Graph Neural Networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/c4d59d82adffe19e759f0e29fbe1d162.html" rel="alternate" type="text/html" title="Geometric Signal Processing with Graph Neural Networks" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/c4d59d82adffe19e759f0e29fbe1d162</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/c4d59d82adffe19e759f0e29fbe1d162.html">&lt;p&gt;One of the most predominant techniques that have achieved phenomenal success in many modern applications is deep learning. The obsession with massive data analysis in image recognition, speech processing, and text understanding spawns remarkable advances in deep learning of diverse research areas. The alliance of deep learning technologies yields mighty graph neural networks (GNNs), an emerging type of deep neural networks that encodes internal structural relationships … Cites: ‪Blockwise Self-Attention for Long Document Understanding‬&lt;/p&gt;</content><author><name>B Zhou - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">One of the most predominant techniques that have achieved phenomenal success in many modern applications is deep learning. The obsession with massive data analysis in image recognition, speech processing, and text understanding spawns remarkable advances in deep learning of diverse research areas. The alliance of deep learning technologies yields mighty graph neural networks (GNNs), an emerging type of deep neural networks that encodes internal structural relationships … Cites: ‪Blockwise Self-Attention for Long Document Understanding‬</summary></entry><entry><title type="html">Commonsense Knowledge Salience Evaluation with a Benchmark Dataset in E-commerce</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/c75e9919eb3eb0d13fa9f25b77cf9a45.html" rel="alternate" type="text/html" title="Commonsense Knowledge Salience Evaluation with a Benchmark Dataset in E-commerce" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/c75e9919eb3eb0d13fa9f25b77cf9a45</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/c75e9919eb3eb0d13fa9f25b77cf9a45.html">&lt;p&gt;In e-commerce, the salience of commonsense knowledge (CSK) is beneficial for widespread applications such as product search and recommendation. For example, when users search for  running  in e-commerce, they would like to find items highly related to running, such as  running shoes  rather than  shoes . However, many existing CSK collections rank statements solely by confidence scores, and there is no information about which ones are salient from a human perspective. In this work, we … Cites: ‪Relation prediction as an auxiliary training objective for improving …‬&lt;/p&gt;</content><author><name>Y Qu, N Zhang, H Chen, Z Dai, Z Xu, C Wang, X Wang… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In e-commerce, the salience of commonsense knowledge (CSK) is beneficial for widespread applications such as product search and recommendation. For example, when users search for running in e-commerce, they would like to find items highly related to running, such as running shoes rather than shoes . However, many existing CSK collections rank statements solely by confidence scores, and there is no information about which ones are salient from a human perspective. In this work, we … Cites: ‪Relation prediction as an auxiliary training objective for improving …‬</summary></entry><entry><title type="html">GraB: Finding Provably Better Data Permutations than Random Reshuffling</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/c97008eb71b068d2db76d21cbc99dbdb.html" rel="alternate" type="text/html" title="GraB: Finding Provably Better Data Permutations than Random Reshuffling" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/c97008eb71b068d2db76d21cbc99dbdb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/c97008eb71b068d2db76d21cbc99dbdb.html">&lt;p&gt;Random reshuffling, which randomly permutes the dataset each epoch, is widely adopted in model training because it yields faster convergence than with-replacement sampling. Recent studies indicate greedily chosen data orderings can further speed up convergence empirically, at the cost of using more computation and memory. However, greedy ordering lacks theoretical justification and has limited utility due to its non-trivial memory and computation overhead. In this paper, we first … Cites: ‪Well-read students learn better: On the importance of pre-training …‬&lt;/p&gt;</content><author><name>Y Lu, W Guo, C De Sa - arXiv preprint arXiv:2205.10733, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Random reshuffling, which randomly permutes the dataset each epoch, is widely adopted in model training because it yields faster convergence than with-replacement sampling. Recent studies indicate greedily chosen data orderings can further speed up convergence empirically, at the cost of using more computation and memory. However, greedy ordering lacks theoretical justification and has limited utility due to its non-trivial memory and computation overhead. In this paper, we first … Cites: ‪Well-read students learn better: On the importance of pre-training …‬</summary></entry><entry><title type="html">Learning to Reverse DNNs from AI Programs Automatically</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cb35d68e9fc0880561b2c7ccbd42fc87.html" rel="alternate" type="text/html" title="Learning to Reverse DNNs from AI Programs Automatically" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cb35d68e9fc0880561b2c7ccbd42fc87</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cb35d68e9fc0880561b2c7ccbd42fc87.html">&lt;p&gt;With the privatization deployment of DNNs on edge devices, the security of on-device DNNs has raised significant concern. To quantify the model leakage risk of on-device DNNs automatically, we propose NNReverse, the first learning-based method which can reverse DNNs from AI programs without domain knowledge. NNReverse trains a representation model to represent the semantics of binary code for DNN layers. By searching the most similar function in our database, NNReverse infers the layer type … Cites: ‪Thieves on Sesame Street! Model Extraction of BERT-based APIs‬&lt;/p&gt;</content><author><name>S Chen, H Khanpour, C Liu, W Yang - arXiv preprint arXiv:2205.10364, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">With the privatization deployment of DNNs on edge devices, the security of on-device DNNs has raised significant concern. To quantify the model leakage risk of on-device DNNs automatically, we propose NNReverse, the first learning-based method which can reverse DNNs from AI programs without domain knowledge. NNReverse trains a representation model to represent the semantics of binary code for DNN layers. By searching the most similar function in our database, NNReverse infers the layer type … Cites: ‪Thieves on Sesame Street! Model Extraction of BERT-based APIs‬</summary></entry><entry><title type="html">KOLD: Korean Offensive Language Dataset</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cc0619a5537ad4493f2dfcdb4d6741c6.html" rel="alternate" type="text/html" title="KOLD: Korean Offensive Language Dataset" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cc0619a5537ad4493f2dfcdb4d6741c6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cc0619a5537ad4493f2dfcdb4d6741c6.html">&lt;p&gt;Although large attention has been paid to the detection of hate speech, most work has been done in English, failing to make it applicable to other languages. To fill this gap, we present a Korean offensive language dataset (KOLD), 40k comments labeled with offensiveness, target, and targeted group information. We also collect two types of span, offensive and target span that justifies the decision of the categorization within the text. Comparing the distribution of targeted groups with the … Cites: ‪Annotators with attitudes: How annotator beliefs and identities bias …‬&lt;/p&gt;</content><author><name>Y Jeong, J Oh, J Ahn, J Lee, J Mon, S Park, A Oh - arXiv preprint arXiv:2205.11315, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Although large attention has been paid to the detection of hate speech, most work has been done in English, failing to make it applicable to other languages. To fill this gap, we present a Korean offensive language dataset (KOLD), 40k comments labeled with offensiveness, target, and targeted group information. We also collect two types of span, offensive and target span that justifies the decision of the categorization within the text. Comparing the distribution of targeted groups with the … Cites: ‪Annotators with attitudes: How annotator beliefs and identities bias …‬</summary></entry><entry><title type="html">Transition-based Semantic Role Labeling with Pointer Networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cc7c34f0293d345adbec9e853e375010.html" rel="alternate" type="text/html" title="Transition-based Semantic Role Labeling with Pointer Networks" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cc7c34f0293d345adbec9e853e375010</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cc7c34f0293d345adbec9e853e375010.html">&lt;p&gt;Semantic role labeling (SRL) focuses on recognizing the predicate-argument structure of a sentence and plays a critical role in many natural language processing tasks such as machine translation and question answering. Practically all available methods do not perform full SRL, since they rely on pre-identified predicates, and most of them follow a pipeline strategy, using specific models for undertaking one or several SRL subtasks. In addition, previous approaches have a strong dependence … Cites: ‪A structural probe for finding syntax in word representations‬&lt;/p&gt;</content><author><name>D Fernández-González - arXiv preprint arXiv:2205.10023, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Semantic role labeling (SRL) focuses on recognizing the predicate-argument structure of a sentence and plays a critical role in many natural language processing tasks such as machine translation and question answering. Practically all available methods do not perform full SRL, since they rely on pre-identified predicates, and most of them follow a pipeline strategy, using specific models for undertaking one or several SRL subtasks. In addition, previous approaches have a strong dependence … Cites: ‪A structural probe for finding syntax in word representations‬</summary></entry><entry><title type="html">Prototypical Calibration for Few-shot Learning of Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cce020dfac079b60032b3add828add68.html" rel="alternate" type="text/html" title="Prototypical Calibration for Few-shot Learning of Language Models" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cce020dfac079b60032b3add828add68</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cce020dfac079b60032b3add828add68.html">&lt;p&gt;In-context learning of GPT-like models has been recognized as fragile across different hand-crafted templates, and demonstration permutations. In this work, we propose prototypical calibration to adaptively learn a more robust decision boundary for zero-and few-shot classification, instead of greedy decoding. Concretely, our method first adopts Gaussian mixture distribution to estimate the prototypical clusters for all categories. Then we assign each cluster to the corresponding label by solving … Cites: ‪Learning To Retrieve Prompts for In-Context Learning‬&lt;/p&gt;</content><author><name>Z Han, Y Hao, L Dong, F Wei - arXiv preprint arXiv:2205.10183, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In-context learning of GPT-like models has been recognized as fragile across different hand-crafted templates, and demonstration permutations. In this work, we propose prototypical calibration to adaptively learn a more robust decision boundary for zero-and few-shot classification, instead of greedy decoding. Concretely, our method first adopts Gaussian mixture distribution to estimate the prototypical clusters for all categories. Then we assign each cluster to the corresponding label by solving … Cites: ‪Learning To Retrieve Prompts for In-Context Learning‬</summary></entry><entry><title type="html">Active Learning Through a Covering Lens</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cd7018135c644543c1705e3151811303.html" rel="alternate" type="text/html" title="Active Learning Through a Covering Lens" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cd7018135c644543c1705e3151811303</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cd7018135c644543c1705e3151811303.html">&lt;p&gt;Deep active learning aims to reduce the annotation cost for deep neural networks, which are notoriously data-hungry. Until recently, deep active learning methods struggled in the low-budget regime, where only a small amount of samples are annotated. The situation has been alleviated by recent advances in self-supervised representation learning methods, which impart the geometry of the data representation with rich information about the points. Taking advantage of this … Cites: ‪Cold-start active learning through self-supervised language …‬&lt;/p&gt;</content><author><name>O Yehuda, A Dekel, G Hacohen, D Weinshall - arXiv preprint arXiv:2205.11320, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep active learning aims to reduce the annotation cost for deep neural networks, which are notoriously data-hungry. Until recently, deep active learning methods struggled in the low-budget regime, where only a small amount of samples are annotated. The situation has been alleviated by recent advances in self-supervised representation learning methods, which impart the geometry of the data representation with rich information about the points. Taking advantage of this … Cites: ‪Cold-start active learning through self-supervised language …‬</summary></entry><entry><title type="html">When More Data Hurts: A Troubling Quirk in Developing Broad-Coverage Natural Language Understanding Systems</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cdc4afe983f6742119cb54fb6d7da31f.html" rel="alternate" type="text/html" title="When More Data Hurts: A Troubling Quirk in Developing Broad-Coverage Natural Language Understanding Systems" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cdc4afe983f6742119cb54fb6d7da31f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cdc4afe983f6742119cb54fb6d7da31f.html">&lt;p&gt;In natural language understanding (NLU) production systems, users  evolving needs necessitate the addition of new features over time, indexed by new symbols added to the meaning representation space. This requires additional training data and results in ever-growing datasets. We present the first systematic investigation into this incremental symbol learning scenario. Our analyses reveal a troubling quirk in building (broad-coverage) NLU systems: as the training dataset grows, more data is … Cites: ‪Examining and Combating Spurious Features under Distribution Shift‬&lt;/p&gt;</content><author><name>E Stengel-Eskin, EA Platanios, A Pauls, S Thomson… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In natural language understanding (NLU) production systems, users evolving needs necessitate the addition of new features over time, indexed by new symbols added to the meaning representation space. This requires additional training data and results in ever-growing datasets. We present the first systematic investigation into this incremental symbol learning scenario. Our analyses reveal a troubling quirk in building (broad-coverage) NLU systems: as the training dataset grows, more data is … Cites: ‪Examining and Combating Spurious Features under Distribution Shift‬</summary></entry><entry><title type="html">Human and technological infrastructures of fact-checking</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cea24854463b33491d970cf038d55ae0.html" rel="alternate" type="text/html" title="Human and technological infrastructures of fact-checking" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cea24854463b33491d970cf038d55ae0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cea24854463b33491d970cf038d55ae0.html">&lt;p&gt;Increasing demands for fact-checking has led to a growing interest in developing systems and tools to automate the fact-checking process. However, such systems are limited in practice because their system design often does not take into account how fact-checking is done in the real world and ignores the insights and needs of various stakeholder groups core to the fact-checking process. This paper unpacks the fact-checking process by revealing the infrastructures–both human and technological … Cites: ‪Closing the loop: User-centered design and evaluation of a human …‬&lt;/p&gt;</content><author><name>P Juneja, T Mitra - arXiv preprint arXiv:2205.10894, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Increasing demands for fact-checking has led to a growing interest in developing systems and tools to automate the fact-checking process. However, such systems are limited in practice because their system design often does not take into account how fact-checking is done in the real world and ignores the insights and needs of various stakeholder groups core to the fact-checking process. This paper unpacks the fact-checking process by revealing the infrastructures–both human and technological … Cites: ‪Closing the loop: User-centered design and evaluation of a human …‬</summary></entry><entry><title type="html">Computer and Information Sciences</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ceb0ee9b8bb6655d1b8fca3cab849865.html" rel="alternate" type="text/html" title="Computer and Information Sciences" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ceb0ee9b8bb6655d1b8fca3cab849865</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ceb0ee9b8bb6655d1b8fca3cab849865.html">&lt;p&gt;abstract Hadoop is the most economical and cheap software framework that allows distributed storage and parallel processing of more extensive data sets. Hadoop distributed file system (HDFS) allows distributed storage and parallel processing of vast data sets using MapReduce. However, Hadoop s current implementation believes that computing nodes connected in a cluster are homogeneous and distribute the tasks equally. This equal load distribution creates the load imbalance … Cites: ‪Challenges and Opportunities with Big Data. A community white …‬&lt;/p&gt;</content><author><name>KL Bawankule, RK Dewang, AK Singh - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">abstract Hadoop is the most economical and cheap software framework that allows distributed storage and parallel processing of more extensive data sets. Hadoop distributed file system (HDFS) allows distributed storage and parallel processing of vast data sets using MapReduce. However, Hadoop s current implementation believes that computing nodes connected in a cluster are homogeneous and distribute the tasks equally. This equal load distribution creates the load imbalance … Cites: ‪Challenges and Opportunities with Big Data. A community white …‬</summary></entry><entry><title type="html">Physically Informed Machine Learning Prediction of Electronic Density of States</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cecc3beac82cdf80d738b0794b936eba.html" rel="alternate" type="text/html" title="Physically Informed Machine Learning Prediction of Electronic Density of States" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cecc3beac82cdf80d738b0794b936eba</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cecc3beac82cdf80d738b0794b936eba.html">&lt;p&gt;The electronic structure of a material, such as its density of states (DOS), provides key insights into its physical and functional properties and serves as a valuable source of high-quality features for many materials screening and discovery workflows. However, the computational cost of calculating the DOS, most commonly with density functional theory (DFT), becomes prohibitive for meeting high-fidelity or high-throughput requirements, necessitating a cheaper but sufficiently accurate … Cites: ‪Graph neural networks: A review of methods and applications‬&lt;/p&gt;</content><author><name>V Fung, P Ganesh, BG Sumpter - Chemistry of Materials, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The electronic structure of a material, such as its density of states (DOS), provides key insights into its physical and functional properties and serves as a valuable source of high-quality features for many materials screening and discovery workflows. However, the computational cost of calculating the DOS, most commonly with density functional theory (DFT), becomes prohibitive for meeting high-fidelity or high-throughput requirements, necessitating a cheaper but sufficiently accurate … Cites: ‪Graph neural networks: A review of methods and applications‬</summary></entry><entry><title type="html">DistilCamemBERT: a distillation of the French model CamemBERT</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cedce13ab1aecfcda35fd230a78c5421.html" rel="alternate" type="text/html" title="DistilCamemBERT: a distillation of the French model CamemBERT" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cedce13ab1aecfcda35fd230a78c5421</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cedce13ab1aecfcda35fd230a78c5421.html">&lt;p&gt;Modern Natural Language Processing (NLP) models based on Transformer structures represent the state of the art in terms of performance on very diverse tasks. However, these models are complex and represent several hundred million parameters for the smallest of them. This may hinder their adoption at the industrial level, making it difficult to scale up to a reasonable infrastructure and/or to comply with societal and environmental responsibilities. To this end, we present in this paper … Cites: ‪Mobilebert: Task-agnostic compression of bert by progressive …‬&lt;/p&gt;</content><author><name>C Delestre, A Amar - arXiv preprint arXiv:2205.11111, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Modern Natural Language Processing (NLP) models based on Transformer structures represent the state of the art in terms of performance on very diverse tasks. However, these models are complex and represent several hundred million parameters for the smallest of them. This may hinder their adoption at the industrial level, making it difficult to scale up to a reasonable infrastructure and/or to comply with societal and environmental responsibilities. To this end, we present in this paper … Cites: ‪Mobilebert: Task-agnostic compression of bert by progressive …‬</summary></entry><entry><title type="html">Least-to-Most Prompting Enables Complex Reasoning in Large Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cf284b5a1fcbbb8d32f3adb48feb3b67.html" rel="alternate" type="text/html" title="Least-to-Most Prompting Enables Complex Reasoning in Large Language Models" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cf284b5a1fcbbb8d32f3adb48feb3b67</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/cf284b5a1fcbbb8d32f3adb48feb3b67.html">&lt;p&gt;We propose a novel prompting strategy, least-to-most prompting, that enables large language models to better perform multi-step reasoning tasks. Least-to-most prompting first reduces a complex problem into a list of subproblems, and then sequentially solves the subproblems, whereby solving a given subproblem is facilitated by the model s answers to previously solved subproblems. Experiments on symbolic manipulation, compositional generalization and numerical reasoning … Cites: ‪Palm: Scaling language modeling with pathways‬&lt;/p&gt;</content><author><name>D Zhou, N Schärli, L Hou, J Wei, N Scales, X Wang… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose a novel prompting strategy, least-to-most prompting, that enables large language models to better perform multi-step reasoning tasks. Least-to-most prompting first reduces a complex problem into a list of subproblems, and then sequentially solves the subproblems, whereby solving a given subproblem is facilitated by the model s answers to previously solved subproblems. Experiments on symbolic manipulation, compositional generalization and numerical reasoning … Cites: ‪Palm: Scaling language modeling with pathways‬</summary></entry><entry><title type="html">Survey on Fair Reinforcement Learning: Theory and Practice</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d0853922171d4fbc4ffc9bdc0f3114a3.html" rel="alternate" type="text/html" title="Survey on Fair Reinforcement Learning: Theory and Practice" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d0853922171d4fbc4ffc9bdc0f3114a3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d0853922171d4fbc4ffc9bdc0f3114a3.html">&lt;p&gt;Fairness-aware learning aims at satisfying various fairness constraints in addition to the usual performance criteria via data-driven machine learning techniques. Most of the research in fairness-aware learning employs the setting of fair-supervised learning. However, many dynamic real-world applications can be better modeled using sequential decision-making problems and fair reinforcement learning provides a more suitable alternative for addressing these problems. In this article, we provide … Cites: ‪Provably optimal algorithms for generalized linear contextual bandits‬&lt;/p&gt;</content><author><name>P Gajane, A Saxena, M Tavakol, G Fletcher… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Fairness-aware learning aims at satisfying various fairness constraints in addition to the usual performance criteria via data-driven machine learning techniques. Most of the research in fairness-aware learning employs the setting of fair-supervised learning. However, many dynamic real-world applications can be better modeled using sequential decision-making problems and fair reinforcement learning provides a more suitable alternative for addressing these problems. In this article, we provide … Cites: ‪Provably optimal algorithms for generalized linear contextual bandits‬</summary></entry><entry><title type="html">A Dynamic, Interpreted CheckList for Meaning-oriented NLG Metric Evaluation–through the Lens of Semantic Similarity Rating</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d273cebbf03d9d18c525e198cca13960.html" rel="alternate" type="text/html" title="A Dynamic, Interpreted CheckList for Meaning-oriented NLG Metric Evaluation–through the Lens of Semantic Similarity Rating" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d273cebbf03d9d18c525e198cca13960</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d273cebbf03d9d18c525e198cca13960.html">&lt;p&gt;Evaluating the quality of generated text is difficult, since traditional NLG evaluation metrics, focusing more on surface form than meaning, often fail to assign appropriate scores. This is especially problematic for AMR-to-text evaluation, given the abstract nature of AMR. Our work aims to support the development and improvement of NLG evaluation metrics that focus on meaning, by developing a dynamic CheckList for NLG metrics that is interpreted by being organized around meaning-relevant … Cites: ‪Beyond Accuracy: Behavioral Testing of NLP Models with CheckList‬&lt;/p&gt;</content><author><name>L Zeidler, J Opitz, A Frank - arXiv preprint arXiv:2205.12176, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Evaluating the quality of generated text is difficult, since traditional NLG evaluation metrics, focusing more on surface form than meaning, often fail to assign appropriate scores. This is especially problematic for AMR-to-text evaluation, given the abstract nature of AMR. Our work aims to support the development and improvement of NLG evaluation metrics that focus on meaning, by developing a dynamic CheckList for NLG metrics that is interpreted by being organized around meaning-relevant … Cites: ‪Beyond Accuracy: Behavioral Testing of NLP Models with CheckList‬</summary></entry><entry><title type="html">Graph Alignment for Cross-Domain Text-to-SQL</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d41081680d78801ab7c6354d3ba06e2f.html" rel="alternate" type="text/html" title="Graph Alignment for Cross-Domain Text-to-SQL" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d41081680d78801ab7c6354d3ba06e2f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d41081680d78801ab7c6354d3ba06e2f.html">&lt;p&gt;Text-to-SQL, the task of translating the natural language utterance into SQL, has attracted much attention recently. Under the cross-domain setting, the traditional semantic parse model is difficult to adapt to the invisible database schema. The key to being able to better handle cross-domain issues lies in the encoding method for modeling the natural language utterance and the database schema and establishing alignment between them. We propose a Graph Alignment for cross-domain Text-to … Cites: ‪Spider: A Large-Scale Human-Labeled Dataset for Complex and …‬&lt;/p&gt;</content><author><name>Y Liu, Y Hu, Z Li, Z Zhu - 2022 7th International Conference on Intelligent …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Text-to-SQL, the task of translating the natural language utterance into SQL, has attracted much attention recently. Under the cross-domain setting, the traditional semantic parse model is difficult to adapt to the invisible database schema. The key to being able to better handle cross-domain issues lies in the encoding method for modeling the natural language utterance and the database schema and establishing alignment between them. We propose a Graph Alignment for cross-domain Text-to … Cites: ‪Spider: A Large-Scale Human-Labeled Dataset for Complex and …‬</summary></entry><entry><title type="html">Computational Storytelling and Emotions: A Survey</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d60913b88c17eaa39a3d6ff92618e8d6.html" rel="alternate" type="text/html" title="Computational Storytelling and Emotions: A Survey" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d60913b88c17eaa39a3d6ff92618e8d6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d60913b88c17eaa39a3d6ff92618e8d6.html">&lt;p&gt;Storytelling has always been vital for human nature. From ancient times, humans have used stories for several objectives including entertainment, advertisement, and education. Various analyses have been conducted by researchers and creators to determine the way of producing good stories. The deep relationship between stories and emotions is a prime example. With the advancement in deep learning technology, computers are expected to understand and generate stories. This survey … Cites: ‪Feuding Families and Former Friends: Unsupervised Learning for …‬&lt;/p&gt;</content><author><name>Y Mori, H Yamane, Y Mukuta, T Harada - arXiv preprint arXiv:2205.10967, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Storytelling has always been vital for human nature. From ancient times, humans have used stories for several objectives including entertainment, advertisement, and education. Various analyses have been conducted by researchers and creators to determine the way of producing good stories. The deep relationship between stories and emotions is a prime example. With the advancement in deep learning technology, computers are expected to understand and generate stories. This survey … Cites: ‪Feuding Families and Former Friends: Unsupervised Learning for …‬</summary></entry><entry><title type="html">StreamingQA: A Benchmark for Adaptation to New Knowledge over Time in Question Answering Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d6781d1787cd84044e53ca9052496edd.html" rel="alternate" type="text/html" title="StreamingQA: A Benchmark for Adaptation to New Knowledge over Time in Question Answering Models" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d6781d1787cd84044e53ca9052496edd</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d6781d1787cd84044e53ca9052496edd.html">&lt;p&gt;Knowledge and language understanding of models evaluated through question answering (QA) has been usually studied on static snapshots of knowledge, like Wikipedia. However, our world is dynamic, evolves over time, and our models  knowledge becomes outdated. To study how semi-parametric QA models and their underlying parametric language models (LMs) adapt to evolving knowledge, we construct a new large-scale dataset, StreamingQA, with human written and … Cites: ‪Dense Passage Retrieval for Open-Domain Question Answering‬&lt;/p&gt;</content><author><name>A Liška, T Kočiský, E Gribovskaya, T Terzi, E Sezener… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Knowledge and language understanding of models evaluated through question answering (QA) has been usually studied on static snapshots of knowledge, like Wikipedia. However, our world is dynamic, evolves over time, and our models knowledge becomes outdated. To study how semi-parametric QA models and their underlying parametric language models (LMs) adapt to evolving knowledge, we construct a new large-scale dataset, StreamingQA, with human written and … Cites: ‪Dense Passage Retrieval for Open-Domain Question Answering‬</summary></entry><entry><title type="html">SubTab: Data Exploration with Informative Sub-Tables</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d681bf664b399ade095e43ba046e69af.html" rel="alternate" type="text/html" title="SubTab: Data Exploration with Informative Sub-Tables" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d681bf664b399ade095e43ba046e69af</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d681bf664b399ade095e43ba046e69af.html">&lt;p&gt;We demonstrate SubTab, a framework for creating small, informative sub-tables of large data tables to speed up data exploration. Given a table with n rows and m columns where n and m are large, SubTab creates a sub-table Tsub with k« n rows and l« m columns, ie a subset of k rows of the table projected over a subset of l columns. The rows and columns are chosen as representatives of prominent data patterns within and across columns in the input table. SubTab can also be used for … Cites: ‪Visualization-aware sampling for very large databases‬&lt;/p&gt;</content><author><name>K Razmadze, Y Amsterdamer, A Somech, SB Davidson…</name></author><category term="jekyll" /><category term="update" /><summary type="html">We demonstrate SubTab, a framework for creating small, informative sub-tables of large data tables to speed up data exploration. Given a table with n rows and m columns where n and m are large, SubTab creates a sub-table Tsub with k« n rows and l« m columns, ie a subset of k rows of the table projected over a subset of l columns. The rows and columns are chosen as representatives of prominent data patterns within and across columns in the input table. SubTab can also be used for … Cites: ‪Visualization-aware sampling for very large databases‬</summary></entry><entry><title type="html">Translating Hanja historical documents to understandable Korean and English</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d9c7feaaae7571175ab89eb8469e1fdf.html" rel="alternate" type="text/html" title="Translating Hanja historical documents to understandable Korean and English" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d9c7feaaae7571175ab89eb8469e1fdf</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/d9c7feaaae7571175ab89eb8469e1fdf.html">&lt;p&gt;The Annals of Joseon Dynasty (AJD) contain the daily records of the Kings of Joseon, the 500-year kingdom preceding the modern nation of Korea. The Annals were originally written in an archaic Korean writing system,Hanja , and translated into …&lt;/p&gt;</content><author><name>J Son, J Jin, H Yoo, JY Bak, K Cho, A Oh - arXiv preprint arXiv:2205.10019, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The Annals of Joseon Dynasty (AJD) contain the daily records of the Kings of Joseon, the 500-year kingdom preceding the modern nation of Korea. The Annals were originally written in an archaic Korean writing system,Hanja , and translated into …</summary></entry><entry><title type="html">How Human is Human Evaluation? Improving the Gold Standard for NLG with Utility Theory</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/dad54ba8785a3c8e5605cadc7de5a29c.html" rel="alternate" type="text/html" title="How Human is Human Evaluation? Improving the Gold Standard for NLG with Utility Theory" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/dad54ba8785a3c8e5605cadc7de5a29c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/dad54ba8785a3c8e5605cadc7de5a29c.html">&lt;p&gt;Human ratings are treated as the gold standard in NLG evaluation. The standard protocol is to collect ratings of generated text, average across annotators, and then rank NLG systems by their average scores. However, little consideration has been given as to whether this approach faithfully captures human preferences. In this work, we analyze this standard protocol through the lens of utility theory in economics. We first identify the implicit assumptions it makes about annotators and find that these … Cites: ‪All That s  Human Is Not Gold: Evaluating Human Evaluation of …‬&lt;/p&gt;</content><author><name>K Ethayarajh, D Jurafsky - arXiv preprint arXiv:2205.11930, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Human ratings are treated as the gold standard in NLG evaluation. The standard protocol is to collect ratings of generated text, average across annotators, and then rank NLG systems by their average scores. However, little consideration has been given as to whether this approach faithfully captures human preferences. In this work, we analyze this standard protocol through the lens of utility theory in economics. We first identify the implicit assumptions it makes about annotators and find that these … Cites: ‪All That s Human Is Not Gold: Evaluating Human Evaluation of …‬</summary></entry><entry><title type="html">Deeper vs Wider: A Revisit of Transformer Configuration</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/db4c239aae28db4aec3ec24a6f39fbe4.html" rel="alternate" type="text/html" title="Deeper vs Wider: A Revisit of Transformer Configuration" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/db4c239aae28db4aec3ec24a6f39fbe4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/db4c239aae28db4aec3ec24a6f39fbe4.html">&lt;p&gt;Transformer-based models have delivered impressive results on many tasks, particularly vision and language tasks. In many model training situations, conventional configurations are typically adopted. For example, we often set the base model with hidden dimensions (ie model width) to be 768 and the number of transformer layers (ie model depth) to be 12. In this paper, we revisit these conventional configurations. Through theoretical analysis and experimental … Cites: ‪GLaM: Efficient Scaling of Language Models with Mixture-of-Experts‬&lt;/p&gt;</content><author><name>F Xue, J Chen, A Sun, X Ren, Z Zheng, X He, X Jiang… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Transformer-based models have delivered impressive results on many tasks, particularly vision and language tasks. In many model training situations, conventional configurations are typically adopted. For example, we often set the base model with hidden dimensions (ie model width) to be 768 and the number of transformer layers (ie model depth) to be 12. In this paper, we revisit these conventional configurations. Through theoretical analysis and experimental … Cites: ‪GLaM: Efficient Scaling of Language Models with Mixture-of-Experts‬</summary></entry><entry><title type="html">Named Entity Linking on Namesakes</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/dc234ce4206dbc4436a41e12ff12c520.html" rel="alternate" type="text/html" title="Named Entity Linking on Namesakes" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/dc234ce4206dbc4436a41e12ff12c520</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/dc234ce4206dbc4436a41e12ff12c520.html">&lt;p&gt;We propose a simple and practical method of named entity linking (NEL), and explore its features and performance on a dataset of ambiguous named entities-Namesakes. We represent knowledge base (KB) entity by a set of embeddings. Our observations suggest that it is reasonable to keep a limited number of such embeddings, and that the number of mentions required to create a KB entity is important. We show that representations of entities in the knowledge base (KB) can … Cites: ‪Efficient One-Pass End-to-End Entity Linking for Questions‬&lt;/p&gt;</content><author><name>O Vasilyev, A Dauenhauer, V Dharnidharka… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose a simple and practical method of named entity linking (NEL), and explore its features and performance on a dataset of ambiguous named entities-Namesakes. We represent knowledge base (KB) entity by a set of embeddings. Our observations suggest that it is reasonable to keep a limited number of such embeddings, and that the number of mentions required to create a KB entity is important. We show that representations of entities in the knowledge base (KB) can … Cites: ‪Efficient One-Pass End-to-End Entity Linking for Questions‬</summary></entry><entry><title type="html">Unsupervised Learning of Hierarchical Conversation Structure</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/df0fc483f3d290a9e5e345ba831cc3e2.html" rel="alternate" type="text/html" title="Unsupervised Learning of Hierarchical Conversation Structure" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/df0fc483f3d290a9e5e345ba831cc3e2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/df0fc483f3d290a9e5e345ba831cc3e2.html">&lt;p&gt;Human conversations can evolve in many different ways, creating challenges for automatic understanding and summarization. Goal-oriented conversations often have meaningful sub-dialogue structure, but it can be highly domain-dependent. This …&lt;/p&gt;</content><author><name>BR Lu, Y Hu, H Cheng, NA Smith, M Ostendorf - arXiv preprint arXiv:2205.12244, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Human conversations can evolve in many different ways, creating challenges for automatic understanding and summarization. Goal-oriented conversations often have meaningful sub-dialogue structure, but it can be highly domain-dependent. This …</summary></entry><entry><title type="html">Domain Adaptation for Memory-Efficient Dense Retrieval</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/e442ccef84f707c2b1c1728d18cc70dd.html" rel="alternate" type="text/html" title="Domain Adaptation for Memory-Efficient Dense Retrieval" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/e442ccef84f707c2b1c1728d18cc70dd</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/e442ccef84f707c2b1c1728d18cc70dd.html">&lt;p&gt;Dense retrievers encode documents into fixed dimensional embeddings. However, storing all the document embeddings within an index produces bulky indexes which are expensive to serve. Recently, BPR (Yamada et al., 2021) and JPQ (Zhan et al., 2021a) have been proposed which train the model to produce binary document vectors, which reduce the index 32x and more. The authors showed these binary embedding models significantly outperform more traditional index compression … Cites: ‪Efficient passage retrieval with hashing for open-domain question …‬&lt;/p&gt;</content><author><name>N Thakur, N Reimers, J Lin - arXiv preprint arXiv:2205.11498, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Dense retrievers encode documents into fixed dimensional embeddings. However, storing all the document embeddings within an index produces bulky indexes which are expensive to serve. Recently, BPR (Yamada et al., 2021) and JPQ (Zhan et al., 2021a) have been proposed which train the model to produce binary document vectors, which reduce the index 32x and more. The authors showed these binary embedding models significantly outperform more traditional index compression … Cites: ‪Efficient passage retrieval with hashing for open-domain question …‬</summary></entry><entry><title type="html">WeDef: Weakly Supervised Backdoor Defense for Text Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/e71d25fa1df471d9e362b0e725424efb.html" rel="alternate" type="text/html" title="WeDef: Weakly Supervised Backdoor Defense for Text Classification" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/e71d25fa1df471d9e362b0e725424efb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/e71d25fa1df471d9e362b0e725424efb.html">&lt;p&gt;Existing backdoor defense methods are only effective for limited trigger types. To defend different trigger types at once, we start from the class-irrelevant nature of the poisoning process and propose a novel weakly supervised backdoor defense framework WeDef. Recent advances in weak supervision make it possible to train a reasonably accurate text classifier using only a small number of user-provided, class-indicative seed words. Such seed words shall be considered independent of the … Cites: ‪Textual Backdoor Attacks Can Be More Harmful via Two Simple …‬&lt;/p&gt;</content><author><name>L Jin, Z Wang, J Shang - arXiv preprint arXiv:2205.11803, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Existing backdoor defense methods are only effective for limited trigger types. To defend different trigger types at once, we start from the class-irrelevant nature of the poisoning process and propose a novel weakly supervised backdoor defense framework WeDef. Recent advances in weak supervision make it possible to train a reasonably accurate text classifier using only a small number of user-provided, class-indicative seed words. Such seed words shall be considered independent of the … Cites: ‪Textual Backdoor Attacks Can Be More Harmful via Two Simple …‬</summary></entry><entry><title type="html">Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/e8f5fc8e5fbc2478cf93fbaf7b120c0d.html" rel="alternate" type="text/html" title="Language Models with Image Descriptors are Strong Few-Shot Video-Language Learners" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/e8f5fc8e5fbc2478cf93fbaf7b120c0d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/e8f5fc8e5fbc2478cf93fbaf7b120c0d.html">&lt;p&gt;The goal of this work is to build flexible video-language models that can generalize to various video-to-text tasks from few examples, such as domain-specific captioning, question answering, and future event prediction. Existing few-shot video-language learners focus exclusively on the encoder, resulting in the absence of a video-to-text decoder to handle generative tasks. Video captioners have been pretrained on large-scale video-language datasets, but they rely heavily on finetuning and lack the ability … Cites: ‪Finetuned language models are zero-shot learners‬&lt;/p&gt;</content><author><name>Z Wang, M Li, R Xu, L Zhou, J Lei, X Lin, S Wang… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The goal of this work is to build flexible video-language models that can generalize to various video-to-text tasks from few examples, such as domain-specific captioning, question answering, and future event prediction. Existing few-shot video-language learners focus exclusively on the encoder, resulting in the absence of a video-to-text decoder to handle generative tasks. Video captioners have been pretrained on large-scale video-language datasets, but they rely heavily on finetuning and lack the ability … Cites: ‪Finetuned language models are zero-shot learners‬</summary></entry><entry><title type="html">Educational Tools for Mapuzugun</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/e927ac3d2da0ea673fb8bf6666295499.html" rel="alternate" type="text/html" title="Educational Tools for Mapuzugun" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/e927ac3d2da0ea673fb8bf6666295499</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/e927ac3d2da0ea673fb8bf6666295499.html">&lt;p&gt;Mapuzugun is the language of the Mapuche people. Due to political and historical reasons, its number of speakers has decreased and the language has been excluded from the educational system in Chile and Argentina. For this reason, it is very important to support the revitalization of the Mapuzugun in all spaces and media of society. In this work we present a tool towards supporting educational activities of Mapuzugun, tailored to the characteristics of the language. The tool consists of three … Cites: ‪Systematic Inequalities in Language Technology Performance …‬&lt;/p&gt;</content><author><name>C Ahumada, C Gutierrez, A Anastasopoulos - arXiv preprint arXiv:2205.10411, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Mapuzugun is the language of the Mapuche people. Due to political and historical reasons, its number of speakers has decreased and the language has been excluded from the educational system in Chile and Argentina. For this reason, it is very important to support the revitalization of the Mapuzugun in all spaces and media of society. In this work we present a tool towards supporting educational activities of Mapuzugun, tailored to the characteristics of the language. The tool consists of three … Cites: ‪Systematic Inequalities in Language Technology Performance …‬</summary></entry><entry><title type="html">Semi-Parametric Deep Neural Networks in Linear Time and Memory</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/eaef9359bc55ae9b90b83ec5b55c1b11.html" rel="alternate" type="text/html" title="Semi-Parametric Deep Neural Networks in Linear Time and Memory" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/eaef9359bc55ae9b90b83ec5b55c1b11</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/eaef9359bc55ae9b90b83ec5b55c1b11.html">&lt;p&gt;Recent advances in deep learning have been driven by large-scale parametric models, which can be computationally expensive and lack interpretability. Semi-parametric methods query the training set at inference time and can be more compact, although they typically have quadratic computational complexity. Here, we introduce SPIN, a general-purpose semi-parametric neural architecture whose computational cost is linear in the size and dimensionality of the data. Our … Cites: ‪Detecting formal thought disorder by deep contextualized word …‬&lt;/p&gt;</content><author><name>R Rastogi, Y Deng, I Lee, MR Sabuncu, V Kuleshov - arXiv preprint arXiv:2205.11718, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent advances in deep learning have been driven by large-scale parametric models, which can be computationally expensive and lack interpretability. Semi-parametric methods query the training set at inference time and can be more compact, although they typically have quadratic computational complexity. Here, we introduce SPIN, a general-purpose semi-parametric neural architecture whose computational cost is linear in the size and dimensionality of the data. Our … Cites: ‪Detecting formal thought disorder by deep contextualized word …‬</summary></entry><entry><title type="html">Development and multimodal validation of a substance misuse algorithm for referral to treatment using artificial intelligence (SMART-AI): a retrospective deep learning …</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ebe1aae5c6016cc66761a3d8a37c2810.html" rel="alternate" type="text/html" title="Development and multimodal validation of a substance misuse algorithm for referral to treatment using artificial intelligence (SMART-AI): a retrospective deep learning …" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ebe1aae5c6016cc66761a3d8a37c2810</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ebe1aae5c6016cc66761a3d8a37c2810.html">&lt;p&gt;Background Substance misuse is a heterogeneous and complex set of behavioural conditions that are highly prevalent in hospital settings and frequently co-occur. Few hospital-wide solutions exist to comprehensively and reliably identify these conditions to prioritise care and guide treatment. The aim of this study was to apply natural language processing (NLP) to clinical notes collected in the electronic health record (EHR) to accurately screen for substance misuse. Methods The model was … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/p&gt;</content><author><name>M Afshar, B Sharma, D Dligach, M Oguss, R Brown… - The Lancet Digital Health, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Background Substance misuse is a heterogeneous and complex set of behavioural conditions that are highly prevalent in hospital settings and frequently co-occur. Few hospital-wide solutions exist to comprehensively and reliably identify these conditions to prioritise care and guide treatment. The aim of this study was to apply natural language processing (NLP) to clinical notes collected in the electronic health record (EHR) to accurately screen for substance misuse. Methods The model was … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">RetroMAE: Pre-training Retrieval-oriented Transformers via Masked Auto-Encoder</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ee69372fc0023b3ab55885a97519f2c9.html" rel="alternate" type="text/html" title="RetroMAE: Pre-training Retrieval-oriented Transformers via Masked Auto-Encoder" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ee69372fc0023b3ab55885a97519f2c9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ee69372fc0023b3ab55885a97519f2c9.html">&lt;p&gt;Pre-trained models have demonstrated superior power on many important tasks. However, it is still an open problem of designing effective pre-training strategies so as to promote the models  usability on dense retrieval. In this paper, we propose a novel pre-training framework for dense retrieval based on the Masked Auto-Encoder, known as RetroMAE. Our proposed framework is highlighted for the following critical designs: 1) a MAE based pre-training workflow, where the input sentence is polluted … Cites: ‪Towards Unsupervised Dense Information Retrieval with …‬&lt;/p&gt;</content><author><name>Z Liu, Y Shao - arXiv preprint arXiv:2205.12035, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pre-trained models have demonstrated superior power on many important tasks. However, it is still an open problem of designing effective pre-training strategies so as to promote the models usability on dense retrieval. In this paper, we propose a novel pre-training framework for dense retrieval based on the Masked Auto-Encoder, known as RetroMAE. Our proposed framework is highlighted for the following critical designs: 1) a MAE based pre-training workflow, where the input sentence is polluted … Cites: ‪Towards Unsupervised Dense Information Retrieval with …‬</summary></entry><entry><title type="html">Automatic semantic knowledge extraction from electronic forms</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ef2dd5fa186a8cfed11d8a49581cb39c.html" rel="alternate" type="text/html" title="Automatic semantic knowledge extraction from electronic forms" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ef2dd5fa186a8cfed11d8a49581cb39c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ef2dd5fa186a8cfed11d8a49581cb39c.html">&lt;p&gt;Electronic tabular forms are an intuitive way for organisations to collect, present and store structured information for human readers. Forms use features such as fonts, colours and cell positioning to help readers navigate and find information. Millions of forms, typically in Portable Document Format (PDF), are generated by businesses as part of routine operations. Unlike human readers, machines are not able to directly  understand the implicit cues contained in the fonts, colours and use of boxes without … Cites: ‪Pre-Trained Models: Past, Present and Future‬&lt;/p&gt;</content><author><name>H Wu, T French, W Liu, M Hodkiewicz - Proceedings of the Institution of Mechanical …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Electronic tabular forms are an intuitive way for organisations to collect, present and store structured information for human readers. Forms use features such as fonts, colours and cell positioning to help readers navigate and find information. Millions of forms, typically in Portable Document Format (PDF), are generated by businesses as part of routine operations. Unlike human readers, machines are not able to directly understand the implicit cues contained in the fonts, colours and use of boxes without … Cites: ‪Pre-Trained Models: Past, Present and Future‬</summary></entry><entry><title type="html">Understanding Limitations of Unsupervised Graph Representation Learning from a Data-Dependent Perspective</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f0f5a2b4eb75911a151136216f9d0d46.html" rel="alternate" type="text/html" title="Understanding Limitations of Unsupervised Graph Representation Learning from a Data-Dependent Perspective" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f0f5a2b4eb75911a151136216f9d0d46</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f0f5a2b4eb75911a151136216f9d0d46.html">&lt;p&gt;Recent advances in unsupervised graph representation learning (UGRL) have primarily been driven by new paradigms, such as contrastive learning (CL) and novel reconstruction-based approaches. However, understanding of how dataset properties, often assumed true for vision datasets, apply to URGL remains limited. By taking a datacentric perspective, we investigate augmentation invariance and recoverability, as well as dataset separability in graph classification. Finding popular … Cites: ‪AAVAE: Augmentation-Augmented Variational Autoencoders‬&lt;/p&gt;</content><author><name>P Trivedi, M Heimann, ES Lubana, D Koutra… - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent advances in unsupervised graph representation learning (UGRL) have primarily been driven by new paradigms, such as contrastive learning (CL) and novel reconstruction-based approaches. However, understanding of how dataset properties, often assumed true for vision datasets, apply to URGL remains limited. By taking a datacentric perspective, we investigate augmentation invariance and recoverability, as well as dataset separability in graph classification. Finding popular … Cites: ‪AAVAE: Augmentation-Augmented Variational Autoencoders‬</summary></entry><entry><title type="html">HyperTree Proof Search for Neural Theorem Proving</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f21690f4a6f516c88cf7e6bbe348efd8.html" rel="alternate" type="text/html" title="HyperTree Proof Search for Neural Theorem Proving" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f21690f4a6f516c88cf7e6bbe348efd8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f21690f4a6f516c88cf7e6bbe348efd8.html">&lt;p&gt;We propose an online training procedure for a transformer-based automated theorem prover. Our approach leverages a new search algorithm, HyperTree Proof Search (HTPS), inspired by the recent success of AlphaZero. Our model learns from previous proof searches through online training, allowing it to generalize to domains far from the training distribution. We report detailed ablations of our pipeline s main components by studying performance on three environments of increasing … Cites: ‪Deep encoder, shallow decoder: Reevaluating non-autoregressive …‬&lt;/p&gt;</content><author><name>G Lample, MA Lachaux, T Lavril, X Martinet, A Hayat… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose an online training procedure for a transformer-based automated theorem prover. Our approach leverages a new search algorithm, HyperTree Proof Search (HTPS), inspired by the recent success of AlphaZero. Our model learns from previous proof searches through online training, allowing it to generalize to domains far from the training distribution. We report detailed ablations of our pipeline s main components by studying performance on three environments of increasing … Cites: ‪Deep encoder, shallow decoder: Reevaluating non-autoregressive …‬</summary></entry><entry><title type="html">GraphQ IR: Unifying Semantic Parsing of Graph Query Language with Intermediate Representation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f2fad942677d1da11c9e675f721095f5.html" rel="alternate" type="text/html" title="GraphQ IR: Unifying Semantic Parsing of Graph Query Language with Intermediate Representation" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f2fad942677d1da11c9e675f721095f5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f2fad942677d1da11c9e675f721095f5.html">&lt;p&gt;Subject to the semantic gap lying between natural and formal language, neural semantic parsing is typically bottlenecked by the paucity and imbalance of data. In this paper, we propose a unified intermediate representation (IR) for graph query languages, namely GraphQ IR. With the IR s natural-language-like representation that bridges the semantic gap and its formally defined syntax that maintains the graph structure, neural semantic parser can more effectively convert user queries … Cites: ‪A syntactic neural model for general-purpose code generation‬&lt;/p&gt;</content><author><name>L Nie, S Cao, J Shi, Q Tian, L Hou, J Li, J Zhai - arXiv preprint arXiv:2205.12078, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Subject to the semantic gap lying between natural and formal language, neural semantic parsing is typically bottlenecked by the paucity and imbalance of data. In this paper, we propose a unified intermediate representation (IR) for graph query languages, namely GraphQ IR. With the IR s natural-language-like representation that bridges the semantic gap and its formally defined syntax that maintains the graph structure, neural semantic parser can more effectively convert user queries … Cites: ‪A syntactic neural model for general-purpose code generation‬</summary></entry><entry><title type="html">Why GANs are overkill for NLP</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f4f4701a235dbd844371dac31466d301.html" rel="alternate" type="text/html" title="Why GANs are overkill for NLP" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f4f4701a235dbd844371dac31466d301</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f4f4701a235dbd844371dac31466d301.html">&lt;p&gt;This work offers a novel theoretical perspective on why, despite numerous attempts, adversarial approaches to generative modeling (eg, GANs) have not been as popular for certain generation tasks, particularly sequential tasks such as Natural Language Generation, as they have in others, such as Computer Vision. In particular, on sequential data such as text, maximum-likelihood approaches are significantly more utilized than GANs. We show that, while it may seem that maximizing likelihood … Cites: ‪Palm: Scaling language modeling with pathways‬&lt;/p&gt;</content><author><name>D Alvarez-Melis, V Garg, AT Kalai - arXiv preprint arXiv:2205.09838, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This work offers a novel theoretical perspective on why, despite numerous attempts, adversarial approaches to generative modeling (eg, GANs) have not been as popular for certain generation tasks, particularly sequential tasks such as Natural Language Generation, as they have in others, such as Computer Vision. In particular, on sequential data such as text, maximum-likelihood approaches are significantly more utilized than GANs. We show that, while it may seem that maximizing likelihood … Cites: ‪Palm: Scaling language modeling with pathways‬</summary></entry><entry><title type="html">Meta Policy Learning for Cold-Start Conversational Recommendation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f501848e3224ed7fc4794a3b666a372e.html" rel="alternate" type="text/html" title="Meta Policy Learning for Cold-Start Conversational Recommendation" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f501848e3224ed7fc4794a3b666a372e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f501848e3224ed7fc4794a3b666a372e.html">&lt;p&gt;Conversational recommender systems (CRS) explicitly solicit users  preferences for improved recommendations on the fly. Most existing CRS solutions employ reinforcement learning methods to train a single policy for a population of users. However, for users new to the system, such a global policy becomes ineffective to produce conversational recommendations, ie, the cold-start challenge. In this paper, we study CRS policy learning for cold-start users via meta reinforcement learning … Cites: ‪Decoupling exploration and exploitation for meta-reinforcement …‬&lt;/p&gt;</content><author><name>Z Chu, H Wang, Y Xiao, B Long, L Wu - arXiv preprint arXiv:2205.11788, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Conversational recommender systems (CRS) explicitly solicit users preferences for improved recommendations on the fly. Most existing CRS solutions employ reinforcement learning methods to train a single policy for a population of users. However, for users new to the system, such a global policy becomes ineffective to produce conversational recommendations, ie, the cold-start challenge. In this paper, we study CRS policy learning for cold-start users via meta reinforcement learning … Cites: ‪Decoupling exploration and exploitation for meta-reinforcement …‬</summary></entry><entry><title type="html">PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f5ed249cc9167938571b54b83ab407fe.html" rel="alternate" type="text/html" title="PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f5ed249cc9167938571b54b83ab407fe</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f5ed249cc9167938571b54b83ab407fe.html">&lt;p&gt;Vision-language pre-training (VLP) has shown impressive performance on a wide range of cross-modal tasks, where VLP models without reliance on object detectors are becoming the mainstream due to their superior computation efficiency and competitive performance. However, the removal of object detectors also deprives the capability of VLP models in explicit object modeling, which is essential to various position-sensitive vision-language (VL) tasks, such as referring expression … Cites: ‪Unifying Vision-and-Language Tasks via Text Generation‬&lt;/p&gt;</content><author><name>Y Yao, Q Chen, A Zhang, W Ji, Z Liu, TS Chua, M Sun - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Vision-language pre-training (VLP) has shown impressive performance on a wide range of cross-modal tasks, where VLP models without reliance on object detectors are becoming the mainstream due to their superior computation efficiency and competitive performance. However, the removal of object detectors also deprives the capability of VLP models in explicit object modeling, which is essential to various position-sensitive vision-language (VL) tasks, such as referring expression … Cites: ‪Unifying Vision-and-Language Tasks via Text Generation‬</summary></entry><entry><title type="html">SafeNet: Mitigating Data Poisoning Attacks on Private Machine Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f6cfc2c643dd3a76c831f1d370344fdd.html" rel="alternate" type="text/html" title="SafeNet: Mitigating Data Poisoning Attacks on Private Machine Learning" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f6cfc2c643dd3a76c831f1d370344fdd</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f6cfc2c643dd3a76c831f1d370344fdd.html">&lt;p&gt;Secure multiparty computation (MPC) has been proposed to allow multiple mutually distrustful data owners to jointly train machine learning (ML) models on their combined data. However, the datasets used for training ML models might be under the control of an adversary mounting a data poisoning attack, and MPC prevents inspecting training sets to detect poisoning. We show that multiple MPC frameworks for private ML training are susceptible to backdoor and targeted poisoning attacks … Cites: ‪Stronger data poisoning attacks break data sanitization defenses‬&lt;/p&gt;</content><author><name>H Chaudhari, M Jagielski, A Oprea - arXiv preprint arXiv:2205.09986, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Secure multiparty computation (MPC) has been proposed to allow multiple mutually distrustful data owners to jointly train machine learning (ML) models on their combined data. However, the datasets used for training ML models might be under the control of an adversary mounting a data poisoning attack, and MPC prevents inspecting training sets to detect poisoning. We show that multiple MPC frameworks for private ML training are susceptible to backdoor and targeted poisoning attacks … Cites: ‪Stronger data poisoning attacks break data sanitization defenses‬</summary></entry><entry><title type="html">A Survey on Neural Open Information Extraction: Current Status and Future Directions</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f6eda3e1ca39361f63b04bc2dbdd1261.html" rel="alternate" type="text/html" title="A Survey on Neural Open Information Extraction: Current Status and Future Directions" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f6eda3e1ca39361f63b04bc2dbdd1261</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f6eda3e1ca39361f63b04bc2dbdd1261.html">&lt;p&gt;Open Information Extraction (OpenIE) facilitates domain-independent discovery of relational facts from large corpora. The technique well suits many open-world natural language understanding scenarios, such as automatic knowledge base construction, open-domain question answering, and explicit reasoning. Thanks to the rapid development in deep learning technologies, numerous neural OpenIE architectures have been proposed and achieve considerable performance improvement. In this … Cites: ‪Improving open information extraction via iterative rank-aware …‬&lt;/p&gt;</content><author><name>S Zhou, B Yu, A Sun, C Long, J Li, J Sun - arXiv preprint arXiv:2205.11725, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Open Information Extraction (OpenIE) facilitates domain-independent discovery of relational facts from large corpora. The technique well suits many open-world natural language understanding scenarios, such as automatic knowledge base construction, open-domain question answering, and explicit reasoning. Thanks to the rapid development in deep learning technologies, numerous neural OpenIE architectures have been proposed and achieve considerable performance improvement. In this … Cites: ‪Improving open information extraction via iterative rank-aware …‬</summary></entry><entry><title type="html">HYBRID METADATA CLASSIFICATION IN LARGE-SCALE STRUCTURED DATASETS</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f8eea5ee56e52573724cbca2af818a2c.html" rel="alternate" type="text/html" title="HYBRID METADATA CLASSIFICATION IN LARGE-SCALE STRUCTURED DATASETS" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f8eea5ee56e52573724cbca2af818a2c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f8eea5ee56e52573724cbca2af818a2c.html">&lt;p&gt;Metadata location and classification is an important problem for large-scale structured datasets. For example, Web tables [29] have hundreds of millions of tables, but often have missing or incorrect labels for rows (or columns) with attribute names. Such errors [24] significantly complicate all data management tasks such as query processing, data integration, indexing, etc. Different sources or authors position metadata rows/columns differently inside a table, which makes its reliable … Cites: ‪Webtables: exploring the power of tables on the web‬&lt;/p&gt;</content><author><name>S PAVIA, N PIRAINO, K ISLAM, A PYAYT… - Journal of Data Intelligence, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Metadata location and classification is an important problem for large-scale structured datasets. For example, Web tables [29] have hundreds of millions of tables, but often have missing or incorrect labels for rows (or columns) with attribute names. Such errors [24] significantly complicate all data management tasks such as query processing, data integration, indexing, etc. Different sources or authors position metadata rows/columns differently inside a table, which makes its reliable … Cites: ‪Webtables: exploring the power of tables on the web‬</summary></entry><entry><title type="html">SALTED: A Framework for SAlient Long-Tail Translation Error Detection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f9cf3d4326b955d928b8f528853b46b8.html" rel="alternate" type="text/html" title="SALTED: A Framework for SAlient Long-Tail Translation Error Detection" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f9cf3d4326b955d928b8f528853b46b8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/f9cf3d4326b955d928b8f528853b46b8.html">&lt;p&gt;Traditional machine translation (MT) metrics provide an average measure of translation quality that is insensitive to the long tail of behavioral problems in MT. Examples include translation of numbers, physical units, dropped content and hallucinations. These errors, which occur rarely and unpredictably in Neural Machine Translation (NMT), greatly undermine the reliability of state-of-the-art MT systems. Consequently, it is important to have visibility into these problems during model … Cites: ‪Beyond Accuracy: Behavioral Testing of NLP Models with CheckList‬&lt;/p&gt;</content><author><name>V Raunak, M Post, A Menezes - arXiv preprint arXiv:2205.09988, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Traditional machine translation (MT) metrics provide an average measure of translation quality that is insensitive to the long tail of behavioral problems in MT. Examples include translation of numbers, physical units, dropped content and hallucinations. These errors, which occur rarely and unpredictably in Neural Machine Translation (NMT), greatly undermine the reliability of state-of-the-art MT systems. Consequently, it is important to have visibility into these problems during model … Cites: ‪Beyond Accuracy: Behavioral Testing of NLP Models with CheckList‬</summary></entry><entry><title type="html">How to Find Actionable Static Analysis Warnings</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/fa7322366ba1458ee9fe0dee72838241.html" rel="alternate" type="text/html" title="How to Find Actionable Static Analysis Warnings" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/fa7322366ba1458ee9fe0dee72838241</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/fa7322366ba1458ee9fe0dee72838241.html">&lt;p&gt;Automatically generated static code warnings suffer from a large number of false alarms. Hence, developers only take action on a small percent of those warnings. To better predict which static code warnings should not be ignored, we suggest that analysts need to look deeper into their algorithms to find choices that better improve the particulars of their specific problem. Specifically, we show here that effective predictors of such warnings can be created by methods that locally adjust the … Cites: ‪Codebert: A pre-trained model for programming and natural …‬&lt;/p&gt;</content><author><name>R Yedida, HJ Kang, H Tu, X Yang, D Lo, T Menzies - arXiv preprint arXiv:2205.10504, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Automatically generated static code warnings suffer from a large number of false alarms. Hence, developers only take action on a small percent of those warnings. To better predict which static code warnings should not be ignored, we suggest that analysts need to look deeper into their algorithms to find choices that better improve the particulars of their specific problem. Specifically, we show here that effective predictors of such warnings can be created by methods that locally adjust the … Cites: ‪Codebert: A pre-trained model for programming and natural …‬</summary></entry><entry><title type="html">Enhancing Distributed In-situ CNN Inference in the Internet of Things</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/fc8fee805c7bbf2c2ddbe5ce1e6ae6e0.html" rel="alternate" type="text/html" title="Enhancing Distributed In-situ CNN Inference in the Internet of Things" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/fc8fee805c7bbf2c2ddbe5ce1e6ae6e0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/fc8fee805c7bbf2c2ddbe5ce1e6ae6e0.html">&lt;p&gt;Convolutional Neural Networks (CNN) enable machines to view the world as humans and become increasing prevalent for IoT applications. Instead of streaming the raw data to the cloud and executing CNN inference remotely, it would be very attractive to use local IoT devices to process as it enables IoT applications with independent decision-making ability. Since a single IoT device can hardly match the requirements of the CNN inference, especially for time-sensitive and high-accuracy … Cites: ‪Roberta: A robustly optimized bert pretraining approach‬&lt;/p&gt;</content><author><name>J Du, Y Du, D Huang, Y Lu, X Liao - IEEE Internet of Things Journal, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Convolutional Neural Networks (CNN) enable machines to view the world as humans and become increasing prevalent for IoT applications. Instead of streaming the raw data to the cloud and executing CNN inference remotely, it would be very attractive to use local IoT devices to process as it enables IoT applications with independent decision-making ability. Since a single IoT device can hardly match the requirements of the CNN inference, especially for time-sensitive and high-accuracy … Cites: ‪Roberta: A robustly optimized bert pretraining approach‬</summary></entry><entry><title type="html">Visually-Augmented Language Modeling</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/fcafab66bd2c3bddd9c56457baa54de5.html" rel="alternate" type="text/html" title="Visually-Augmented Language Modeling" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/fcafab66bd2c3bddd9c56457baa54de5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/fcafab66bd2c3bddd9c56457baa54de5.html">&lt;p&gt;Human language is grounded on multimodal knowledge including visual knowledge like colors, sizes, and shapes. However, current large-scale pre-trained language models rely on the text-only self-supervised training with massive text data, which precludes them from utilizing relevant visual information when necessary. To address this, we propose a novel pre-training framework, named VaLM, to Visually-augment text tokens with retrieved relevant images for Language Modeling … Cites: ‪Retrieval-augmented generation for knowledge-intensive NLP tasks‬&lt;/p&gt;</content><author><name>W Wang, L Dong, H Cheng, H Song, X Liu, X Yan… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Human language is grounded on multimodal knowledge including visual knowledge like colors, sizes, and shapes. However, current large-scale pre-trained language models rely on the text-only self-supervised training with massive text data, which precludes them from utilizing relevant visual information when necessary. To address this, we propose a novel pre-training framework, named VaLM, to Visually-augment text tokens with retrieved relevant images for Language Modeling … Cites: ‪Retrieval-augmented generation for knowledge-intensive NLP tasks‬</summary></entry><entry><title type="html">Organizational Geosocial Network: A Graph Machine Learning Approach Integrating Geographic and Public Policy Information for Studying the Development of Social …</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/fe81b478ca8cebcfb0001369ea8d6c95.html" rel="alternate" type="text/html" title="Organizational Geosocial Network: A Graph Machine Learning Approach Integrating Geographic and Public Policy Information for Studying the Development of Social …" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/fe81b478ca8cebcfb0001369ea8d6c95</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/fe81b478ca8cebcfb0001369ea8d6c95.html">&lt;p&gt;This study aims to give an insight into the development trends and patterns of social organizations (SOs) in China from the perspective of network science integrating geography and public policy information embedded in the network structure. Firstly, we constructed a first-of-its-kind database which encompasses almost all social organizations established in China throughout the past decade. Secondly, we proposed four basic structures to represent the homogeneous and heterogeneous … Cites: ‪The Web Is Your Oyster–Knowledge-Intensive NLP against a Very …‬&lt;/p&gt;</content><author><name>X Zhao, S Wang, H Wang - ISPRS International Journal of Geo-Information, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This study aims to give an insight into the development trends and patterns of social organizations (SOs) in China from the perspective of network science integrating geography and public policy information embedded in the network structure. Firstly, we constructed a first-of-its-kind database which encompasses almost all social organizations established in China throughout the past decade. Secondly, we proposed four basic structures to represent the homogeneous and heterogeneous … Cites: ‪The Web Is Your Oyster–Knowledge-Intensive NLP against a Very …‬</summary></entry><entry><title type="html">What Drives the Use of Metaphorical Language? Negative Insights from Abstractness, Affect, Discourse Coherence and Contextualized Word Representations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ff8dc1fe4076e773c8d4404a423d6a10.html" rel="alternate" type="text/html" title="What Drives the Use of Metaphorical Language? Negative Insights from Abstractness, Affect, Discourse Coherence and Contextualized Word Representations" /><published>2022-05-28T02:05:27-04:00</published><updated>2022-05-28T02:05:27-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ff8dc1fe4076e773c8d4404a423d6a10</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/28/ff8dc1fe4076e773c8d4404a423d6a10.html">&lt;p&gt;Given a specific discourse, which discourse properties trigger the use of metaphorical language, rather than using literal alternatives? For example, what drives people to say  grasp the meaning  rather than  understand the meaning  within a specific context? Many NLP approaches to metaphorical language rely on cognitive and (psycho-) linguistic insights and have successfully defined models of discourse coherence, abstractness and affect. In this work, we build five simple … Cites: ‪What does BERT look at? An analysis of BERT s attention‬&lt;/p&gt;</content><author><name>P Piccirilli, SS Walde - arXiv preprint arXiv:2205.11113, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Given a specific discourse, which discourse properties trigger the use of metaphorical language, rather than using literal alternatives? For example, what drives people to say grasp the meaning rather than understand the meaning within a specific context? Many NLP approaches to metaphorical language rely on cognitive and (psycho-) linguistic insights and have successfully defined models of discourse coherence, abstractness and affect. In this work, we build five simple … Cites: ‪What does BERT look at? An analysis of BERT s attention‬</summary></entry><entry><title type="html">Towards the Future of Work: Managing the Risks of AI and Automation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/04467e7cb4199b4c24e392723dcfc3ec.html" rel="alternate" type="text/html" title="Towards the Future of Work: Managing the Risks of AI and Automation" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/04467e7cb4199b4c24e392723dcfc3ec</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/04467e7cb4199b4c24e392723dcfc3ec.html">&lt;p&gt;Many believe in a vision of the future where almost all work is automated. A first step already underway involves Robotic Process Automation (RPA) technology, which firms use to automate standardized computer work. The larger step that needs to be taken towards this vision lies in connecting RPA to AI, so that Machine Learning (ML) algorithms can be used to automate human “intelligence” and decision making in companies. Cites: ‪On the opportunities and risks of foundation models‬&lt;/p&gt;</content><author><name>J Man - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Many believe in a vision of the future where almost all work is automated. A first step already underway involves Robotic Process Automation (RPA) technology, which firms use to automate standardized computer work. The larger step that needs to be taken towards this vision lies in connecting RPA to AI, so that Machine Learning (ML) algorithms can be used to automate human “intelligence” and decision making in companies. Cites: ‪On the opportunities and risks of foundation models‬</summary></entry><entry><title type="html">Brassinolide Maximized the Fruit and Oil Yield, Induced the Secondary Metabolites, and Stimulated Linoleic Acid Synthesis of Opuntia ficus-indica Oil</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/09ab7f3bf84e331ef946d955ca157bc6.html" rel="alternate" type="text/html" title="Brassinolide Maximized the Fruit and Oil Yield, Induced the Secondary Metabolites, and Stimulated Linoleic Acid Synthesis of Opuntia ficus-indica Oil" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/09ab7f3bf84e331ef946d955ca157bc6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/09ab7f3bf84e331ef946d955ca157bc6.html">&lt;p&gt;Prickly pear plant is widely cultivated in arid and semi-arid climates. Its fruits are rich in polyphenols, proteins, vitamin C, minerals, fatty acids, and amino acids. The oil extracted from the seeds also has a significant proportion of linoleic acid (ω6) and might be employed as a therapeutic raw material. The potential of enhancing fruit yield, increasing bioactive compounds of the fruit pulp, and improving the unsaturated fatty acid content of prickly pear oilseed by using the foliar application of … Cites: ‪BRL1 and BRL3 are novel brassinosteroid receptors that function …‬&lt;/p&gt;</content><author><name>AKG Atteya, RS El-Serafy, KM El-Zabalawy, A Elhakem… - Horticulturae, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Prickly pear plant is widely cultivated in arid and semi-arid climates. Its fruits are rich in polyphenols, proteins, vitamin C, minerals, fatty acids, and amino acids. The oil extracted from the seeds also has a significant proportion of linoleic acid (ω6) and might be employed as a therapeutic raw material. The potential of enhancing fruit yield, increasing bioactive compounds of the fruit pulp, and improving the unsaturated fatty acid content of prickly pear oilseed by using the foliar application of … Cites: ‪BRL1 and BRL3 are novel brassinosteroid receptors that function …‬</summary></entry><entry><title type="html">A STUDY OF ASPECT-BASED SENTIMENT ANALYSIS FOR ONLINE FOOD DELIVERY PLATFORMS</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/0c15b207da9e2c38e6fb3be5db70693f.html" rel="alternate" type="text/html" title="A STUDY OF ASPECT-BASED SENTIMENT ANALYSIS FOR ONLINE FOOD DELIVERY PLATFORMS" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/0c15b207da9e2c38e6fb3be5db70693f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/0c15b207da9e2c38e6fb3be5db70693f.html">&lt;p&gt;Nowadays, with the rapid development and innovation of new technologies, the Internet has become the main driving force of national and even global economic growth, which has greatly enriched people s lives. Millions of users can obtain information, exchange information, express their views and share their experiences, and express various emotions on the Internet. When people want to evaluate something, they often have their subjective emotional tendency, and when people … Cites: ‪Segmental recurrent neural networks‬&lt;/p&gt;</content><author><name>張子涵 - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Nowadays, with the rapid development and innovation of new technologies, the Internet has become the main driving force of national and even global economic growth, which has greatly enriched people s lives. Millions of users can obtain information, exchange information, express their views and share their experiences, and express various emotions on the Internet. When people want to evaluate something, they often have their subjective emotional tendency, and when people … Cites: ‪Segmental recurrent neural networks‬</summary></entry><entry><title type="html">Multi-Constrained Embedding for Accurate Community Detection on Undirected Networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/0ce3c318658dbaff0fec78430ec74e8c.html" rel="alternate" type="text/html" title="Multi-Constrained Embedding for Accurate Community Detection on Undirected Networks" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/0ce3c318658dbaff0fec78430ec74e8c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/0ce3c318658dbaff0fec78430ec74e8c.html">&lt;p&gt;A Symmetric Non-negative Matrix Factorization (SNMF)-based network embedding model adopts a unique Latent Factor (LF) matrix for describing the symmetry of an undirected network, which reduces its representation ability to the target network and thus resulting in accuracy loss when performing community detection. To address this issue, this paper proposes a new undirected network embedding model, ie, Alternating Direction Method of Multipliers (ADMM)-based, Modularity, Symmetry and … Cites: ‪Network Representation Learning with Rich Text Information‬&lt;/p&gt;</content><author><name>Q Wang, X Liu, T Shang, Z Liu, H Yang, X Luo - IEEE Transactions on Network …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A Symmetric Non-negative Matrix Factorization (SNMF)-based network embedding model adopts a unique Latent Factor (LF) matrix for describing the symmetry of an undirected network, which reduces its representation ability to the target network and thus resulting in accuracy loss when performing community detection. To address this issue, this paper proposes a new undirected network embedding model, ie, Alternating Direction Method of Multipliers (ADMM)-based, Modularity, Symmetry and … Cites: ‪Network Representation Learning with Rich Text Information‬</summary></entry><entry><title type="html">Greedy Modality Selection via Approximate Submodular Maximization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/0e961e8496fd2509b2097ab0402c5ce0.html" rel="alternate" type="text/html" title="Greedy Modality Selection via Approximate Submodular Maximization" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/0e961e8496fd2509b2097ab0402c5ce0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/0e961e8496fd2509b2097ab0402c5ce0.html">&lt;p&gt;Multimodal learning considers learning from multi-modality data, aiming to fuse heterogeneous sources of information. However, it is not always feasible to leverage all available modalities due to memory constraints. Further, training on all the modalities may be inefficient when redundant information exists within data, such as different subsets of modalities providing similar performance. In light of these challenges, we study modality selection, intending to efficiently select the most … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬&lt;/p&gt;</content><author><name>R Cheng, G Balasubramaniam, Y He, YHH Tsai… - The 38th Conference on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Multimodal learning considers learning from multi-modality data, aiming to fuse heterogeneous sources of information. However, it is not always feasible to leverage all available modalities due to memory constraints. Further, training on all the modalities may be inefficient when redundant information exists within data, such as different subsets of modalities providing similar performance. In light of these challenges, we study modality selection, intending to efficiently select the most … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬</summary></entry><entry><title type="html">A Graph-Based Recommendation Algorithm on Quaternion Algebra</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/0f90a2118319e246dc5dc0a277a2b8e7.html" rel="alternate" type="text/html" title="A Graph-Based Recommendation Algorithm on Quaternion Algebra" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/0f90a2118319e246dc5dc0a277a2b8e7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/0f90a2118319e246dc5dc0a277a2b8e7.html">&lt;p&gt;This study presents a novel Quaternion-based link prediction method to be used in different recommendation systems. The method performs Quaternion algebra-based computations while making use of expressive and wide-ranged learning properties of the Hamilton products. The proposed key capabilities rely on link prediction to boost performance in top-N recommendation tasks. According to the achieved experimental results, the proposed method allows for highly improved performance … Cites: ‪Complex embeddings for simple link prediction‬&lt;/p&gt;</content><author><name>Z Kurt, ÖN Gerek, A Bilge, K Özkan - SN Computer Science, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This study presents a novel Quaternion-based link prediction method to be used in different recommendation systems. The method performs Quaternion algebra-based computations while making use of expressive and wide-ranged learning properties of the Hamilton products. The proposed key capabilities rely on link prediction to boost performance in top-N recommendation tasks. According to the achieved experimental results, the proposed method allows for highly improved performance … Cites: ‪Complex embeddings for simple link prediction‬</summary></entry><entry><title type="html">基于知识协同微调的低资源知识图谱补全方法</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/130bd930d13dab286e3585052f4ec4a7.html" rel="alternate" type="text/html" title="基于知识协同微调的低资源知识图谱补全方法" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/130bd930d13dab286e3585052f4ec4a7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/130bd930d13dab286e3585052f4ec4a7.html">&lt;p&gt;知识图谱补全能让知识图谱变得更加完整. 现有的知识图谱补全工作大多会假设知识图谱中的实体或关系有充足的三元组实例. 然而, 在通用领域, 存在大量长尾三元组; 在垂直领域, 较难获得大量高质量的标注数据. 本文针对这一问题, 提出了一种基于知识协同微调的低资源知识图谱补全方法. 本文通过已有的结构化知识来构造初始的知识图谱补全提示, 并提出一种协同微调算法来学习最优的模板, 标签和模型的参数. 本文的方法同时利用了知识图谱中的显式结构化知识和语言模型中的隐式事实知识 … Cites: ‪Language models as knowledge bases?‬&lt;/p&gt;</content><author><name>张宁豫， 谢辛， 陈想， 邓淑敏， 叶宏彬， 陈华钧</name></author><category term="jekyll" /><category term="update" /><summary type="html">知识图谱补全能让知识图谱变得更加完整. 现有的知识图谱补全工作大多会假设知识图谱中的实体或关系有充足的三元组实例. 然而, 在通用领域, 存在大量长尾三元组; 在垂直领域, 较难获得大量高质量的标注数据. 本文针对这一问题, 提出了一种基于知识协同微调的低资源知识图谱补全方法. 本文通过已有的结构化知识来构造初始的知识图谱补全提示, 并提出一种协同微调算法来学习最优的模板, 标签和模型的参数. 本文的方法同时利用了知识图谱中的显式结构化知识和语言模型中的隐式事实知识 … Cites: ‪Language models as knowledge bases?‬</summary></entry><entry><title type="html">説明可能な多変量時系列異常検知手法</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/1c54b809ee904c079147fc2b616101d4.html" rel="alternate" type="text/html" title="説明可能な多変量時系列異常検知手法" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/1c54b809ee904c079147fc2b616101d4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/1c54b809ee904c079147fc2b616101d4.html">&lt;p&gt;1 はじめに製造業分野の生産性向上を目指す Industry4. 0 という概念が 2011 年頃から提唱されている. 工場の生産プロセスでは IoT 機器の導入が加速しており, 大量のデータ収集を低コストで取得し, それを多様な用途で活用することが可能になった [1]. そして, 多数の企業が工場の運用効率化や運用コスト削減を目的に, IoT 機器から取得したデータを用いて, 設備の監視業務を効率化している. この監視業務効率化の一環として, 取得したデータから通常とは異なる挙動を検出することで設備の異常を発見する異常検知 … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/p&gt;</content><author><name>中原英里， 塩田哲哉， 豊田真智子 - IEICE Conferences Archives, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">1 はじめに製造業分野の生産性向上を目指す Industry4. 0 という概念が 2011 年頃から提唱されている. 工場の生産プロセスでは IoT 機器の導入が加速しており, 大量のデータ収集を低コストで取得し, それを多様な用途で活用することが可能になった [1]. そして, 多数の企業が工場の運用効率化や運用コスト削減を目的に, IoT 機器から取得したデータを用いて, 設備の監視業務を効率化している. この監視業務効率化の一環として, 取得したデータから通常とは異なる挙動を検出することで設備の異常を発見する異常検知 … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">LIPI at the NTCIR-16 FinNum-3 Task: Ensembling transformer based models to detect in-claim numerals in Financial Conversations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/210545fc80ef40230f98f55bb810cd41.html" rel="alternate" type="text/html" title="LIPI at the NTCIR-16 FinNum-3 Task: Ensembling transformer based models to detect in-claim numerals in Financial Conversations" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/210545fc80ef40230f98f55bb810cd41</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/210545fc80ef40230f98f55bb810cd41.html">&lt;p&gt;The third edition of FinNum shared task, being held with NTCIR-16 presented the challenge of classifying numerals present in financial texts into in-claim or out-of-claim classes. It consisted of two claim detection sub-tasks on i) professional analysts  reports written in Chinese and ii) earning conference calls transcribed in English. In this paper, we describe the approach our team (LIPI) followed while participating in the English subtask of FinNum-3. This approach consists of … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬&lt;/p&gt;</content><author><name>S Ghosh, SK Naskar - Proceedings of the 16th NTCIR conference on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The third edition of FinNum shared task, being held with NTCIR-16 presented the challenge of classifying numerals present in financial texts into in-claim or out-of-claim classes. It consisted of two claim detection sub-tasks on i) professional analysts reports written in Chinese and ii) earning conference calls transcribed in English. In this paper, we describe the approach our team (LIPI) followed while participating in the English subtask of FinNum-3. This approach consists of … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬</summary></entry><entry><title type="html">Improving scripts with a memory of natural feedback</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/24f310bb8599fbc0532a2a4fe1610e92.html" rel="alternate" type="text/html" title="Improving scripts with a memory of natural feedback" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/24f310bb8599fbc0532a2a4fe1610e92</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/24f310bb8599fbc0532a2a4fe1610e92.html">&lt;p&gt;How can an end-user provide feedback if a deployed structured prediction model generates incorrect output? Our goal is to allow users to correct errors directly through interaction, without retraining, by giving feedback on the model s output. We create a dynamic memory architecture with a growing memory of feedbacks about errors in the output. Given a new, unseen input, our model can use feedback from a similar, past erroneous state. On a script generation task, we show empirically that … Cites: ‪REALM: Retrieval-Augmented Language Model Pre-Training‬&lt;/p&gt;</content><author><name>N Tandon, A Madaan, P Clark, Y Yang - arXiv preprint arXiv:2112.09737, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">How can an end-user provide feedback if a deployed structured prediction model generates incorrect output? Our goal is to allow users to correct errors directly through interaction, without retraining, by giving feedback on the model s output. We create a dynamic memory architecture with a growing memory of feedbacks about errors in the output. Given a new, unseen input, our model can use feedback from a similar, past erroneous state. On a script generation task, we show empirically that … Cites: ‪REALM: Retrieval-Augmented Language Model Pre-Training‬</summary></entry><entry><title type="html">Semantic Supervision: Enabling Generalization over Output Spaces</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/2b14f0ec22fa2fb4e1d75fb2e62c224a.html" rel="alternate" type="text/html" title="Semantic Supervision: Enabling Generalization over Output Spaces" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/2b14f0ec22fa2fb4e1d75fb2e62c224a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/2b14f0ec22fa2fb4e1d75fb2e62c224a.html">&lt;p&gt;In this paper, we propose semantic supervision (SemSup)-a unified paradigm for training classifiers that generalize over output spaces. In contrast to standard classification, which treats classes as discrete symbols, SemSup represents them as dense vector features obtained from descriptions of classes (eg,  The cat is a small carnivorous mammal ). This allows the output space to be unbounded (in the space of descriptions) and enables models to generalize both over unseen inputs and … Cites: ‪Well-read students learn better: On the importance of pre-training …‬&lt;/p&gt;</content><author><name>A Deshpande, AW Hanjie, KR Narasimhan - ACL Workshop on Learning with Natural …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper, we propose semantic supervision (SemSup)-a unified paradigm for training classifiers that generalize over output spaces. In contrast to standard classification, which treats classes as discrete symbols, SemSup represents them as dense vector features obtained from descriptions of classes (eg, The cat is a small carnivorous mammal ). This allows the output space to be unbounded (in the space of descriptions) and enables models to generalize both over unseen inputs and … Cites: ‪Well-read students learn better: On the importance of pre-training …‬</summary></entry><entry><title type="html">Transformers only look once with nonlinear combination for real-time object detection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/30696402b5a64dc82ce2b11b2a97d23b.html" rel="alternate" type="text/html" title="Transformers only look once with nonlinear combination for real-time object detection" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/30696402b5a64dc82ce2b11b2a97d23b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/30696402b5a64dc82ce2b11b2a97d23b.html">&lt;p&gt;In this article, a novel real-time object detector called Transformers Only Look Once (TOLO) is proposed to resolve two problems. The first problem is the inefficiency of building long-distance dependencies among local features for amounts of modern real-time object detectors. The second one is the lack of inductive biases for vision Transformer networks with heavily computational cost. TOLO is composed of Convolutional Neural Network (CNN) backbone, Feature Fusion Neck (FFN), and … Cites: ‪Efficientdet: Scalable and efficient object detection‬&lt;/p&gt;</content><author><name>R Xia, G Li, Z Huang, Y Pang, M Qi - Neural Computing and Applications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this article, a novel real-time object detector called Transformers Only Look Once (TOLO) is proposed to resolve two problems. The first problem is the inefficiency of building long-distance dependencies among local features for amounts of modern real-time object detectors. The second one is the lack of inductive biases for vision Transformer networks with heavily computational cost. TOLO is composed of Convolutional Neural Network (CNN) backbone, Feature Fusion Neck (FFN), and … Cites: ‪Efficientdet: Scalable and efficient object detection‬</summary></entry><entry><title type="html">Dataset of Student Solutions to Algorithm and Data Structure Programming Assignments</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/333c8e5082168e4f3af39cb83f28b023.html" rel="alternate" type="text/html" title="Dataset of Student Solutions to Algorithm and Data Structure Programming Assignments" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/333c8e5082168e4f3af39cb83f28b023</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/333c8e5082168e4f3af39cb83f28b023.html">&lt;p&gt;We present a dataset containing source code solutions to algorithmic programming exercises solved by hundreds of Bachelor-level students at the Universität Hamburg. These solutions were collected during the winter semesters 2019/2020, 2020/2021 and 2021/2022. The dataset contains a set of solutions to a total of 21 tasks written in Java as well as Python and a total of over 1500 individual solutions. All solutions were submitted through Moodle and the Coderunner plugin and passed a number of … Cites: ‪Juice: A large scale distantly supervised dataset for open domain …‬&lt;/p&gt;</content><author><name>F Petersen-Frey, M Soll, L Kobras, M Johannsen…</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present a dataset containing source code solutions to algorithmic programming exercises solved by hundreds of Bachelor-level students at the Universität Hamburg. These solutions were collected during the winter semesters 2019/2020, 2020/2021 and 2021/2022. The dataset contains a set of solutions to a total of 21 tasks written in Java as well as Python and a total of over 1500 individual solutions. All solutions were submitted through Moodle and the Coderunner plugin and passed a number of … Cites: ‪Juice: A large scale distantly supervised dataset for open domain …‬</summary></entry><entry><title type="html">A New Human Factor Study in Developing Practical Vision-Based Applications with the Transformer-Based Deep Learning Model</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/33dcfe7ed9e112e7e31d95f11acb8846.html" rel="alternate" type="text/html" title="A New Human Factor Study in Developing Practical Vision-Based Applications with the Transformer-Based Deep Learning Model" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/33dcfe7ed9e112e7e31d95f11acb8846</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/33dcfe7ed9e112e7e31d95f11acb8846.html">&lt;p&gt;The convolutional neural network is a deep learning architecture that has dominated most computer vision tasks for several years. But starting from 2020, Transformer architecture has turned to be a new challenger that has been expected to replace convolutional neural networks in the near future. Unlike researchers that prefer observing any new possibility in order to look for chances of improvement, achieving a new state-of-the-art model is not a goal for most practitioners. This paper observes … Cites: ‪Training EfficientNets at Supercomputer Scale: 83% ImageNet Top …‬&lt;/p&gt;</content><author><name>T Siriborvornratanakul - Artificial Intelligence in HCI: 3rd International …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The convolutional neural network is a deep learning architecture that has dominated most computer vision tasks for several years. But starting from 2020, Transformer architecture has turned to be a new challenger that has been expected to replace convolutional neural networks in the near future. Unlike researchers that prefer observing any new possibility in order to look for chances of improvement, achieving a new state-of-the-art model is not a goal for most practitioners. This paper observes … Cites: ‪Training EfficientNets at Supercomputer Scale: 83% ImageNet Top …‬</summary></entry><entry><title type="html">質問応答を用いた日本語要約評価システム</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/39fc932b3dacd9ffee078f6a94b5601e.html" rel="alternate" type="text/html" title="質問応答を用いた日本語要約評価システム" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/39fc932b3dacd9ffee078f6a94b5601e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/39fc932b3dacd9ffee078f6a94b5601e.html">&lt;p&gt;2.1 概要 QAGS [1] は要約文から質問を生成し原文と要約文に対して同じ質問を投げかけることで, 得られた解答との類似度を比較し要約文を評価する. 解答の比較では F 値を用いており, 全ての質問について F 値を計算し平均を求める. 以下に概要図を載せる.(図 1) Cites: ‪Asking and Answering Questions to Evaluate the Factual …‬&lt;/p&gt;</content><author><name>岡田直士， 松澤智史 - IEICE Conferences Archives, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">2.1 概要 QAGS [1] は要約文から質問を生成し原文と要約文に対して同じ質問を投げかけることで, 得られた解答との類似度を比較し要約文を評価する. 解答の比較では F 値を用いており, 全ての質問について F 値を計算し平均を求める. 以下に概要図を載せる.(図 1) Cites: ‪Asking and Answering Questions to Evaluate the Factual …‬</summary></entry><entry><title type="html">Crop Growth Monitoring System in Vertical Farms Based on Region-of-Interest Prediction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/3a093e7486814fc11b8093c88609116a.html" rel="alternate" type="text/html" title="Crop Growth Monitoring System in Vertical Farms Based on Region-of-Interest Prediction" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/3a093e7486814fc11b8093c88609116a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/3a093e7486814fc11b8093c88609116a.html">&lt;p&gt;Vertical farms are to be considered the future of agriculture given that they not only use space and resources efficiently but can also consistently produce large yields. Recently, artificial intelligence has been introduced for use in vertical farms to boost crop yields, and crop growth monitoring is an essential example of the type of automation necessary to manage a vertical farm system. Region of interest predictions are generally used to find crop regions from the color images captured by … Cites: ‪Simple copy-paste is a strong data augmentation method for …‬&lt;/p&gt;</content><author><name>Y Hwang, S Lee, T Kim, K Baik, Y Choi - Agriculture, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Vertical farms are to be considered the future of agriculture given that they not only use space and resources efficiently but can also consistently produce large yields. Recently, artificial intelligence has been introduced for use in vertical farms to boost crop yields, and crop growth monitoring is an essential example of the type of automation necessary to manage a vertical farm system. Region of interest predictions are generally used to find crop regions from the color images captured by … Cites: ‪Simple copy-paste is a strong data augmentation method for …‬</summary></entry><entry><title type="html">対話要約における話者情報を持つ Embedding の効果</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/3c37f13f0f86abf74b2c9af3af000933.html" rel="alternate" type="text/html" title="対話要約における話者情報を持つ Embedding の効果" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/3c37f13f0f86abf74b2c9af3af000933</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/3c37f13f0f86abf74b2c9af3af000933.html">&lt;p&gt;対話要約における話者情報を持つ Embedding の効果 Page 1 対話要約における話者情報  を持つ Embedding の効果 The Effects of Embedding with Speaker Identity Information   in Dialogue Summarization 楢木悠士 早稲田大学理工学術院 yuji.1277@akane.waseda.jp   酒井哲也 早稲田大学理工学術院 tetsuyasakai@acm.org 林良彦 早稲田大学理工学術院   yshk.hayashi@aoni.waseda.jp 1 はじめに 膨大なテキスト情報を的確に把握するための  手段 として自動要約の重要性が増している.また,イン ターネット上での会議などが増える … Cites: ‪Don t give me the details, just the summary! topic-aware …‬&lt;/p&gt;</content><author><name>楢木悠士， 酒井哲也， 林良彦 - IEICE Conferences Archives, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">対話要約における話者情報を持つ Embedding の効果 Page 1 対話要約における話者情報 を持つ Embedding の効果 The Effects of Embedding with Speaker Identity Information in Dialogue Summarization 楢木悠士 早稲田大学理工学術院 yuji.1277@akane.waseda.jp 酒井哲也 早稲田大学理工学術院 tetsuyasakai@acm.org 林良彦 早稲田大学理工学術院 yshk.hayashi@aoni.waseda.jp 1 はじめに 膨大なテキスト情報を的確に把握するための 手段 として自動要約の重要性が増している.また,イン ターネット上での会議などが増える … Cites: ‪Don t give me the details, just the summary! topic-aware …‬</summary></entry><entry><title type="html">Few-shot image classification by generating natural language rules</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/404b0658f003346742f25b1239807bce.html" rel="alternate" type="text/html" title="Few-shot image classification by generating natural language rules" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/404b0658f003346742f25b1239807bce</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/404b0658f003346742f25b1239807bce.html">&lt;p&gt;The ability to generate rules and hypotheses plays a key role in multiple aspects of human cognition including concept learning and explanation. Previous research has framed this ability as a form of inference via probabilistic program induction. However, this approach requires careful construction of the right grammar and hypothesis space for a particular task. In this work, we propose an alternative computational account of rule generation and concept learning that sidesteps some … Cites: ‪Shaping visual representations with language for few-shot …‬&lt;/p&gt;</content><author><name>WK Vong, BM Lake - ACL Workshop on Learning with Natural Language …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The ability to generate rules and hypotheses plays a key role in multiple aspects of human cognition including concept learning and explanation. Previous research has framed this ability as a form of inference via probabilistic program induction. However, this approach requires careful construction of the right grammar and hypothesis space for a particular task. In this work, we propose an alternative computational account of rule generation and concept learning that sidesteps some … Cites: ‪Shaping visual representations with language for few-shot …‬</summary></entry><entry><title type="html">Step 3: What Should Be Happening?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/4691c6fa20d1e8ec7d260fbcea9c8f74.html" rel="alternate" type="text/html" title="Step 3: What Should Be Happening?" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/4691c6fa20d1e8ec7d260fbcea9c8f74</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/4691c6fa20d1e8ec7d260fbcea9c8f74.html">&lt;p&gt;Vision is an anchor for individuals to center their mindset, attitude, and behavior in a productive way, both personally and professionally. Individual vision and organizational vision are intended to motivate individuals, teams, and organizations in their performance and productivity by offering compelling guidance for the future in organization or one s individual career and progress. Envisioning is similar to the process of environmental scanning, which should be part of an organization s … Cites: ‪Does the whole exceed its parts? the effect of ai explanations on …‬&lt;/p&gt;</content><author><name>B Bakhshandeh - High-Performance Coaching for Managers</name></author><category term="jekyll" /><category term="update" /><summary type="html">Vision is an anchor for individuals to center their mindset, attitude, and behavior in a productive way, both personally and professionally. Individual vision and organizational vision are intended to motivate individuals, teams, and organizations in their performance and productivity by offering compelling guidance for the future in organization or one s individual career and progress. Envisioning is similar to the process of environmental scanning, which should be part of an organization s … Cites: ‪Does the whole exceed its parts? the effect of ai explanations on …‬</summary></entry><entry><title type="html">Detecting explicit lyrics: a case study in Italian music</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/4a49ed9bdf7e8e6d977c5dc88747f93b.html" rel="alternate" type="text/html" title="Detecting explicit lyrics: a case study in Italian music" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/4a49ed9bdf7e8e6d977c5dc88747f93b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/4a49ed9bdf7e8e6d977c5dc88747f93b.html">&lt;p&gt;Preventing the reproduction of songs whose textual content is offensive or inappropriate for kids is an important issue in the music industry. In this paper, we investigate the problem of assessing whether music lyrics contain content unsuitable for children (aka, explicit content). Previous works that have computationally tackled this problem have dealt with English or Korean songs, comparing the performance of various machine learning approaches. We investigate the automatic detection of … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬&lt;/p&gt;</content><author><name>M Rospocher - Language Resources and Evaluation, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Preventing the reproduction of songs whose textual content is offensive or inappropriate for kids is an important issue in the music industry. In this paper, we investigate the problem of assessing whether music lyrics contain content unsuitable for children (aka, explicit content). Previous works that have computationally tackled this problem have dealt with English or Korean songs, comparing the performance of various machine learning approaches. We investigate the automatic detection of … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬</summary></entry><entry><title type="html">QuExEnt: Improved Zero-Shot Classification from Explanations Through Quantifier Modeling and Curriculum Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/4c69feba0f242380cd59ac90fc1d2ecc.html" rel="alternate" type="text/html" title="QuExEnt: Improved Zero-Shot Classification from Explanations Through Quantifier Modeling and Curriculum Learning" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/4c69feba0f242380cd59ac90fc1d2ecc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/4c69feba0f242380cd59ac90fc1d2ecc.html">&lt;p&gt;A hallmark of human intelligence is the ability to learn new concepts purely from language. While recent advances in training machine learning models via natural language explanations show promise, these approaches still fall short on modeling the the intricacies of natural language (such as quantifiers) or in mimicking human behavior in learning a suite a tasks with varying difficulty. In this work, we present QuExEnt, to learn better zero-shot classifiers from explanations by using three … Cites: ‪Competence-based Curriculum Learning for Neural Machine …‬&lt;/p&gt;</content><author><name>S Ghosh, RR Menon, S Srivastava - ACL Workshop on Learning with Natural …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A hallmark of human intelligence is the ability to learn new concepts purely from language. While recent advances in training machine learning models via natural language explanations show promise, these approaches still fall short on modeling the the intricacies of natural language (such as quantifiers) or in mimicking human behavior in learning a suite a tasks with varying difficulty. In this work, we present QuExEnt, to learn better zero-shot classifiers from explanations by using three … Cites: ‪Competence-based Curriculum Learning for Neural Machine …‬</summary></entry><entry><title type="html">背景入替えデータ集計による XAI 結果評価方式の提案</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/53fef52457028d1d856acfa271f54287.html" rel="alternate" type="text/html" title="背景入替えデータ集計による XAI 結果評価方式の提案" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/53fef52457028d1d856acfa271f54287</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/53fef52457028d1d856acfa271f54287.html">&lt;ol&gt;
  &lt;li&gt;はじめに機械学習の技術が発展する一方で, 機械学習モデルやアルゴリズムのいわゆるブラックボックス化が加速している. ブラックボックス化とは, 当該モデルがどのような理由でその結果を出力したのかについて直感的な理解を得ることが難しくなってきていることをいう. 機械学習のブラックボックス化に対し, モデルがなぜそのような判断結果を出力したのかを説明できるようにする, XAI (eXplainable AI, 説明可能な AI) という技術が研究されている. また, XAI を自らが開発する機械学習モデルに適用し, 出力される判定根拠からその挙動の … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬&lt;/li&gt;
&lt;/ol&gt;</content><author><name>安井雅彦， 浜直史， 森靖英， 和久井一則 - IEICE Conferences Archives, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">はじめに機械学習の技術が発展する一方で, 機械学習モデルやアルゴリズムのいわゆるブラックボックス化が加速している. ブラックボックス化とは, 当該モデルがどのような理由でその結果を出力したのかについて直感的な理解を得ることが難しくなってきていることをいう. 機械学習のブラックボックス化に対し, モデルがなぜそのような判断結果を出力したのかを説明できるようにする, XAI (eXplainable AI, 説明可能な AI) という技術が研究されている. また, XAI を自らが開発する機械学習モデルに適用し, 出力される判定根拠からその挙動の … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬</summary></entry><entry><title type="html">A Short Text Similarity Calculation Method Combining Semantic and Headword Attention Mechanism</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/54ced8b5bf23d0c561d2229cdf2c4a07.html" rel="alternate" type="text/html" title="A Short Text Similarity Calculation Method Combining Semantic and Headword Attention Mechanism" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/54ced8b5bf23d0c561d2229cdf2c4a07</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/54ced8b5bf23d0c561d2229cdf2c4a07.html">&lt;p&gt;Short text similarity computation plays an important role in various natural language processing tasks. Siamese neural networks are widely used in short text similarity calculation. However, due to the complexity of syntax and the correlation between words, siamese networks alone cannot achieve satisfactory results. Many studies show that the use of an attention mechanism will improve the impact of key features that can be utilized to measure sentence similarity. In this paper, a similarity … Cites: ‪Neural machine translation by jointly learning to align and translate‬&lt;/p&gt;</content><author><name>M Ji, X Zhang - Scientific Programming, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Short text similarity computation plays an important role in various natural language processing tasks. Siamese neural networks are widely used in short text similarity calculation. However, due to the complexity of syntax and the correlation between words, siamese networks alone cannot achieve satisfactory results. Many studies show that the use of an attention mechanism will improve the impact of key features that can be utilized to measure sentence similarity. In this paper, a similarity … Cites: ‪Neural machine translation by jointly learning to align and translate‬</summary></entry><entry><title type="html">Learning from Natural Language Feedback</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/5860504c21a624feab043e9ae27e0855.html" rel="alternate" type="text/html" title="Learning from Natural Language Feedback" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/5860504c21a624feab043e9ae27e0855</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/5860504c21a624feab043e9ae27e0855.html">&lt;p&gt;Pretrained language models often do not perform tasks in ways that are in line with our preferences, eg, generating offensive text or factually incorrect summaries. Recent work approaches the above issue by learning from a simple form of human evaluation: comparisons between pairs of model-generated task outputs. Comparison feedback conveys limited information about human preferences per human evaluation. Here, we propose to learn from natural language feedback, which … Cites: ‪Realtoxicityprompts: Evaluating neural toxic degeneration in …‬&lt;/p&gt;</content><author><name>J Scheurer, JA Campos, JS Chan, A Chen, K Cho… - ACL Workshop on Learning …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pretrained language models often do not perform tasks in ways that are in line with our preferences, eg, generating offensive text or factually incorrect summaries. Recent work approaches the above issue by learning from a simple form of human evaluation: comparisons between pairs of model-generated task outputs. Comparison feedback conveys limited information about human preferences per human evaluation. Here, we propose to learn from natural language feedback, which … Cites: ‪Realtoxicityprompts: Evaluating neural toxic degeneration in …‬</summary></entry><entry><title type="html">Detecting Illicit Cryptocurrency Mining Activity in Cloud Computing Platform</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/5a94e63bb79d22b5d7647fe7d36a5d36.html" rel="alternate" type="text/html" title="Detecting Illicit Cryptocurrency Mining Activity in Cloud Computing Platform" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/5a94e63bb79d22b5d7647fe7d36a5d36</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/5a94e63bb79d22b5d7647fe7d36a5d36.html">&lt;p&gt;Cloud computing adoption in IT infrastructure is one of the key elements in the digital transformation strategy of an organization. The features such as on-demand self-service, resource allocation elasticity and massive scalability that cloud solutions offer have further accelerated adoption during Covid-19 Pandemics. This is because during a lockdown, the organization IT infrastructure must be able to cater for the dynamic requirements while supporting a remote working environment for their … Cites: ‪Ad3: Alternating directions dual decomposition for map inference …‬&lt;/p&gt;</content><author><name>MAM Ariffin, MY Darus, AM Taib, R Osman, CMAC Mat - Journal of Positive School …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Cloud computing adoption in IT infrastructure is one of the key elements in the digital transformation strategy of an organization. The features such as on-demand self-service, resource allocation elasticity and massive scalability that cloud solutions offer have further accelerated adoption during Covid-19 Pandemics. This is because during a lockdown, the organization IT infrastructure must be able to cater for the dynamic requirements while supporting a remote working environment for their … Cites: ‪Ad3: Alternating directions dual decomposition for map inference …‬</summary></entry><entry><title type="html">Counterfactual Interpolation Augmentation (CIA): A Unified Approach to Enhance Fairness and Explainability of DNN</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/612073e3bfb7fabf188ba031c1eca7e8.html" rel="alternate" type="text/html" title="Counterfactual Interpolation Augmentation (CIA): A Unified Approach to Enhance Fairness and Explainability of DNN" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/612073e3bfb7fabf188ba031c1eca7e8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/612073e3bfb7fabf188ba031c1eca7e8.html">&lt;p&gt;Bias in the training data can jeopardize fairness and explainability of deep neural network prediction on test data. We propose a novel bias-tailored data augmentation approach, Counterfactual Interpolation Augmentation (CIA), attempting to debias the training data by d-separating the spurious correlation between the target variable and the sensitive attribute. CIA generates counterfactual interpolations along a path simulating the distribution transitions between the input and its counterfactual … Cites: ‪Do feature attribution methods correctly attribute features?‬&lt;/p&gt;</content><author><name>Y Qiang, C Li, M Brocanelli, D Zhu</name></author><category term="jekyll" /><category term="update" /><summary type="html">Bias in the training data can jeopardize fairness and explainability of deep neural network prediction on test data. We propose a novel bias-tailored data augmentation approach, Counterfactual Interpolation Augmentation (CIA), attempting to debias the training data by d-separating the spurious correlation between the target variable and the sensitive attribute. CIA generates counterfactual interpolations along a path simulating the distribution transitions between the input and its counterfactual … Cites: ‪Do feature attribution methods correctly attribute features?‬</summary></entry><entry><title type="html">日本語事前学習言語モデルにおける語彙の直接的操作を用いたドメイン適応の試みが下流タスクの精度に与える影響の評価</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/618737f5bc0dbc48218daa3445a6d59b.html" rel="alternate" type="text/html" title="日本語事前学習言語モデルにおける語彙の直接的操作を用いたドメイン適応の試みが下流タスクの精度に与える影響の評価" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/618737f5bc0dbc48218daa3445a6d59b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/618737f5bc0dbc48218daa3445a6d59b.html">&lt;p&gt;1 はじめに近年の機械学習を利用した自然言語処理技術の発展の要因の 1 つが, 学習過程を事前学習言語モデル (PLM: pretrained language model) の作成とタスク依存の Fine-Tuning へ分離可能になったこと [1, 2] である. 一般に, 大量のコーパスを用意し大規模なモデルを作成することで, 多くのタスクで高精度を達成する高性能な事前学習言語モデルが作成できると考えられている. また, 実際に自然言語処理モデルを運用するドメインと同一ドメインからコーパスを収集するようにすると … Cites: ‪Don t stop pretraining: adapt language models to domains and tasks‬&lt;/p&gt;</content><author><name>浜直史， 安井雅彦， 森靖英， 和久井一則 - IEICE Conferences Archives, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">1 はじめに近年の機械学習を利用した自然言語処理技術の発展の要因の 1 つが, 学習過程を事前学習言語モデル (PLM: pretrained language model) の作成とタスク依存の Fine-Tuning へ分離可能になったこと [1, 2] である. 一般に, 大量のコーパスを用意し大規模なモデルを作成することで, 多くのタスクで高精度を達成する高性能な事前学習言語モデルが作成できると考えられている. また, 実際に自然言語処理モデルを運用するドメインと同一ドメインからコーパスを収集するようにすると … Cites: ‪Don t stop pretraining: adapt language models to domains and tasks‬</summary></entry><entry><title type="html">Contrastive Latent Variable Models for Neural Text Generation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/638ec38f774e61f8e2044bd2373b1d1d.html" rel="alternate" type="text/html" title="Contrastive Latent Variable Models for Neural Text Generation" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/638ec38f774e61f8e2044bd2373b1d1d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/638ec38f774e61f8e2044bd2373b1d1d.html">&lt;p&gt;Deep latent variable models such as variational autoencoders and energy-based models are widely used for neural text generation. Most of them focus on matching the prior distribution with the posterior distribution of the latent variable for text reconstruction. In addition to instance-level reconstruction, this paper aims to integrate contrastive learning in the latent space, forcing the latent variables to learn high-level semantics by exploring inter-instance relationships. Experiments on … Cites: ‪Lagging Inference Networks and Posterior Collapse in Variational …‬&lt;/p&gt;</content><author><name>Z Teng, C Chen, Y Zhang, Y Zhang - The 38th Conference on Uncertainty in Artificial …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep latent variable models such as variational autoencoders and energy-based models are widely used for neural text generation. Most of them focus on matching the prior distribution with the posterior distribution of the latent variable for text reconstruction. In addition to instance-level reconstruction, this paper aims to integrate contrastive learning in the latent space, forcing the latent variables to learn high-level semantics by exploring inter-instance relationships. Experiments on … Cites: ‪Lagging Inference Networks and Posterior Collapse in Variational …‬</summary></entry><entry><title type="html">Stepping into the (social media) game</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/643d12b7c2a8e39045f4e8b768c95032.html" rel="alternate" type="text/html" title="Stepping into the (social media) game" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/643d12b7c2a8e39045f4e8b768c95032</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/643d12b7c2a8e39045f4e8b768c95032.html">&lt;p&gt;This chapter explores how rookie athletes in Major League Baseball (MLB), the National Basketball Association (NBA), National Football League (NFL), and National Hockey League (NHL), used Twitter as an identity expression tool. A representative sample of tweets from athletes selected in the first round of the 2011 amateur draft of each sports league was selected for analysis. Results revealed that identity manifested in the following ways:(a) Athletes as dedicated workers;(b) … Cites: ‪From tweets to polls: Linking text sentiment to public opinion time …‬&lt;/p&gt;</content><author><name>J Sanderson - Handbook of Research on</name></author><category term="jekyll" /><category term="update" /><summary type="html">This chapter explores how rookie athletes in Major League Baseball (MLB), the National Basketball Association (NBA), National Football League (NFL), and National Hockey League (NHL), used Twitter as an identity expression tool. A representative sample of tweets from athletes selected in the first round of the 2011 amateur draft of each sports league was selected for analysis. Results revealed that identity manifested in the following ways:(a) Athletes as dedicated workers;(b) … Cites: ‪From tweets to polls: Linking text sentiment to public opinion time …‬</summary></entry><entry><title type="html">Shared Autonomy for Robotic Manipulation with Language Corrections</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/64c7801d8101a4068977b1dbbe6ab01c.html" rel="alternate" type="text/html" title="Shared Autonomy for Robotic Manipulation with Language Corrections" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/64c7801d8101a4068977b1dbbe6ab01c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/64c7801d8101a4068977b1dbbe6ab01c.html">&lt;p&gt;Traditional end-to-end instruction following approaches for robotic manipulation are notoriously sample inefficient and lack adaptivity; for most single-turn methods, there is no way to provide additional language supervision to adapt robot behavior online–a property critical to deploying robots in collaborative, safety-critical environments. In this work, we present a method for incorporating language corrections, built on the insight that an initial instruction and subsequent corrections differ mainly in the … Cites: ‪Vision-and-dialog navigation‬&lt;/p&gt;</content><author><name>S Karamcheti, R Palleti, Y Cui, P Liang, D Sadigh - ACL Workshop on Learning with …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Traditional end-to-end instruction following approaches for robotic manipulation are notoriously sample inefficient and lack adaptivity; for most single-turn methods, there is no way to provide additional language supervision to adapt robot behavior online–a property critical to deploying robots in collaborative, safety-critical environments. In this work, we present a method for incorporating language corrections, built on the insight that an initial instruction and subsequent corrections differ mainly in the … Cites: ‪Vision-and-dialog navigation‬</summary></entry><entry><title type="html">Open Source Vizier: Distributed Infrastructure and API for Reliable and Flexible Blackbox Optimization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/6659d97ac684d704dae0d5ded27ff2bd.html" rel="alternate" type="text/html" title="Open Source Vizier: Distributed Infrastructure and API for Reliable and Flexible Blackbox Optimization" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/6659d97ac684d704dae0d5ded27ff2bd</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/6659d97ac684d704dae0d5ded27ff2bd.html">&lt;p&gt;Vizier is the de-facto blackbox optimization service across Google, having optimized some of Google s largest products and research efforts. To operate at the scale of tuning thousands of users  critical systems, Vizier solved key design challenges in providing multiple different features, while remaining fully fault-tolerant. In this paper, we introduce Open Source (OSS) Vizier, a Python-based interface for blackbox optimization and research, based on the Google-internal Vizier infrastructure and … Cites: ‪A full-stack accelerator search technique for vision applications‬&lt;/p&gt;</content><author><name>X Song, S Perel, C Lee, G Kochanski, D Golovin - First Conference on Automated …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Vizier is the de-facto blackbox optimization service across Google, having optimized some of Google s largest products and research efforts. To operate at the scale of tuning thousands of users critical systems, Vizier solved key design challenges in providing multiple different features, while remaining fully fault-tolerant. In this paper, we introduce Open Source (OSS) Vizier, a Python-based interface for blackbox optimization and research, based on the Google-internal Vizier infrastructure and … Cites: ‪A full-stack accelerator search technique for vision applications‬</summary></entry><entry><title type="html">A Profiling and Query Platform for Research Management Based on Knowledge Graph</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/6d8433c83790f9d1fbb1367e01f4b65e.html" rel="alternate" type="text/html" title="A Profiling and Query Platform for Research Management Based on Knowledge Graph" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/6d8433c83790f9d1fbb1367e01f4b65e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/6d8433c83790f9d1fbb1367e01f4b65e.html">&lt;p&gt;Researching is a process whereby a large amount of new and unstructured knowledge is created and accumulated. In this context, the capture of complex knowledge about detailed work and decision-making issues throughout a research project is very challenging for modern researchers. Knowledge graph technology can help machines better understand complicated relationships between entities, has great potential for helping researchers with organizing and automating such … Cites: ‪Design challenges and misconceptions in named entity recognition‬&lt;/p&gt;</content><author><name>K Ma, B Qin, H Wang - 2022 IEEE 25th International Conference on Computer …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Researching is a process whereby a large amount of new and unstructured knowledge is created and accumulated. In this context, the capture of complex knowledge about detailed work and decision-making issues throughout a research project is very challenging for modern researchers. Knowledge graph technology can help machines better understand complicated relationships between entities, has great potential for helping researchers with organizing and automating such … Cites: ‪Design challenges and misconceptions in named entity recognition‬</summary></entry><entry><title type="html">Sentence classification based on the concept kernel attention mechanism</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/76d5aee8ec4135cf361c6a018929d1ed.html" rel="alternate" type="text/html" title="Sentence classification based on the concept kernel attention mechanism" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/76d5aee8ec4135cf361c6a018929d1ed</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/76d5aee8ec4135cf361c6a018929d1ed.html">&lt;p&gt;Sentence classification is important for data mining and information security. Recently, researchers have paid increasing attention to applying conceptual knowledge to assist in sentence classification. Most existing approaches enhance classification by finding word-related concepts in external knowledge bases and incorporating them into sentence representations. However, this approach assumes that all concepts are equally important, which is not helpful for distinguishing the … Cites: ‪Stanza: A python natural language processing toolkit for many …‬&lt;/p&gt;</content><author><name>H Li, G Huang, Y Li, X Zhang, Y Wang - EAI Endorsed Transactions on Scalable …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Sentence classification is important for data mining and information security. Recently, researchers have paid increasing attention to applying conceptual knowledge to assist in sentence classification. Most existing approaches enhance classification by finding word-related concepts in external knowledge bases and incorporating them into sentence representations. However, this approach assumes that all concepts are equally important, which is not helpful for distinguishing the … Cites: ‪Stanza: A python natural language processing toolkit for many …‬</summary></entry><entry><title type="html">Unsupervised English Intelligent Machine Translation in Wireless Network Environment</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/77faadfab46803a394b4be216987a406.html" rel="alternate" type="text/html" title="Unsupervised English Intelligent Machine Translation in Wireless Network Environment" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/77faadfab46803a394b4be216987a406</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/77faadfab46803a394b4be216987a406.html">&lt;p&gt;Researchers suggest unsupervised English machine translation to address the absence of parallel corpus in English translation. Unsupervised pretraining techniques, denoising autoencoders, back translation, and shared latent representation mechanisms are used to simulate the translation task using just monolingual corpora. This paper uses pseudo-parallel data to construct unsupervised neural machine translation (NMT) and dissimilar language pair … Cites: ‪Unsupervised neural machine translation‬&lt;/p&gt;</content><author><name>B Zhang - Security and Communication Networks, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Researchers suggest unsupervised English machine translation to address the absence of parallel corpus in English translation. Unsupervised pretraining techniques, denoising autoencoders, back translation, and shared latent representation mechanisms are used to simulate the translation task using just monolingual corpora. This paper uses pseudo-parallel data to construct unsupervised neural machine translation (NMT) and dissimilar language pair … Cites: ‪Unsupervised neural machine translation‬</summary></entry><entry><title type="html">Development status and trend of autonomous operation for unmanned surface vehicle</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/78c1af8b0217882f479faa66e873a38c.html" rel="alternate" type="text/html" title="Development status and trend of autonomous operation for unmanned surface vehicle" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/78c1af8b0217882f479faa66e873a38c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/78c1af8b0217882f479faa66e873a38c.html">&lt;p&gt;Autonomous operation for unmanned surface vehicle (USV) is the core competence for USV, and an important mean for unmanned and intelligent operation. USVs can be used for multi-mission, so autonomous operation for USV faces a lot of challenges, such as complex and changeable marine environmental factors, limited means of awareness in sea, low degree of automated operational decisions, difficult integration control of sailing and combat equipment. This study summarizes the … Cites: ‪A General Framework for Information Extraction using Dynamic …‬&lt;/p&gt;</content><author><name>Q Cai Sr, F Li - International Conference on Computer Application and …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Autonomous operation for unmanned surface vehicle (USV) is the core competence for USV, and an important mean for unmanned and intelligent operation. USVs can be used for multi-mission, so autonomous operation for USV faces a lot of challenges, such as complex and changeable marine environmental factors, limited means of awareness in sea, low degree of automated operational decisions, difficult integration control of sailing and combat equipment. This study summarizes the … Cites: ‪A General Framework for Information Extraction using Dynamic …‬</summary></entry><entry><title type="html">IoDM: A Study on a IoT-Based Organizational Deception Modeling with Adaptive General-Sum Game Competition</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/82d4d67db3638ace46e914d260572cac.html" rel="alternate" type="text/html" title="IoDM: A Study on a IoT-Based Organizational Deception Modeling with Adaptive General-Sum Game Competition" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/82d4d67db3638ace46e914d260572cac</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/82d4d67db3638ace46e914d260572cac.html">&lt;p&gt;Moving target defense (MTD) and decoy strategies, measures of active defense, were introduced to secure both the proactive security and reactive adaptability of internet-of-things (IoT) networks that have been explosively applied to various industries without any strong security measures and to mitigate the side effects of threats. However, the existing MTD and decoy strategies are limited to avoiding the attacker s reconnaissance and initial intrusion attempts through simple structural … Cites: ‪Graph neural networks: A review of methods and applications‬&lt;/p&gt;</content><author><name>S Seo, D Kim - Electronics, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Moving target defense (MTD) and decoy strategies, measures of active defense, were introduced to secure both the proactive security and reactive adaptability of internet-of-things (IoT) networks that have been explosively applied to various industries without any strong security measures and to mitigate the side effects of threats. However, the existing MTD and decoy strategies are limited to avoiding the attacker s reconnaissance and initial intrusion attempts through simple structural … Cites: ‪Graph neural networks: A review of methods and applications‬</summary></entry><entry><title type="html">UCred: fusion of machine learning and deep learning methods for user credibility on social media</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/830241998cb3440a8d958492c556986f.html" rel="alternate" type="text/html" title="UCred: fusion of machine learning and deep learning methods for user credibility on social media" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/830241998cb3440a8d958492c556986f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/830241998cb3440a8d958492c556986f.html">&lt;p&gt;Abstract Online Social Network (OSN) is one of the biggest platforms that spread real and fake news. Many OSN users spread malicious data, fake news, and hoaxes using fake or social bot account for business, political and entertainment purposes. These accounts are also used to spread malicious URLs, viruses and malware. This paper proposes UCred (User Credibility) model to classify user accounts as fake or real. This model uses the combined results of RoBERT (Robustly optimized BERT) … Cites: ‪Roberta: A robustly optimized bert pretraining approach‬&lt;/p&gt;</content><author><name>PK Verma, P Agrawal, V Madaan, C Gupta - Social Network Analysis and Mining, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Online Social Network (OSN) is one of the biggest platforms that spread real and fake news. Many OSN users spread malicious data, fake news, and hoaxes using fake or social bot account for business, political and entertainment purposes. These accounts are also used to spread malicious URLs, viruses and malware. This paper proposes UCred (User Credibility) model to classify user accounts as fake or real. This model uses the combined results of RoBERT (Robustly optimized BERT) … Cites: ‪Roberta: A robustly optimized bert pretraining approach‬</summary></entry><entry><title type="html">Universal Semantic Annotator: the First Unified API for WSD, SRL and Semantic Parsing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/84f07aa6c2b2d570edc28d518a848203.html" rel="alternate" type="text/html" title="Universal Semantic Annotator: the First Unified API for WSD, SRL and Semantic Parsing" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/84f07aa6c2b2d570edc28d518a848203</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/84f07aa6c2b2d570edc28d518a848203.html">&lt;p&gt;In this paper, we present the Universal Semantic Annotator (USeA), which offers the first unified API for high-quality automatic annotations of texts in 100 languages through state-of-the-art systems for Word Sense Disambiguation, Semantic Role Labeling and Semantic Parsing. Together, such annotations can be used to provide users with rich and diverse semantic information, help second-language learners, and allow researchers to integrate explicit semantic knowledge into downstream … Cites: ‪Multilingual denoising pre-training for neural machine translation‬&lt;/p&gt;</content><author><name>R Orlando, S Conia, S Faralli, R Navigli</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper, we present the Universal Semantic Annotator (USeA), which offers the first unified API for high-quality automatic annotations of texts in 100 languages through state-of-the-art systems for Word Sense Disambiguation, Semantic Role Labeling and Semantic Parsing. Together, such annotations can be used to provide users with rich and diverse semantic information, help second-language learners, and allow researchers to integrate explicit semantic knowledge into downstream … Cites: ‪Multilingual denoising pre-training for neural machine translation‬</summary></entry><entry><title type="html">A Deductive System based on Froglingo for Natural Language Processing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/8972749c6ccf7977aacc7114d3a5853c.html" rel="alternate" type="text/html" title="A Deductive System based on Froglingo for Natural Language Processing" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/8972749c6ccf7977aacc7114d3a5853c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/8972749c6ccf7977aacc7114d3a5853c.html">&lt;p&gt;A word, a prepositional phrase, and a sentence can have different meanings in different contexts. Machine learning based Natural Language Processing (NLP) technologies build contexts for disambiguation using datasets from different disciplines such as medicine vs. finance. This approach, however, struggles to eliminate ambiguity at the degree human beings can, as we possess more granular knowledge of the context for a given circumstance. In other words, this approach is … Cites: ‪Semantic parsing on freebase from question-answer pairs‬&lt;/p&gt;</content><author><name>KH Xu</name></author><category term="jekyll" /><category term="update" /><summary type="html">A word, a prepositional phrase, and a sentence can have different meanings in different contexts. Machine learning based Natural Language Processing (NLP) technologies build contexts for disambiguation using datasets from different disciplines such as medicine vs. finance. This approach, however, struggles to eliminate ambiguity at the degree human beings can, as we possess more granular knowledge of the context for a given circumstance. In other words, this approach is … Cites: ‪Semantic parsing on freebase from question-answer pairs‬</summary></entry><entry><title type="html">End‐to‐end waveform level receiver with deep learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/8a8a242d2c71c5a72a7b53c5d8289697.html" rel="alternate" type="text/html" title="End‐to‐end waveform level receiver with deep learning" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/8a8a242d2c71c5a72a7b53c5d8289697</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/8a8a242d2c71c5a72a7b53c5d8289697.html">&lt;p&gt;Numerous researches on communication receiver design with deep learning algorithms have been implemented effectively recently. In this paper, an innovative scheme is proposed to construct an end‐to‐end neural network (NN) receiver to directly recover information bits from unsynchronized waveform sequences. Considering the correlation between samples, multiple bidirectional long‐short term memory (BiLSTM) layers to process oversampled signals. Then, shifted binary cross … Cites: ‪Aligned cross entropy for non-autoregressive machine translation‬&lt;/p&gt;</content><author><name>Z Zhu, H Yu, C Shen - IET Communications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Numerous researches on communication receiver design with deep learning algorithms have been implemented effectively recently. In this paper, an innovative scheme is proposed to construct an end‐to‐end neural network (NN) receiver to directly recover information bits from unsynchronized waveform sequences. Considering the correlation between samples, multiple bidirectional long‐short term memory (BiLSTM) layers to process oversampled signals. Then, shifted binary cross … Cites: ‪Aligned cross entropy for non-autoregressive machine translation‬</summary></entry><entry><title type="html">Реальность российского промышленного региона в американских СМИ: аспекты фреймирования</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/8dfbab50eee2f0be868b72b7427b5ea3.html" rel="alternate" type="text/html" title="Реальность российского промышленного региона в американских СМИ: аспекты фреймирования" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/8dfbab50eee2f0be868b72b7427b5ea3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/8dfbab50eee2f0be868b72b7427b5ea3.html">&lt;p&gt;Аннотация В статье рассмотрены особенности медийного фреймирования представлений о стратегически важном для России промышленном регионе в американских СМИ. Заметный рост зарубежных журналистских публикаций, освещающих проблемы Челябинской области в период с 2010 по 2021 год, определяет актуальность изучения генерации смыслов о Южном Урале как субъекте открытого глобального социума. В теоретико-методологическом … Cites: ‪Tracking the development of media frames within and across …‬&lt;/p&gt;</content><author><name>СЛ Кушнерук - Научный диалог, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Аннотация В статье рассмотрены особенности медийного фреймирования представлений о стратегически важном для России промышленном регионе в американских СМИ. Заметный рост зарубежных журналистских публикаций, освещающих проблемы Челябинской области в период с 2010 по 2021 год, определяет актуальность изучения генерации смыслов о Южном Урале как субъекте открытого глобального социума. В теоретико-методологическом … Cites: ‪Tracking the development of media frames within and across …‬</summary></entry><entry><title type="html">Semantic consistency learning on manifold for source data-free unsupervised domain adaptation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/91428ec54c4e83cdb3e58d2b06ab883f.html" rel="alternate" type="text/html" title="Semantic consistency learning on manifold for source data-free unsupervised domain adaptation" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/91428ec54c4e83cdb3e58d2b06ab883f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/91428ec54c4e83cdb3e58d2b06ab883f.html">&lt;p&gt;Recently, source data-free unsupervised domain adaptation (SFUDA) attracts increasing attention. Current work shows that the geometry of the target data is helpful to solving this challenging problem. However, these methods define the geometric structures in Euclidean space. The geometry cannot completely draw the semantic relationship between the target data distributed on a manifold. This article proposed a new SFUDA method, semantic consistency learning on manifold … Cites: ‪Imagenet: A large-scale hierarchical image database‬&lt;/p&gt;</content><author><name>S Tang, Y Zou, Z Song, J Lyu, L Chen, M Ye, S Zhong… - Neural Networks, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recently, source data-free unsupervised domain adaptation (SFUDA) attracts increasing attention. Current work shows that the geometry of the target data is helpful to solving this challenging problem. However, these methods define the geometric structures in Euclidean space. The geometry cannot completely draw the semantic relationship between the target data distributed on a manifold. This article proposed a new SFUDA method, semantic consistency learning on manifold … Cites: ‪Imagenet: A large-scale hierarchical image database‬</summary></entry><entry><title type="html">Learning Advisor Networks for Noisy Image Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/91d555e137a804619a24811e3e8cca53.html" rel="alternate" type="text/html" title="Learning Advisor Networks for Noisy Image Classification" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/91d555e137a804619a24811e3e8cca53</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/91d555e137a804619a24811e3e8cca53.html">&lt;p&gt;In this paper, we introduced the novel concept of advisor network to address the problem of noisy labels in image classification. Deep neural networks (DNN) are prone to performance reduction and overfitting problems on training data with noisy annotations. Weighting loss methods aim to mitigate the influence of noisy labels during the training, completely removing their contribution. This discarding process prevents DNNs from learning wrong associations between images and their correct … Cites: ‪Dividemix: Learning with noisy labels as semi-supervised learning‬&lt;/p&gt;</content><author><name>S Ricci, T Uricchio, AD Bimbo - Image Analysis and Processing–ICIAP 2022: 21st …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper, we introduced the novel concept of advisor network to address the problem of noisy labels in image classification. Deep neural networks (DNN) are prone to performance reduction and overfitting problems on training data with noisy annotations. Weighting loss methods aim to mitigate the influence of noisy labels during the training, completely removing their contribution. This discarding process prevents DNNs from learning wrong associations between images and their correct … Cites: ‪Dividemix: Learning with noisy labels as semi-supervised learning‬</summary></entry><entry><title type="html">Constraining word alignments with posterior regularization for label transfer</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/933de68eae2fc4148afa19acb1b441fe.html" rel="alternate" type="text/html" title="Constraining word alignments with posterior regularization for label transfer" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/933de68eae2fc4148afa19acb1b441fe</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/933de68eae2fc4148afa19acb1b441fe.html">&lt;p&gt;Unsupervised word alignments offer a lightweight and interpretable method to transfer labels from high-to low-resource languages, as long as semantically related words have the same label across languages. But such an assumption is often not true in industrial NLP pipelines, where multilingual annotation guidelines are complex and deviate from semantic consistency due to various factors (such as annotation difficulty, conflicting ontology, upcoming feature launches etc.); We … Cites: ‪Guiding semi-supervision with constraint-driven learning‬&lt;/p&gt;</content><author><name>KM Jose, T Gueudre</name></author><category term="jekyll" /><category term="update" /><summary type="html">Unsupervised word alignments offer a lightweight and interpretable method to transfer labels from high-to low-resource languages, as long as semantically related words have the same label across languages. But such an assumption is often not true in industrial NLP pipelines, where multilingual annotation guidelines are complex and deviate from semantic consistency due to various factors (such as annotation difficulty, conflicting ontology, upcoming feature launches etc.); We … Cites: ‪Guiding semi-supervision with constraint-driven learning‬</summary></entry><entry><title type="html">A Survey of Techniques for Constructing Mongolian Domain-Specific Knowledge Graph</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/9419438d0580d82cedac37b5aa79c70a.html" rel="alternate" type="text/html" title="A Survey of Techniques for Constructing Mongolian Domain-Specific Knowledge Graph" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/9419438d0580d82cedac37b5aa79c70a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/9419438d0580d82cedac37b5aa79c70a.html">&lt;p&gt;In 2012, Google originally introduced the conception of “Knowledge Graph” on their official blog site. As described, knowledge graph can provide richer search capabilities for the search engines to improve search quality and user experience, making search about things, not strings [1]. Knowledge graph is a particular database that amalgamates information in a structured format that can explicitly represent the relations between entities. In brief, the knowledge graph is composed … Cites: ‪Design challenges and misconceptions in named entity recognition‬&lt;/p&gt;</content><author><name>G Bao, H Bao, D Tang, A Suyila, A Gudamu - Mobile Wireless Middleware, Operating …</name></author><category term="jekyll" /><category term="update" /><summary type="html">In 2012, Google originally introduced the conception of “Knowledge Graph” on their official blog site. As described, knowledge graph can provide richer search capabilities for the search engines to improve search quality and user experience, making search about things, not strings [1]. Knowledge graph is a particular database that amalgamates information in a structured format that can explicitly represent the relations between entities. In brief, the knowledge graph is composed … Cites: ‪Design challenges and misconceptions in named entity recognition‬</summary></entry><entry><title type="html">Coarse-to-Fine Visual Question Answering by Iterative, Conditional Refinement</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/94d87ed9389b16243b3cc496c6f788ff.html" rel="alternate" type="text/html" title="Coarse-to-Fine Visual Question Answering by Iterative, Conditional Refinement" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/94d87ed9389b16243b3cc496c6f788ff</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/94d87ed9389b16243b3cc496c6f788ff.html">&lt;p&gt;Abstract Visual Question Answering (VQA) is a very interesting technique to answer natural language questions about an image. Recent methods have focused on incorporating knowledge into an improved VQA model, by augmenting the training set, representing scene graphs, or including reasoning. We also leverage knowledge to make VQA more robust. Yet we take a different route: we take the VQA model as-is and extend it with a novel algorithm called Guided-VQA that guides the questioning … Cites: ‪GQA: A new dataset for real-world visual reasoning and …‬&lt;/p&gt;</content><author><name>GJ Burghouts, W Huizinga - International Conference on Image Analysis and …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Visual Question Answering (VQA) is a very interesting technique to answer natural language questions about an image. Recent methods have focused on incorporating knowledge into an improved VQA model, by augmenting the training set, representing scene graphs, or including reasoning. We also leverage knowledge to make VQA more robust. Yet we take a different route: we take the VQA model as-is and extend it with a novel algorithm called Guided-VQA that guides the questioning … Cites: ‪GQA: A new dataset for real-world visual reasoning and …‬</summary></entry><entry><title type="html">A pose-aware dynamic weighting model using feature integration for driver action recognition</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/991e78fb457dd2a7c4f2703eae4e5f4b.html" rel="alternate" type="text/html" title="A pose-aware dynamic weighting model using feature integration for driver action recognition" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/991e78fb457dd2a7c4f2703eae4e5f4b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/991e78fb457dd2a7c4f2703eae4e5f4b.html">&lt;p&gt;Traffic accidents caused by distracted driving are on the rise, posing a serious threat to the safety of people s lives and property. Recognition and early warning of the driver s actions is particularly important. Considering the differences in local details of driver actions, we use the keypoint information of drivers that reflects the category differences. Specifically, we explicitly model keypoints features and propose a pose-aware driver action recognition model. We design a pose-based feature fusion … Cites: ‪Imagenet: A large-scale hierarchical image database‬&lt;/p&gt;</content><author><name>M Lu, Y Hu, X Lu - Engineering Applications of Artificial Intelligence, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Traffic accidents caused by distracted driving are on the rise, posing a serious threat to the safety of people s lives and property. Recognition and early warning of the driver s actions is particularly important. Considering the differences in local details of driver actions, we use the keypoint information of drivers that reflects the category differences. Specifically, we explicitly model keypoints features and propose a pose-aware driver action recognition model. We design a pose-based feature fusion … Cites: ‪Imagenet: A large-scale hierarchical image database‬</summary></entry><entry><title type="html">Sarcasm detection using deep learning and ensemble learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/9d77631ef33d03bf18d1786f1c9181c8.html" rel="alternate" type="text/html" title="Sarcasm detection using deep learning and ensemble learning" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/9d77631ef33d03bf18d1786f1c9181c8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/9d77631ef33d03bf18d1786f1c9181c8.html">&lt;p&gt;Across the globe, there is a noticeable upward trend of incorporating sarcasm in everyday life. This trend can be easily attributed to the frequent use of sarcasm in everyday life, but more specifically to social media and the Internet. This study aims to bridge the gap between human and machine intelligence to recognize and understand sarcastic behavior and patterns. The research is based on using various neural techniques, namely Long Short-Term Memory (LSTM), Gated Recurrent Unit … Cites: ‪Retweet Wars: Tweet Popularity Prediction via Dynamic …‬&lt;/p&gt;</content><author><name>P Goel, R Jain, A Nayyar, S Singhal, M Srivastava - Multimedia Tools and …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Across the globe, there is a noticeable upward trend of incorporating sarcasm in everyday life. This trend can be easily attributed to the frequent use of sarcasm in everyday life, but more specifically to social media and the Internet. This study aims to bridge the gap between human and machine intelligence to recognize and understand sarcastic behavior and patterns. The research is based on using various neural techniques, namely Long Short-Term Memory (LSTM), Gated Recurrent Unit … Cites: ‪Retweet Wars: Tweet Popularity Prediction via Dynamic …‬</summary></entry><entry><title type="html">Neuro-Symbolic Entropy Regularization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/9f2eea13c83e180f0c04cc3018639b4f.html" rel="alternate" type="text/html" title="Neuro-Symbolic Entropy Regularization" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/9f2eea13c83e180f0c04cc3018639b4f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/9f2eea13c83e180f0c04cc3018639b4f.html">&lt;p&gt;In structured prediction, the goal is to jointly predict many output variables that together encode a structured object–a path in a graph, an entity-relation triple, or an ordering of objects. Such a large output space makes learning hard and requires vast amounts of labeled data. Different approaches leverage alternate sources of supervision. One approach–entropy regularization–posits that decision boundaries should lie in low-probability regions. It extracts supervision from unlabeled examples … Cites: ‪Programming with a differentiable forth interpreter‬&lt;/p&gt;</content><author><name>E Wang, KW Chang, G Van den Broeck - The 38th Conference on Uncertainty in …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In structured prediction, the goal is to jointly predict many output variables that together encode a structured object–a path in a graph, an entity-relation triple, or an ordering of objects. Such a large output space makes learning hard and requires vast amounts of labeled data. Different approaches leverage alternate sources of supervision. One approach–entropy regularization–posits that decision boundaries should lie in low-probability regions. It extracts supervision from unlabeled examples … Cites: ‪Programming with a differentiable forth interpreter‬</summary></entry><entry><title type="html">From Logic to Language</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/a314195acc41e849ea60b9aa6dd5b62c.html" rel="alternate" type="text/html" title="From Logic to Language" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/a314195acc41e849ea60b9aa6dd5b62c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/a314195acc41e849ea60b9aa6dd5b62c.html">&lt;p&gt;In the beginning of the electronic computation era, when computers (then called supercomputers) were as big as office rooms, those gigantic machines typically used punched cards to read the program to execute and the data to set the input and the parameters of the computation. Before they were attached to electronic screens, they used to communicate the results of their elaboration by printing long lists of numbers, characters and symbols on rolls of papers. The human operator was responsible of … Cites: ‪Applying morphology generation models to machine translation‬&lt;/p&gt;</content><author><name>V Basile</name></author><category term="jekyll" /><category term="update" /><summary type="html">In the beginning of the electronic computation era, when computers (then called supercomputers) were as big as office rooms, those gigantic machines typically used punched cards to read the program to execute and the data to set the input and the parameters of the computation. Before they were attached to electronic screens, they used to communicate the results of their elaboration by printing long lists of numbers, characters and symbols on rolls of papers. The human operator was responsible of … Cites: ‪Applying morphology generation models to machine translation‬</summary></entry><entry><title type="html">Transducer Cascades for Biological Literature-Based Discovery</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/a74bda9efbed3ffbdde4ee3c1a1a76e9.html" rel="alternate" type="text/html" title="Transducer Cascades for Biological Literature-Based Discovery" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/a74bda9efbed3ffbdde4ee3c1a1a76e9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/a74bda9efbed3ffbdde4ee3c1a1a76e9.html">&lt;p&gt;G protein-coupled receptors (GPCRs) control the response of cells to many signals, and as such, are involved in most cellular processes. As membrane receptors, they are accessible at the surface of the cell. GPCRs are also the largest family of membrane receptors, with more than 800 representatives in mammal genomes. For this reason, they are ideal targets for drugs. Although about one third of approved drugs target GPCRs, only about 16% of GPCRs are targeted by drugs. One of the … Cites: ‪Distant supervision for cancer pathway extraction from text‬&lt;/p&gt;</content><author><name>D Maurel, S Chéry, N Bidoit, P Chatalic, A Filali… - Information, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">G protein-coupled receptors (GPCRs) control the response of cells to many signals, and as such, are involved in most cellular processes. As membrane receptors, they are accessible at the surface of the cell. GPCRs are also the largest family of membrane receptors, with more than 800 representatives in mammal genomes. For this reason, they are ideal targets for drugs. Although about one third of approved drugs target GPCRs, only about 16% of GPCRs are targeted by drugs. One of the … Cites: ‪Distant supervision for cancer pathway extraction from text‬</summary></entry><entry><title type="html">DHA: End-to-End Joint Optimization of Data Augmentation Policy, Hyper-parameter and Architecture</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/a92a63e167337a215d4c0e2b45cc01e8.html" rel="alternate" type="text/html" title="DHA: End-to-End Joint Optimization of Data Augmentation Policy, Hyper-parameter and Architecture" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/a92a63e167337a215d4c0e2b45cc01e8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/a92a63e167337a215d4c0e2b45cc01e8.html">&lt;p&gt;Automated machine learning (AutoML) usually involves several crucial components, such as Data Augmentation (DA) policy, Hyper-Parameter Optimization (HPO), and Neural Architecture Search (NAS). However joint optimization of these components remains challenging due to the largely increased search dimension and the variant input types of each component. In parallel to this, the common practice of searching for the optimal architecture first and then retraining it before deployment in NAS often … Cites: ‪AutoHAS: Differentiable hyper-parameter and architecture search‬&lt;/p&gt;</content><author><name>H Lanqing, S Hu, F Zhou, B Ru, J Feng, Z Li - First Conference on Automated …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Automated machine learning (AutoML) usually involves several crucial components, such as Data Augmentation (DA) policy, Hyper-Parameter Optimization (HPO), and Neural Architecture Search (NAS). However joint optimization of these components remains challenging due to the largely increased search dimension and the variant input types of each component. In parallel to this, the common practice of searching for the optimal architecture first and then retraining it before deployment in NAS often … Cites: ‪AutoHAS: Differentiable hyper-parameter and architecture search‬</summary></entry><entry><title type="html">Time Series Building Energy Systems Data Imputation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/a9e1d9c737bbca7ba29daa37a923e98f.html" rel="alternate" type="text/html" title="Time Series Building Energy Systems Data Imputation" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/a9e1d9c737bbca7ba29daa37a923e98f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/a9e1d9c737bbca7ba29daa37a923e98f.html">&lt;p&gt;Systems (BMS) as missing data can result in biased decision making down the line. This study creates a guideline for imputing the gaps in BMS datasets by comparing four methods: K Nearest Neighbour algorithm (KNN), Recurrent Neural Network (RNN), Hot Deck (HD) and Last Observation Carried Forward (LOCF). The guideline contains the best method per gap size and scales of measurement. The four selected methods are from various backgrounds and are tested on a real BMS and … Cites: ‪Recurrent neural networks for multivariate time series with missing …‬&lt;/p&gt;</content><author><name>A Lucbert, J van der Niet, A Corson, M Weij… - CLIMA 2022 conference, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Systems (BMS) as missing data can result in biased decision making down the line. This study creates a guideline for imputing the gaps in BMS datasets by comparing four methods: K Nearest Neighbour algorithm (KNN), Recurrent Neural Network (RNN), Hot Deck (HD) and Last Observation Carried Forward (LOCF). The guideline contains the best method per gap size and scales of measurement. The four selected methods are from various backgrounds and are tested on a real BMS and … Cites: ‪Recurrent neural networks for multivariate time series with missing …‬</summary></entry><entry><title type="html">アンケートデータを対象とした傾向抽出手法と評価</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ad15078c57a2f509e157bfd4e4ec621b.html" rel="alternate" type="text/html" title="アンケートデータを対象とした傾向抽出手法と評価" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ad15078c57a2f509e157bfd4e4ec621b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ad15078c57a2f509e157bfd4e4ec621b.html">&lt;ol&gt;
  &lt;li&gt;はじめに情報技術の進歩に伴い, 大規模なデータの分析技術や機械学習による高精度の予測技術が注目を浴びて久しい. 一方で, 大規模で安定的なデータを取得できないような社会活動や業態も存在する. たとえば短期的な意識調査やマーケティングなどにおいては, 収集されるデータは過去のデータとの連続性が乏しく小規模であることが一般的であり, 昨今研究されているデータ分析の技術を活かせる場面は少ない. さらに, 実際の調査やマーケティングでは分析の結果を解釈して後の活動に活かすことを目的とするため … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/li&gt;
&lt;/ol&gt;</content><author><name>岡本大輝， 後藤淳 - IEICE Conferences Archives, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">はじめに情報技術の進歩に伴い, 大規模なデータの分析技術や機械学習による高精度の予測技術が注目を浴びて久しい. 一方で, 大規模で安定的なデータを取得できないような社会活動や業態も存在する. たとえば短期的な意識調査やマーケティングなどにおいては, 収集されるデータは過去のデータとの連続性が乏しく小規模であることが一般的であり, 昨今研究されているデータ分析の技術を活かせる場面は少ない. さらに, 実際の調査やマーケティングでは分析の結果を解釈して後の活動に活かすことを目的とするため … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">HIT&amp;amp;QMUL at SemEval-2022 Task 9: Label-Enclosed Generative Question Answering (LEG-QA)</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/af2c20351de217b30f895f64bfb50722.html" rel="alternate" type="text/html" title="HIT&amp;amp;QMUL at SemEval-2022 Task 9: Label-Enclosed Generative Question Answering (LEG-QA)" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/af2c20351de217b30f895f64bfb50722</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/af2c20351de217b30f895f64bfb50722.html">&lt;p&gt;This paper presents the second place system for the R2VQ: competence-based multimodal question answering shared task. The task consisted in building question answering systems that could process procedural recipes involving both text and image, and enriched with semantic and cooking roles. We tackled the task by using a text-to-text generative model based on the transformer architecture, with the aim of generalising across different question types. Our proposed architecture incorporates … Cites: ‪Jointly predicting predicates and arguments in neural semantic …‬&lt;/p&gt;</content><author><name>W Zhai, M Feng, A Zubiaga, B Liu</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper presents the second place system for the R2VQ: competence-based multimodal question answering shared task. The task consisted in building question answering systems that could process procedural recipes involving both text and image, and enriched with semantic and cooking roles. We tackled the task by using a text-to-text generative model based on the transformer architecture, with the aim of generalising across different question types. Our proposed architecture incorporates … Cites: ‪Jointly predicting predicates and arguments in neural semantic …‬</summary></entry><entry><title type="html">SNS ユーザの自己紹介文にあらわれる偏りに着目したフェイクニュース検知</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/b50d8e4cf2dacd12dc40c6f0abbb823d.html" rel="alternate" type="text/html" title="SNS ユーザの自己紹介文にあらわれる偏りに着目したフェイクニュース検知" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/b50d8e4cf2dacd12dc40c6f0abbb823d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/b50d8e4cf2dacd12dc40c6f0abbb823d.html">&lt;p&gt;概要 SNS におけるフェイクニュースの拡散が問題となっている. フェイクニュースを共有するユーザは承認欲求や帰属欲求, 自己顕示欲といったヒューマンニーズが強く, 自己紹介文に特徴的な単語が現れやすい. 本研究では, それら自己紹介文に含まれる単語の偏りに基づき, フェイクニュースを検知する手法を提案する. Twitter 上で同一のニュース URL を投稿する複数ユーザの自己紹介文に含まれる単語から特徴量ベクトルを作成し, 機械学習によりその真偽を分類する. 日米のリアルおよびフェイクニュースを含む複数の … Cites: ‪Truth of varying shades: Analyzing language in fake news and …‬&lt;/p&gt;</content><author><name>古川凌也， 伊藤大貴， 高田雄太， 熊谷裕志， 神薗雅紀… - IEICE Conferences Archives, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">概要 SNS におけるフェイクニュースの拡散が問題となっている. フェイクニュースを共有するユーザは承認欲求や帰属欲求, 自己顕示欲といったヒューマンニーズが強く, 自己紹介文に特徴的な単語が現れやすい. 本研究では, それら自己紹介文に含まれる単語の偏りに基づき, フェイクニュースを検知する手法を提案する. Twitter 上で同一のニュース URL を投稿する複数ユーザの自己紹介文に含まれる単語から特徴量ベクトルを作成し, 機械学習によりその真偽を分類する. 日米のリアルおよびフェイクニュースを含む複数の … Cites: ‪Truth of varying shades: Analyzing language in fake news and …‬</summary></entry><entry><title type="html">Bridging between Cognitive Processing Signals and Linguistic Features via a Unified Attentional Network</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/b73dd757ff397a59ed89e029897aed0a.html" rel="alternate" type="text/html" title="Bridging between Cognitive Processing Signals and Linguistic Features via a Unified Attentional Network" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/b73dd757ff397a59ed89e029897aed0a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/b73dd757ff397a59ed89e029897aed0a.html">&lt;p&gt;Cognitive processing signals can be used to improve natural language processing (NLP) tasks. However, it is not clear how these signals correlate with linguistic information. Bridging between human language processing and linguistic features has been widely studied in neurolinguistics, usually via single-variable controlled experiments with highly-controlled stimuli. Such methods not only compromises the authenticity of natural reading, but also are time-consuming and expensive. In this … Cites: ‪A structural probe for finding syntax in word representations‬&lt;/p&gt;</content><author><name>Y Ren, D Xiong - arXiv preprint arXiv:2112.08831, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">Cognitive processing signals can be used to improve natural language processing (NLP) tasks. However, it is not clear how these signals correlate with linguistic information. Bridging between human language processing and linguistic features has been widely studied in neurolinguistics, usually via single-variable controlled experiments with highly-controlled stimuli. Such methods not only compromises the authenticity of natural reading, but also are time-consuming and expensive. In this … Cites: ‪A structural probe for finding syntax in word representations‬</summary></entry><entry><title type="html">Novel Indicators for Adverse Glycemic Events Detection Analysis Based on Continuous Glucose Monitoring Neural Network Predictive Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ba7f2abf9cbc51cefc5ac2eae3b7ef99.html" rel="alternate" type="text/html" title="Novel Indicators for Adverse Glycemic Events Detection Analysis Based on Continuous Glucose Monitoring Neural Network Predictive Models" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ba7f2abf9cbc51cefc5ac2eae3b7ef99</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ba7f2abf9cbc51cefc5ac2eae3b7ef99.html">&lt;p&gt;This paper proposes five indicators to evaluate the effectiveness and viability for adverse glycemic events detection based on predicted blood glucose (BG) values. False negative rate (FNR) and false positive rate (FPR) are defined to evaluate whether it can detect adverse glycemic events (AGEs) based on the predicted value. The temporal overlap (TO) and time difference (TD) are proposed to evaluate whether the predicted model can capture the accurate time duration of AGEs. The … Cites: ‪Learning Phrase Representations using RNN Encoder-Decoder …‬&lt;/p&gt;</content><author><name>G Lu, M Wang, T Fox, P Jiang, F Jiang - Journal of Shanghai Jiaotong University …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper proposes five indicators to evaluate the effectiveness and viability for adverse glycemic events detection based on predicted blood glucose (BG) values. False negative rate (FNR) and false positive rate (FPR) are defined to evaluate whether it can detect adverse glycemic events (AGEs) based on the predicted value. The temporal overlap (TO) and time difference (TD) are proposed to evaluate whether the predicted model can capture the accurate time duration of AGEs. The … Cites: ‪Learning Phrase Representations using RNN Encoder-Decoder …‬</summary></entry><entry><title type="html">Data Poisoning Attacks on Off-Policy Policy Evaluation Methods</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/bafd7e2d4ca61260441b40a2c1d9dac0.html" rel="alternate" type="text/html" title="Data Poisoning Attacks on Off-Policy Policy Evaluation Methods" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/bafd7e2d4ca61260441b40a2c1d9dac0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/bafd7e2d4ca61260441b40a2c1d9dac0.html">&lt;p&gt;Off-policy Evaluation (OPE) methods are a crucial tool for evaluating policies in high-stakes domains such as healthcare, where exploration is often infeasible or expensive. However, the extent to which such methods can be trusted under adversarial threats to data quality is largely unexplored. In this work, we make the first attempt at investigating the sensitivity of OPE methods to marginal adversarial perturbations in the data. We design a generic data poisoning attack framework … Cites: ‪Stronger data poisoning attacks break data sanitization defenses‬&lt;/p&gt;</content><author><name>E Lobo, H Singh, M Petrik, C Rudin, H Lakkaraju - The 38th Conference on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Off-policy Evaluation (OPE) methods are a crucial tool for evaluating policies in high-stakes domains such as healthcare, where exploration is often infeasible or expensive. However, the extent to which such methods can be trusted under adversarial threats to data quality is largely unexplored. In this work, we make the first attempt at investigating the sensitivity of OPE methods to marginal adversarial perturbations in the data. We design a generic data poisoning attack framework … Cites: ‪Stronger data poisoning attacks break data sanitization defenses‬</summary></entry><entry><title type="html">Addressing Token Uniformity in Transformers via Singular Value Transformation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/bd3f3cfd489af6d4c0302e3d9a91c268.html" rel="alternate" type="text/html" title="Addressing Token Uniformity in Transformers via Singular Value Transformation" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/bd3f3cfd489af6d4c0302e3d9a91c268</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/bd3f3cfd489af6d4c0302e3d9a91c268.html">&lt;p&gt;Token uniformity is commonly observed in transformer-based models, in which different tokens share a large proportion of similar information after going through stacked multiple self-attention layers in a transformer. In this paper, we propose to use the distribution of singular values of outputs of each transformer layer to characterise the phenomenon of token uniformity and empirically illustrate that a less skewed singular value distribution can alleviate the token uniformity problem. Base … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬&lt;/p&gt;</content><author><name>L Gui, W Li, Y He - The 38th Conference on Uncertainty in Artificial …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Token uniformity is commonly observed in transformer-based models, in which different tokens share a large proportion of similar information after going through stacked multiple self-attention layers in a transformer. In this paper, we propose to use the distribution of singular values of outputs of each transformer layer to characterise the phenomenon of token uniformity and empirically illustrate that a less skewed singular value distribution can alleviate the token uniformity problem. Base … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬</summary></entry><entry><title type="html">ExMo: plainable AI del Using Inverse Frequency Decision Rules</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/bf0d6fc5ab382bf07921ba48c8509d2c.html" rel="alternate" type="text/html" title="ExMo: plainable AI del Using Inverse Frequency Decision Rules" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/bf0d6fc5ab382bf07921ba48c8509d2c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/bf0d6fc5ab382bf07921ba48c8509d2c.html">&lt;p&gt;In this paper, we present a novel method to compute decision rules to build a more accurate interpretable machine learning model, denoted as ExMo. The ExMo interpretable machine learning model consists of a list of IF… THEN… statements with a decision rule in the condition. This way, ExMo naturally provides an explanation for a prediction using the decision rule that was triggered. ExMo uses a new approach to extract decision rules from the training data using term frequency-inverse document … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬&lt;/p&gt;</content><author><name>P Mainali, I Psychoula, FAP Petitcolas - International Conference on Human …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper, we present a novel method to compute decision rules to build a more accurate interpretable machine learning model, denoted as ExMo. The ExMo interpretable machine learning model consists of a list of IF… THEN… statements with a decision rule in the condition. This way, ExMo naturally provides an explanation for a prediction using the decision rule that was triggered. ExMo uses a new approach to extract decision rules from the training data using term frequency-inverse document … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬</summary></entry><entry><title type="html">Review of Research on Speech Emotion Recognition</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/bf2e67e8ad62502895f6de2c3cb913a1.html" rel="alternate" type="text/html" title="Review of Research on Speech Emotion Recognition" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/bf2e67e8ad62502895f6de2c3cb913a1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/bf2e67e8ad62502895f6de2c3cb913a1.html">&lt;p&gt;Abstract Language is an effective way to express human emotions, but emotions are difficult to describe and judge with computers, so it is an important task to analyze their emotions through speech. We summarized the current situation of speech emotion recognition from five aspects: the development of speech emotion recognition, emotion description model, emotion speech database, feature extraction, and emotion recognition algorithm. By summarizing and analyzing these … Cites: ‪Neural machine translation by jointly learning to align and translate …‬&lt;/p&gt;</content><author><name>Y Yang, F Xu - International Conference on Machine Learning and …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Language is an effective way to express human emotions, but emotions are difficult to describe and judge with computers, so it is an important task to analyze their emotions through speech. We summarized the current situation of speech emotion recognition from five aspects: the development of speech emotion recognition, emotion description model, emotion speech database, feature extraction, and emotion recognition algorithm. By summarizing and analyzing these … Cites: ‪Neural machine translation by jointly learning to align and translate …‬</summary></entry><entry><title type="html">AtM-DNN: A Multimodal Attention Fusion Network with Auxiliary Function for Sentiment Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/c20ce9131b449ab37e6a7040d7362354.html" rel="alternate" type="text/html" title="AtM-DNN: A Multimodal Attention Fusion Network with Auxiliary Function for Sentiment Classification" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/c20ce9131b449ab37e6a7040d7362354</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/c20ce9131b449ab37e6a7040d7362354.html">&lt;p&gt;Multimodal sentiment classification is an important research attracting many scientists  attention in natural language processing. In most multimodal sentiment research, each modal of the dataset is labeled with a unified label. However, this unified label of multimodal data may limit the model to obtain the different information between multimodal in the training process. To address the above issues, this paper proposes AtM-DNN, a model based on multimodal attention fusion network in … Cites: ‪Adaptive recursive neural network for target-dependent twitter …‬&lt;/p&gt;</content><author><name>J Huang, X Xu - 2022 IEEE 25th International Conference on Computer …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Multimodal sentiment classification is an important research attracting many scientists attention in natural language processing. In most multimodal sentiment research, each modal of the dataset is labeled with a unified label. However, this unified label of multimodal data may limit the model to obtain the different information between multimodal in the training process. To address the above issues, this paper proposes AtM-DNN, a model based on multimodal attention fusion network in … Cites: ‪Adaptive recursive neural network for target-dependent twitter …‬</summary></entry><entry><title type="html">COVID-19 Tweets Classification Based on a Hybrid Word Embedding Method. Big Data Cogn. Comput. 2022, 6, 58</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/c7baa723021a9b6242fc512a250b4ba6.html" rel="alternate" type="text/html" title="COVID-19 Tweets Classification Based on a Hybrid Word Embedding Method. Big Data Cogn. Comput. 2022, 6, 58" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/c7baa723021a9b6242fc512a250b4ba6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/c7baa723021a9b6242fc512a250b4ba6.html">&lt;p&gt;In March 2020, the World Health Organisation declared that COVID-19 was a new pandemic. This deadly virus spread and affected many countries in the world. During the outbreak, social media platforms such as Twitter contributed valuable and massive amounts of data to better assess health-related decision making. Therefore, we propose that users  sentiments could be analysed with the application of effective supervised machine learning approaches to predict disease prevalence and provide … Cites: ‪Bag of tricks for efficient text classification. arXiv 2016‬&lt;/p&gt;</content><author><name>Y Didi, A Walha, A Wali - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In March 2020, the World Health Organisation declared that COVID-19 was a new pandemic. This deadly virus spread and affected many countries in the world. During the outbreak, social media platforms such as Twitter contributed valuable and massive amounts of data to better assess health-related decision making. Therefore, we propose that users sentiments could be analysed with the application of effective supervised machine learning approaches to predict disease prevalence and provide … Cites: ‪Bag of tricks for efficient text classification. arXiv 2016‬</summary></entry><entry><title type="html">Generating Dynamic Urban Traffic Based on Stochastic Origin-Destination Matrix</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/c81e99930856e5cdd39255e1ef8c04fb.html" rel="alternate" type="text/html" title="Generating Dynamic Urban Traffic Based on Stochastic Origin-Destination Matrix" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/c81e99930856e5cdd39255e1ef8c04fb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/c81e99930856e5cdd39255e1ef8c04fb.html">&lt;p&gt;Urban traffic data plays an important role in urban transportation planning. Due to the scarcity of real-life urban traffic data, many transportation planning applications need to generate synthesized traffic flows based on the real-life trajectory datasets. However, those synthesized traffic flows can only fit the input trajectories, which are static and does not reflect the real traffic distributions. In this paper, we use a stochastic origin-destination (OD) matrix to represent the density of the dynamic … Cites: ‪On the Properties of Neural Machine Translation: Encoder …‬&lt;/p&gt;</content><author><name>Z Wang, B Zhang, N Xia, J Jin - 2022 IEEE 25th International Conference on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Urban traffic data plays an important role in urban transportation planning. Due to the scarcity of real-life urban traffic data, many transportation planning applications need to generate synthesized traffic flows based on the real-life trajectory datasets. However, those synthesized traffic flows can only fit the input trajectories, which are static and does not reflect the real traffic distributions. In this paper, we use a stochastic origin-destination (OD) matrix to represent the density of the dynamic … Cites: ‪On the Properties of Neural Machine Translation: Encoder …‬</summary></entry><entry><title type="html">推薦システムにおける推薦理由の説明可能性に関するサーベイ</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/c8334a34ec644328f583494e1a68a668.html" rel="alternate" type="text/html" title="推薦システムにおける推薦理由の説明可能性に関するサーベイ" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/c8334a34ec644328f583494e1a68a668</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/c8334a34ec644328f583494e1a68a668.html">&lt;p&gt;推薦システムは Web ページ, 動画配信サイト, 音楽アプリなど様々な場面で利用されている. しかし, 推薦システムの内部でどのように推薦アイテムを選んでいるのかはブラックボックスとなっており, 推薦システムの透明性, 説得力, 有効性, 信頼性, 満足度を向上させるために利用者に対して推薦理由を提示することが求められている. 推薦理由を提示する研究は, モデル内在型とモデル独立側に分類できる. モデル内在型は, 元来の推薦モデルに改変を加え推薦理由を抽出しようとするものである. 一方, モデル独立型は元来の推薦モデルを … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/p&gt;</content><author><name>松島ひろむ， 森澤竣， 石山琢己， 山名早人 - IEICE Conferences Archives, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">推薦システムは Web ページ, 動画配信サイト, 音楽アプリなど様々な場面で利用されている. しかし, 推薦システムの内部でどのように推薦アイテムを選んでいるのかはブラックボックスとなっており, 推薦システムの透明性, 説得力, 有効性, 信頼性, 満足度を向上させるために利用者に対して推薦理由を提示することが求められている. 推薦理由を提示する研究は, モデル内在型とモデル独立側に分類できる. モデル内在型は, 元来の推薦モデルに改変を加え推薦理由を抽出しようとするものである. 一方, モデル独立型は元来の推薦モデルを … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">中医学における分散表現を用いた情報検索手法</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ce9117cc7863895a2cf1e28de01a344d.html" rel="alternate" type="text/html" title="中医学における分散表現を用いた情報検索手法" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ce9117cc7863895a2cf1e28de01a344d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ce9117cc7863895a2cf1e28de01a344d.html">&lt;p&gt;中医学における分散表現を用いた情報検索手法 Search method using word embedding   in Traditional Chinese Medici Page 1 中医学における分散表現を用いた情報検索手法   Search method using word embedding in Traditional Chinese Medicine 太田遥人 1 関  隆志 2 髙橋晶子 3 力武克彰 1 Haruto Ota Takashi Seki Akiko Takahashi Yoshiaki   Rikitake 1. 背景 近年,国際疾病分類第 11 版(ICD-11)において新たに伝 統医学の疾病分類  が追加される[1]など,中医学は補完医療と しての需要が高まっている.中医学では, 診察により … Cites: ‪Retrofitting word vectors to semantic lexicons‬&lt;/p&gt;</content><author><name>太田遥人， 関隆志， 高橋晶子， 力武克彰 - IEICE Conferences Archives, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">中医学における分散表現を用いた情報検索手法 Search method using word embedding in Traditional Chinese Medici Page 1 中医学における分散表現を用いた情報検索手法 Search method using word embedding in Traditional Chinese Medicine 太田遥人 1 関 隆志 2 髙橋晶子 3 力武克彰 1 Haruto Ota Takashi Seki Akiko Takahashi Yoshiaki Rikitake 1. 背景 近年,国際疾病分類第 11 版(ICD-11)において新たに伝 統医学の疾病分類 が追加される[1]など,中医学は補完医療と しての需要が高まっている.中医学では, 診察により … Cites: ‪Retrofitting word vectors to semantic lexicons‬</summary></entry><entry><title type="html">Short-term individual residential load forecasting using an enhanced machine learning-based approach based on a feature engineering framework: A comparative …</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/d6787cf3e5dac22246811e6296579912.html" rel="alternate" type="text/html" title="Short-term individual residential load forecasting using an enhanced machine learning-based approach based on a feature engineering framework: A comparative …" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/d6787cf3e5dac22246811e6296579912</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/d6787cf3e5dac22246811e6296579912.html">&lt;p&gt;Accurate short-term forecasting of the individual residential load is a challenging task due to the nonlinear behavior of the residential customer. Moreover, there are a large number of features that have impact on the energy consumption of the residential load. Recently, deep learning algorithms are widely used for short-term load forecasting (STLF) of residential load. Although deep learning algorithms are capable of achieving promising results due to their ability in feature extraction … Cites: ‪Empirical evaluation of gated recurrent neural networks on …‬&lt;/p&gt;</content><author><name>A Forootani, M Rastegar, A Sami - Electric Power Systems Research, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Accurate short-term forecasting of the individual residential load is a challenging task due to the nonlinear behavior of the residential customer. Moreover, there are a large number of features that have impact on the energy consumption of the residential load. Recently, deep learning algorithms are widely used for short-term load forecasting (STLF) of residential load. Although deep learning algorithms are capable of achieving promising results due to their ability in feature extraction … Cites: ‪Empirical evaluation of gated recurrent neural networks on …‬</summary></entry><entry><title type="html">Benchmarking, Profiling and White-Box Performance Modeling for DNN Training</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/d74577057f313a3edd0f1ce0bda3710b.html" rel="alternate" type="text/html" title="Benchmarking, Profiling and White-Box Performance Modeling for DNN Training" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/d74577057f313a3edd0f1ce0bda3710b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/d74577057f313a3edd0f1ce0bda3710b.html">&lt;p&gt;Recent years have witnessed the co-evolution of deep neural network (DNN) algorithms and the underlying hardware and software design. Despite that system researchers proposed a variety of optimization techniques to improve DNN training efficiency, most techniques are under-utilized in practice. The software/hardware deployments that ML programmers use in practice are widely diverse. Differences in algorithms, hardware features, or even software versions could all shift the … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬&lt;/p&gt;</content><author><name>H Zhu - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent years have witnessed the co-evolution of deep neural network (DNN) algorithms and the underlying hardware and software design. Despite that system researchers proposed a variety of optimization techniques to improve DNN training efficiency, most techniques are under-utilized in practice. The software/hardware deployments that ML programmers use in practice are widely diverse. Differences in algorithms, hardware features, or even software versions could all shift the … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬</summary></entry><entry><title type="html">感情分析に基づくデマ検知アルゴリズムの開発</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/d75ad0a6a7b2d5287a0867614636f0bc.html" rel="alternate" type="text/html" title="感情分析に基づくデマ検知アルゴリズムの開発" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/d75ad0a6a7b2d5287a0867614636f0bc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/d75ad0a6a7b2d5287a0867614636f0bc.html">&lt;p&gt;SNS 上で自由に発信された情報の中で, 人々に役立つ情報がありながら, 政治的・利益的な意図を待って拡散されるデマ情報も含まれており, 社会問題となって対策が求められている. デマとはデマゴギー (demagogy) の略で, 元々は政治的な目的で相手を誹謗し, 相手に不利な世論を作り出すように流す虚偽の情報である. 現在では, 社会情勢が不安な時などに発生して, 人心を惑わすような憶測や事実誤認による情報や単なる悪口や根拠のないウワサ話, 流言飛語もデマの範囲になっている. デマは特定の状況 … Cites: ‪CED: Credible early detection of social media rumors‬&lt;/p&gt;</content><author><name>成凱 - IEICE Conferences Archives, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">SNS 上で自由に発信された情報の中で, 人々に役立つ情報がありながら, 政治的・利益的な意図を待って拡散されるデマ情報も含まれており, 社会問題となって対策が求められている. デマとはデマゴギー (demagogy) の略で, 元々は政治的な目的で相手を誹謗し, 相手に不利な世論を作り出すように流す虚偽の情報である. 現在では, 社会情勢が不安な時などに発生して, 人心を惑わすような憶測や事実誤認による情報や単なる悪口や根拠のないウワサ話, 流言飛語もデマの範囲になっている. デマは特定の状況 … Cites: ‪CED: Credible early detection of social media rumors‬</summary></entry><entry><title type="html">An Efficient Big Data Storage Service Architecture</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/dcb8b682ee60c46e30ab7e60e9582747.html" rel="alternate" type="text/html" title="An Efficient Big Data Storage Service Architecture" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/dcb8b682ee60c46e30ab7e60e9582747</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/dcb8b682ee60c46e30ab7e60e9582747.html">&lt;p&gt;Due to the limitations of the distributed file storage system, when data storage is surging, the depth and width of file directory will continue to increase, which results in reduced I/O efficiency of metadata management. Rapidly growing data can also cause system congestion or data loss. In today s environment where information and data are linked and collaborative in all walks of life, this phenomenon is absolutely unacceptable. Object storage is an efficient way to store massive data through … Cites: ‪The Beckman report on database research‬&lt;/p&gt;</content><author><name>Y Wang, X Li, P Bai, H Wang, J Dong - 2022 IEEE 25th International Conference on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Due to the limitations of the distributed file storage system, when data storage is surging, the depth and width of file directory will continue to increase, which results in reduced I/O efficiency of metadata management. Rapidly growing data can also cause system congestion or data loss. In today s environment where information and data are linked and collaborative in all walks of life, this phenomenon is absolutely unacceptable. Object storage is an efficient way to store massive data through … Cites: ‪The Beckman report on database research‬</summary></entry><entry><title type="html">Application of convolutional neural networks for recognition of diabetic retinopathy in digital images</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/dd3557f484c4532b00b59fd27aba15e4.html" rel="alternate" type="text/html" title="Application of convolutional neural networks for recognition of diabetic retinopathy in digital images" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/dd3557f484c4532b00b59fd27aba15e4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/dd3557f484c4532b00b59fd27aba15e4.html">&lt;p&gt;Results. The maximum accuracy achieved during training of the mathematical model of the convolutional neural network for classification into 5 classes (absence of diabetic retinopathy signs and 4 stages in presence of such signs) was only 57.4%[56.9; 57.9]. Training of the mathematical model of the convolutional neural network for binary classification (presence of retinopathy at any stage or its absence) lead to 80.7% accuracy [79.9; 81.2] in recognition of diabetic retinopathy on digital … Cites: ‪Deep learning-enabled medical computer vision‬&lt;/p&gt;</content><author><name>TH Mamedov, DV Dzjuba, AN Narkevich - Siberian Medical Review, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Results. The maximum accuracy achieved during training of the mathematical model of the convolutional neural network for classification into 5 classes (absence of diabetic retinopathy signs and 4 stages in presence of such signs) was only 57.4%[56.9; 57.9]. Training of the mathematical model of the convolutional neural network for binary classification (presence of retinopathy at any stage or its absence) lead to 80.7% accuracy [79.9; 81.2] in recognition of diabetic retinopathy on digital … Cites: ‪Deep learning-enabled medical computer vision‬</summary></entry><entry><title type="html">Matryoshka Representations for Adaptive Deployment</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/e022f17142a7c0c3fced7cae69c14c4e.html" rel="alternate" type="text/html" title="Matryoshka Representations for Adaptive Deployment" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/e022f17142a7c0c3fced7cae69c14c4e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/e022f17142a7c0c3fced7cae69c14c4e.html">&lt;p&gt;Learned representations are a central component in modern ML systems, serving a multitude of downstream tasks. When training such representations, it is often the case that computational and statistical constraints for each downstream task are unknown. In this context, rigid fixed-capacity representations can be either over or under-accommodating to the task at hand. This leads us to ask: can we design a flexible representation that can adapt to multiple downstream tasks with varying … Cites: ‪Detecting formal thought disorder by deep contextualized word …‬&lt;/p&gt;</content><author><name>A Kusupati, G Bhatt, A Rege, M Wallingford, A Sinha…</name></author><category term="jekyll" /><category term="update" /><summary type="html">Learned representations are a central component in modern ML systems, serving a multitude of downstream tasks. When training such representations, it is often the case that computational and statistical constraints for each downstream task are unknown. In this context, rigid fixed-capacity representations can be either over or under-accommodating to the task at hand. This leads us to ask: can we design a flexible representation that can adapt to multiple downstream tasks with varying … Cites: ‪Detecting formal thought disorder by deep contextualized word …‬</summary></entry><entry><title type="html">KRIT: Knowledge-Reasoning Intelligence in vision-language Transformer</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/e2d634e2014016b9cccf86a84f9c2290.html" rel="alternate" type="text/html" title="KRIT: Knowledge-Reasoning Intelligence in vision-language Transformer" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/e2d634e2014016b9cccf86a84f9c2290</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/e2d634e2014016b9cccf86a84f9c2290.html">&lt;p&gt;Transformer-based pretraining techniques have achieved impressive performance on learning cross-model representations for various multi-modality tasks. However, most off-the-shelf models do not take advantage of commonsense knowledge and logical reasoning that are crucial to many real-world tasks. To this end, we introduce a new variant of the Transformer model for representation learning, Knowledge Reasoning Intelligence in Vision-Language Transformer (KRIT). It utilizes a … Cites: ‪Detecting formal thought disorder by deep contextualized word …‬&lt;/p&gt;</content><author><name>K Chen, Q Huang, D McDuff, Y Bisk, J Gao - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Transformer-based pretraining techniques have achieved impressive performance on learning cross-model representations for various multi-modality tasks. However, most off-the-shelf models do not take advantage of commonsense knowledge and logical reasoning that are crucial to many real-world tasks. To this end, we introduce a new variant of the Transformer model for representation learning, Knowledge Reasoning Intelligence in Vision-Language Transformer (KRIT). It utilizes a … Cites: ‪Detecting formal thought disorder by deep contextualized word …‬</summary></entry><entry><title type="html">Multi-view Clustering and Multi-view Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ec5c86115f2bab6a390d54506bdddea0.html" rel="alternate" type="text/html" title="Multi-view Clustering and Multi-view Models" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ec5c86115f2bab6a390d54506bdddea0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ec5c86115f2bab6a390d54506bdddea0.html">&lt;p&gt;Over the years, the development of information technology applications, in particular, Artificial Intelligence has spurred the need to collect multi-view data on a large scale. Multi-view data, in general, is large, heterogeneous and uncertain, but also contains a lot of knowledge to mine and apply. Some of the single-view data clustering techniques have been improved to analyze multi-view data by extending the structure of the objective function or building associative models. Currently, multi … Cites: ‪Spectral clustering and transductive learning with multiple views‬&lt;/p&gt;</content><author><name>N Pham Van, L Ngo Thanh - Recent Advancements in Multi-View Data Analytics, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Over the years, the development of information technology applications, in particular, Artificial Intelligence has spurred the need to collect multi-view data on a large scale. Multi-view data, in general, is large, heterogeneous and uncertain, but also contains a lot of knowledge to mine and apply. Some of the single-view data clustering techniques have been improved to analyze multi-view data by extending the structure of the objective function or building associative models. Currently, multi … Cites: ‪Spectral clustering and transductive learning with multiple views‬</summary></entry><entry><title type="html">DEGREE: A Data-Efficient Generation-Based Event Extraction Model</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ee055ea190bd9b09d713545940333d7e.html" rel="alternate" type="text/html" title="DEGREE: A Data-Efficient Generation-Based Event Extraction Model" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ee055ea190bd9b09d713545940333d7e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/ee055ea190bd9b09d713545940333d7e.html">&lt;p&gt;Event extraction requires high-quality expert human annotations, which are usually expensive. Therefore, learning a data-efficient event extraction model that can be trained with only a few labeled examples has become a crucial challenge. In this paper, we focus on low-resource end-to-end event extraction and propose DE-GREE, a data-efficient model that formulates event extraction as a conditional generation problem. Given a passage and a manually designed prompt, DEGREE … Cites: ‪ESTER: A Machine Reading Comprehension Dataset for …‬&lt;/p&gt;</content><author><name>IH Hsu, KH Huang, E Boschee, S Miller, P Natarajan…</name></author><category term="jekyll" /><category term="update" /><summary type="html">Event extraction requires high-quality expert human annotations, which are usually expensive. Therefore, learning a data-efficient event extraction model that can be trained with only a few labeled examples has become a crucial challenge. In this paper, we focus on low-resource end-to-end event extraction and propose DE-GREE, a data-efficient model that formulates event extraction as a conditional generation problem. Given a passage and a manually designed prompt, DEGREE … Cites: ‪ESTER: A Machine Reading Comprehension Dataset for …‬</summary></entry><entry><title type="html">A distantly supervised approach for enriching product graphs with user opinions</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/eef7846082a7dbc7dd98708aaa64f0d5.html" rel="alternate" type="text/html" title="A distantly supervised approach for enriching product graphs with user opinions" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/eef7846082a7dbc7dd98708aaa64f0d5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/eef7846082a7dbc7dd98708aaa64f0d5.html">&lt;p&gt;Abstract Product Graphs (PGs) are knowledge graphs that structure the relationship of products and their characteristics. They have become very popular lately due to their potential to enable AI-related tasks in e-commerce. With the rise of social media, many dynamic and subjective information on products and their characteristics became widely available, creating an opportunity to aggregate such information to PGs. In this paper, we propose a method called PGOpi (Product Graph enriched with … Cites: ‪Subjective databases‬&lt;/p&gt;</content><author><name>J Moreira, T de Melo, L Barbosa, A Silva - Journal of Intelligent Information Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Product Graphs (PGs) are knowledge graphs that structure the relationship of products and their characteristics. They have become very popular lately due to their potential to enable AI-related tasks in e-commerce. With the rise of social media, many dynamic and subjective information on products and their characteristics became widely available, creating an opportunity to aggregate such information to PGs. In this paper, we propose a method called PGOpi (Product Graph enriched with … Cites: ‪Subjective databases‬</summary></entry><entry><title type="html">Size-invariant 3D generation from a single 2D rock image</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/f005642adb6a0c8d742ebfc6a82ed660.html" rel="alternate" type="text/html" title="Size-invariant 3D generation from a single 2D rock image" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/f005642adb6a0c8d742ebfc6a82ed660</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/f005642adb6a0c8d742ebfc6a82ed660.html">&lt;p&gt;The characterization of 3D structures in porous media is crucial for predicting physical properties in many industries, such as CO2 capture and storage, hydrology, oil &amp;amp; gas. In contrast to the expensive and time-consuming acquisition of 3D images, 2D imaging can provide cheap and fast data. However, the reconstruction of a 3D image from a single 2D image is a complex non-deterministic inverse problem. Several statistical and deep learning-based algorithms have been introduced in the … Cites: ‪The curious case of neural text degeneration‬&lt;/p&gt;</content><author><name>J Phan, L Ruspini, G Kiss, F Lindseth - Journal of Petroleum Science and Engineering, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The characterization of 3D structures in porous media is crucial for predicting physical properties in many industries, such as CO2 capture and storage, hydrology, oil &amp;amp; gas. In contrast to the expensive and time-consuming acquisition of 3D images, 2D imaging can provide cheap and fast data. However, the reconstruction of a 3D image from a single 2D image is a complex non-deterministic inverse problem. Several statistical and deep learning-based algorithms have been introduced in the … Cites: ‪The curious case of neural text degeneration‬</summary></entry><entry><title type="html">ROBUST DEEP LEARNING ALGORITHMS FOR SYSTEM IDENTIFICATION</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/f21366ca36e3ee6d0edb5d098fc8277a.html" rel="alternate" type="text/html" title="ROBUST DEEP LEARNING ALGORITHMS FOR SYSTEM IDENTIFICATION" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/f21366ca36e3ee6d0edb5d098fc8277a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/f21366ca36e3ee6d0edb5d098fc8277a.html">&lt;p&gt;In this dissertation we develop mathematically-principled deep learning algorithms for system identification. Our algorithms are completely data-driven, robust to noise and can be used to solve a variety of real world problems coming from areas such as economics, biology and finance. Governing laws for dynamical systems x (t)= f (t, x (t)) have traditionally been derived from expert knowledge and first principles, however in recent years the large amount of data available resulted in a growing … Cites: ‪Identifying and attacking the saddle point problem in high …‬&lt;/p&gt;</content><author><name>E NEGRINI - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this dissertation we develop mathematically-principled deep learning algorithms for system identification. Our algorithms are completely data-driven, robust to noise and can be used to solve a variety of real world problems coming from areas such as economics, biology and finance. Governing laws for dynamical systems x (t)= f (t, x (t)) have traditionally been derived from expert knowledge and first principles, however in recent years the large amount of data available resulted in a growing … Cites: ‪Identifying and attacking the saddle point problem in high …‬</summary></entry><entry><title type="html">Evolved Optimizer for Vision</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/f3f7cbedfc3f0c4a6dc5a258f96d01e8.html" rel="alternate" type="text/html" title="Evolved Optimizer for Vision" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/f3f7cbedfc3f0c4a6dc5a258f96d01e8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/f3f7cbedfc3f0c4a6dc5a258f96d01e8.html">&lt;p&gt;We present an optimizer, LION (EvoLved SIgn MOmeNtum), discovered by evolutionary search from basic math operations for training vision models. It keeps track of only momentum and leverages the sign operation to calculate the update to the weights. Despite the simplicity, LION outperforms the commonly used optimizer, such as AdamW and SGD with momentum, for training a variety of vision models on different tasks. Notably, it improves the accuracy of Vision Transformer for up to 2 … Cites: ‪Randaugment: Practical automated data augmentation with a …‬&lt;/p&gt;</content><author><name>X Chen, C Liang, D Huang, E Real, Y Liu, K Wang… - First Conference on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present an optimizer, LION (EvoLved SIgn MOmeNtum), discovered by evolutionary search from basic math operations for training vision models. It keeps track of only momentum and leverages the sign operation to calculate the update to the weights. Despite the simplicity, LION outperforms the commonly used optimizer, such as AdamW and SGD with momentum, for training a variety of vision models on different tasks. Notably, it improves the accuracy of Vision Transformer for up to 2 … Cites: ‪Randaugment: Practical automated data augmentation with a …‬</summary></entry><entry><title type="html">Tiny RNN Model with Certified Robustness for Text Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/f85fa2fc17b429659cadaa18ac5230f9.html" rel="alternate" type="text/html" title="Tiny RNN Model with Certified Robustness for Text Classification" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/f85fa2fc17b429659cadaa18ac5230f9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/f85fa2fc17b429659cadaa18ac5230f9.html">&lt;p&gt;Mobile artificial intelligence has recently gained more attention due to the increasing computing power of mobile devices and applications in computer vision, natural language processing, and internet of things. Although large pre-trained language models (eg, BERT, GPT) have recently achieved the state-of-the-art results on text classification tasks, they are not well suited for latency critical applications on mobile devices. Therefore, it is essential to design tiny models to reduce their memory and … Cites: ‪Word embeddings with limited memory‬&lt;/p&gt;</content><author><name>Y Qiang, STS Kumar, M Brocanelli, D Zhu</name></author><category term="jekyll" /><category term="update" /><summary type="html">Mobile artificial intelligence has recently gained more attention due to the increasing computing power of mobile devices and applications in computer vision, natural language processing, and internet of things. Although large pre-trained language models (eg, BERT, GPT) have recently achieved the state-of-the-art results on text classification tasks, they are not well suited for latency critical applications on mobile devices. Therefore, it is essential to design tiny models to reduce their memory and … Cites: ‪Word embeddings with limited memory‬</summary></entry><entry><title type="html">Leveraging Fusion of Sequence Tagging Models for Toxic Spans Detection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/fb141c172a0a54e421c792dc56aa4aef.html" rel="alternate" type="text/html" title="Leveraging Fusion of Sequence Tagging Models for Toxic Spans Detection" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/fb141c172a0a54e421c792dc56aa4aef</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/fb141c172a0a54e421c792dc56aa4aef.html">&lt;p&gt;The upsurge of prolific blogging and microblogging platforms enabled the abusers to spread negativity and threats greater than ever. Negative and hateful comments are averting users from sharing their opinion freely on social media platforms. It often breaks people s confidence and causes extensive damage to their mental health. Hence, identifying these toxic contents and taking appropriate measures against them is crucial to preserve a safe environment on social media. Numerous state-of … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬&lt;/p&gt;</content><author><name>J Naim, T Hossain, F Tasneem, AN Chy, M Aono - Neurocomputing, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The upsurge of prolific blogging and microblogging platforms enabled the abusers to spread negativity and threats greater than ever. Negative and hateful comments are averting users from sharing their opinion freely on social media platforms. It often breaks people s confidence and causes extensive damage to their mental health. Hence, identifying these toxic contents and taking appropriate measures against them is crucial to preserve a safe environment on social media. Numerous state-of … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬</summary></entry><entry><title type="html">Sepsis Mortality Prediction Using Wearable Monitoring in Low–Middle Income Countries</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/fbd4931ae392ee345526780390306bf2.html" rel="alternate" type="text/html" title="Sepsis Mortality Prediction Using Wearable Monitoring in Low–Middle Income Countries" /><published>2022-05-25T22:16:33-04:00</published><updated>2022-05-25T22:16:33-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/fbd4931ae392ee345526780390306bf2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/25/fbd4931ae392ee345526780390306bf2.html">&lt;p&gt;Sepsis is associated with high mortality—particularly in low–middle income countries (LMICs). Critical care management of sepsis is challenging in LMICs due to the lack of care providers and the high cost of bedside monitors. Recent advances in wearable sensor technology and machine learning (ML) models in healthcare promise to deliver new ways of digital monitoring integrated with automated decision systems to reduce the mortality risk in sepsis. In this study, firstly, we aim to assess … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/p&gt;</content><author><name>S Ghiasi, T Zhu, P Lu, J Hagenah, PNQ Khanh, NV Hao… - Sensors, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Sepsis is associated with high mortality—particularly in low–middle income countries (LMICs). Critical care management of sepsis is challenging in LMICs due to the lack of care providers and the high cost of bedside monitors. Recent advances in wearable sensor technology and machine learning (ML) models in healthcare promise to deliver new ways of digital monitoring integrated with automated decision systems to reduce the mortality risk in sepsis. In this study, firstly, we aim to assess … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">When to Use Multi-Task Learning vs Intermediate Fine-Tuning for Pre-Trained Encoder Transfer Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/004d2b7dc1d198085cab98b723003813.html" rel="alternate" type="text/html" title="When to Use Multi-Task Learning vs Intermediate Fine-Tuning for Pre-Trained Encoder Transfer Learning" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/004d2b7dc1d198085cab98b723003813</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/004d2b7dc1d198085cab98b723003813.html">&lt;p&gt;Transfer learning (TL) in natural language processing (NLP) has seen a surge of interest in recent years, as pre-trained models have shown an impressive ability to transfer to novel tasks. Three main strategies have emerged for making use of …&lt;/p&gt;</content><author><name>O Weller, K Seppi, M Gardner - arXiv preprint arXiv:2205.08124, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Transfer learning (TL) in natural language processing (NLP) has seen a surge of interest in recent years, as pre-trained models have shown an impressive ability to transfer to novel tasks. Three main strategies have emerged for making use of …</summary></entry><entry><title type="html">A novel end-to-end neural network for simultaneous filtering of task-unrelated named entities and fine-grained typing of task-related named entities</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/006c1b3078cab82a985b505cb1513d0f.html" rel="alternate" type="text/html" title="A novel end-to-end neural network for simultaneous filtering of task-unrelated named entities and fine-grained typing of task-related named entities" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/006c1b3078cab82a985b505cb1513d0f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/006c1b3078cab82a985b505cb1513d0f.html">&lt;p&gt;Recently, one emerging problem in Named Entity Typing (NET) is the fine-grained classification of task-related entities co-existing with task-unrelated entities. The traditional pipeline framework decomposes this problem into two sub-tasks. The first sub-task filters out the task-unrelated entities, while the second sub-task performs fine-grained classification for task-related entities. In the present study, we have developed an end-to-end neural network to solve the two sub-tasks simultaneously … Cites: ‪Ultra-fine entity typing‬&lt;/p&gt;</content><author><name>Q Li, K Mao, P Li, Y Xu, EYM Lo - Expert Systems with Applications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recently, one emerging problem in Named Entity Typing (NET) is the fine-grained classification of task-related entities co-existing with task-unrelated entities. The traditional pipeline framework decomposes this problem into two sub-tasks. The first sub-task filters out the task-unrelated entities, while the second sub-task performs fine-grained classification for task-related entities. In the present study, we have developed an end-to-end neural network to solve the two sub-tasks simultaneously … Cites: ‪Ultra-fine entity typing‬</summary></entry><entry><title type="html">Tight Last-Iterate Convergence of the Extragradient and the Optimistic Gradient Descent-Ascent Algorithm for Constrained Monotone Variational Inequalities</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/00d146e001c40f74d9faa7d7fa7576ce.html" rel="alternate" type="text/html" title="Tight Last-Iterate Convergence of the Extragradient and the Optimistic Gradient Descent-Ascent Algorithm for Constrained Monotone Variational Inequalities" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/00d146e001c40f74d9faa7d7fa7576ce</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/00d146e001c40f74d9faa7d7fa7576ce.html">&lt;p&gt;The monotone variational inequality is a central problem in mathematical programming that unifies and generalizes many important settings such as smooth convex optimization, twoplayer zero-sum games, convex-concave saddle point problems, etc. The extragradient algorithm by Korpelevich [1976] and the optimistic gradient descent-ascent algorithm by Popov [1980] are arguably the two most classical and popular methods for solving monotone variational inequalities. Despite … Cites: ‪Stochastic variance reduction methods for policy evaluation‬&lt;/p&gt;</content><author><name>Y Cai, A Oikonomou, W Zheng - arXiv preprint arXiv:2204.09228, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The monotone variational inequality is a central problem in mathematical programming that unifies and generalizes many important settings such as smooth convex optimization, twoplayer zero-sum games, convex-concave saddle point problems, etc. The extragradient algorithm by Korpelevich [1976] and the optimistic gradient descent-ascent algorithm by Popov [1980] are arguably the two most classical and popular methods for solving monotone variational inequalities. Despite … Cites: ‪Stochastic variance reduction methods for policy evaluation‬</summary></entry><entry><title type="html">Dialog Inpainting: Turning Documents into Dialogs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/015a2c4b0bb01e9a33fd2ed425949ea7.html" rel="alternate" type="text/html" title="Dialog Inpainting: Turning Documents into Dialogs" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/015a2c4b0bb01e9a33fd2ed425949ea7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/015a2c4b0bb01e9a33fd2ed425949ea7.html">&lt;p&gt;Many important questions (eg  How to eat healthier? ) require conversation to establish context and explore in depth. However, conversational question answering (ConvQA) systems have long been stymied by scarce training data that is expensive to collect. To address this problem, we propose a new technique for synthetically generating diverse and high-quality dialog data: dialog inpainting. Our approach takes the text of any document and transforms it into a two-person dialog between … Cites: ‪Can you unpack that? learning to rewrite questions-in-context‬&lt;/p&gt;</content><author><name>Z Dai, AT Chaganty, V Zhao, A Amini, QM Rashid… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Many important questions (eg How to eat healthier? ) require conversation to establish context and explore in depth. However, conversational question answering (ConvQA) systems have long been stymied by scarce training data that is expensive to collect. To address this problem, we propose a new technique for synthetically generating diverse and high-quality dialog data: dialog inpainting. Our approach takes the text of any document and transforms it into a two-person dialog between … Cites: ‪Can you unpack that? learning to rewrite questions-in-context‬</summary></entry><entry><title type="html">Data augmentation for aspect-based sentiment analysis</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/01ea7a70bb5806cb49f55999bd58af1b.html" rel="alternate" type="text/html" title="Data augmentation for aspect-based sentiment analysis" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/01ea7a70bb5806cb49f55999bd58af1b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/01ea7a70bb5806cb49f55999bd58af1b.html">&lt;p&gt;In recent years, deep learning has been widely used in the field of natural language processing (NLP), achieving spectacular successes in various NLP tasks. These successes are largely due to its capability to automatically learn feature representations from text data. However, the performance of deep learning in NLP can be negatively affected by a lack of sufficiently large labeled corpus for training, resulting in limited improvement in performance. Data augmentation overcomes this … Cites: ‪Xlda: Cross-lingual data augmentation for natural language …‬&lt;/p&gt;</content><author><name>G Li, H Wang, Y Ding, K Zhou, X Yan - International Journal of Machine Learning and …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In recent years, deep learning has been widely used in the field of natural language processing (NLP), achieving spectacular successes in various NLP tasks. These successes are largely due to its capability to automatically learn feature representations from text data. However, the performance of deep learning in NLP can be negatively affected by a lack of sufficiently large labeled corpus for training, resulting in limited improvement in performance. Data augmentation overcomes this … Cites: ‪Xlda: Cross-lingual data augmentation for natural language …‬</summary></entry><entry><title type="html">Deep learning accurately predicts food categories and nutrients based on ingredient statements</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/01eac8f4de0c710bfbec636dae2e6993.html" rel="alternate" type="text/html" title="Deep learning accurately predicts food categories and nutrients based on ingredient statements" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/01eac8f4de0c710bfbec636dae2e6993</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/01eac8f4de0c710bfbec636dae2e6993.html">&lt;p&gt;Determining attributes such as classification, creating taxonomies and nutrients for foods can be a challenging and resource-intensive task, albeit important for a better understanding of foods. In this study, a novel dataset, 134k BFPD, was collected from USDA Branded Food Products Database with modification and labeled with three food taxonomy and nutrient values and became an artificial intelligence (AI) dataset that covered the largest food types to date. Overall, the Multi-Layer Perceptron (MLP) … Cites: ‪Multi-channel reverse dictionary model‬&lt;/p&gt;</content><author><name>P Ma, Z Zhang, Y Li, N Yu, J Sheng, HK McGinty… - Food Chemistry, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Determining attributes such as classification, creating taxonomies and nutrients for foods can be a challenging and resource-intensive task, albeit important for a better understanding of foods. In this study, a novel dataset, 134k BFPD, was collected from USDA Branded Food Products Database with modification and labeled with three food taxonomy and nutrient values and became an artificial intelligence (AI) dataset that covered the largest food types to date. Overall, the Multi-Layer Perceptron (MLP) … Cites: ‪Multi-channel reverse dictionary model‬</summary></entry><entry><title type="html">Continual Pre-Training Mitigates Forgetting in Language and Vision</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/01ee4ea9e909daa48211144a167a0d7e.html" rel="alternate" type="text/html" title="Continual Pre-Training Mitigates Forgetting in Language and Vision" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/01ee4ea9e909daa48211144a167a0d7e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/01ee4ea9e909daa48211144a167a0d7e.html">&lt;p&gt;Pre-trained models are nowadays a fundamental component of machine learning research. In continual learning, they are commonly used to initialize the model before training on the stream of non-stationary data. However, pre-training is rarely applied during continual learning. We formalize and investigate the characteristics of the continual pre-training scenario in both language and vision environments, where a model is continually pre-trained on a stream of incoming data and only later fine … Cites: ‪Don t stop pretraining: adapt language models to domains and tasks‬&lt;/p&gt;</content><author><name>A Cossu, T Tuytelaars, A Carta, L Passaro… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pre-trained models are nowadays a fundamental component of machine learning research. In continual learning, they are commonly used to initialize the model before training on the stream of non-stationary data. However, pre-training is rarely applied during continual learning. We formalize and investigate the characteristics of the continual pre-training scenario in both language and vision environments, where a model is continually pre-trained on a stream of incoming data and only later fine … Cites: ‪Don t stop pretraining: adapt language models to domains and tasks‬</summary></entry><entry><title type="html">Understanding the difference in malicious activity between Surface Web and Dark Web</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/04b237ed46f560e81a81572609eff8be.html" rel="alternate" type="text/html" title="Understanding the difference in malicious activity between Surface Web and Dark Web" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/04b237ed46f560e81a81572609eff8be</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/04b237ed46f560e81a81572609eff8be.html">&lt;p&gt;The world has seen a dramatic increase in illegal activities on the Internet. Prior research has investigated different types of cybercrime, especially in the Surface Web, which is the portion of the content on the World Wide Web that popular engines may index. At the same time, evidence suggests cybercriminals are moving their operations to the Dark Web. This portion is not indexed by conventional search engines and is accessed through network overlays such as The Onion Router … Cites: ‪Tools for Automated Analysis of Cybercriminal Markets‬&lt;/p&gt;</content><author><name>DA Bermudez Villalva - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The world has seen a dramatic increase in illegal activities on the Internet. Prior research has investigated different types of cybercrime, especially in the Surface Web, which is the portion of the content on the World Wide Web that popular engines may index. At the same time, evidence suggests cybercriminals are moving their operations to the Dark Web. This portion is not indexed by conventional search engines and is accessed through network overlays such as The Onion Router … Cites: ‪Tools for Automated Analysis of Cybercriminal Markets‬</summary></entry><entry><title type="html">Automatic generation of natural language descriptions of visual data: describing images and videos using recurrent and self-attentive models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/089221dfe5d2f2a4e27c7cd91761d405.html" rel="alternate" type="text/html" title="Automatic generation of natural language descriptions of visual data: describing images and videos using recurrent and self-attentive models" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/089221dfe5d2f2a4e27c7cd91761d405</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/089221dfe5d2f2a4e27c7cd91761d405.html">&lt;p&gt;Humans are faced with a constant flow of visual stimuli, eg, from the environment or when looking at social media. In contrast, visually-impaired people are often incapable to perceive and process this advantageous and beneficial information that could help maneuver them through everyday situations and activities. However, audible feedback such as natural language can give them the ability to better be aware of their surroundings, thus enabling them to autonomously master everyday s … Cites: ‪Linguistic regularities in continuous space word representations‬&lt;/p&gt;</content><author><name>P Harzig - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Humans are faced with a constant flow of visual stimuli, eg, from the environment or when looking at social media. In contrast, visually-impaired people are often incapable to perceive and process this advantageous and beneficial information that could help maneuver them through everyday situations and activities. However, audible feedback such as natural language can give them the ability to better be aware of their surroundings, thus enabling them to autonomously master everyday s … Cites: ‪Linguistic regularities in continuous space word representations‬</summary></entry><entry><title type="html">Application of Data Integration in Dataspace in Multi-value Chain Collaboration of Electric Power Manufacturing Industry</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/11e7eb726b308f12608547a55fa2d65c.html" rel="alternate" type="text/html" title="Application of Data Integration in Dataspace in Multi-value Chain Collaboration of Electric Power Manufacturing Industry" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/11e7eb726b308f12608547a55fa2d65c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/11e7eb726b308f12608547a55fa2d65c.html">&lt;p&gt;The manufacturing industry is currently in a critical period of intelligent change, and the generation of massive amounts of data makes data management and data integration increasingly important. With the continuous upgrading of data management technology, how to handle diversified data and effectively collect multi-source heterogeneous data while ensuring data security has become the key to intelligent data management in current manufacturing enterprises. This paper … Cites: ‪Bootstrapping pay-as-you-go data integration systems‬&lt;/p&gt;</content><author><name>Y Liu, D Niu, S Geng, J Sun, H Zhang - 2022 IEEE 25th International Conference on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The manufacturing industry is currently in a critical period of intelligent change, and the generation of massive amounts of data makes data management and data integration increasingly important. With the continuous upgrading of data management technology, how to handle diversified data and effectively collect multi-source heterogeneous data while ensuring data security has become the key to intelligent data management in current manufacturing enterprises. This paper … Cites: ‪Bootstrapping pay-as-you-go data integration systems‬</summary></entry><entry><title type="html">Named Entity Linking on Handwritten Document Images</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/129df66e52ac7c1b1ced8adc80f64039.html" rel="alternate" type="text/html" title="Named Entity Linking on Handwritten Document Images" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/129df66e52ac7c1b1ced8adc80f64039</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/129df66e52ac7c1b1ced8adc80f64039.html">&lt;p&gt;Abstract Named Entity Linking (NEL) is an information extraction task that semantically enriches documents by recognizing mentions of entities in a text and matching them against an entry in a Knowledge Base (KB). This semantic information is fundamentally important for realizing a semantic search. Furthermore, it serves as a feature for subsequent tasks (ie Question Answering) as well as for improving the user experience. Current NEL approaches and datasets from the … Cites: ‪Autoregressive entity retrieval‬&lt;/p&gt;</content><author><name>O Tüselmann, GA Fink - International Workshop on Document Analysis Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Named Entity Linking (NEL) is an information extraction task that semantically enriches documents by recognizing mentions of entities in a text and matching them against an entry in a Knowledge Base (KB). This semantic information is fundamentally important for realizing a semantic search. Furthermore, it serves as a feature for subsequent tasks (ie Question Answering) as well as for improving the user experience. Current NEL approaches and datasets from the … Cites: ‪Autoregressive entity retrieval‬</summary></entry><entry><title type="html">PERKGQA: Question Answering over Personalized Knowledge Graphs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/12e2a0f744785db9000c153dfe57513c.html" rel="alternate" type="text/html" title="PERKGQA: Question Answering over Personalized Knowledge Graphs" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/12e2a0f744785db9000c153dfe57513c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/12e2a0f744785db9000c153dfe57513c.html">&lt;p&gt;Previous studies on question answering over knowledge graphs have typically operated over a single knowledge graph (KG). This KG is assumed to be known a priori and is leveraged similarly for all users  queries during inference. However …&lt;/p&gt;</content><author><name>R Dutt, K Bhattacharjee, R Gangadharaiah, D Roth…</name></author><category term="jekyll" /><category term="update" /><summary type="html">Previous studies on question answering over knowledge graphs have typically operated over a single knowledge graph (KG). This KG is assumed to be known a priori and is leveraged similarly for all users queries during inference. However …</summary></entry><entry><title type="html">Sum-Product Loop Programming: From Probabilistic Circuits to Loop Programming</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/12fc2867f35f0837ae097e2e735de2e5.html" rel="alternate" type="text/html" title="Sum-Product Loop Programming: From Probabilistic Circuits to Loop Programming" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/12fc2867f35f0837ae097e2e735de2e5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/12fc2867f35f0837ae097e2e735de2e5.html">&lt;p&gt;Abstract Recently, Probabilistic Circuits such as Sum-Product Networks have received growing attention, as they can represent complex features but still provide tractable inference. Although quite successful, unfortunately, they lack the capability of handling control structures, such as for and while loops. In this work, we introduce Sum-Product Loop Language (SPLL), a novel programming language that is capable of tractable inference on complex probabilistic code that includes loops … Cites: ‪End-to-end differentiable proving‬&lt;/p&gt;</content><author><name>V Pfanschilling, H Shindo, DS Dhami, K Kersting</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Recently, Probabilistic Circuits such as Sum-Product Networks have received growing attention, as they can represent complex features but still provide tractable inference. Although quite successful, unfortunately, they lack the capability of handling control structures, such as for and while loops. In this work, we introduce Sum-Product Loop Language (SPLL), a novel programming language that is capable of tractable inference on complex probabilistic code that includes loops … Cites: ‪End-to-end differentiable proving‬</summary></entry><entry><title type="html">Provably Precise, Succinct and Efficient Explanations for Decision Trees</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/13f1c9cf45ca3ab873daedfd076323a6.html" rel="alternate" type="text/html" title="Provably Precise, Succinct and Efficient Explanations for Decision Trees" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/13f1c9cf45ca3ab873daedfd076323a6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/13f1c9cf45ca3ab873daedfd076323a6.html">&lt;p&gt;Decision trees (DTs) embody interpretable classifiers. DTs have been advocated for deployment in high-risk applications, but also for explaining other complex classifiers. Nevertheless, recent work has demonstrated that predictions in DTs ought to be explained with rigorous approaches. Although rigorous explanations can be computed in polynomial time for DTs, their size may be beyond the cognitive limits of human decision makers. This paper investigates the computation of {\delta}-relevant … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬&lt;/p&gt;</content><author><name>Y Izza, A Ignatiev, N Narodytska, MC Cooper… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Decision trees (DTs) embody interpretable classifiers. DTs have been advocated for deployment in high-risk applications, but also for explaining other complex classifiers. Nevertheless, recent work has demonstrated that predictions in DTs ought to be explained with rigorous approaches. Although rigorous explanations can be computed in polynomial time for DTs, their size may be beyond the cognitive limits of human decision makers. This paper investigates the computation of {\delta}-relevant … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬</summary></entry><entry><title type="html">Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency Analysis</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/15e07bd4d4d8569fec97f072a546b1c8.html" rel="alternate" type="text/html" title="Parallel and Distributed Graph Neural Networks: An In-Depth Concurrency Analysis" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/15e07bd4d4d8569fec97f072a546b1c8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/15e07bd4d4d8569fec97f072a546b1c8.html">&lt;p&gt;Graph neural networks (GNNs) are among the most powerful tools in deep learning. They routinely solve complex problems on unstructured networks, such as node classification, graph classification, or link prediction, with high accuracy. However, both inference and training of GNNs are complex, and they uniquely combine the features of irregular graph processing with dense and regular computations. This complexity makes it very challenging to execute GNNs efficiently on modern … Cites: ‪Learning with Local and Global Consistency.‬&lt;/p&gt;</content><author><name>M Besta, T Hoefler - arXiv preprint arXiv:2205.09702, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Graph neural networks (GNNs) are among the most powerful tools in deep learning. They routinely solve complex problems on unstructured networks, such as node classification, graph classification, or link prediction, with high accuracy. However, both inference and training of GNNs are complex, and they uniquely combine the features of irregular graph processing with dense and regular computations. This complexity makes it very challenging to execute GNNs efficiently on modern … Cites: ‪Learning with Local and Global Consistency.‬</summary></entry><entry><title type="html">Logic-Guided Message Generation from Raw Real-Time Sensor Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1830d5281b1ff301a6043bdf7da4ee1d.html" rel="alternate" type="text/html" title="Logic-Guided Message Generation from Raw Real-Time Sensor Data" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1830d5281b1ff301a6043bdf7da4ee1d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1830d5281b1ff301a6043bdf7da4ee1d.html">&lt;p&gt;Natural language generation in real-time settings with raw sensor data is a challenging task. We find that formulating the task as an end-to-end problem leads to two major challenges in content selection–the sensor data is both redundant and diverse across environments, thereby making it hard for the encoders to select and reason on the data. We here present a new corpus for a specific domain that instantiates these properties. It includes handover utterances that an assistant for a … Cites: ‪Handling divergent reference texts when evaluating table-to-text …‬&lt;/p&gt;</content><author><name>E Chang, A Kovtunova, S Borgwardt, V Demberg…</name></author><category term="jekyll" /><category term="update" /><summary type="html">Natural language generation in real-time settings with raw sensor data is a challenging task. We find that formulating the task as an end-to-end problem leads to two major challenges in content selection–the sensor data is both redundant and diverse across environments, thereby making it hard for the encoders to select and reason on the data. We here present a new corpus for a specific domain that instantiates these properties. It includes handover utterances that an assistant for a … Cites: ‪Handling divergent reference texts when evaluating table-to-text …‬</summary></entry><entry><title type="html">Cross-document attention-based gated fusion network for automated medical licensing exam</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1a8609f1756c360a0259f8aa3034527e.html" rel="alternate" type="text/html" title="Cross-document attention-based gated fusion network for automated medical licensing exam" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1a8609f1756c360a0259f8aa3034527e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1a8609f1756c360a0259f8aa3034527e.html">&lt;p&gt;One of the applications of machine-learning in the medical industry is to automatically learn knowledge from medical textbooks and transfer medical knowledge into diagnosis abilities. Because of complex nature of medical issues, the learning process usually requires multiple knowledge documents to form a comprehensive reasoning chain for diagnosis, which increases the difficulty of the automatic learning process. Existing models for multiple document comprehension … Cites: ‪Understanding Dataset Design Choices for Multi-hop Reasoning‬&lt;/p&gt;</content><author><name>J Liu, J Ren, Z Lu, W He, M Cui, Z Zhang, R Bai - Expert Systems with Applications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">One of the applications of machine-learning in the medical industry is to automatically learn knowledge from medical textbooks and transfer medical knowledge into diagnosis abilities. Because of complex nature of medical issues, the learning process usually requires multiple knowledge documents to form a comprehensive reasoning chain for diagnosis, which increases the difficulty of the automatic learning process. Existing models for multiple document comprehension … Cites: ‪Understanding Dataset Design Choices for Multi-hop Reasoning‬</summary></entry><entry><title type="html">Semi-Parametric Continuous-Time Models for Adverse Health Behaviors</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1b7a62e2f3696e9b25c905a1cda95b3d.html" rel="alternate" type="text/html" title="Semi-Parametric Continuous-Time Models for Adverse Health Behaviors" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1b7a62e2f3696e9b25c905a1cda95b3d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1b7a62e2f3696e9b25c905a1cda95b3d.html">&lt;p&gt;Two important problems in behavioral medicine are modeling the risk of adverse health behaviors such as smoking, and classifying longitudinal health data to determine health conditions. Models for each can be used for prediction in order to inform just in time adaptive interventions (JITAI) and inference to help behavioral scientists understand processes driving these behaviors. In this thesis we propose several models for both event risk and factors that contribute to risk for behaviors … Cites: ‪Random feature attention‬&lt;/p&gt;</content><author><name>AF Moreno - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Two important problems in behavioral medicine are modeling the risk of adverse health behaviors such as smoking, and classifying longitudinal health data to determine health conditions. Models for each can be used for prediction in order to inform just in time adaptive interventions (JITAI) and inference to help behavioral scientists understand processes driving these behaviors. In this thesis we propose several models for both event risk and factors that contribute to risk for behaviors … Cites: ‪Random feature attention‬</summary></entry><entry><title type="html">Visual context learning based on textual knowledge for image-text retrieval</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1bbc063e0b594122809027b65b14d324.html" rel="alternate" type="text/html" title="Visual context learning based on textual knowledge for image-text retrieval" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1bbc063e0b594122809027b65b14d324</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1bbc063e0b594122809027b65b14d324.html">&lt;p&gt;Image-text bidirectional retrieval is a significant task within cross-modal learning field. The main issue lies on the jointly embedding learning and accurately measuring image-text matching score. Most prior works make use of either intra-modality methods performing within two separate modalities or inter-modality ones combining two modalities tightly. However, intra-modality methods remain ambiguous when learning visual context due to the existence of redundant … Cites: ‪Oscar: Object-semantics aligned pre-training for vision-language …‬&lt;/p&gt;</content><author><name>Y Qin, X Gu, Z Tan - Neural Networks, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Image-text bidirectional retrieval is a significant task within cross-modal learning field. The main issue lies on the jointly embedding learning and accurately measuring image-text matching score. Most prior works make use of either intra-modality methods performing within two separate modalities or inter-modality ones combining two modalities tightly. However, intra-modality methods remain ambiguous when learning visual context due to the existence of redundant … Cites: ‪Oscar: Object-semantics aligned pre-training for vision-language …‬</summary></entry><entry><title type="html">Training Vision-Language Transformers from Captions Alone</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1d1e2e9dbbaa243041e2c2d1a6d01617.html" rel="alternate" type="text/html" title="Training Vision-Language Transformers from Captions Alone" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1d1e2e9dbbaa243041e2c2d1a6d01617</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1d1e2e9dbbaa243041e2c2d1a6d01617.html">&lt;p&gt;We show that Vision-Language Transformers can be learned without human labels (eg class labels, bounding boxes, etc). Existing work, whether explicitly utilizing bounding boxes or patches, assumes that the visual backbone must first be trained on ImageNet class prediction before being integrated into a multimodal linguistic pipeline. We show that this is not necessary and introduce a new model Vision-Language from Captions (VLC) built on top of Masked Auto-Encoders that does not … Cites: ‪LXMERT: Learning Cross-Modality Encoder Representations from …‬&lt;/p&gt;</content><author><name>L Gui, Q Huang, A Hauptmann, Y Bisk, J Gao - arXiv preprint arXiv:2205.09256, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We show that Vision-Language Transformers can be learned without human labels (eg class labels, bounding boxes, etc). Existing work, whether explicitly utilizing bounding boxes or patches, assumes that the visual backbone must first be trained on ImageNet class prediction before being integrated into a multimodal linguistic pipeline. We show that this is not necessary and introduce a new model Vision-Language from Captions (VLC) built on top of Masked Auto-Encoders that does not … Cites: ‪LXMERT: Learning Cross-Modality Encoder Representations from …‬</summary></entry><entry><title type="html">Linguistic Frameworks Go Toe-to-Toe at Neuro-Symbolic Language Modeling</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1fdd5d13e33787cef80abe528871d78a.html" rel="alternate" type="text/html" title="Linguistic Frameworks Go Toe-to-Toe at Neuro-Symbolic Language Modeling" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1fdd5d13e33787cef80abe528871d78a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/1fdd5d13e33787cef80abe528871d78a.html">&lt;p&gt;We examine the extent to which, in principle, different syntactic and semantic graph representations can complement and improve neural language modeling. Specifically, by conditioning on a subgraph encapsulating the locally relevant sentence history, can a model make better next-word predictions than a pretrained sequential language model alone? With an ensemble setup consisting of GPT-2 and ground-truth graphs from one of 7 different formalisms, we find that the graph … Cites: ‪Linguistic Knowledge and Transferability of Contextual …‬&lt;/p&gt;</content><author><name>JPN Schneider, L Kong</name></author><category term="jekyll" /><category term="update" /><summary type="html">We examine the extent to which, in principle, different syntactic and semantic graph representations can complement and improve neural language modeling. Specifically, by conditioning on a subgraph encapsulating the locally relevant sentence history, can a model make better next-word predictions than a pretrained sequential language model alone? With an ensemble setup consisting of GPT-2 and ground-truth graphs from one of 7 different formalisms, we find that the graph … Cites: ‪Linguistic Knowledge and Transferability of Contextual …‬</summary></entry><entry><title type="html">Named Entity Recognition, Multi-Task Learning, Nested Entities, BERT, Arabic NER Corpus</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/225df45ce1e2f4a49304b92b3691caea.html" rel="alternate" type="text/html" title="Named Entity Recognition, Multi-Task Learning, Nested Entities, BERT, Arabic NER Corpus" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/225df45ce1e2f4a49304b92b3691caea</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/225df45ce1e2f4a49304b92b3691caea.html">&lt;p&gt;This paper presents Wojood, a corpus for Arabic nested Named Entity Recognition (NER). Nested entities occur when one entity mention is embedded inside another entity mention. Wojood consists of about 550K Modern Standard Arabic (MSA) and dialect tokens that are manually annotated with 21 entity types including person, organization, location, event and date. More importantly, the corpus is annotated with nested entities instead of the more common flat annotations. The data contains about … Cites: ‪A language-independent neural network for event detection‬&lt;/p&gt;</content><author><name>M Jarrar, M Khalilia, S Ghanem - arXiv preprint arXiv:2205.09651, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper presents Wojood, a corpus for Arabic nested Named Entity Recognition (NER). Nested entities occur when one entity mention is embedded inside another entity mention. Wojood consists of about 550K Modern Standard Arabic (MSA) and dialect tokens that are manually annotated with 21 entity types including person, organization, location, event and date. More importantly, the corpus is annotated with nested entities instead of the more common flat annotations. The data contains about … Cites: ‪A language-independent neural network for event detection‬</summary></entry><entry><title type="html">A hybrid recommender-system for startup scouting</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/24c7a0a38fd2ab392d83d27c7856da9b.html" rel="alternate" type="text/html" title="A hybrid recommender-system for startup scouting" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/24c7a0a38fd2ab392d83d27c7856da9b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/24c7a0a38fd2ab392d83d27c7856da9b.html">&lt;p&gt;This design science research study investigates whether problems in the startup scouting process of Unknown Group can be solved by implementing a hybrid recommender-system, hereby improving efficiency and reliability of this scouting process. With use of a literature study, a design theory for a hybrid recommender-system for startup scouting was established. This design theory was translated to requirements that were supplemented by the direct stakeholders. These … Cites: ‪Recommender systems with social regularization‬&lt;/p&gt;</content><author><name>KTD Bosch - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This design science research study investigates whether problems in the startup scouting process of Unknown Group can be solved by implementing a hybrid recommender-system, hereby improving efficiency and reliability of this scouting process. With use of a literature study, a design theory for a hybrid recommender-system for startup scouting was established. This design theory was translated to requirements that were supplemented by the direct stakeholders. These … Cites: ‪Recommender systems with social regularization‬</summary></entry><entry><title type="html">Journal: Proceedings of the 10th International Conference on Web Intelligence, Mining and Semantics, 2020</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/2641aa2453b6ff9cda6f990e8849293d.html" rel="alternate" type="text/html" title="Journal: Proceedings of the 10th International Conference on Web Intelligence, Mining and Semantics, 2020" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/2641aa2453b6ff9cda6f990e8849293d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/2641aa2453b6ff9cda6f990e8849293d.html">&lt;p&gt;OUCI logo Search Analytics About укр Українською SciPuRe https://doi.org/10.1145/3405962.3405978   Journal: Proceedings of the 10th International Conference on Web Intelligence,   Mining and Semantics, 2020 Publisher: ACM Authors: Martin Lentschat, Patrice   Buche, Juliette Dibie-Barthelemy, Mathieu Roche Funder IDEX/I-SITE MUSE List of   references 1.https://doi.org/10.1007/978-3-642-28604-9_13 2.https://doi.org/10.1016/j.eswa.2016.12.028   3.Berrahou Soumia Lilia, KDIR: Knowledge Discovery and Information Retrieval 4.Soumia … Cites: ‪Ontology-driven information extraction with ontosyphon‬&lt;/p&gt;</content><author><name>M Lentschat, P Buche, J Dibie-Barthelemy, M Roche</name></author><category term="jekyll" /><category term="update" /><summary type="html">OUCI logo Search Analytics About укр Українською SciPuRe https://doi.org/10.1145/3405962.3405978 Journal: Proceedings of the 10th International Conference on Web Intelligence, Mining and Semantics, 2020 Publisher: ACM Authors: Martin Lentschat, Patrice Buche, Juliette Dibie-Barthelemy, Mathieu Roche Funder IDEX/I-SITE MUSE List of references 1.https://doi.org/10.1007/978-3-642-28604-9_13 2.https://doi.org/10.1016/j.eswa.2016.12.028 3.Berrahou Soumia Lilia, KDIR: Knowledge Discovery and Information Retrieval 4.Soumia … Cites: ‪Ontology-driven information extraction with ontosyphon‬</summary></entry><entry><title type="html">Defect Criticality Analysis on Fatigue Life of L-PBF 17-4 PH Stainless Steel via Machine Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/299c17f40501921283e007cde77d2379.html" rel="alternate" type="text/html" title="Defect Criticality Analysis on Fatigue Life of L-PBF 17-4 PH Stainless Steel via Machine Learning" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/299c17f40501921283e007cde77d2379</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/299c17f40501921283e007cde77d2379.html">&lt;p&gt;Defects innate in additively manufactured components may lead to inferior and more scatter in fatigue lives, thus challenging the qualification of these components in fatigue-critical applications. This work seeks to correlate geometrical features of critical defects measured from fracture surfaces to the fatigue performance of laser beam powder bed fusion (L-PBF) components with machine learning and to develop an integrated data-driven analytical framework for defect criticality (IDADC). IDADC … Cites: ‪Model-agnostic interpretability of machine learning‬&lt;/p&gt;</content><author><name>A Li, S Baig, J Liu, S Shao, N Shamsaei - International Journal of Fatigue, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Defects innate in additively manufactured components may lead to inferior and more scatter in fatigue lives, thus challenging the qualification of these components in fatigue-critical applications. This work seeks to correlate geometrical features of critical defects measured from fracture surfaces to the fatigue performance of laser beam powder bed fusion (L-PBF) components with machine learning and to develop an integrated data-driven analytical framework for defect criticality (IDADC). IDADC … Cites: ‪Model-agnostic interpretability of machine learning‬</summary></entry><entry><title type="html">Masked Autoencoders As Spatiotemporal Learners</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/29f71555579e03e054a88dc78fc7a325.html" rel="alternate" type="text/html" title="Masked Autoencoders As Spatiotemporal Learners" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/29f71555579e03e054a88dc78fc7a325</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/29f71555579e03e054a88dc78fc7a325.html">&lt;p&gt;This paper studies a conceptually simple extension of Masked Autoencoders (MAE) to spatiotemporal representation learning from videos. We randomly mask out spacetime patches in videos and learn an autoencoder to reconstruct them in pixels. Interestingly, we show that our MAE method can learn strong representations with almost no inductive bias on spacetime (only except for patch and positional embeddings), and spacetime-agnostic random masking performs the best. We … Cites: ‪VIMPAC: Video Pre-Training via Masked Token Prediction and …‬&lt;/p&gt;</content><author><name>C Feichtenhofer, H Fan, Y Li, K He - arXiv preprint arXiv:2205.09113, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper studies a conceptually simple extension of Masked Autoencoders (MAE) to spatiotemporal representation learning from videos. We randomly mask out spacetime patches in videos and learn an autoencoder to reconstruct them in pixels. Interestingly, we show that our MAE method can learn strong representations with almost no inductive bias on spacetime (only except for patch and positional embeddings), and spacetime-agnostic random masking performs the best. We … Cites: ‪VIMPAC: Video Pre-Training via Masked Token Prediction and …‬</summary></entry><entry><title type="html">Describing Differences between Text Distributions with Natural Language</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/2b21b7e4a9159d47f68bcd3194640479.html" rel="alternate" type="text/html" title="Describing Differences between Text Distributions with Natural Language" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/2b21b7e4a9159d47f68bcd3194640479</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/2b21b7e4a9159d47f68bcd3194640479.html">&lt;p&gt;How do two distributions of text differ? Humans are slow at answering this, since discovering patterns might require tediously reading through hundreds of samples. We propose to automatically describe the differences by “learning a natural language hypothesis”: given two distributions D0 and D1, we search for a description that is more often true for D1, eg,“is military-related.” To tackle this problem, we fine-tune GPT-3 to propose descriptions with the prompt:“[samples of D0]+[samples of … Cites: ‪Learning To Retrieve Prompts for In-Context Learning‬&lt;/p&gt;</content><author><name>R Zhong, C Snell, D Klein, J Steinhardt - Red</name></author><category term="jekyll" /><category term="update" /><summary type="html">How do two distributions of text differ? Humans are slow at answering this, since discovering patterns might require tediously reading through hundreds of samples. We propose to automatically describe the differences by “learning a natural language hypothesis”: given two distributions D0 and D1, we search for a description that is more often true for D1, eg,“is military-related.” To tackle this problem, we fine-tune GPT-3 to propose descriptions with the prompt:“[samples of D0]+[samples of … Cites: ‪Learning To Retrieve Prompts for In-Context Learning‬</summary></entry><entry><title type="html">Plane Geometry Diagram Parsing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/2d51a98732c836149cb631a6e0054f8d.html" rel="alternate" type="text/html" title="Plane Geometry Diagram Parsing" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/2d51a98732c836149cb631a6e0054f8d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/2d51a98732c836149cb631a6e0054f8d.html">&lt;p&gt;Geometry diagram parsing plays a key role in geometry problem solving, wherein the primitive extraction and relation parsing remain challenging due to the complex layout and between-primitive relationship. In this paper, we propose a powerful diagram parser based on deep learning and graph reasoning. Specifically, a modified instance segmentation method is proposed to extract geometric primitives, and the graph neural network (GNN) is leveraged to realize relation parsing and … Cites: ‪MathQA: Towards interpretable math word problem solving with …‬&lt;/p&gt;</content><author><name>ML Zhang, F Yin, YH Hao, CL Liu - arXiv preprint arXiv:2205.09363, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Geometry diagram parsing plays a key role in geometry problem solving, wherein the primitive extraction and relation parsing remain challenging due to the complex layout and between-primitive relationship. In this paper, we propose a powerful diagram parser based on deep learning and graph reasoning. Specifically, a modified instance segmentation method is proposed to extract geometric primitives, and the graph neural network (GNN) is leveraged to realize relation parsing and … Cites: ‪MathQA: Towards interpretable math word problem solving with …‬</summary></entry><entry><title type="html">LeRaC: Learning Rate Curriculum</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/3437d722b3264c625569a7a19e7a7077.html" rel="alternate" type="text/html" title="LeRaC: Learning Rate Curriculum" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/3437d722b3264c625569a7a19e7a7077</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/3437d722b3264c625569a7a19e7a7077.html">&lt;p&gt;Most curriculum learning methods require an approach to sort the data samples by difficulty, which is often cumbersome to perform. In this work, we propose a novel curriculum learning approach termed Learning Rate Curriculum (LeRaC), which leverages the use of a different learning rate for each layer of a neural network to create a data-free curriculum during the initial training epochs. More specifically, LeRaC assigns higher learning rates to neural layers closer to the input, gradually … Cites: ‪Competence-based Curriculum Learning for Neural Machine …‬&lt;/p&gt;</content><author><name>FA Croitoru, NC Ristea, RT Ionescu, N Sebe - arXiv preprint arXiv:2205.09180, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Most curriculum learning methods require an approach to sort the data samples by difficulty, which is often cumbersome to perform. In this work, we propose a novel curriculum learning approach termed Learning Rate Curriculum (LeRaC), which leverages the use of a different learning rate for each layer of a neural network to create a data-free curriculum during the initial training epochs. More specifically, LeRaC assigns higher learning rates to neural layers closer to the input, gradually … Cites: ‪Competence-based Curriculum Learning for Neural Machine …‬</summary></entry><entry><title type="html">Do Transformer Networks Improve the Discovery of Rules from Text?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/3f73c60bfeb52e7da4338710488df61a.html" rel="alternate" type="text/html" title="Do Transformer Networks Improve the Discovery of Rules from Text?" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/3f73c60bfeb52e7da4338710488df61a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/3f73c60bfeb52e7da4338710488df61a.html">&lt;p&gt;Abstract With their Discovery of Inference Rules from Text (DIRT) algorithm, Lin and Pantel (2001) made a seminal contribution to the field of rule acquisition from text, by adapting the distributional hypothesis of Harris (1954) to patterns that model binary relations such as X treat Y, where patterns are implemented as syntactic dependency paths. DIRT s relevance is renewed in today s neural era given the recent focus on interpretability in the field of natural language processing. We propose a novel take … Cites: ‪A two level model for context sensitive inference rules‬&lt;/p&gt;</content><author><name>M Rahimi, M Surdeanu</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract With their Discovery of Inference Rules from Text (DIRT) algorithm, Lin and Pantel (2001) made a seminal contribution to the field of rule acquisition from text, by adapting the distributional hypothesis of Harris (1954) to patterns that model binary relations such as X treat Y, where patterns are implemented as syntactic dependency paths. DIRT s relevance is renewed in today s neural era given the recent focus on interpretability in the field of natural language processing. We propose a novel take … Cites: ‪A two level model for context sensitive inference rules‬</summary></entry><entry><title type="html">ERNIE-Search: Bridging Cross-Encoder with Dual-Encoder via Self On-the-fly Distillation for Dense Passage Retrieval</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/3fd9296ce929215b82f80727ed3160de.html" rel="alternate" type="text/html" title="ERNIE-Search: Bridging Cross-Encoder with Dual-Encoder via Self On-the-fly Distillation for Dense Passage Retrieval" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/3fd9296ce929215b82f80727ed3160de</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/3fd9296ce929215b82f80727ed3160de.html">&lt;p&gt;Neural retrievers based on pre-trained language models (PLMs), such as dual-encoders, have achieved promising performance on the task of open-domain question answering (QA). Their effectiveness can further reach new state-of-the-arts by incorporating cross-architecture knowledge distillation. However, most of the existing studies just directly apply conventional distillation methods. They fail to consider the particular situation where the teacher and student have different … Cites: ‪Speeding up Deep Model Training by Sharing Weights and Then …‬&lt;/p&gt;</content><author><name>Y Lu, Y Liu, J Liu, Y Shi, Z Huang, SFY Sun, H Tian… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Neural retrievers based on pre-trained language models (PLMs), such as dual-encoders, have achieved promising performance on the task of open-domain question answering (QA). Their effectiveness can further reach new state-of-the-arts by incorporating cross-architecture knowledge distillation. However, most of the existing studies just directly apply conventional distillation methods. They fail to consider the particular situation where the teacher and student have different … Cites: ‪Speeding up Deep Model Training by Sharing Weights and Then …‬</summary></entry><entry><title type="html">Generating Consistent and Diverse QA pairs from Contexts with BN Conditional VAE</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/40de38426ee85c1cff3652ec5745e49d.html" rel="alternate" type="text/html" title="Generating Consistent and Diverse QA pairs from Contexts with BN Conditional VAE" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/40de38426ee85c1cff3652ec5745e49d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/40de38426ee85c1cff3652ec5745e49d.html">&lt;p&gt;One of the most challenging problems in the question answering (QA) area is the lack of high-quality labeled data. However, the cost of manually labeling a question-answer (QA) pair from the target text is very high. One way to solve this problem is to automatically generate QA pairs from the target text. In this paper, we propose the Batch Normalization conditional VAE-QA pair generation (BNCVAE-QAG) model to generate QA pairs for a given text. First, we employ the Batch Normalization (BN) … Cites: ‪Addressing Semantic Drift in Question Generation for Semi …‬&lt;/p&gt;</content><author><name>J Li, P Qi, H Luo - 2022 IEEE 25th International Conference on Computer …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">One of the most challenging problems in the question answering (QA) area is the lack of high-quality labeled data. However, the cost of manually labeling a question-answer (QA) pair from the target text is very high. One way to solve this problem is to automatically generate QA pairs from the target text. In this paper, we propose the Batch Normalization conditional VAE-QA pair generation (BNCVAE-QAG) model to generate QA pairs for a given text. First, we employ the Batch Normalization (BN) … Cites: ‪Addressing Semantic Drift in Question Generation for Semi …‬</summary></entry><entry><title type="html">Incorporating AI and learning analytics to build trustworthy peer assessment systems</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/43b9a4a96f663cc02f56b81cf5f02269.html" rel="alternate" type="text/html" title="Incorporating AI and learning analytics to build trustworthy peer assessment systems" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/43b9a4a96f663cc02f56b81cf5f02269</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/43b9a4a96f663cc02f56b81cf5f02269.html">&lt;p&gt;Peer assessment has been recognised as a sustainable and scalable assessment method that promotes higher‐order learning and provides students with fast and detailed feedback on their work. Despite these benefits, some common concerns and criticisms are associated with the use of peer assessments (eg, scarcity of high‐quality feedback from peer student‐assessors and lack of accuracy in assigning a grade to the assessee) that raise questions about their trustworthiness … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬&lt;/p&gt;</content><author><name>A Darvishi, H Khosravi, S Sadiq, D Gašević - British Journal of Educational …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Peer assessment has been recognised as a sustainable and scalable assessment method that promotes higher‐order learning and provides students with fast and detailed feedback on their work. Despite these benefits, some common concerns and criticisms are associated with the use of peer assessments (eg, scarcity of high‐quality feedback from peer student‐assessors and lack of accuracy in assigning a grade to the assessee) that raise questions about their trustworthiness … Cites: ‪BERT: Pre-training of Deep Bidirectional Transformers for …‬</summary></entry><entry><title type="html">A deep learning model and human-machine fusion for prediction of EBV-associated gastric cancer from histopathology</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4585a879d201b617975008af634698c6.html" rel="alternate" type="text/html" title="A deep learning model and human-machine fusion for prediction of EBV-associated gastric cancer from histopathology" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4585a879d201b617975008af634698c6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4585a879d201b617975008af634698c6.html">&lt;p&gt;Epstein–Barr virus-associated gastric cancer (EBVaGC) shows a robust response to immune checkpoint inhibitors. Therefore, a cost-efficient and accessible tool is needed for discriminating EBV status in patients with gastric cancer. Here we introduce a deep convolutional neural network called EBVNet and its fusion with pathologists for predicting EBVaGC from histopathology. The EBVNet yields an averaged area under the receiver operating curve (AUROC) of 0.969 from the … Cites: ‪Deep learning-enabled breast cancer hormonal receptor status …‬&lt;/p&gt;</content><author><name>X Zheng, R Wang, X Zhang, Y Sun, H Zhang, Z Zhao… - Nature Communications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Epstein–Barr virus-associated gastric cancer (EBVaGC) shows a robust response to immune checkpoint inhibitors. Therefore, a cost-efficient and accessible tool is needed for discriminating EBV status in patients with gastric cancer. Here we introduce a deep convolutional neural network called EBVNet and its fusion with pathologists for predicting EBVaGC from histopathology. The EBVNet yields an averaged area under the receiver operating curve (AUROC) of 0.969 from the … Cites: ‪Deep learning-enabled breast cancer hormonal receptor status …‬</summary></entry><entry><title type="html">A Novel Transformer Pre-training Objective and a Novel Fine-Tuning Method for Abstractive Summarization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/46ae0e74536088ce796029486cc7851b.html" rel="alternate" type="text/html" title="A Novel Transformer Pre-training Objective and a Novel Fine-Tuning Method for Abstractive Summarization" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/46ae0e74536088ce796029486cc7851b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/46ae0e74536088ce796029486cc7851b.html">&lt;p&gt;Pre-training Transformer has been widely used in many NLP tasks including document summarization. Researchers designed many different self-supervised objectives for their pre-training transformer models, then based on the seq2seq model to fine tune on these pre-trained Transformer models for downstream tasks. However, most researchers designed their self-supervised objectives for all NLP tasks, the ability of self-supervised objectives for a specific task such as abstractive … Cites: ‪Neural text summarization: A critical evaluation‬&lt;/p&gt;</content><author><name>C Zhang - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pre-training Transformer has been widely used in many NLP tasks including document summarization. Researchers designed many different self-supervised objectives for their pre-training transformer models, then based on the seq2seq model to fine tune on these pre-trained Transformer models for downstream tasks. However, most researchers designed their self-supervised objectives for all NLP tasks, the ability of self-supervised objectives for a specific task such as abstractive … Cites: ‪Neural text summarization: A critical evaluation‬</summary></entry><entry><title type="html">Applying Machine Learning in Sociology: How to Predict Gender and Reveal Research Preferences</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/46d739c31e6d612901ec5b1aa5bfb034.html" rel="alternate" type="text/html" title="Applying Machine Learning in Sociology: How to Predict Gender and Reveal Research Preferences" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/46d739c31e6d612901ec5b1aa5bfb034</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/46d739c31e6d612901ec5b1aa5bfb034.html">&lt;p&gt;Applications of machine learning (ML) in industry and natural sciences yielded some of the most impactful innovations of the last decade (for instance, artificial intelligence, gene prediction or search engines) and changed the everyday-life of many people. From a methodological perspective, we can differentiate between unsupervised machine learning (UML) and supervised machine learning (SML). While SML uses labeled data as input to train algorithms in order to predict outcomes … Cites: ‪Reading tea leaves: How humans interpret topic models‬&lt;/p&gt;</content><author><name>RH Heiberger - KZfSS Kölner Zeitschrift für Soziologie und …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Applications of machine learning (ML) in industry and natural sciences yielded some of the most impactful innovations of the last decade (for instance, artificial intelligence, gene prediction or search engines) and changed the everyday-life of many people. From a methodological perspective, we can differentiate between unsupervised machine learning (UML) and supervised machine learning (SML). While SML uses labeled data as input to train algorithms in order to predict outcomes … Cites: ‪Reading tea leaves: How humans interpret topic models‬</summary></entry><entry><title type="html">Spatial Autoregressive Coding for Graph Neural Recommendation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/46ebeb35e2daf8ab521c09a47dd5d3da.html" rel="alternate" type="text/html" title="Spatial Autoregressive Coding for Graph Neural Recommendation" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/46ebeb35e2daf8ab521c09a47dd5d3da</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/46ebeb35e2daf8ab521c09a47dd5d3da.html">&lt;p&gt;Graph embedding methods including traditional shallow models and deep Graph Neural Networks (GNNs) have led to promising applications in recommendation. Nevertheless, shallow models especially random-walk-based algorithms fail to adequately exploit neighbor proximity in sampled subgraphs or sequences due to their optimization paradigm. GNN-based algorithms suffer from the insufficient utilization of high-order information and easily cause over-smoothing problems when … Cites: ‪UPRec: User-Aware Pre-training for Recommender Systems‬&lt;/p&gt;</content><author><name>J Zheng, L Yang, H Wang, C Yang, Y Li, X Hu, S Hong - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Graph embedding methods including traditional shallow models and deep Graph Neural Networks (GNNs) have led to promising applications in recommendation. Nevertheless, shallow models especially random-walk-based algorithms fail to adequately exploit neighbor proximity in sampled subgraphs or sequences due to their optimization paradigm. GNN-based algorithms suffer from the insufficient utilization of high-order information and easily cause over-smoothing problems when … Cites: ‪UPRec: User-Aware Pre-training for Recommender Systems‬</summary></entry><entry><title type="html">Transformer attention optimization in time series forecasting</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/47d218c2b09dca32e605e15da6309db3.html" rel="alternate" type="text/html" title="Transformer attention optimization in time series forecasting" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/47d218c2b09dca32e605e15da6309db3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/47d218c2b09dca32e605e15da6309db3.html">&lt;p&gt;Transformer-based architectures are neural networks architectures developed for natural language processing. These state-of-the-art architectures innovation is the use of the self-attention mechanism. These models have been deployed in several settings, not just limited to natural language, but also including videos and images. However they are hard to scale up for industrial applications due to the quadratic time and memory complexity of attention mechanism. Therefore, there has been a … Cites: ‪Delight: Very deep and light-weight transformer‬&lt;/p&gt;</content><author><name>A ARCIDIACONO - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Transformer-based architectures are neural networks architectures developed for natural language processing. These state-of-the-art architectures innovation is the use of the self-attention mechanism. These models have been deployed in several settings, not just limited to natural language, but also including videos and images. However they are hard to scale up for industrial applications due to the quadratic time and memory complexity of attention mechanism. Therefore, there has been a … Cites: ‪Delight: Very deep and light-weight transformer‬</summary></entry><entry><title type="html">Fair and Green Hyperparameter Optimization via Multi-objective and Multiple Information Source Bayesian Optimization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4b60749dd63834c5582512bae94a1f5c.html" rel="alternate" type="text/html" title="Fair and Green Hyperparameter Optimization via Multi-objective and Multiple Information Source Bayesian Optimization" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4b60749dd63834c5582512bae94a1f5c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4b60749dd63834c5582512bae94a1f5c.html">&lt;p&gt;There is a consensus that focusing only on accuracy in searching for optimal machine learning models amplifies biases contained in the data, leading to unfair predictions and decision supports. Recently, multi-objective hyperparameter optimization has been proposed to search for machine learning models which offer equally Pareto-efficient trade-offs between accuracy and fairness. Although these approaches proved to be more versatile than fairness-aware machine learning … Cites: ‪Green AI‬&lt;/p&gt;</content><author><name>A Candelieri, A Ponti, F Archetti - arXiv preprint arXiv:2205.08835, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">There is a consensus that focusing only on accuracy in searching for optimal machine learning models amplifies biases contained in the data, leading to unfair predictions and decision supports. Recently, multi-objective hyperparameter optimization has been proposed to search for machine learning models which offer equally Pareto-efficient trade-offs between accuracy and fairness. Although these approaches proved to be more versatile than fairness-aware machine learning … Cites: ‪Green AI‬</summary></entry><entry><title type="html">Modeling Exemplification in Long-form Question Answering via Retrieval</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4bd04f3070d032fe69445ae50d8c05b1.html" rel="alternate" type="text/html" title="Modeling Exemplification in Long-form Question Answering via Retrieval" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4bd04f3070d032fe69445ae50d8c05b1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4bd04f3070d032fe69445ae50d8c05b1.html">&lt;p&gt;Exemplification is a process by which writers explain or clarify a concept by providing an example. While common in all forms of writing, exemplification is particularly useful in the task of long-form question answering (LFQA), where a complicated …&lt;/p&gt;</content><author><name>S Wang, F Xu, L Thompson, E Choi, M Iyyer - arXiv preprint arXiv:2205.09278, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Exemplification is a process by which writers explain or clarify a concept by providing an example. While common in all forms of writing, exemplification is particularly useful in the task of long-form question answering (LFQA), where a complicated …</summary></entry><entry><title type="html">Improving Information Extraction on Business Documents with Specific Pre-training Tasks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4cbe45e73e72dee7813dd65b0f7faffe.html" rel="alternate" type="text/html" title="Improving Information Extraction on Business Documents with Specific Pre-training Tasks" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4cbe45e73e72dee7813dd65b0f7faffe</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4cbe45e73e72dee7813dd65b0f7faffe.html">&lt;p&gt;Abstract Transformer-based Language Models are widely used in Natural Language Processing related tasks. Thanks to their pre-training, they have been successfully adapted to Information Extraction in business documents. However, most pre-training tasks proposed in the literature for business documents are too generic and not sufficient to learn more complex structures. In this paper, we use LayoutLM, a language model pre-trained on a collection of business documents, and introduce … Cites: ‪Question Answering is a Format; When is it Useful?‬&lt;/p&gt;</content><author><name>T Douzon, S Duffner, C Garcia, J Espinas - International Workshop on Document …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Transformer-based Language Models are widely used in Natural Language Processing related tasks. Thanks to their pre-training, they have been successfully adapted to Information Extraction in business documents. However, most pre-training tasks proposed in the literature for business documents are too generic and not sufficient to learn more complex structures. In this paper, we use LayoutLM, a language model pre-trained on a collection of business documents, and introduce … Cites: ‪Question Answering is a Format; When is it Useful?‬</summary></entry><entry><title type="html">Des arbres, des chevaliers et des marionnettes: apprentissages par transferts pour le traitement des langues historiques</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4e4f50bdf40939d7fdc44838d821d237.html" rel="alternate" type="text/html" title="Des arbres, des chevaliers et des marionnettes: apprentissages par transferts pour le traitement des langues historiques" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4e4f50bdf40939d7fdc44838d821d237</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4e4f50bdf40939d7fdc44838d821d237.html">&lt;p&gt;In recent years, automatic natural language processing (NLP) has evolved extremely rapidly, with NLP systems achieving record performance for many tasks and domains. These developments are largely due to the contributions of deep learning techniques, of which the most recent and impactful are based on the use of semi-supervised pre-training on large amounts of unannotated data complemented by targeted learning (fine-tuning) for target tasks (Peters et al., 2018; Howard et Ruder … Cites: ‪Kristina, Toutanova‬&lt;/p&gt;</content><author><name>TEL Team, LST Team - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In recent years, automatic natural language processing (NLP) has evolved extremely rapidly, with NLP systems achieving record performance for many tasks and domains. These developments are largely due to the contributions of deep learning techniques, of which the most recent and impactful are based on the use of semi-supervised pre-training on large amounts of unannotated data complemented by targeted learning (fine-tuning) for target tasks (Peters et al., 2018; Howard et Ruder … Cites: ‪Kristina, Toutanova‬</summary></entry><entry><title type="html">Geographical Distance Is The New Hyperparameter: A Case Study Of Finding The Optimal Pre-trained Language For English-isiZulu Machine Translation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4f47f7fd35831f2aff61e29f079fd502.html" rel="alternate" type="text/html" title="Geographical Distance Is The New Hyperparameter: A Case Study Of Finding The Optimal Pre-trained Language For English-isiZulu Machine Translation" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4f47f7fd35831f2aff61e29f079fd502</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/4f47f7fd35831f2aff61e29f079fd502.html">&lt;p&gt;Stemming from the limited availability of datasets and textual resources for low-resource languages such as isiZulu, there is a significant need to be able to harness knowledge from pre-trained models to improve low resource machine translation. Moreover, a lack of techniques to handle the complexities of morphologically rich languages has compounded the unequal development of translation models, with many widely spoken African languages being left behind. This study explores the … Cites: ‪Dynamic Data Selection and Weighting for Iterative Back-Translation‬&lt;/p&gt;</content><author><name>MU Nasir, IA Mchechesi - arXiv preprint arXiv:2205.08621, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Stemming from the limited availability of datasets and textual resources for low-resource languages such as isiZulu, there is a significant need to be able to harness knowledge from pre-trained models to improve low resource machine translation. Moreover, a lack of techniques to handle the complexities of morphologically rich languages has compounded the unequal development of translation models, with many widely spoken African languages being left behind. This study explores the … Cites: ‪Dynamic Data Selection and Weighting for Iterative Back-Translation‬</summary></entry><entry><title type="html">Extract Dynamic Information To Improve Time Series Modeling: a Case Study with Scientific Workflow</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5396bb0479d6ce60083ea2a03e728706.html" rel="alternate" type="text/html" title="Extract Dynamic Information To Improve Time Series Modeling: a Case Study with Scientific Workflow" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5396bb0479d6ce60083ea2a03e728706</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5396bb0479d6ce60083ea2a03e728706.html">&lt;p&gt;In modeling time series data, we often need to augment the existing data records to increase the modeling accuracy. In this work, we describe a number of techniques to extract dynamic information about the current state of a large scientific workflow, which could be generalized to other types of applications. The specific task to be modeled is the time needed for transferring a file from an experimental facility to a data center. The key idea of our approach is to find recent past data transfer events … Cites: ‪Input selection for fast feature engineering‬&lt;/p&gt;</content><author><name>J Kim, M Jin, Y Homma, A Sim, W Kroeger, K Wu - arXiv preprint arXiv:2205.09703, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In modeling time series data, we often need to augment the existing data records to increase the modeling accuracy. In this work, we describe a number of techniques to extract dynamic information about the current state of a large scientific workflow, which could be generalized to other types of applications. The specific task to be modeled is the time needed for transferring a file from an experimental facility to a data center. The key idea of our approach is to find recent past data transfer events … Cites: ‪Input selection for fast feature engineering‬</summary></entry><entry><title type="html">Prediction of GPCR activity using Machine Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/54518d17c996d666b5b5973d784ec63a.html" rel="alternate" type="text/html" title="Prediction of GPCR activity using Machine Learning" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/54518d17c996d666b5b5973d784ec63a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/54518d17c996d666b5b5973d784ec63a.html">&lt;p&gt;GPCRs are the target for one-third of the FDA-approved drugs, however; the development of new drug molecules targeting GPCRs is limited by the lack of mechanistic understanding of the GPCR structure-activity-function relationship. To modulate the GPCR activity with highly specific drugs and minimal side-effects, it is necessary to quantitatively describe the important structural features in the GPCR and correlate them to the activation state of GPCR. In this study, we developed 3 ML … Cites: ‪Strategies for pre-training graph neural networks‬&lt;/p&gt;</content><author><name>P Yadav, P Mollaei, Z Cao, Y Wang, AB Farimani - Computational and Structural …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">GPCRs are the target for one-third of the FDA-approved drugs, however; the development of new drug molecules targeting GPCRs is limited by the lack of mechanistic understanding of the GPCR structure-activity-function relationship. To modulate the GPCR activity with highly specific drugs and minimal side-effects, it is necessary to quantitatively describe the important structural features in the GPCR and correlate them to the activation state of GPCR. In this study, we developed 3 ML … Cites: ‪Strategies for pre-training graph neural networks‬</summary></entry><entry><title type="html">FiLM: Frequency improved Legendre Memory Model for Long-term Time Series Forecasting</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5542af0a15051f7bcb59a6123aeb7463.html" rel="alternate" type="text/html" title="FiLM: Frequency improved Legendre Memory Model for Long-term Time Series Forecasting" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5542af0a15051f7bcb59a6123aeb7463</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5542af0a15051f7bcb59a6123aeb7463.html">&lt;p&gt;Recent studies have shown the promising performance of deep learning models (eg, RNN and Transformer) for long-term time series forecasting. These studies mostly focus on designing deep models to effectively combine historical information for long-term forecasting. However, the question of how to effectively represent historical information for long-term forecasting has not received enough attention, limiting our capacity to exploit powerful deep learning models. The main challenge in time series … Cites: ‪Luna: Linear unified nested attention‬&lt;/p&gt;</content><author><name>T Zhou, Z Ma, Q Wen, L Sun, T Yao, R Jin - arXiv preprint arXiv:2205.08897, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent studies have shown the promising performance of deep learning models (eg, RNN and Transformer) for long-term time series forecasting. These studies mostly focus on designing deep models to effectively combine historical information for long-term forecasting. However, the question of how to effectively represent historical information for long-term forecasting has not received enough attention, limiting our capacity to exploit powerful deep learning models. The main challenge in time series … Cites: ‪Luna: Linear unified nested attention‬</summary></entry><entry><title type="html">Exploring sparse expert models and beyond</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5643c3b17b4566e5ffe773e899c7f83f.html" rel="alternate" type="text/html" title="Exploring sparse expert models and beyond" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5643c3b17b4566e5ffe773e899c7f83f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5643c3b17b4566e5ffe773e899c7f83f.html">&lt;p&gt;Abstract Mixture-of-Experts (MoE) models can achieve promising results with outrageous large amount of parameters but constant computation cost, and thus it has become a trend in model scaling. Still it is a mystery how MoE layers bring quality gains by leveraging the parameters with sparse activation. In this work, we investigate several key factors in sparse expert models. We observe that load imbalance may not be a significant problem affecting model quality, contrary to the … Cites: ‪RoBERTa: A Robustly Optimized BERT Pretraining Approach‬&lt;/p&gt;</content><author><name>A Yang, J Lin, R Men, C Zhou, L Jiang, X Jia, A Wang… - arXiv preprint arXiv …, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Mixture-of-Experts (MoE) models can achieve promising results with outrageous large amount of parameters but constant computation cost, and thus it has become a trend in model scaling. Still it is a mystery how MoE layers bring quality gains by leveraging the parameters with sparse activation. In this work, we investigate several key factors in sparse expert models. We observe that load imbalance may not be a significant problem affecting model quality, contrary to the … Cites: ‪RoBERTa: A Robustly Optimized BERT Pretraining Approach‬</summary></entry><entry><title type="html">Powerful Molecule Generation with Simple ConvNet</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/569183d32b33ba2064a344632de6d937.html" rel="alternate" type="text/html" title="Powerful Molecule Generation with Simple ConvNet" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/569183d32b33ba2064a344632de6d937</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/569183d32b33ba2064a344632de6d937.html">&lt;p&gt;Motivation Automated molecule generation is a crucial step in in-silico drug discovery. Graph-based generation algorithms have seen significant progress over recent years. However, they are often complex to implement, hard to train and can under-perform when generating long-sequence molecules. The development of a simple and powerful alternative can help improve practicality of automated drug discovery method. Results We proposed a ConvNet-based sequential graph … Cites: ‪Masked graph modeling for molecule generation‬&lt;/p&gt;</content><author><name>H Yu, H Yu - Bioinformatics, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Motivation Automated molecule generation is a crucial step in in-silico drug discovery. Graph-based generation algorithms have seen significant progress over recent years. However, they are often complex to implement, hard to train and can under-perform when generating long-sequence molecules. The development of a simple and powerful alternative can help improve practicality of automated drug discovery method. Results We proposed a ConvNet-based sequential graph … Cites: ‪Masked graph modeling for molecule generation‬</summary></entry><entry><title type="html">基于混合相似度度量的跨语言舰船实体匹配算法</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/56f20ac069a63d544600788f72b2560d.html" rel="alternate" type="text/html" title="基于混合相似度度量的跨语言舰船实体匹配算法" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/56f20ac069a63d544600788f72b2560d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/56f20ac069a63d544600788f72b2560d.html">&lt;p&gt;由于装备信息的敏感性, 军事领域的跨语言实体匹配问题会面临缺乏标注好的平行语料, 依赖机器翻译质量等问题. 从这些问题出发, 提出了一种跨语言舰船实体匹配算法. 首先归纳匹配规则, 通过融合机器翻译和词典短语释义取得语言转换结果, 设计了检测后缀相同字符串的相似度度量suffix-matter 优化候选集, 提高了算法的效率. 还设计了捕捉字符和发音特征的混合相似度度量MixSim 协助寻找匹配的实体. 利用从互联网上爬取各国舰船活动事件的新闻报道和简式舰船数据进行实验 … Cites: ‪Principles of data integration‬&lt;/p&gt;</content><author><name>孟卓鹏， 吴继冰， 刘丽华， 王懋， 邓苏， 黄宏斌 - 郑州大学学报 (理学版), 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">由于装备信息的敏感性, 军事领域的跨语言实体匹配问题会面临缺乏标注好的平行语料, 依赖机器翻译质量等问题. 从这些问题出发, 提出了一种跨语言舰船实体匹配算法. 首先归纳匹配规则, 通过融合机器翻译和词典短语释义取得语言转换结果, 设计了检测后缀相同字符串的相似度度量suffix-matter 优化候选集, 提高了算法的效率. 还设计了捕捉字符和发音特征的混合相似度度量MixSim 协助寻找匹配的实体. 利用从互联网上爬取各国舰船活动事件的新闻报道和简式舰船数据进行实验 … Cites: ‪Principles of data integration‬</summary></entry><entry><title type="html">GPoeT-2: A GPT-2 Based Poem Generator</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5b403c92cafd5eac15b444a04b2dba4f.html" rel="alternate" type="text/html" title="GPoeT-2: A GPT-2 Based Poem Generator" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5b403c92cafd5eac15b444a04b2dba4f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5b403c92cafd5eac15b444a04b2dba4f.html">&lt;p&gt;This project aims to produce the next volume of machine-generated poetry, a complex art form that can be structured and unstructured, and carries depth in the meaning between the lines. GPoeT-2 is based on fine-tuning a state of the art natural language model (ie GPT-2) to generate limericks, typically humorous structured poems consisting of five lines with a AABBA rhyming scheme. With a two-stage generation system utilizing both forward and reverse language modeling, GPoeT-2 is … Cites: ‪Chinese poetry generation with recurrent neural networks‬&lt;/p&gt;</content><author><name>KL Lo, R Ariss, P Kurz - arXiv preprint arXiv:2205.08847, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This project aims to produce the next volume of machine-generated poetry, a complex art form that can be structured and unstructured, and carries depth in the meaning between the lines. GPoeT-2 is based on fine-tuning a state of the art natural language model (ie GPT-2) to generate limericks, typically humorous structured poems consisting of five lines with a AABBA rhyming scheme. With a two-stage generation system utilizing both forward and reverse language modeling, GPoeT-2 is … Cites: ‪Chinese poetry generation with recurrent neural networks‬</summary></entry><entry><title type="html">The Value of Social Media Language for the Assessment of Wellbeing: A Systematic Review and Meta-Analysis</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5beac0527c2d77e127646095d1886314.html" rel="alternate" type="text/html" title="The Value of Social Media Language for the Assessment of Wellbeing: A Systematic Review and Meta-Analysis" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5beac0527c2d77e127646095d1886314</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5beac0527c2d77e127646095d1886314.html">&lt;p&gt;Wellbeing is an important concept that concerns researchers, policy makers, and the broader general public. The measurement of individuals  wellbeing levels has predominantly been done through self-reports (eg, survey questionnaires), which is time-consuming for respondents and costly. Alternatively, wellbeing can be measured in real-time by automatically analysing the language expressed on social media platforms (eg, Facebook, Twitter, Weibo), through social media language text … Cites: ‪Twitter sentiment in New York City parks as measure of well-being‬&lt;/p&gt;</content><author><name>S Sametoglu, D Pelt, LH Ungar, M Bartels - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Wellbeing is an important concept that concerns researchers, policy makers, and the broader general public. The measurement of individuals wellbeing levels has predominantly been done through self-reports (eg, survey questionnaires), which is time-consuming for respondents and costly. Alternatively, wellbeing can be measured in real-time by automatically analysing the language expressed on social media platforms (eg, Facebook, Twitter, Weibo), through social media language text … Cites: ‪Twitter sentiment in New York City parks as measure of well-being‬</summary></entry><entry><title type="html">Investigating the spatial variability of water security risk and its driving mechanisms in China using machine learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5c68deca03de20a268b81bf385e37541.html" rel="alternate" type="text/html" title="Investigating the spatial variability of water security risk and its driving mechanisms in China using machine learning" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5c68deca03de20a268b81bf385e37541</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/5c68deca03de20a268b81bf385e37541.html">&lt;p&gt;Water security is widely defined as adequate availability of water resources in both quantity and quality, coupled with an acceptable level of water-related risk to support human livelihood, national socio-economic development, and ecosystem services (Bakker, 2012; Sun et al., 2016). To ensure a sustainable state of water security or to reduce the risk of water insecurity is still one of fundamental topics relative to human civilization over the past decades (Vörösmarty et al., 2010; Cook and Bakker, 2012; … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/p&gt;</content><author><name>Z Xu, L Cheng, P Liu, Q Hou, S Cheng, S Qin, L Liu… - Journal of Cleaner …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Water security is widely defined as adequate availability of water resources in both quantity and quality, coupled with an acceptable level of water-related risk to support human livelihood, national socio-economic development, and ecosystem services (Bakker, 2012; Sun et al., 2016). To ensure a sustainable state of water security or to reduce the risk of water insecurity is still one of fundamental topics relative to human civilization over the past decades (Vörösmarty et al., 2010; Cook and Bakker, 2012; … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">Persian Natural Language Inference: A Meta-learning approach</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6341156bce0a7e0e806057546fd957b5.html" rel="alternate" type="text/html" title="Persian Natural Language Inference: A Meta-learning approach" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6341156bce0a7e0e806057546fd957b5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6341156bce0a7e0e806057546fd957b5.html">&lt;p&gt;Incorporating information from other languages can improve the results of tasks in low-resource languages. A powerful method of building functional natural language processing systems for low-resource languages is to combine multilingual pre-trained representations with cross-lingual transfer learning. In general, however, shared representations are learned separately, either across tasks or across languages. This paper proposes a meta-learning approach for inferring natural … Cites: ‪MetaXL: Meta Representation Transformation for Low-resource …‬&lt;/p&gt;</content><author><name>H Soudani, MH Mojab, H Beigy - arXiv preprint arXiv:2205.08755, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Incorporating information from other languages can improve the results of tasks in low-resource languages. A powerful method of building functional natural language processing systems for low-resource languages is to combine multilingual pre-trained representations with cross-lingual transfer learning. In general, however, shared representations are learned separately, either across tasks or across languages. This paper proposes a meta-learning approach for inferring natural … Cites: ‪MetaXL: Meta Representation Transformation for Low-resource …‬</summary></entry><entry><title type="html">Acceptability Judgements via Examining the Topology of Attention Maps</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/64fd8a475ebd2b8814d0e9642788c4f4.html" rel="alternate" type="text/html" title="Acceptability Judgements via Examining the Topology of Attention Maps" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/64fd8a475ebd2b8814d0e9642788c4f4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/64fd8a475ebd2b8814d0e9642788c4f4.html">&lt;p&gt;The role of the attention mechanism in encoding linguistic knowledge has received special interest in NLP. However, the ability of the attention heads to judge the grammatical acceptability of a sentence has been underexplored. This paper approaches the paradigm of acceptability judgments with topological data analysis (TDA), showing that the geometric properties of the attention graph can be efficiently exploited for two standard practices in linguistics: binary judgments and linguistic … Cites: ‪Emergent linguistic structure in artificial neural networks trained by …‬&lt;/p&gt;</content><author><name>D Cherniavskii, E Tulchinskii, V Mikhailov, I Proskurina… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The role of the attention mechanism in encoding linguistic knowledge has received special interest in NLP. However, the ability of the attention heads to judge the grammatical acceptability of a sentence has been underexplored. This paper approaches the paradigm of acceptability judgments with topological data analysis (TDA), showing that the geometric properties of the attention graph can be efficiently exploited for two standard practices in linguistics: binary judgments and linguistic … Cites: ‪Emergent linguistic structure in artificial neural networks trained by …‬</summary></entry><entry><title type="html">Developing a physics-informed and physics-penalized neural network model for preliminary design of multi-stage friction pendulum bearings</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/656769c4c02daa76d2153577c43fc1f9.html" rel="alternate" type="text/html" title="Developing a physics-informed and physics-penalized neural network model for preliminary design of multi-stage friction pendulum bearings" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/656769c4c02daa76d2153577c43fc1f9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/656769c4c02daa76d2153577c43fc1f9.html">&lt;p&gt;Over the last few decades, the field of base isolation systems has made significant strides forward by developing new systems to improve the behavior of isolated structures under moderate and severe seismic excitations. One of the most efficient systems is the multi-stage friction pendulum that can provide a wide range of effective pendula with various regimes to reach high energy dissipation capability. The difficulty in designing such bearing at the preliminary stage comes from the … Cites: ‪Smooth adversarial training‬&lt;/p&gt;</content><author><name>A Habib, U Yildirim - Engineering Applications of Artificial Intelligence, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Over the last few decades, the field of base isolation systems has made significant strides forward by developing new systems to improve the behavior of isolated structures under moderate and severe seismic excitations. One of the most efficient systems is the multi-stage friction pendulum that can provide a wide range of effective pendula with various regimes to reach high energy dissipation capability. The difficulty in designing such bearing at the preliminary stage comes from the … Cites: ‪Smooth adversarial training‬</summary></entry><entry><title type="html">Design and validation of a comparison methodology for Explainable AI techniques</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/662a5a2f76c51eafa71ceb1b75afd896.html" rel="alternate" type="text/html" title="Design and validation of a comparison methodology for Explainable AI techniques" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/662a5a2f76c51eafa71ceb1b75afd896</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/662a5a2f76c51eafa71ceb1b75afd896.html">&lt;p&gt;Abstract Nowadays, Artificial Intelligence (AI) has expanded everywhere and people have become accustomed to the fact that AI can make decisions for us in our daily lives, ranging from product recommendations on Amazon and films on Netflix, to suggestions of friends on Facebook or Instagram, or even advertisements tailored to who is browsing web pages provided by Google. However, in decisions that can really make a difference, such as diagnosing a disease, it is important to know the … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬&lt;/p&gt;</content><author><name>F VANNI - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Nowadays, Artificial Intelligence (AI) has expanded everywhere and people have become accustomed to the fact that AI can make decisions for us in our daily lives, ranging from product recommendations on Amazon and films on Netflix, to suggestions of friends on Facebook or Instagram, or even advertisements tailored to who is browsing web pages provided by Google. However, in decisions that can really make a difference, such as diagnosing a disease, it is important to know the … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬</summary></entry><entry><title type="html">PromptDA: Label-guided Data Augmentation for Prompt-based Few Shot Learners</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/672852363bec1cd82a77cd7607484683.html" rel="alternate" type="text/html" title="PromptDA: Label-guided Data Augmentation for Prompt-based Few Shot Learners" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/672852363bec1cd82a77cd7607484683</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/672852363bec1cd82a77cd7607484683.html">&lt;p&gt;Recent advances on large pre-trained language models (PLMs) lead impressive gains on natural language understanding (NLU) tasks with task-specific fine-tuning. However, direct fine-tuning PLMs heavily relies on large amount of labeled instances, which are expensive and time-consuming to obtain. Prompt-based tuning on PLMs has proven valuable for few shot tasks. Existing works studying prompt-based tuning for few-shot NLU mainly focus on deriving proper label words with a … Cites: ‪Pre-train, prompt, and predict: A systematic survey of prompting …‬&lt;/p&gt;</content><author><name>C Chen, K Shu - arXiv preprint arXiv:2205.09229, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent advances on large pre-trained language models (PLMs) lead impressive gains on natural language understanding (NLU) tasks with task-specific fine-tuning. However, direct fine-tuning PLMs heavily relies on large amount of labeled instances, which are expensive and time-consuming to obtain. Prompt-based tuning on PLMs has proven valuable for few shot tasks. Existing works studying prompt-based tuning for few-shot NLU mainly focus on deriving proper label words with a … Cites: ‪Pre-train, prompt, and predict: A systematic survey of prompting …‬</summary></entry><entry><title type="html">Contrastive Learning-Based Dual Dynamic GCN for SAR Image Scene Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6952f84f9b418339da6bf97e6d224109.html" rel="alternate" type="text/html" title="Contrastive Learning-Based Dual Dynamic GCN for SAR Image Scene Classification" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6952f84f9b418339da6bf97e6d224109</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6952f84f9b418339da6bf97e6d224109.html">&lt;p&gt;As a typical label-limited task, it is significant and valuable to explore networks that enable to utilize labeled and unlabeled samples simultaneously for synthetic aperture radar (SAR) image scene classification. Graph convolutional network (GCN) is a powerful semisupervised learning paradigm that helps to capture the topological relationships of scenes in SAR images. While the performance is not satisfactory when existing GCNs are directly used for SAR image scene classification with limited … Cites: ‪Semi-supervised Learning on Directed Graphs.‬&lt;/p&gt;</content><author><name>F Liu, X Qian, L Jiao, X Zhang, L Li, Y Cui - IEEE Transactions on Neural Networks …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As a typical label-limited task, it is significant and valuable to explore networks that enable to utilize labeled and unlabeled samples simultaneously for synthetic aperture radar (SAR) image scene classification. Graph convolutional network (GCN) is a powerful semisupervised learning paradigm that helps to capture the topological relationships of scenes in SAR images. While the performance is not satisfactory when existing GCNs are directly used for SAR image scene classification with limited … Cites: ‪Semi-supervised Learning on Directed Graphs.‬</summary></entry><entry><title type="html">Research on Automatic Generation of Comment Labels Oriented to Users Individualized Needs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/69e074caab77dc534c6cd2857eab8ec5.html" rel="alternate" type="text/html" title="Research on Automatic Generation of Comment Labels Oriented to Users Individualized Needs" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/69e074caab77dc534c6cd2857eab8ec5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/69e074caab77dc534c6cd2857eab8ec5.html">&lt;p&gt;As the scale of online shopping users continues expanding, comments and feedback to users of their opinions after purchase and use are of great significance to assist users in purchasing decisions. In order to encourage users to actively comment, some websites provide comment tags for users to choose. These labels only summarize the common features of the products, but do not consider the differences among different products, it is even more unable to meet the personalized … Cites: ‪Neural latent extractive document summarization‬&lt;/p&gt;</content><author><name>Y Zheng, J Shen, R Jia, R Li - 2022 IEEE 25th International Conference on Computer …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As the scale of online shopping users continues expanding, comments and feedback to users of their opinions after purchase and use are of great significance to assist users in purchasing decisions. In order to encourage users to actively comment, some websites provide comment tags for users to choose. These labels only summarize the common features of the products, but do not consider the differences among different products, it is even more unable to meet the personalized … Cites: ‪Neural latent extractive document summarization‬</summary></entry><entry><title type="html">On the Limits of Evaluating Embodied Agent Model Generalization Using Validation Sets</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6a6b4ab1e8de06261deb5e9d2036a1de.html" rel="alternate" type="text/html" title="On the Limits of Evaluating Embodied Agent Model Generalization Using Validation Sets" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6a6b4ab1e8de06261deb5e9d2036a1de</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6a6b4ab1e8de06261deb5e9d2036a1de.html">&lt;p&gt;Natural language guided embodied task completion is a challenging problem since it requires understanding natural language instructions, aligning them with egocentric visual observations, and choosing appropriate actions to execute in the environment …&lt;/p&gt;</content><author><name>H Kim, A Padmakumar, D Jin, M Bansal, D Hakkani-Tur - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Natural language guided embodied task completion is a challenging problem since it requires understanding natural language instructions, aligning them with egocentric visual observations, and choosing appropriate actions to execute in the environment …</summary></entry><entry><title type="html">The Power of Reuse: A Multi-Scale Transformer Model for Structural Dynamic Segmentation in Symbolic Music Generation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6e9eb558d4e85cec31cae97668ac4a9c.html" rel="alternate" type="text/html" title="The Power of Reuse: A Multi-Scale Transformer Model for Structural Dynamic Segmentation in Symbolic Music Generation" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6e9eb558d4e85cec31cae97668ac4a9c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6e9eb558d4e85cec31cae97668ac4a9c.html">&lt;p&gt;Symbolic Music Generation relies on the contextual representation capabilities of the generative model, where the most prevalent approach is the Transformer-based model. Not only that, the learning of long-term context is also related to the dynamic segmentation of musical structures, ie intro, verse and chorus, which is currently overlooked by the research community. In this paper, we propose a multi-scale Transformer, which uses coarse-decoder and fine-decoders to model the contexts at … Cites: ‪Paragraph-level commonsense transformers with recurrent memory‬&lt;/p&gt;</content><author><name>G Wu, S Liu, X Fan - arXiv preprint arXiv:2205.08579, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Symbolic Music Generation relies on the contextual representation capabilities of the generative model, where the most prevalent approach is the Transformer-based model. Not only that, the learning of long-term context is also related to the dynamic segmentation of musical structures, ie intro, verse and chorus, which is currently overlooked by the research community. In this paper, we propose a multi-scale Transformer, which uses coarse-decoder and fine-decoders to model the contexts at … Cites: ‪Paragraph-level commonsense transformers with recurrent memory‬</summary></entry><entry><title type="html">Automatic Rule Induction for Efficient Semi-Supervised Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6ecd7f1dce9a4712abc2af72ccc971f5.html" rel="alternate" type="text/html" title="Automatic Rule Induction for Efficient Semi-Supervised Learning" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6ecd7f1dce9a4712abc2af72ccc971f5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/6ecd7f1dce9a4712abc2af72ccc971f5.html">&lt;p&gt;Semi-supervised learning has shown promise in allowing NLP models to generalize from small amounts of labeled data. Meanwhile, pretrained transformer models act as black-box correlation engines that are difficult to explain and sometimes behave unreliably. In this paper, we propose tackling both of these challenges via Automatic Rule Induction (ARI), a simple and general-purpose framework for the automatic discovery and integration of symbolic rules into pretrained transformer models. First … Cites: ‪Dataset cartography: Mapping and diagnosing datasets with …‬&lt;/p&gt;</content><author><name>R Pryzant, Z Yang, Y Xu, C Zhu, M Zeng - arXiv preprint arXiv:2205.09067, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Semi-supervised learning has shown promise in allowing NLP models to generalize from small amounts of labeled data. Meanwhile, pretrained transformer models act as black-box correlation engines that are difficult to explain and sometimes behave unreliably. In this paper, we propose tackling both of these challenges via Automatic Rule Induction (ARI), a simple and general-purpose framework for the automatic discovery and integration of symbolic rules into pretrained transformer models. First … Cites: ‪Dataset cartography: Mapping and diagnosing datasets with …‬</summary></entry><entry><title type="html">Enhancing Natural Language Inference of Cross-lingual N-shot Transfer with Multilingual Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/700f3d1622508f82e58f8fd85954354a.html" rel="alternate" type="text/html" title="Enhancing Natural Language Inference of Cross-lingual N-shot Transfer with Multilingual Data" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/700f3d1622508f82e58f8fd85954354a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/700f3d1622508f82e58f8fd85954354a.html">&lt;p&gt;Cross-lingual N-shot transfers are often used to solve low-resource language problems. However, the result of transfer in different languages can be inconsistent due to large fluctuations in accuracy. To reduce the inconsistency caused by the fluctuation of accuracy and improve the overall accuracy of Cross-lingual N-shot transfer, we propose the use of Multitasking Cross-lingual N-shot transfer. To the best of our knowledge, our propose Multitasking Cross-lingual N-shot transfer is the first … Cites: ‪Revisiting the primacy of english in zero-shot cross-lingual transfer‬&lt;/p&gt;</content><author><name>K Tseng, CS Lin - 2022 8th International Conference on Applied System …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Cross-lingual N-shot transfers are often used to solve low-resource language problems. However, the result of transfer in different languages can be inconsistent due to large fluctuations in accuracy. To reduce the inconsistency caused by the fluctuation of accuracy and improve the overall accuracy of Cross-lingual N-shot transfer, we propose the use of Multitasking Cross-lingual N-shot transfer. To the best of our knowledge, our propose Multitasking Cross-lingual N-shot transfer is the first … Cites: ‪Revisiting the primacy of english in zero-shot cross-lingual transfer‬</summary></entry><entry><title type="html">基于时间关系的 Bi-LSTM+ GCN 因果关系抽取</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/72b9c311a54ab54323e07f085bf64ef0.html" rel="alternate" type="text/html" title="基于时间关系的 Bi-LSTM+ GCN 因果关系抽取" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/72b9c311a54ab54323e07f085bf64ef0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/72b9c311a54ab54323e07f085bf64ef0.html">&lt;p&gt;针对传统时间关系只应用在机器学习方向关系抽取的问题, 提出一种基于序列标注实体识别的关系抽取方法. 先构建双向长短期记忆网络(Bi-LSTM) 模型进行特征提取, 再输入时间关系作为特征矩阵进行图卷积. 实验结果表明: 时间关系能提高因果关系抽取效果, 并且包含时间关系的Bi-LSTM+ GCN 模型能有效抽取因果事件; 带有时间关系的Bi-LSTM+ GCN 模型获得因果关系的抽取结果优于传统方法因果关系的抽取结果. Cites: ‪Joint reasoning for temporal and causal relations‬&lt;/p&gt;</content><author><name>郑余祥， 左祥麟， 左万利， 梁世宁， 王英 - 吉林大学学报 (理学版), 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">针对传统时间关系只应用在机器学习方向关系抽取的问题, 提出一种基于序列标注实体识别的关系抽取方法. 先构建双向长短期记忆网络(Bi-LSTM) 模型进行特征提取, 再输入时间关系作为特征矩阵进行图卷积. 实验结果表明: 时间关系能提高因果关系抽取效果, 并且包含时间关系的Bi-LSTM+ GCN 模型能有效抽取因果事件; 带有时间关系的Bi-LSTM+ GCN 模型获得因果关系的抽取结果优于传统方法因果关系的抽取结果. Cites: ‪Joint reasoning for temporal and causal relations‬</summary></entry><entry><title type="html">A Longitudinal Study of Topic</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/73738d327f8db6cae0f58333b0c62dac.html" rel="alternate" type="text/html" title="A Longitudinal Study of Topic" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/73738d327f8db6cae0f58333b0c62dac</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/73738d327f8db6cae0f58333b0c62dac.html">&lt;p&gt;With the emergence of the social Web in the mid-2000s, the Web has evolved from a static Web, where 33 users were only able to consume information, to a Web where users are also able to interact and produce 34 information (Bouadjenek et al., 2016). This evolution, which is commonly known as the Social Web, has 35 introduced new freedoms for the user in their relation with the Web by facilitating their interactions with 36 other users who have similar tastes or share similar resources. Specifically … Cites: ‪Tweet recommendation with graph co-ranking‬&lt;/p&gt;</content><author><name>MR Bouadjenek, S Sanner, Z Iman, L Xie, DX Shi</name></author><category term="jekyll" /><category term="update" /><summary type="html">With the emergence of the social Web in the mid-2000s, the Web has evolved from a static Web, where 33 users were only able to consume information, to a Web where users are also able to interact and produce 34 information (Bouadjenek et al., 2016). This evolution, which is commonly known as the Social Web, has 35 introduced new freedoms for the user in their relation with the Web by facilitating their interactions with 36 other users who have similar tastes or share similar resources. Specifically … Cites: ‪Tweet recommendation with graph co-ranking‬</summary></entry><entry><title type="html">Text mining tweets on e-cigarette risks and benefits using machine learning following a vaping related lung injury outbreak in the USA</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/73d4358c69d608dab0c98e3ab63b895a.html" rel="alternate" type="text/html" title="Text mining tweets on e-cigarette risks and benefits using machine learning following a vaping related lung injury outbreak in the USA" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/73d4358c69d608dab0c98e3ab63b895a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/73d4358c69d608dab0c98e3ab63b895a.html">&lt;p&gt;Electronic nicotine delivery systems (ENDS)(also known as  e-cigarettes ) can support smoking cessation, although the long-term health impacts are not yet known. In 2019, a cluster of lung injury cases in the USA emerged that were ostensibly associated with ENDS use. Subsequent investigations revealed a link with vitamin E acetate, an additive used in some ENDS liquid products containing tetrahydrocannabinol (THC). This became known as the EVALI (E-cigarette or … Cites: ‪Reading tea leaves: How humans interpret topic models‬&lt;/p&gt;</content><author><name>L Hassan, M Elkaref, G deMel, I Bogdanovica… - Healthcare Analytics, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Electronic nicotine delivery systems (ENDS)(also known as e-cigarettes ) can support smoking cessation, although the long-term health impacts are not yet known. In 2019, a cluster of lung injury cases in the USA emerged that were ostensibly associated with ENDS use. Subsequent investigations revealed a link with vitamin E acetate, an additive used in some ENDS liquid products containing tetrahydrocannabinol (THC). This became known as the EVALI (E-cigarette or … Cites: ‪Reading tea leaves: How humans interpret topic models‬</summary></entry><entry><title type="html">A STEP towards Interpretable Multi-Hop Reasoning: Bridge Phrase Identification and Query Expansion</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/7aa254bfb89ad2c8448a2ff8ba7fa287.html" rel="alternate" type="text/html" title="A STEP towards Interpretable Multi-Hop Reasoning: Bridge Phrase Identification and Query Expansion" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/7aa254bfb89ad2c8448a2ff8ba7fa287</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/7aa254bfb89ad2c8448a2ff8ba7fa287.html">&lt;p&gt;We propose an unsupervised method for the identification of bridge phrases in multi-hop question answering (QA). Our method constructs a graph of noun phrases from the question and the available context, and applies the Steiner tree algorithm to identify the minimal sub-graph that connects all question phrases. Nodes in the sub-graph that bridge loosely-connected or disjoint subsets of question phrases due to low-strength semantic relations are extracted as bridge phrases. The identified … Cites: ‪Self-Assembling Modular Networks for Interpretable Multi-Hop …‬&lt;/p&gt;</content><author><name>F Luo, M Surdeanu</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose an unsupervised method for the identification of bridge phrases in multi-hop question answering (QA). Our method constructs a graph of noun phrases from the question and the available context, and applies the Steiner tree algorithm to identify the minimal sub-graph that connects all question phrases. Nodes in the sub-graph that bridge loosely-connected or disjoint subsets of question phrases due to low-strength semantic relations are extracted as bridge phrases. The identified … Cites: ‪Self-Assembling Modular Networks for Interpretable Multi-Hop …‬</summary></entry><entry><title type="html">Relational representation learning with spike trains</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/7d602580a3c6c4f319a13db92ac30926.html" rel="alternate" type="text/html" title="Relational representation learning with spike trains" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/7d602580a3c6c4f319a13db92ac30926</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/7d602580a3c6c4f319a13db92ac30926.html">&lt;p&gt;Relational representation learning has lately received an increase in interest due to its flexibility in modeling a variety of systems like interacting particles, materials and industrial projects for, eg, the design of spacecraft. A prominent method for dealing with relational data are knowledge graph embedding algorithms, where entities and relations of a knowledge graph are mapped to a low-dimensional vector space while preserving its semantic structure. Recently, a graph embedding method has been … Cites: ‪Observed Versus Latent Features for Knowledge Base and Text …‬&lt;/p&gt;</content><author><name>D Dold - arXiv preprint arXiv:2205.09140, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Relational representation learning has lately received an increase in interest due to its flexibility in modeling a variety of systems like interacting particles, materials and industrial projects for, eg, the design of spacecraft. A prominent method for dealing with relational data are knowledge graph embedding algorithms, where entities and relations of a knowledge graph are mapped to a low-dimensional vector space while preserving its semantic structure. Recently, a graph embedding method has been … Cites: ‪Observed Versus Latent Features for Knowledge Base and Text …‬</summary></entry><entry><title type="html">Automated machine learning: the new data science challenge.</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/7f86abd4d675f5d3c5f8a47b2ae00dbb.html" rel="alternate" type="text/html" title="Automated machine learning: the new data science challenge." /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/7f86abd4d675f5d3c5f8a47b2ae00dbb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/7f86abd4d675f5d3c5f8a47b2ae00dbb.html">&lt;p&gt;The world is changing quite rapidly while increasingly tuning into digitalization. However, it is important to note that data science is what most technology is evolving around and data is definitely the future of everything. For industries, adopting a  data science approach  is no longer an option, it becomes an obligation in order to enhance their business rather than survive. This paper offers a roadmap for anyone interested in this research field or getting started with  machine learning  learning … Cites: ‪The unreasonable effectiveness of data‬&lt;/p&gt;</content><author><name>I Slimani, N Slimani, S Achchab, M Saber, I El Farissi… - International Journal of …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The world is changing quite rapidly while increasingly tuning into digitalization. However, it is important to note that data science is what most technology is evolving around and data is definitely the future of everything. For industries, adopting a data science approach is no longer an option, it becomes an obligation in order to enhance their business rather than survive. This paper offers a roadmap for anyone interested in this research field or getting started with machine learning learning … Cites: ‪The unreasonable effectiveness of data‬</summary></entry><entry><title type="html">Explanations and Processes to Enable Humans to Assess AI with Respect to Manipulable Properties</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/817a2ccdbadcb515f905ce18d7005b0e.html" rel="alternate" type="text/html" title="Explanations and Processes to Enable Humans to Assess AI with Respect to Manipulable Properties" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/817a2ccdbadcb515f905ce18d7005b0e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/817a2ccdbadcb515f905ce18d7005b0e.html">&lt;p&gt;Assessing AI systems is difficult. Humans rely on AI systems in increasing ways, both visible and invisible, meaning a variety of stakeholders need a variety of assessment tools (eg, a professional auditor, a developer, and an end user all have different needs). We posit that it is possible to provide explanations and assessment processes that enable AI non-experts observing multiple intelligent agents in sequential domains to differentiate the agents with respect to a property (eg, quality … Cites: ‪Digging into user control: perceptions of adherence and instability …‬&lt;/p&gt;</content><author><name>JE Dodge - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Assessing AI systems is difficult. Humans rely on AI systems in increasing ways, both visible and invisible, meaning a variety of stakeholders need a variety of assessment tools (eg, a professional auditor, a developer, and an end user all have different needs). We posit that it is possible to provide explanations and assessment processes that enable AI non-experts observing multiple intelligent agents in sequential domains to differentiate the agents with respect to a property (eg, quality … Cites: ‪Digging into user control: perceptions of adherence and instability …‬</summary></entry><entry><title type="html">Contrastive Representation Learning for Cross-Document Coreference Resolution of Events and Entities</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/8184a74745072d161e38a36f81a67c8c.html" rel="alternate" type="text/html" title="Contrastive Representation Learning for Cross-Document Coreference Resolution of Events and Entities" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/8184a74745072d161e38a36f81a67c8c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/8184a74745072d161e38a36f81a67c8c.html">&lt;p&gt;Identifying related entities and events within and across documents is fundamental to natural language understanding. We present an approach to entity and event coreference resolution utilizing contrastive representation learning. Earlier state-of-the-art methods have formulated this problem as a binary classification problem and leveraged large transformers in a cross-encoder architecture to achieve their results. For large collections of documents and corresponding set of n mentions, the … Cites: ‪Paired representation learning for event and entity coreference‬&lt;/p&gt;</content><author><name>B Hsu, G Horwood</name></author><category term="jekyll" /><category term="update" /><summary type="html">Identifying related entities and events within and across documents is fundamental to natural language understanding. We present an approach to entity and event coreference resolution utilizing contrastive representation learning. Earlier state-of-the-art methods have formulated this problem as a binary classification problem and leveraged large transformers in a cross-encoder architecture to achieve their results. For large collections of documents and corresponding set of n mentions, the … Cites: ‪Paired representation learning for event and entity coreference‬</summary></entry><entry><title type="html">Certified Error Control of Candidate Set Pruning for Two-Stage Relevance Ranking</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/82568bb71c56145eb4eb01ecce7651ce.html" rel="alternate" type="text/html" title="Certified Error Control of Candidate Set Pruning for Two-Stage Relevance Ranking" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/82568bb71c56145eb4eb01ecce7651ce</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/82568bb71c56145eb4eb01ecce7651ce.html">&lt;p&gt;In information retrieval (IR), candidate set pruning has been commonly used to speed up two-stage relevance ranking. However, such an approach lacks accurate error control and often trades accuracy off against computational efficiency in an empirical fashion, lacking theoretical guarantees. In this paper, we propose the concept of certified error control of candidate set pruning for relevance ranking, which means that the test error after pruning is guaranteed to be controlled under a … Cites: ‪Simple Entity-Centric Questions Challenge Dense Retrievers‬&lt;/p&gt;</content><author><name>M Li, X Zhang, J Xin, H Zhang, J Lin - arXiv preprint arXiv:2205.09638, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In information retrieval (IR), candidate set pruning has been commonly used to speed up two-stage relevance ranking. However, such an approach lacks accurate error control and often trades accuracy off against computational efficiency in an empirical fashion, lacking theoretical guarantees. In this paper, we propose the concept of certified error control of candidate set pruning for relevance ranking, which means that the test error after pruning is guaranteed to be controlled under a … Cites: ‪Simple Entity-Centric Questions Challenge Dense Retrievers‬</summary></entry><entry><title type="html">COVID-19 datasets: A brief overview</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/835d62668c09614c67d59a82aaf83bfe.html" rel="alternate" type="text/html" title="COVID-19 datasets: A brief overview" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/835d62668c09614c67d59a82aaf83bfe</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/835d62668c09614c67d59a82aaf83bfe.html">&lt;p&gt;The outbreak of the COVID-19 pandemic affects lives and social-economic development around the world. The affecting of the pandemic has motivated researchers from different domains to find effective solutions to diagnose, prevent, and estimate the pandemic and relieve its adverse effects. Numerous COVID-19 datasets are built from these studies and are available to the public. These datasets can be used for disease diagnosis and case prediction, speeding up solving … Cites: ‪Rapidly bootstrapping a question answering dataset for COVID-19‬&lt;/p&gt;</content><author><name>K Sun, W Li, V Saikrishna, M Chadhar, F Xia - Computer Science and Information …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The outbreak of the COVID-19 pandemic affects lives and social-economic development around the world. The affecting of the pandemic has motivated researchers from different domains to find effective solutions to diagnose, prevent, and estimate the pandemic and relieve its adverse effects. Numerous COVID-19 datasets are built from these studies and are available to the public. These datasets can be used for disease diagnosis and case prediction, speeding up solving … Cites: ‪Rapidly bootstrapping a question answering dataset for COVID-19‬</summary></entry><entry><title type="html">Interactive capsule network for implicit sentiment analysis</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/85d0ce553dd4c1b3adf38cf137f6a649.html" rel="alternate" type="text/html" title="Interactive capsule network for implicit sentiment analysis" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/85d0ce553dd4c1b3adf38cf137f6a649</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/85d0ce553dd4c1b3adf38cf137f6a649.html">&lt;p&gt;Existing sentiment analysis models mainly rely on evident emotive words within phrases. When the apparent emotional words within phrases are eliminated, the performance of these models will inevitably decrease. The implicit communication of emotion without the use of explicit emotional phrases is highly widespread in several cultures. As a result, a classification model is required to learn the link between contexts and the emotions they trigger in an automatic way. Based on whether the … Cites: ‪Roberta: A robustly optimized bert pretraining approach. arXiv 2019‬&lt;/p&gt;</content><author><name>Y Qian, J Wang, D Li, X Zhang - Applied Intelligence, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Existing sentiment analysis models mainly rely on evident emotive words within phrases. When the apparent emotional words within phrases are eliminated, the performance of these models will inevitably decrease. The implicit communication of emotion without the use of explicit emotional phrases is highly widespread in several cultures. As a result, a classification model is required to learn the link between contexts and the emotions they trigger in an automatic way. Based on whether the … Cites: ‪Roberta: A robustly optimized bert pretraining approach. arXiv 2019‬</summary></entry><entry><title type="html">Graph Adaptive Semantic Transfer for Cross-domain Sentiment Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/882ad1b05bdb0187eead5437b0ccbb7d.html" rel="alternate" type="text/html" title="Graph Adaptive Semantic Transfer for Cross-domain Sentiment Classification" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/882ad1b05bdb0187eead5437b0ccbb7d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/882ad1b05bdb0187eead5437b0ccbb7d.html">&lt;p&gt;Cross-domain sentiment classification (CDSC) aims to use the transferable semantics learned from the source domain to predict the sentiment of reviews in the unlabeled target domain. Existing studies in this task attach more attention to the sequence modeling of sentences while largely ignoring the rich domain-invariant semantics embedded in graph structures (ie, the part-of-speech tags and dependency relations). As an important aspect of exploring characteristics of … Cites: ‪A Fast and Accurate Dependency Parser using Neural Networks‬&lt;/p&gt;</content><author><name>K Zhang, Q Liu, Z Huang, M Cheng, K Zhang, M Zhang… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Cross-domain sentiment classification (CDSC) aims to use the transferable semantics learned from the source domain to predict the sentiment of reviews in the unlabeled target domain. Existing studies in this task attach more attention to the sequence modeling of sentences while largely ignoring the rich domain-invariant semantics embedded in graph structures (ie, the part-of-speech tags and dependency relations). As an important aspect of exploring characteristics of … Cites: ‪A Fast and Accurate Dependency Parser using Neural Networks‬</summary></entry><entry><title type="html">An interdisciplinary review of the experimental evidence on how humans interact with machines</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/899c30920c16d71aa0db8dc7f04dff0f.html" rel="alternate" type="text/html" title="An interdisciplinary review of the experimental evidence on how humans interact with machines" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/899c30920c16d71aa0db8dc7f04dff0f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/899c30920c16d71aa0db8dc7f04dff0f.html">&lt;p&gt;Today, humans interact with automation frequently and in a variety of settings ranging from private to professional. Their behavior in these interactions has attracted considerable research interest across several fields, with sometimes little exchange among them and seemingly inconsistent findings. In this article, we review 138 experimental studies on how people interact with automated agents, that can assume different roles. We synthesize the evidence, suggest ways to reconcile … Cites: ‪  Why Should I Trust You? : Explaining the Predictions of Any …‬&lt;/p&gt;</content><author><name>M Chugunova, D Sele - Journal of Behavioral and Experimental Economics, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Today, humans interact with automation frequently and in a variety of settings ranging from private to professional. Their behavior in these interactions has attracted considerable research interest across several fields, with sometimes little exchange among them and seemingly inconsistent findings. In this article, we review 138 experimental studies on how people interact with automated agents, that can assume different roles. We synthesize the evidence, suggest ways to reconcile … Cites: ‪ Why Should I Trust You? : Explaining the Predictions of Any …‬</summary></entry><entry><title type="html">Robust and Efficient Medical Imaging with Self-Supervision</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/8e2bc5ef3a37e8eeef6c923b3871550c.html" rel="alternate" type="text/html" title="Robust and Efficient Medical Imaging with Self-Supervision" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/8e2bc5ef3a37e8eeef6c923b3871550c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/8e2bc5ef3a37e8eeef6c923b3871550c.html">&lt;p&gt;Recent progress in Medical Artificial Intelligence (AI) has delivered systems that can reach clinical expert level performance. However, such systems tend to demonstrate sub-optimal  out-of-distribution  performance when evaluated in clinical settings different from the training environment. A common mitigation strategy is to develop separate systems for each clinical setting using site-specific data [1]. However, this quickly becomes impractical as medical data is time-consuming to acquire and … Cites: ‪Robust fine-tuning of zero-shot models‬&lt;/p&gt;</content><author><name>S Azizi, L Culp, J Freyberg, B Mustafa, S Baur… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent progress in Medical Artificial Intelligence (AI) has delivered systems that can reach clinical expert level performance. However, such systems tend to demonstrate sub-optimal out-of-distribution performance when evaluated in clinical settings different from the training environment. A common mitigation strategy is to develop separate systems for each clinical setting using site-specific data [1]. However, this quickly becomes impractical as medical data is time-consuming to acquire and … Cites: ‪Robust fine-tuning of zero-shot models‬</summary></entry><entry><title type="html">Metrics of calibration for probabilistic predictions</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/8e5a8b5f84710209b0e26441aaf1df5b.html" rel="alternate" type="text/html" title="Metrics of calibration for probabilistic predictions" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/8e5a8b5f84710209b0e26441aaf1df5b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/8e5a8b5f84710209b0e26441aaf1df5b.html">&lt;p&gt;Predictions are often probabilities; eg, a prediction could be for precipitation tomorrow, but with only a 30% chance. Given such probabilistic predictions together with the actual outcomes,  reliability diagrams  help detect and diagnose statistically significant discrepancies–so-called  miscalibration –between the predictions and the outcomes. The canonical reliability diagrams histogram the observed and expected values of the predictions; replacing the hard histogram binning with soft … Cites: ‪Verified uncertainty calibration‬&lt;/p&gt;</content><author><name>I Arrieta-Ibarra, P Gujral, J Tannen, M Tygert, C Xu - arXiv preprint arXiv:2205.09680, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Predictions are often probabilities; eg, a prediction could be for precipitation tomorrow, but with only a 30% chance. Given such probabilistic predictions together with the actual outcomes, reliability diagrams help detect and diagnose statistically significant discrepancies–so-called miscalibration –between the predictions and the outcomes. The canonical reliability diagrams histogram the observed and expected values of the predictions; replacing the hard histogram binning with soft … Cites: ‪Verified uncertainty calibration‬</summary></entry><entry><title type="html">On the Limits of Evaluating Embodied Agent Model Generalization Using Validation Sets</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/919a03ab4866b66043d6ddf1b281dbca.html" rel="alternate" type="text/html" title="On the Limits of Evaluating Embodied Agent Model Generalization Using Validation Sets" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/919a03ab4866b66043d6ddf1b281dbca</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/919a03ab4866b66043d6ddf1b281dbca.html">&lt;p&gt;Natural language guided embodied task completion is a challenging problem since it requires understanding natural language instructions, aligning them with egocentric visual observations, and choosing appropriate actions to execute in the environment …&lt;/p&gt;</content><author><name>HKAP Di Jin, M Bansal, D Hakkani-Tur</name></author><category term="jekyll" /><category term="update" /><summary type="html">Natural language guided embodied task completion is a challenging problem since it requires understanding natural language instructions, aligning them with egocentric visual observations, and choosing appropriate actions to execute in the environment …</summary></entry><entry><title type="html">Personalized Prompts for Sequential Recommendation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/92427434da0975e13f29341c590cc39a.html" rel="alternate" type="text/html" title="Personalized Prompts for Sequential Recommendation" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/92427434da0975e13f29341c590cc39a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/92427434da0975e13f29341c590cc39a.html">&lt;p&gt;Pre-training models have shown their power in sequential recommendation. Recently, prompt has been widely explored and verified for tuning in NLP pre-training, which could help to more effectively and efficiently extract useful knowledge from pre-training models for downstream tasks, especially in cold-start scenarios. However, it is challenging to bring prompt-tuning from NLP to recommendation, since the tokens in recommendation (ie, items) do not have explicit explainable semantics … Cites: ‪How can we know what language models know?‬&lt;/p&gt;</content><author><name>Y Wu, R Xie, Y Zhu, F Zhuang, X Zhang, L Lin, Q He - arXiv preprint arXiv:2205.09666, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pre-training models have shown their power in sequential recommendation. Recently, prompt has been widely explored and verified for tuning in NLP pre-training, which could help to more effectively and efficiently extract useful knowledge from pre-training models for downstream tasks, especially in cold-start scenarios. However, it is challenging to bring prompt-tuning from NLP to recommendation, since the tokens in recommendation (ie, items) do not have explicit explainable semantics … Cites: ‪How can we know what language models know?‬</summary></entry><entry><title type="html">Quote Erat Demonstrandum: A Web Interface for Exploring the Quotebank Corpus</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/928450a5cccf28ebede78b8bfaaa5f05.html" rel="alternate" type="text/html" title="Quote Erat Demonstrandum: A Web Interface for Exploring the Quotebank Corpus" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/928450a5cccf28ebede78b8bfaaa5f05</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/928450a5cccf28ebede78b8bfaaa5f05.html">&lt;p&gt;The use of attributed quotes is the most direct and least filtered pathway of information propagation in news. Consequently, quotes play a central role in the conception, reception, and analysis of news stories. Since quotes provide a more direct window into a speaker s mind than regular reporting, they are a valuable resource for journalists and researchers alike. While substantial research efforts have been devoted to methods for the automated extraction of quotes from news and … Cites: ‪Context-based quotation recommendation‬&lt;/p&gt;</content><author><name>V Vuković, A Arora, HC Chang, A Spitz, R West - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The use of attributed quotes is the most direct and least filtered pathway of information propagation in news. Consequently, quotes play a central role in the conception, reception, and analysis of news stories. Since quotes provide a more direct window into a speaker s mind than regular reporting, they are a valuable resource for journalists and researchers alike. While substantial research efforts have been devoted to methods for the automated extraction of quotes from news and … Cites: ‪Context-based quotation recommendation‬</summary></entry><entry><title type="html">PLAID: An Efficient Engine for Late Interaction Retrieval</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9458c82d311651dde23f2b611694ec57.html" rel="alternate" type="text/html" title="PLAID: An Efficient Engine for Late Interaction Retrieval" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9458c82d311651dde23f2b611694ec57</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9458c82d311651dde23f2b611694ec57.html">&lt;p&gt;Pre-trained language models are increasingly important components across multiple information retrieval (IR) paradigms. Late interaction, introduced with the ColBERT model and recently refined in ColBERTv2, is a popular paradigm that holds state-of-the-art status across many benchmarks. To dramatically speed up the search latency of late interaction, we introduce the Performance-optimized Late Interaction Driver (PLAID). Without impacting quality, PLAID swiftly eliminates low-scoring passages … Cites: ‪Dense Passage Retrieval for Open-Domain Question Answering‬&lt;/p&gt;</content><author><name>K Santhanam, O Khattab, C Potts, M Zaharia - arXiv preprint arXiv:2205.09707, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pre-trained language models are increasingly important components across multiple information retrieval (IR) paradigms. Late interaction, introduced with the ColBERT model and recently refined in ColBERTv2, is a popular paradigm that holds state-of-the-art status across many benchmarks. To dramatically speed up the search latency of late interaction, we introduce the Performance-optimized Late Interaction Driver (PLAID). Without impacting quality, PLAID swiftly eliminates low-scoring passages … Cites: ‪Dense Passage Retrieval for Open-Domain Question Answering‬</summary></entry><entry><title type="html">Suspicious Sentence Detection and Claim Verification in the COVID-19 Domain</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/94ac692b4acd31de45b8418e59d3af2e.html" rel="alternate" type="text/html" title="Suspicious Sentence Detection and Claim Verification in the COVID-19 Domain" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/94ac692b4acd31de45b8418e59d3af2e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/94ac692b4acd31de45b8418e59d3af2e.html">&lt;p&gt;The processing, identification and fact checking of online information has received a lot of attention recently. One of the challenges is that scandalous or “blown up” news tend to become viral, even when coming from unreliable sources. Particularly during a global pandemic, it is crucial to find efficient ways of determining the credibility of information. Fact-checking initiatives such as Snopes, FactCheck. org etc., perform manual claim validation but they are unable to cover all suspicious claims that can … Cites: ‪Fact or fiction: Verifying scientific claims‬&lt;/p&gt;</content><author><name>E Pankovska, K Schulz, G Rehm - Proceedings of the Workshop Reducing Online …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The processing, identification and fact checking of online information has received a lot of attention recently. One of the challenges is that scandalous or “blown up” news tend to become viral, even when coming from unreliable sources. Particularly during a global pandemic, it is crucial to find efficient ways of determining the credibility of information. Fact-checking initiatives such as Snopes, FactCheck. org etc., perform manual claim validation but they are unable to cover all suspicious claims that can … Cites: ‪Fact or fiction: Verifying scientific claims‬</summary></entry><entry><title type="html">Relation Extraction with Weighted Contrastive Pre-training on Distant Supervision</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/95d5b8826540efab99d738dcaa261ab7.html" rel="alternate" type="text/html" title="Relation Extraction with Weighted Contrastive Pre-training on Distant Supervision" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/95d5b8826540efab99d738dcaa261ab7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/95d5b8826540efab99d738dcaa261ab7.html">&lt;p&gt;Contrastive pre-training on distant supervision has shown remarkable effectiveness for improving supervised relation extraction tasks. However, the existing methods ignore the intrinsic noise of distant supervision during the pre-training stage. In this paper, we propose a weighted contrastive learning method by leveraging the supervised data to estimate the reliability of pre-training instances and explicitly reduce the effect of noise. Experimental results on three supervised datasets … Cites: ‪A Frustratingly Easy Approach for Entity and Relation Extraction‬&lt;/p&gt;</content><author><name>Z Wan, F Cheng, Q Liu, Z Mao, H Song, S Kurohashi - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Contrastive pre-training on distant supervision has shown remarkable effectiveness for improving supervised relation extraction tasks. However, the existing methods ignore the intrinsic noise of distant supervision during the pre-training stage. In this paper, we propose a weighted contrastive learning method by leveraging the supervised data to estimate the reliability of pre-training instances and explicitly reduce the effect of noise. Experimental results on three supervised datasets … Cites: ‪A Frustratingly Easy Approach for Entity and Relation Extraction‬</summary></entry><entry><title type="html">Knowledge Guided Distance Supervision for Biomedical Relation Extraction in Chinese Electronic Medical Records</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9613c9ac135ed4bb1ba0c938faf7d70a.html" rel="alternate" type="text/html" title="Knowledge Guided Distance Supervision for Biomedical Relation Extraction in Chinese Electronic Medical Records" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9613c9ac135ed4bb1ba0c938faf7d70a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9613c9ac135ed4bb1ba0c938faf7d70a.html">&lt;p&gt;The goal of biomedical relation extraction is to obtain structured information from electronic medical records by identifying relations among clinical entities. By integrating the advantages of unsupervised and semi-supervised learning, the distant supervision approach has achieved significant success for a relation extraction task without a large amount of labeled corpora. However, in many cases, the recognized entities from the Chinese clinical text are not defined in semantic … Cites: ‪Document modeling with gated recurrent neural network for …‬&lt;/p&gt;</content><author><name>Q Zhao, D Xu, J Li, L Zhao, FA Rajput - Expert Systems with Applications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The goal of biomedical relation extraction is to obtain structured information from electronic medical records by identifying relations among clinical entities. By integrating the advantages of unsupervised and semi-supervised learning, the distant supervision approach has achieved significant success for a relation extraction task without a large amount of labeled corpora. However, in many cases, the recognized entities from the Chinese clinical text are not defined in semantic … Cites: ‪Document modeling with gated recurrent neural network for …‬</summary></entry><entry><title type="html">Bridging the Gap between Data Integration and ML Systems</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/974b38a9cc3562dd8d3dc68955380ed9.html" rel="alternate" type="text/html" title="Bridging the Gap between Data Integration and ML Systems" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/974b38a9cc3562dd8d3dc68955380ed9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/974b38a9cc3562dd8d3dc68955380ed9.html">&lt;p&gt;The data needed for machine learning (ML) model training and inference, can reside in different separate sites often termed data silos. For data-intensive ML applications, data silos present a major challenge: the integration and transformation of data, demand a lot of manual work and computational resources. Sometimes, data cannot leave the local store, and the model has to be trained in a decentralized manner. In this work, we propose three matrix-based dataset relationship representations, which … Cites: ‪Data integration: After the teenage years‬&lt;/p&gt;</content><author><name>R Hai, Y Kang, C Koutras, A Ionescu, A Katsifodimos - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The data needed for machine learning (ML) model training and inference, can reside in different separate sites often termed data silos. For data-intensive ML applications, data silos present a major challenge: the integration and transformation of data, demand a lot of manual work and computational resources. Sometimes, data cannot leave the local store, and the model has to be trained in a decentralized manner. In this work, we propose three matrix-based dataset relationship representations, which … Cites: ‪Data integration: After the teenage years‬</summary></entry><entry><title type="html">A Birds Eye View on Knowledge Graph Embeddings, Software Libraries, Applications and Challenges</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/977282534ba667f4718f42ba79727cdc.html" rel="alternate" type="text/html" title="A Birds Eye View on Knowledge Graph Embeddings, Software Libraries, Applications and Challenges" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/977282534ba667f4718f42ba79727cdc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/977282534ba667f4718f42ba79727cdc.html">&lt;p&gt;In recent years, Knowledge Graph (KG) development has attracted significant researches considering the applications in web search, relation prediction, natural language processing, information retrieval, question answering to name a few. However, often KGs are incomplete due to which Knowledge Graph Completion (KGC) has emerged as a sub-domain of research to automatically track down the missing connections in a KG. Numerous strategies have been suggested to work out … Cites: ‪Semantic parsing on freebase from question-answer pairs‬&lt;/p&gt;</content><author><name>S Garg, D Roy - arXiv preprint arXiv:2205.09088, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In recent years, Knowledge Graph (KG) development has attracted significant researches considering the applications in web search, relation prediction, natural language processing, information retrieval, question answering to name a few. However, often KGs are incomplete due to which Knowledge Graph Completion (KGC) has emerged as a sub-domain of research to automatically track down the missing connections in a KG. Numerous strategies have been suggested to work out … Cites: ‪Semantic parsing on freebase from question-answer pairs‬</summary></entry><entry><title type="html">Data Augmentation to Address Out-of-Vocabulary Problem in Low-Resource Sinhala-English Neural Machine Translation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/97a06a8a8bf2f7b19125dbb34eff64df.html" rel="alternate" type="text/html" title="Data Augmentation to Address Out-of-Vocabulary Problem in Low-Resource Sinhala-English Neural Machine Translation" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/97a06a8a8bf2f7b19125dbb34eff64df</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/97a06a8a8bf2f7b19125dbb34eff64df.html">&lt;p&gt;Out-of-Vocabulary (OOV) is a problem for Neural Machine Translation (NMT). OOV refers to words with a low occurrence in the training data, or to those that are absent from the training data. To alleviate this, word or phrase-based Data Augmentation (DA) techniques have been used. However, existing DA techniques have addressed only one of these OOV types and limit to considering either syntactic constraints or semantic constraints. We present a word and phrase replacement-based DA … Cites: ‪Neural machine translation with byte-level subwords‬&lt;/p&gt;</content><author><name>A Fernando, S Ranathunga - arXiv preprint arXiv:2205.08722, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Out-of-Vocabulary (OOV) is a problem for Neural Machine Translation (NMT). OOV refers to words with a low occurrence in the training data, or to those that are absent from the training data. To alleviate this, word or phrase-based Data Augmentation (DA) techniques have been used. However, existing DA techniques have addressed only one of these OOV types and limit to considering either syntactic constraints or semantic constraints. We present a word and phrase replacement-based DA … Cites: ‪Neural machine translation with byte-level subwords‬</summary></entry><entry><title type="html">Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/98053520cf4eed3dc799ac2d9d349f41.html" rel="alternate" type="text/html" title="Selection-Inference: Exploiting Large Language Models for Interpretable Logical Reasoning" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/98053520cf4eed3dc799ac2d9d349f41</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/98053520cf4eed3dc799ac2d9d349f41.html">&lt;p&gt;Large language models (LLMs) have been shown to be capable of impressive few-shot generalisation to new tasks. However, they still tend to perform poorly on multi-step logical reasoning problems. Here we carry out a comprehensive evaluation of LLMs on 50 tasks that probe different aspects of logical reasoning. We show that language models tend to perform fairly well at single step inference or entailment tasks, but struggle to chain together multiple reasoning steps to solve more complex … Cites: ‪Rethinking the Role of Demonstrations: What Makes In-Context …‬&lt;/p&gt;</content><author><name>A Creswell, M Shanahan, I Higgins - arXiv preprint arXiv:2205.09712, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Large language models (LLMs) have been shown to be capable of impressive few-shot generalisation to new tasks. However, they still tend to perform poorly on multi-step logical reasoning problems. Here we carry out a comprehensive evaluation of LLMs on 50 tasks that probe different aspects of logical reasoning. We show that language models tend to perform fairly well at single step inference or entailment tasks, but struggle to chain together multiple reasoning steps to solve more complex … Cites: ‪Rethinking the Role of Demonstrations: What Makes In-Context …‬</summary></entry><entry><title type="html">Twist Decoding: Diverse Generators Guide Each Other</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/98c3f49da132c918556daa0bc909a8b0.html" rel="alternate" type="text/html" title="Twist Decoding: Diverse Generators Guide Each Other" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/98c3f49da132c918556daa0bc909a8b0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/98c3f49da132c918556daa0bc909a8b0.html">&lt;p&gt;Natural language generation technology has recently seen remarkable progress with large-scale training, and many natural language applications are now built upon a wide range of generation models. Combining diverse models may lead to further …&lt;/p&gt;</content><author><name>J Kasai, K Sakaguchi, RL Bras, H Peng, X Lu, D Radev… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Natural language generation technology has recently seen remarkable progress with large-scale training, and many natural language applications are now built upon a wide range of generation models. Combining diverse models may lead to further …</summary></entry><entry><title type="html">Learning from Bootstrapping and Stepwise Reinforcement Reward: A Semi-Supervised Framework for Text Style Transfer</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9a9490d70af9279df6fe30c8880c5230.html" rel="alternate" type="text/html" title="Learning from Bootstrapping and Stepwise Reinforcement Reward: A Semi-Supervised Framework for Text Style Transfer" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9a9490d70af9279df6fe30c8880c5230</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9a9490d70af9279df6fe30c8880c5230.html">&lt;p&gt;Text style transfer is an important task in controllable language generation. Supervised approaches have pushed performance improvement on style-oriented rewriting such as formality conversion. However, challenges remain due to the scarcity of large-scale parallel data in many domains. While unsupervised approaches do not rely on annotated sentence pairs for each style, they are often plagued with instability issues such as mode collapse or quality degradation. To take … Cites: ‪On Learning Text Style Transfer with Direct Rewards‬&lt;/p&gt;</content><author><name>Z Liu, NF Chen - arXiv preprint arXiv:2205.09324, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Text style transfer is an important task in controllable language generation. Supervised approaches have pushed performance improvement on style-oriented rewriting such as formality conversion. However, challenges remain due to the scarcity of large-scale parallel data in many domains. While unsupervised approaches do not rely on annotated sentence pairs for each style, they are often plagued with instability issues such as mode collapse or quality degradation. To take … Cites: ‪On Learning Text Style Transfer with Direct Rewards‬</summary></entry><entry><title type="html">Towards a Theory of Faithfulness: Faithful Explanations of Differentiable Classifiers over Continuous Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9ade3de25fc22279e33932f1e27950e3.html" rel="alternate" type="text/html" title="Towards a Theory of Faithfulness: Faithful Explanations of Differentiable Classifiers over Continuous Data" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9ade3de25fc22279e33932f1e27950e3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9ade3de25fc22279e33932f1e27950e3.html">&lt;p&gt;There is broad agreement in the literature that explanation methods should be faithful to the model that they explain, but faithfulness remains a rather vague term. We revisit faithfulness in the context of continuous data and propose two formal definitions of faithfulness for feature attribution methods. Qualitative faithfulness demands that scores reflect the true qualitative effect (positive vs. negative) of the feature on the model and quanitative faithfulness that the magnitude of scores reflect … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬&lt;/p&gt;</content><author><name>N Potyka, X Yin, F Toni - arXiv preprint arXiv:2205.09620, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">There is broad agreement in the literature that explanation methods should be faithful to the model that they explain, but faithfulness remains a rather vague term. We revisit faithfulness in the context of continuous data and propose two formal definitions of faithfulness for feature attribution methods. Qualitative faithfulness demands that scores reflect the true qualitative effect (positive vs. negative) of the feature on the model and quanitative faithfulness that the magnitude of scores reflect … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬</summary></entry><entry><title type="html">Leveraging Transferability and Improved Beam Search in Textual Adversarial Attacks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9b2d8fc41016b00b16294541dc1a758c.html" rel="alternate" type="text/html" title="Leveraging Transferability and Improved Beam Search in Textual Adversarial Attacks" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9b2d8fc41016b00b16294541dc1a758c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9b2d8fc41016b00b16294541dc1a758c.html">&lt;p&gt;Adversarial attacks in NLP are difficult to ward off because of the discrete and highly abstract nature of human languages. Prior works utilize different word replacement strategies to generate semantic-preserving adversarial texts. These query-based methods, however, have limited exploration of the search space. To fully explore the search space, an improved beam search with multiple random perturbing positions is used. Besides, we use the transferable vulnerability from surrogate models to choose … Cites: ‪Deep contextualized word representations‬&lt;/p&gt;</content><author><name>B Zhu, Z Gu, Y Qian, F Lau, Z Tian - Neurocomputing, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Adversarial attacks in NLP are difficult to ward off because of the discrete and highly abstract nature of human languages. Prior works utilize different word replacement strategies to generate semantic-preserving adversarial texts. These query-based methods, however, have limited exploration of the search space. To fully explore the search space, an improved beam search with multiple random perturbing positions is used. Besides, we use the transferable vulnerability from surrogate models to choose … Cites: ‪Deep contextualized word representations‬</summary></entry><entry><title type="html">LogiGAN: Learning Logical Reasoning via Adversarial Pre-training</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9e75625751566946d29579866e449e27.html" rel="alternate" type="text/html" title="LogiGAN: Learning Logical Reasoning via Adversarial Pre-training" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9e75625751566946d29579866e449e27</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/9e75625751566946d29579866e449e27.html">&lt;p&gt;We present LogiGAN, an unsupervised adversarial pre-training framework for improving logical reasoning abilities of language models. Upon automatic identifying logical reasoning phenomena in massive text corpus via detection heuristics, we train language models to predict the masked-out logical statements. Inspired by the facilitation effect of reflective thinking in human learning, we analogically simulate the learning-thinking process with an adversarial Generator-Verifier architecture to assist … Cites: ‪Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis …‬&lt;/p&gt;</content><author><name>X Pi, W Zhong, Y Gao, N Duan, JG Lou - arXiv preprint arXiv:2205.08794, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present LogiGAN, an unsupervised adversarial pre-training framework for improving logical reasoning abilities of language models. Upon automatic identifying logical reasoning phenomena in massive text corpus via detection heuristics, we train language models to predict the masked-out logical statements. Inspired by the facilitation effect of reflective thinking in human learning, we analogically simulate the learning-thinking process with an adversarial Generator-Verifier architecture to assist … Cites: ‪Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis …‬</summary></entry><entry><title type="html">Who Goes First? Influences of Human-AI Workflow on Decision Making in Clinical Imaging</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a1028c5a63db78e5b97ed0b613f64464.html" rel="alternate" type="text/html" title="Who Goes First? Influences of Human-AI Workflow on Decision Making in Clinical Imaging" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a1028c5a63db78e5b97ed0b613f64464</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a1028c5a63db78e5b97ed0b613f64464.html">&lt;p&gt;Details of the designs and mechanisms in support of human-AI collaboration must be considered in the real-world fielding of AI technologies. A critical aspect of interaction design for AI-assisted human decision making are policies about the display and sequencing of AI inferences within larger decision-making workflows. We have a poor understanding of the influences of making AI inferences available before versus after human review of a diagnostic task at hand. We explore the effects of providing … Cites: ‪Does the whole exceed its parts? the effect of ai explanations on …‬&lt;/p&gt;</content><author><name>R Fogliato, S Chappidi, M Lungren, M Fitzke… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Details of the designs and mechanisms in support of human-AI collaboration must be considered in the real-world fielding of AI technologies. A critical aspect of interaction design for AI-assisted human decision making are policies about the display and sequencing of AI inferences within larger decision-making workflows. We have a poor understanding of the influences of making AI inferences available before versus after human review of a diagnostic task at hand. We explore the effects of providing … Cites: ‪Does the whole exceed its parts? the effect of ai explanations on …‬</summary></entry><entry><title type="html">FactPEGASUS: Factuality-Aware Pre-training and Fine-tuning for Abstractive Summarization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a1e5263e9a1cea9a15219e0876cdfdb4.html" rel="alternate" type="text/html" title="FactPEGASUS: Factuality-Aware Pre-training and Fine-tuning for Abstractive Summarization" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a1e5263e9a1cea9a15219e0876cdfdb4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a1e5263e9a1cea9a15219e0876cdfdb4.html">&lt;p&gt;We present FactPEGASUS, an abstractive summarization model that addresses the problem of factuality during pre-training and fine-tuning:(1) We augment the sentence selection strategy of PEGASUS s (Zhang et al., 2020) pre-training objective …&lt;/p&gt;</content><author><name>D Wan, M Bansal - arXiv preprint arXiv:2205.07830, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present FactPEGASUS, an abstractive summarization model that addresses the problem of factuality during pre-training and fine-tuning:(1) We augment the sentence selection strategy of PEGASUS s (Zhang et al., 2020) pre-training objective …</summary></entry><entry><title type="html">SNaC: Coherence Error Detection for Narrative Summarization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a32e50338f5331ef10978a0cd5d49ae3.html" rel="alternate" type="text/html" title="SNaC: Coherence Error Detection for Narrative Summarization" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a32e50338f5331ef10978a0cd5d49ae3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a32e50338f5331ef10978a0cd5d49ae3.html">&lt;p&gt;Progress in summarizing long texts is inhibited by the lack of appropriate evaluation frameworks. When a long summary must be produced to appropriately cover the facets of that text, that summary needs to present a coherent narrative to be understandable by a reader, but current automatic and human evaluation methods fail to identify gaps in coherence. In this work, we introduce SNaC, a narrative coherence evaluation framework rooted in fine-grained annotations for long … Cites: ‪Re-evaluating Evaluation in Text Summarization‬&lt;/p&gt;</content><author><name>T Goyal, JJ Li, G Durrett - arXiv preprint arXiv:2205.09641, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Progress in summarizing long texts is inhibited by the lack of appropriate evaluation frameworks. When a long summary must be produced to appropriately cover the facets of that text, that summary needs to present a coherent narrative to be understandable by a reader, but current automatic and human evaluation methods fail to identify gaps in coherence. In this work, we introduce SNaC, a narrative coherence evaluation framework rooted in fine-grained annotations for long … Cites: ‪Re-evaluating Evaluation in Text Summarization‬</summary></entry><entry><title type="html">Nebula-I: A General Framework for Collaboratively Training Deep Learning Models on Low-Bandwidth Cloud Clusters</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a3a4173b07f85d64efaf21eeb60e6b38.html" rel="alternate" type="text/html" title="Nebula-I: A General Framework for Collaboratively Training Deep Learning Models on Low-Bandwidth Cloud Clusters" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a3a4173b07f85d64efaf21eeb60e6b38</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a3a4173b07f85d64efaf21eeb60e6b38.html">&lt;p&gt;The ever-growing model size and scale of compute have attracted increasing interests in training deep learning models over multiple nodes. However, when it comes to training on cloud clusters, especially across remote clusters, huge challenges are faced. In this work, we introduce a general framework, Nebula-I, for collaboratively training deep learning models over remote heterogeneous clusters, the connections between which are low-bandwidth wide area networks (WANs). We … Cites: ‪Palm: Scaling language modeling with pathways‬&lt;/p&gt;</content><author><name>Y Xiang, Z Wu, W Gong, S Ding, X Mo, Y Liu, S Wang… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The ever-growing model size and scale of compute have attracted increasing interests in training deep learning models over multiple nodes. However, when it comes to training on cloud clusters, especially across remote clusters, huge challenges are faced. In this work, we introduce a general framework, Nebula-I, for collaboratively training deep learning models over remote heterogeneous clusters, the connections between which are low-bandwidth wide area networks (WANs). We … Cites: ‪Palm: Scaling language modeling with pathways‬</summary></entry><entry><title type="html">MultiJAF: Multi-modal Joint Entity Alignment Framework for Multi-modal Knowledge Graph</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a47cb55f5b6b2e95923a0f9235402585.html" rel="alternate" type="text/html" title="MultiJAF: Multi-modal Joint Entity Alignment Framework for Multi-modal Knowledge Graph" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a47cb55f5b6b2e95923a0f9235402585</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a47cb55f5b6b2e95923a0f9235402585.html">&lt;p&gt;Entity Alignment (EA) is a crucial task in knowledge fusion, which aims to link entities with the same real-world identity from different Knowledge Graphs (KGs). Existing methods have achieved satisfactory performance, however, they mainly focus on single modal KG, which is difficult to be effectively applied to multi-modal scenes. In this paper, we propose a Multi-modal Joint entity Alignment Framework (MultiJAF), which can effectively utilize the knowledge of various modalities. Concretely, we first … Cites: ‪Exploring and Evaluating Attributes, Values, and Structures for …‬&lt;/p&gt;</content><author><name>B Cheng, J Zhu, M Guo - Neurocomputing, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Entity Alignment (EA) is a crucial task in knowledge fusion, which aims to link entities with the same real-world identity from different Knowledge Graphs (KGs). Existing methods have achieved satisfactory performance, however, they mainly focus on single modal KG, which is difficult to be effectively applied to multi-modal scenes. In this paper, we propose a Multi-modal Joint entity Alignment Framework (MultiJAF), which can effectively utilize the knowledge of various modalities. Concretely, we first … Cites: ‪Exploring and Evaluating Attributes, Values, and Structures for …‬</summary></entry><entry><title type="html">Let s Talk! Striking Up Conversations via Conversational Visual Question Generation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a79d2705e94d6185d696dcaefe1c2375.html" rel="alternate" type="text/html" title="Let s Talk! Striking Up Conversations via Conversational Visual Question Generation" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a79d2705e94d6185d696dcaefe1c2375</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a79d2705e94d6185d696dcaefe1c2375.html">&lt;p&gt;An engaging and provocative question can open up a great conversation. In this work, we explore a novel scenario: a conversation agent views a set of the user s photos (for example, from social media platforms) and asks an engaging question to initiate a conversation with the user. The existing vision-to-question models mostly generate tedious and obvious questions, which might not be ideals conversation starters. This paper introduces a two-phase framework that first generates a visual … Cites: ‪Question generation for question answering‬&lt;/p&gt;</content><author><name>SH Chan, TL Yang, YW Chu, CY Hsu, TH Huang… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">An engaging and provocative question can open up a great conversation. In this work, we explore a novel scenario: a conversation agent views a set of the user s photos (for example, from social media platforms) and asks an engaging question to initiate a conversation with the user. The existing vision-to-question models mostly generate tedious and obvious questions, which might not be ideals conversation starters. This paper introduces a two-phase framework that first generates a visual … Cites: ‪Question generation for question answering‬</summary></entry><entry><title type="html">Homophily and Incentive Effects in Use of Algorithms</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a8a5598e3da34fb12547758a85a97340.html" rel="alternate" type="text/html" title="Homophily and Incentive Effects in Use of Algorithms" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a8a5598e3da34fb12547758a85a97340</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/a8a5598e3da34fb12547758a85a97340.html">&lt;p&gt;As algorithmic tools increasingly aid experts in making consequential decisions, the need to understand the precise factors that mediate their influence has grown commensurately. In this paper, we present a crowdsourcing vignette study designed to assess the impacts of two plausible factors on AI-informed decision-making. First, we examine homophily–do people defer more to models that tend to agree with them?–by manipulating the agreement during training between participants and the … Cites: ‪Does the whole exceed its parts? the effect of ai explanations on …‬&lt;/p&gt;</content><author><name>R Fogliato, S Fazelpour, S Gupta, Z Lipton, D Danks - arXiv preprint arXiv:2205.09701, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As algorithmic tools increasingly aid experts in making consequential decisions, the need to understand the precise factors that mediate their influence has grown commensurately. In this paper, we present a crowdsourcing vignette study designed to assess the impacts of two plausible factors on AI-informed decision-making. First, we examine homophily–do people defer more to models that tend to agree with them?–by manipulating the agreement during training between participants and the … Cites: ‪Does the whole exceed its parts? the effect of ai explanations on …‬</summary></entry><entry><title type="html">Learning heterogeneous graph embedding for Chinese legal document similarity</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/aa5c0bda0097e8542cb672c7c06bfa5a.html" rel="alternate" type="text/html" title="Learning heterogeneous graph embedding for Chinese legal document similarity" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/aa5c0bda0097e8542cb672c7c06bfa5a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/aa5c0bda0097e8542cb672c7c06bfa5a.html">&lt;p&gt;Measuring the similarity between legal documents to find prior documents from a massive collection that are similar to a current document is an essential component in legal assistant systems. This type of system can automatically link related legal documents to ensure that the same situations are treated identically in judicial practice. Most existing methodologies propose text-and citation-based methods to calculate the similarity between legal documents. However, those methods have … Cites: ‪Equality before the Law: Legal Judgment Consistency Analysis for …‬&lt;/p&gt;</content><author><name>S Bi, Z Ali, M Wang, T Wu, G Qi - Knowledge-Based Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Measuring the similarity between legal documents to find prior documents from a massive collection that are similar to a current document is an essential component in legal assistant systems. This type of system can automatically link related legal documents to ensure that the same situations are treated identically in judicial practice. Most existing methodologies propose text-and citation-based methods to calculate the similarity between legal documents. However, those methods have … Cites: ‪Equality before the Law: Legal Judgment Consistency Analysis for …‬</summary></entry><entry><title type="html">Graph convolutional network with multiple weight mechanisms for aspect-based sentiment analysis</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ac72096f18c073c44c6dbb848ccb97c2.html" rel="alternate" type="text/html" title="Graph convolutional network with multiple weight mechanisms for aspect-based sentiment analysis" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ac72096f18c073c44c6dbb848ccb97c2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ac72096f18c073c44c6dbb848ccb97c2.html">&lt;p&gt;Aspect-based sentiment analysis (ABSA) aims at determining the sentiment polarity of the given aspect term in a sentence. Recently, graph convolution network (GCN) has been used in the ABSA task and obtained promising results. Despite the proliferation of the methods and their success, prevailing models based on GCN lack a powerful constraint mechanism for the message passing to aspect terms, introducing heavy noise during graph convolution. Further, they simply average the … Cites: ‪Adaptive recursive neural network for target-dependent twitter …‬&lt;/p&gt;</content><author><name>Z Zhao, M Tang, W Tang, C Wang, X Chen - Neurocomputing, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Aspect-based sentiment analysis (ABSA) aims at determining the sentiment polarity of the given aspect term in a sentence. Recently, graph convolution network (GCN) has been used in the ABSA task and obtained promising results. Despite the proliferation of the methods and their success, prevailing models based on GCN lack a powerful constraint mechanism for the message passing to aspect terms, introducing heavy noise during graph convolution. Further, they simply average the … Cites: ‪Adaptive recursive neural network for target-dependent twitter …‬</summary></entry><entry><title type="html">Research on Collaborative Governance of Data Security in the Whole Life Cycle of Electric Power Manufacturing Data Space</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ad08725be69d042c4cbc4c5225731207.html" rel="alternate" type="text/html" title="Research on Collaborative Governance of Data Security in the Whole Life Cycle of Electric Power Manufacturing Data Space" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ad08725be69d042c4cbc4c5225731207</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ad08725be69d042c4cbc4c5225731207.html">&lt;p&gt;Data space is a technology system that allows data to be connected securely and efficiently. In the full life cycle of data space data, data collection, data storage, processing, transmission, exchange and destruction, and provision of services according to the dynamic changes of the subject s needs, is a brand-new data management model. This article first starts from the data security risk assessment of the data space of the electric power manufacturing industry, has analyzed the data … Cites: ‪Dataspaces: A new abstraction for information management‬&lt;/p&gt;</content><author><name>Y Liu, T Gao, D Niu, H Zhang - 2022 IEEE 25th International Conference on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Data space is a technology system that allows data to be connected securely and efficiently. In the full life cycle of data space data, data collection, data storage, processing, transmission, exchange and destruction, and provision of services according to the dynamic changes of the subject s needs, is a brand-new data management model. This article first starts from the data security risk assessment of the data space of the electric power manufacturing industry, has analyzed the data … Cites: ‪Dataspaces: A new abstraction for information management‬</summary></entry><entry><title type="html">Explaining Intelligent Agent s Future Motion on basis of Vocabulary Learning with Human Goal Inference</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b039046b11aad31df21d8c506b001ae9.html" rel="alternate" type="text/html" title="Explaining Intelligent Agent s Future Motion on basis of Vocabulary Learning with Human Goal Inference" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b039046b11aad31df21d8c506b001ae9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b039046b11aad31df21d8c506b001ae9.html">&lt;p&gt;Intelligent agents (IAs) that use machine learning for decision-making often lack the explainability about what they are going to do, which makes human-IA collaboration challenging. However, previous methods of explaining IA behavior require IA developers to predefine vocabulary that expresses motion, which is problematic as IA decision-making becomes complex. This paper proposes Manifestor, a method for explaining an IA s future motion with autonomous vocabulary learning. With … Cites: ‪Enabling Robots to Understand Incomplete Natural Language …‬&lt;/p&gt;</content><author><name>Y Fukuchi, M Osawa, H Yamakawa, M Imai - IEEE Access, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Intelligent agents (IAs) that use machine learning for decision-making often lack the explainability about what they are going to do, which makes human-IA collaboration challenging. However, previous methods of explaining IA behavior require IA developers to predefine vocabulary that expresses motion, which is problematic as IA decision-making becomes complex. This paper proposes Manifestor, a method for explaining an IA s future motion with autonomous vocabulary learning. With … Cites: ‪Enabling Robots to Understand Incomplete Natural Language …‬</summary></entry><entry><title type="html">Eine agentenbasierte Architektur für Programmierung mit gesprochener Sprache</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b2a0870db3a787de68654f5b308981fe.html" rel="alternate" type="text/html" title="Eine agentenbasierte Architektur für Programmierung mit gesprochener Sprache" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b2a0870db3a787de68654f5b308981fe</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b2a0870db3a787de68654f5b308981fe.html">&lt;p&gt;Das in dieser Arbeit beschriebene System ProNat ermöglicht Endnutzer-Programmierung mit gesprochener Sprache. Es befähigt Laien, Programme für unterschiedliche Zielsysteme mit alltäglicher Sprache zu beschreiben und deren Funktionalität zu erweitern. ProNat basiert auf PARSE, einer eigens entworfenen, agentenbasierten Rahmenarchitektur. In drei unabhängigen Untersuchungen konnte gezeigt werden, dass ProNat grundsätzlich in der Lage ist, Programme aus … Cites: ‪Disfluency detection with a semi-markov model and prosodic …‬&lt;/p&gt;</content><author><name>S Weigelt - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Das in dieser Arbeit beschriebene System ProNat ermöglicht Endnutzer-Programmierung mit gesprochener Sprache. Es befähigt Laien, Programme für unterschiedliche Zielsysteme mit alltäglicher Sprache zu beschreiben und deren Funktionalität zu erweitern. ProNat basiert auf PARSE, einer eigens entworfenen, agentenbasierten Rahmenarchitektur. In drei unabhängigen Untersuchungen konnte gezeigt werden, dass ProNat grundsätzlich in der Lage ist, Programme aus … Cites: ‪Disfluency detection with a semi-markov model and prosodic …‬</summary></entry><entry><title type="html">Exploiting Social Media Content for Self-Supervised Style Transfer</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b72efb4eec869f03e302b51981845d79.html" rel="alternate" type="text/html" title="Exploiting Social Media Content for Self-Supervised Style Transfer" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b72efb4eec869f03e302b51981845d79</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b72efb4eec869f03e302b51981845d79.html">&lt;p&gt;Recent research on style transfer takes inspiration from unsupervised neural machine translation (UNMT), learning from large amounts of non-parallel data by exploiting cycle consistency loss, back-translation, and denoising autoencoders. By contrast, the use of self-supervised NMT (SSNMT), which leverages (near) parallel instances hidden in non-parallel data more efficiently than UNMT, has not yet been explored for style transfer. In this paper we present a novel Self-Supervised Style … Cites: ‪A Probabilistic Formulation of Unsupervised Text Style Transfer‬&lt;/p&gt;</content><author><name>D Ruiter, T Kleinbauer, C España-Bonet… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent research on style transfer takes inspiration from unsupervised neural machine translation (UNMT), learning from large amounts of non-parallel data by exploiting cycle consistency loss, back-translation, and denoising autoencoders. By contrast, the use of self-supervised NMT (SSNMT), which leverages (near) parallel instances hidden in non-parallel data more efficiently than UNMT, has not yet been explored for style transfer. In this paper we present a novel Self-Supervised Style … Cites: ‪A Probabilistic Formulation of Unsupervised Text Style Transfer‬</summary></entry><entry><title type="html">Caveat emptor: On the Need for Baseline Quality Standards in Computer Vision Wood Identification. Forests 2022, 13, 632</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b801b49e3d9841e8d6fd58e52d34f451.html" rel="alternate" type="text/html" title="Caveat emptor: On the Need for Baseline Quality Standards in Computer Vision Wood Identification. Forests 2022, 13, 632" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b801b49e3d9841e8d6fd58e52d34f451</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b801b49e3d9841e8d6fd58e52d34f451.html">&lt;p&gt;Computer vision wood identification (CVWID) has focused on laboratory studies reporting consistently high model accuracies with greatly varying input data quality, data hygiene, and wood identification expertise. Employing examples from published literature, we demonstrate that the highly optimistic model performance in prior works may be attributed to evaluating the wrong functionality—wood specimen identification rather than the desired wood species or genus identification—using … Cites: ‪The unreasonable effectiveness of data‬&lt;/p&gt;</content><author><name>P Ravindran, AC Wiedenhoeft - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Computer vision wood identification (CVWID) has focused on laboratory studies reporting consistently high model accuracies with greatly varying input data quality, data hygiene, and wood identification expertise. Employing examples from published literature, we demonstrate that the highly optimistic model performance in prior works may be attributed to evaluating the wrong functionality—wood specimen identification rather than the desired wood species or genus identification—using … Cites: ‪The unreasonable effectiveness of data‬</summary></entry><entry><title type="html">TTAPS: Test-Time Adaption by Aligning Prototypes using Self-Supervision</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b86fefccd59a705d5eb35535748d617b.html" rel="alternate" type="text/html" title="TTAPS: Test-Time Adaption by Aligning Prototypes using Self-Supervision" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b86fefccd59a705d5eb35535748d617b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b86fefccd59a705d5eb35535748d617b.html">&lt;p&gt;Nowadays, deep neural networks outperform humans in many tasks. However, if the input distribution drifts away from the one used in training, their performance drops significantly. Recently published research has shown that adapting the model parameters to the test sample can mitigate this performance degradation. In this paper, we therefore propose a novel modification of the self-supervised training algorithm SwAV that adds the ability to adapt to single test samples. Using the … Cites: ‪Improving out-of-distribution generalization via multi-task self …‬&lt;/p&gt;</content><author><name>A Bartler, F Bender, F Wiewel, B Yang - arXiv preprint arXiv:2205.08731, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Nowadays, deep neural networks outperform humans in many tasks. However, if the input distribution drifts away from the one used in training, their performance drops significantly. Recently published research has shown that adapting the model parameters to the test sample can mitigate this performance degradation. In this paper, we therefore propose a novel modification of the self-supervised training algorithm SwAV that adds the ability to adapt to single test samples. Using the … Cites: ‪Improving out-of-distribution generalization via multi-task self …‬</summary></entry><entry><title type="html">Community social capital or health needs: What is driving hospital-community partnerships to address social determinants of health?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b87c37667b249313685001f3a14dafb4.html" rel="alternate" type="text/html" title="Community social capital or health needs: What is driving hospital-community partnerships to address social determinants of health?" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b87c37667b249313685001f3a14dafb4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b87c37667b249313685001f3a14dafb4.html">&lt;p&gt;Social determinants of health (SDOH) are strongly linked to individual and population health outcomes. Hospitals and health systems are in a unique position to initiate or partner on community-wide efforts address SDOH. However, such efforts typically require collaboration with other healthcare and local community organizations since SDOH affect more than just medical care. Despite studies that have identified specific organizational and environmental factors associated with … Cites: ‪COVID-19 growth rate decreases with social capital‬&lt;/p&gt;</content><author><name>N Puro, RJ Kelly - SSM-Population Health, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Social determinants of health (SDOH) are strongly linked to individual and population health outcomes. Hospitals and health systems are in a unique position to initiate or partner on community-wide efforts address SDOH. However, such efforts typically require collaboration with other healthcare and local community organizations since SDOH affect more than just medical care. Despite studies that have identified specific organizational and environmental factors associated with … Cites: ‪COVID-19 growth rate decreases with social capital‬</summary></entry><entry><title type="html">Fully Automatic MRI Brain Tumor Segmentation Using Efficient Spatial Attention Convolutional Networks with Composite Loss</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b8dcdf16d23b4a084b0e84d4eaf62f82.html" rel="alternate" type="text/html" title="Fully Automatic MRI Brain Tumor Segmentation Using Efficient Spatial Attention Convolutional Networks with Composite Loss" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b8dcdf16d23b4a084b0e84d4eaf62f82</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/b8dcdf16d23b4a084b0e84d4eaf62f82.html">&lt;p&gt;Automatically segmenting tumors from brain magnetic resonance imaging scans is crucial for diagnosis and planning treatment. However, brain tumors are highly diverse in location, contrast, size, and shape, making automatic segmentation extremely challenging. Recent techniques for segmenting brain tumors are mostly built using convolutional neural networks (CNNs). However, most of these existing techniques are inefficient, having slow inference speed and high parameter count … Cites: ‪Espnet: Efficient spatial pyramid of dilated convolutions for …‬&lt;/p&gt;</content><author><name>I Mazumdar, J Mukherjee - Neurocomputing, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Automatically segmenting tumors from brain magnetic resonance imaging scans is crucial for diagnosis and planning treatment. However, brain tumors are highly diverse in location, contrast, size, and shape, making automatic segmentation extremely challenging. Recent techniques for segmenting brain tumors are mostly built using convolutional neural networks (CNNs). However, most of these existing techniques are inefficient, having slow inference speed and high parameter count … Cites: ‪Espnet: Efficient spatial pyramid of dilated convolutions for …‬</summary></entry><entry><title type="html">TransTab: Learning Transferable Tabular Transformers Across Tables</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/bac03533c47922c53ffce7e3c266b81a.html" rel="alternate" type="text/html" title="TransTab: Learning Transferable Tabular Transformers Across Tables" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/bac03533c47922c53ffce7e3c266b81a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/bac03533c47922c53ffce7e3c266b81a.html">&lt;p&gt;Tabular data (or tables) are the most widely used data format in machine learning (ML). However, ML models often assume the table structure keeps fixed in training and testing. Before ML modeling, heavy data cleaning is required to merge disparate tables with different columns. This preprocessing often incurs significant data waste (eg, removing unmatched columns and samples). How to learn ML models from multiple tables with partially overlapping columns? How to incrementally update ML … Cites: ‪TaBERT: Pretraining for Joint Understanding of Textual and …‬&lt;/p&gt;</content><author><name>Z Wang, J Sun - arXiv preprint arXiv:2205.09328, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Tabular data (or tables) are the most widely used data format in machine learning (ML). However, ML models often assume the table structure keeps fixed in training and testing. Before ML modeling, heavy data cleaning is required to merge disparate tables with different columns. This preprocessing often incurs significant data waste (eg, removing unmatched columns and samples). How to learn ML models from multiple tables with partially overlapping columns? How to incrementally update ML … Cites: ‪TaBERT: Pretraining for Joint Understanding of Textual and …‬</summary></entry><entry><title type="html">Rakshak: A Child Identification Software for Recognizing Missing Children Using Machine Learning-Based Speech Clarification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/bd0c6c8462f4f5873f1f34a5defcb20f.html" rel="alternate" type="text/html" title="Rakshak: A Child Identification Software for Recognizing Missing Children Using Machine Learning-Based Speech Clarification" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/bd0c6c8462f4f5873f1f34a5defcb20f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/bd0c6c8462f4f5873f1f34a5defcb20f.html">&lt;p&gt;Almost every country in the world is facing the issue of child trafficking. Besides abduction, children below 10 years sometimes get missed from their homes or other locations due to many reasons. following the criminal record, many of the abducted or missed children got received by police officials where majorly officials face difficulty to get correct information as the founded children are not in their normal state in general due to fear factor or less trust. It is also observed that such children … Cites: ‪Wronging a right: Generating better errors to improve grammatical …‬&lt;/p&gt;</content><author><name>A Dixit, P Sethi, P Garg - … Journal of Knowledge-Based Organizations (IJKBO), 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Almost every country in the world is facing the issue of child trafficking. Besides abduction, children below 10 years sometimes get missed from their homes or other locations due to many reasons. following the criminal record, many of the abducted or missed children got received by police officials where majorly officials face difficulty to get correct information as the founded children are not in their normal state in general due to fear factor or less trust. It is also observed that such children … Cites: ‪Wronging a right: Generating better errors to improve grammatical …‬</summary></entry><entry><title type="html">Construction of real-time manufacturing industry production activity estimation models using high-frequency electricity demand data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/be740500f369c912e1cf130ee287c303.html" rel="alternate" type="text/html" title="Construction of real-time manufacturing industry production activity estimation models using high-frequency electricity demand data" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/be740500f369c912e1cf130ee287c303</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/be740500f369c912e1cf130ee287c303.html">&lt;p&gt;In this paper we describe how we estimated production activity in the manufacturing industry in Japan by analyzing the characteristics of fluctuations in the high-frequency electricity demand data published by major Japanese electric power companies, on the basis that the manufacturing industry consumes electricity when carrying out production activity. We constructed mathematical models to estimate production activity in each area of Japan on the basis of electricity data provided by … Cites: ‪Using social media to measure labor market flows‬&lt;/p&gt;</content><author><name>Y Suimon, H Tanabe - 2022 IEEE Symposium on Computational Intelligence …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper we describe how we estimated production activity in the manufacturing industry in Japan by analyzing the characteristics of fluctuations in the high-frequency electricity demand data published by major Japanese electric power companies, on the basis that the manufacturing industry consumes electricity when carrying out production activity. We constructed mathematical models to estimate production activity in each area of Japan on the basis of electricity data provided by … Cites: ‪Using social media to measure labor market flows‬</summary></entry><entry><title type="html">RankGen: Improving Text Generation with Large Ranking Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/bf1a3050282d9907d4d4afb4ade4a338.html" rel="alternate" type="text/html" title="RankGen: Improving Text Generation with Large Ranking Models" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/bf1a3050282d9907d4d4afb4ade4a338</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/bf1a3050282d9907d4d4afb4ade4a338.html">&lt;p&gt;Given an input sequence (or prefix), modern language models often assign high probabilities to output sequences that are repetitive, incoherent, or irrelevant to the prefix; as such, model-generated text also contains such artifacts. To address these …&lt;/p&gt;</content><author><name>K Krishna, Y Chang, J Wieting, M Iyyer - arXiv preprint arXiv:2205.09726, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Given an input sequence (or prefix), modern language models often assign high probabilities to output sequences that are repetitive, incoherent, or irrelevant to the prefix; as such, model-generated text also contains such artifacts. To address these …</summary></entry><entry><title type="html">Vector Representations of Idioms in Data-Driven Chatbots for Robust Assistance</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/bf2caf80daa1ea16c7a8882a4a228927.html" rel="alternate" type="text/html" title="Vector Representations of Idioms in Data-Driven Chatbots for Robust Assistance" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/bf2caf80daa1ea16c7a8882a4a228927</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/bf2caf80daa1ea16c7a8882a4a228927.html">&lt;p&gt;This thesis presents resources capable of enhancing solutions of some Natural Language Processing (NLP) tasks, demonstrates the learning of abstractions by deep models through cross-lingual transferability, and shows how deep learning models trained on idioms can enhance open-domain conversational systems. The challenges of open-domain conversational systems are many and include bland repetitive utterances, lack of utterance diversity, lack of training data for low-resource … Cites: ‪Dissecting contextual word embeddings: Architecture and …‬&lt;/p&gt;</content><author><name>O Adewumi - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This thesis presents resources capable of enhancing solutions of some Natural Language Processing (NLP) tasks, demonstrates the learning of abstractions by deep models through cross-lingual transferability, and shows how deep learning models trained on idioms can enhance open-domain conversational systems. The challenges of open-domain conversational systems are many and include bland repetitive utterances, lack of utterance diversity, lack of training data for low-resource … Cites: ‪Dissecting contextual word embeddings: Architecture and …‬</summary></entry><entry><title type="html">uSystolic: Byte-Crawling Unary Systolic Array</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c01b1878ae2db4ae513f229db40d5795.html" rel="alternate" type="text/html" title="uSystolic: Byte-Crawling Unary Systolic Array" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c01b1878ae2db4ae513f229db40d5795</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c01b1878ae2db4ae513f229db40d5795.html">&lt;p&gt;General matrix multiply (GEMM) is an important operation in broad applications, especially the thriving deep neural networks. To achieve low power consumption for GEMM, researchers have already leveraged unary computing, which manipulates bitstreams with extremely simple logic. However, existing unary architectures are not well generalizable to varying GEMM configurations in versatile applications and incompatible to the binary computing stack, imposing challenges to execute unary … Cites: ‪Regularized evolution for image classifier architecture search‬&lt;/p&gt;</content><author><name>D Wu, J San Miguel - 2022 IEEE International Symposium on High …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">General matrix multiply (GEMM) is an important operation in broad applications, especially the thriving deep neural networks. To achieve low power consumption for GEMM, researchers have already leveraged unary computing, which manipulates bitstreams with extremely simple logic. However, existing unary architectures are not well generalizable to varying GEMM configurations in versatile applications and incompatible to the binary computing stack, imposing challenges to execute unary … Cites: ‪Regularized evolution for image classifier architecture search‬</summary></entry><entry><title type="html">Diverse Weight Averaging for Out-of-Distribution Generalization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c092b05642069c8911d691c1499074d0.html" rel="alternate" type="text/html" title="Diverse Weight Averaging for Out-of-Distribution Generalization" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c092b05642069c8911d691c1499074d0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c092b05642069c8911d691c1499074d0.html">&lt;p&gt;Standard neural networks struggle to generalize under distribution shifts. For out-of-distribution generalization in computer vision, the best current approach averages the weights along a training run. In this paper, we propose Diverse Weight Averaging (DiWA) that makes a simple change to this strategy: DiWA averages the weights obtained from several independent training runs rather than from a single run. Perhaps surprisingly, averaging these weights performs well under soft constraints … Cites: ‪Fine-tuning can distort pretrained features and underperform out-of …‬&lt;/p&gt;</content><author><name>A Rame, M Kirchmeyer, T Rahier, A Rakotomamonjy… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Standard neural networks struggle to generalize under distribution shifts. For out-of-distribution generalization in computer vision, the best current approach averages the weights along a training run. In this paper, we propose Diverse Weight Averaging (DiWA) that makes a simple change to this strategy: DiWA averages the weights obtained from several independent training runs rather than from a single run. Perhaps surprisingly, averaging these weights performs well under soft constraints … Cites: ‪Fine-tuning can distort pretrained features and underperform out-of …‬</summary></entry><entry><title type="html">Subchondral tibial bone texture of conventional X-rays predicts total knee arthroplasty</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c09478da0c6aed669051d2853ed3f4a8.html" rel="alternate" type="text/html" title="Subchondral tibial bone texture of conventional X-rays predicts total knee arthroplasty" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c09478da0c6aed669051d2853ed3f4a8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c09478da0c6aed669051d2853ed3f4a8.html">&lt;p&gt;Lacking disease-modifying osteoarthritis drugs (DMOADs) for knee osteoarthritis (KOA), Total Knee Arthroplasty (TKA) is often considered an important clinical outcome. Thus, it is important to determine the most relevant factors that are associated with the risk of TKA. The present study aims to develop a model based on a combination of X-ray trabecular bone texture (TBT) analysis, and clinical and radiological information to predict TKA risk in patients with or at risk of developing … Cites: ‪Prediction of total knee replacement and diagnosis of osteoarthritis …‬&lt;/p&gt;</content><author><name>A Almhdie-Imjabbar, H Toumi, K Harrar, A Pinti… - Scientific Reports, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Lacking disease-modifying osteoarthritis drugs (DMOADs) for knee osteoarthritis (KOA), Total Knee Arthroplasty (TKA) is often considered an important clinical outcome. Thus, it is important to determine the most relevant factors that are associated with the risk of TKA. The present study aims to develop a model based on a combination of X-ray trabecular bone texture (TBT) analysis, and clinical and radiological information to predict TKA risk in patients with or at risk of developing … Cites: ‪Prediction of total knee replacement and diagnosis of osteoarthritis …‬</summary></entry><entry><title type="html">A review of visualisation-as-explanation techniques for convolutional neural networks and their evaluation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c1d70c1e5b9708fa5ef51f508ad0b96e.html" rel="alternate" type="text/html" title="A review of visualisation-as-explanation techniques for convolutional neural networks and their evaluation" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c1d70c1e5b9708fa5ef51f508ad0b96e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c1d70c1e5b9708fa5ef51f508ad0b96e.html">&lt;p&gt;Visualisation techniques are powerful tools to understand the behaviour of Artificial Intelligence (AI) systems. They can be used to identify important features contributing to the network decisions, investigate biases in datasets, and find weaknesses in the system s structure (eg, network architectures). Lawmakers and regulators may not allow the use of smart systems if these systems cannot explain the logic underlying a decision or action taken. These systems are required to offer a high level … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬&lt;/p&gt;</content><author><name>E Mohamed, K Sirlantzis, G Howells - Displays, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Visualisation techniques are powerful tools to understand the behaviour of Artificial Intelligence (AI) systems. They can be used to identify important features contributing to the network decisions, investigate biases in datasets, and find weaknesses in the system s structure (eg, network architectures). Lawmakers and regulators may not allow the use of smart systems if these systems cannot explain the logic underlying a decision or action taken. These systems are required to offer a high level … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬</summary></entry><entry><title type="html">Dialog state tracking for assistant systems</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c23fcf52c455d7fea154ccf95f8c0121.html" rel="alternate" type="text/html" title="Dialog state tracking for assistant systems" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c23fcf52c455d7fea154ccf95f8c0121</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c23fcf52c455d7fea154ccf95f8c0121.html">&lt;p&gt;In one embodiment, a method includes, by one or more computing systems, receiving, from a client system, an input in a multi-turn message thread, parsing the input to identify a plurality of hypothesis dialog states associated with the input, generating a plurality of functions corresponding to the plurality of hypothesis dialog states, calculating a plurality of probability scores for the plurality of functions, respectively, based on a prior dialog state associated with the message thread and a … Cites: ‪Joint semantic utterance classification and slot filling with recursive …‬&lt;/p&gt;</content><author><name>PA Crook, B Liu, R Subba - US Patent 11,336,602, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In one embodiment, a method includes, by one or more computing systems, receiving, from a client system, an input in a multi-turn message thread, parsing the input to identify a plurality of hypothesis dialog states associated with the input, generating a plurality of functions corresponding to the plurality of hypothesis dialog states, calculating a plurality of probability scores for the plurality of functions, respectively, based on a prior dialog state associated with the message thread and a … Cites: ‪Joint semantic utterance classification and slot filling with recursive …‬</summary></entry><entry><title type="html">A systematic review of federated learning applications for biomedical data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c460a6db74a57983022dcb9e030f3a5d.html" rel="alternate" type="text/html" title="A systematic review of federated learning applications for biomedical data" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c460a6db74a57983022dcb9e030f3a5d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c460a6db74a57983022dcb9e030f3a5d.html">&lt;p&gt;Objectives Federated learning (FL) allows multiple institutions to collaboratively develop a machine learning algorithm without sharing their data. Organizations instead share model parameters only, allowing them to benefit from a model built with a larger dataset while maintaining the privacy of their own data. We conducted a systematic review to evaluate the current state of FL in healthcare and discuss the limitations and promise of this technology. Methods We conducted a literature search … Cites: ‪Deep learning-enabled medical computer vision‬&lt;/p&gt;</content><author><name>MG Crowson, D Moukheiber, AR Arévalo, BD Lam… - PLOS Digital Health, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Objectives Federated learning (FL) allows multiple institutions to collaboratively develop a machine learning algorithm without sharing their data. Organizations instead share model parameters only, allowing them to benefit from a model built with a larger dataset while maintaining the privacy of their own data. We conducted a systematic review to evaluate the current state of FL in healthcare and discuss the limitations and promise of this technology. Methods We conducted a literature search … Cites: ‪Deep learning-enabled medical computer vision‬</summary></entry><entry><title type="html">Prompt Tuning for Discriminative Pre-trained Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c5f645f4fafc0be1dfa4ee7cd699bf11.html" rel="alternate" type="text/html" title="Prompt Tuning for Discriminative Pre-trained Language Models" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c5f645f4fafc0be1dfa4ee7cd699bf11</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c5f645f4fafc0be1dfa4ee7cd699bf11.html">&lt;p&gt;Recent works have shown promising results of prompt tuning in stimulating pre-trained language models (PLMs) for natural language processing (NLP) tasks. However, to the best of our knowledge, existing works focus on prompt-tuning …&lt;/p&gt;</content><author><name>Y Yao, B Dong, A Zhang, Z Zhang, R Xie, Z Liu, L Lin… - Findings of the Association …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent works have shown promising results of prompt tuning in stimulating pre-trained language models (PLMs) for natural language processing (NLP) tasks. However, to the best of our knowledge, existing works focus on prompt-tuning …</summary></entry><entry><title type="html">Architecture Design of Intelligent Management System for Multi-value Chain Collaborative Data Space</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c5f82368940bb42e5adec2c98cc925d6.html" rel="alternate" type="text/html" title="Architecture Design of Intelligent Management System for Multi-value Chain Collaborative Data Space" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c5f82368940bb42e5adec2c98cc925d6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c5f82368940bb42e5adec2c98cc925d6.html">&lt;p&gt;With the in-depth development of information technology, in order to solve the problems of data collaboration barriers, poor knowledge mining effect and management optimization performance in the process of multi-value chain collaboration in manufacturing industry. At the same time, it realizes the wisdom synchronization of data flow, two-way transmission of information flow, cognitive sharing of knowledge flow, optimized scheduling of business flow and value-added … Cites: ‪Dataspaces: A new abstraction for information management‬&lt;/p&gt;</content><author><name>J Wang, Z Liu, X Yang, J Han - 2022 IEEE 25th International Conference on …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">With the in-depth development of information technology, in order to solve the problems of data collaboration barriers, poor knowledge mining effect and management optimization performance in the process of multi-value chain collaboration in manufacturing industry. At the same time, it realizes the wisdom synchronization of data flow, two-way transmission of information flow, cognitive sharing of knowledge flow, optimized scheduling of business flow and value-added … Cites: ‪Dataspaces: A new abstraction for information management‬</summary></entry><entry><title type="html">Foundation Posteriors for Approximate Probabilistic Inference</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c7a892be4e171eddb5e0d1202d5d4a49.html" rel="alternate" type="text/html" title="Foundation Posteriors for Approximate Probabilistic Inference" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c7a892be4e171eddb5e0d1202d5d4a49</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/c7a892be4e171eddb5e0d1202d5d4a49.html">&lt;p&gt;Probabilistic programs provide an expressive representation language for generative models. Given a probabilistic program, we are interested in the task of posterior inference: estimating a latent variable given a set of observed variables. Existing techniques for inference in probabilistic programs often require choosing many hyper-parameters, are computationally expensive, and/or only work for restricted classes of programs. Here we formulate inference as masked language modeling: given a … Cites: ‪Codebert: A pre-trained model for programming and natural …‬&lt;/p&gt;</content><author><name>M Wu, N Goodman - arXiv preprint arXiv:2205.09735, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Probabilistic programs provide an expressive representation language for generative models. Given a probabilistic program, we are interested in the task of posterior inference: estimating a latent variable given a set of observed variables. Existing techniques for inference in probabilistic programs often require choosing many hyper-parameters, are computationally expensive, and/or only work for restricted classes of programs. Here we formulate inference as masked language modeling: given a … Cites: ‪Codebert: A pre-trained model for programming and natural …‬</summary></entry><entry><title type="html">A Knowledge Graph-Based Abstractive Model Integrating Semantic and Structural Information for Summarizing Chinese Meetings</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ca346f89a0ded0b634325b564e67c850.html" rel="alternate" type="text/html" title="A Knowledge Graph-Based Abstractive Model Integrating Semantic and Structural Information for Summarizing Chinese Meetings" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ca346f89a0ded0b634325b564e67c850</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ca346f89a0ded0b634325b564e67c850.html">&lt;p&gt;With the rapid increase of users, online meeting platforms have accumulated massive meeting transcripts. However, it is still a challenge for users to quickly master the chief information and manage the meetings, despite there are already some useful text summarization models. In this paper, a Knowledge Graph-based Meeting Summarization Framework is proposed to tackle this challenge. First, a two-layers meeting domain Knowledge Graph is developed to integrate more information … Cites: ‪Text generation from knowledge graphs with graph transformers‬&lt;/p&gt;</content><author><name>P Qi, Z Huang, Y Sun, H Luo - 2022 IEEE 25th International Conference on Computer …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">With the rapid increase of users, online meeting platforms have accumulated massive meeting transcripts. However, it is still a challenge for users to quickly master the chief information and manage the meetings, despite there are already some useful text summarization models. In this paper, a Knowledge Graph-based Meeting Summarization Framework is proposed to tackle this challenge. First, a two-layers meeting domain Knowledge Graph is developed to integrate more information … Cites: ‪Text generation from knowledge graphs with graph transformers‬</summary></entry><entry><title type="html">Generic and Trend-aware Curriculum Learning for Relation Extraction in Graph Neural Networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ccbf7cf17b95ac87835468ddca40f91f.html" rel="alternate" type="text/html" title="Generic and Trend-aware Curriculum Learning for Relation Extraction in Graph Neural Networks" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ccbf7cf17b95ac87835468ddca40f91f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ccbf7cf17b95ac87835468ddca40f91f.html">&lt;p&gt;We present a generic and trend-aware curriculum learning approach for graph neural networks. It extends existing approaches by incorporating sample-level loss trends to better discriminate easier from harder samples and schedule them for training. The model effectively integrates textual and structural information for relation extraction in text graphs. Experimental results show that the model provides robust estimations of sample difficulty and shows sizable improvement over the state-of-the … Cites: ‪Cross-sentence n-ary relation extraction with graph lstms‬&lt;/p&gt;</content><author><name>N Vakil, H Amiri - arXiv preprint arXiv:2205.08625, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present a generic and trend-aware curriculum learning approach for graph neural networks. It extends existing approaches by incorporating sample-level loss trends to better discriminate easier from harder samples and schedule them for training. The model effectively integrates textual and structural information for relation extraction in text graphs. Experimental results show that the model provides robust estimations of sample difficulty and shows sizable improvement over the state-of-the … Cites: ‪Cross-sentence n-ary relation extraction with graph lstms‬</summary></entry><entry><title type="html">Faithful approaches to rule learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/cee6342cba702003d71d831347c3aeaf.html" rel="alternate" type="text/html" title="Faithful approaches to rule learning" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/cee6342cba702003d71d831347c3aeaf</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/cee6342cba702003d71d831347c3aeaf.html">&lt;p&gt;Rule learning involves developing machine learning models that can be applied to a set of logical facts to predict additional facts, as well as providing methods for extracting from the learned model a set of logical rules that explain symbolically the model s predictions. Existing such approaches, however, do not describe formally the relationship between the model s predictions and the derivations of the extracted rules; rather, it is often claimed without justification that the extracted rules … Cites: ‪Neural logic machines‬&lt;/p&gt;</content><author><name>DJ Tena Cucala, B Cuenca Grau, B Motik - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Rule learning involves developing machine learning models that can be applied to a set of logical facts to predict additional facts, as well as providing methods for extracting from the learned model a set of logical rules that explain symbolically the model s predictions. Existing such approaches, however, do not describe formally the relationship between the model s predictions and the derivations of the extracted rules; rather, it is often claimed without justification that the extracted rules … Cites: ‪Neural logic machines‬</summary></entry><entry><title type="html">Predicting Rollback Edits on Stack Overflow Based on Deep Fusion of Metadata and Text</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/d02d2ff23b77f7ec1b9f4c1b29165b2e.html" rel="alternate" type="text/html" title="Predicting Rollback Edits on Stack Overflow Based on Deep Fusion of Metadata and Text" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/d02d2ff23b77f7ec1b9f4c1b29165b2e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/d02d2ff23b77f7ec1b9f4c1b29165b2e.html">&lt;p&gt;Online question and answer (Q&amp;amp;A) communities have become an important platform for sharing and gaining knowledge. To ensure the quality of posts, Q&amp;amp;A sites support and encourage collaborative editing. However, some undesired, inaccurate, or poor quality edits will be rejected by rollbacks. Most Q&amp;amp;A communities identify rollback edits by human review, which is not efficient and timely enough. To address this problem, we aim to construct a model that can automatically predict whether an edit … Cites: ‪Learning semantic representations of users and products for …‬&lt;/p&gt;</content><author><name>T Jiang, P Zhang, T Lu, N Gu - 2022 IEEE 25th International Conference on Computer …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Online question and answer (Q&amp;amp;A) communities have become an important platform for sharing and gaining knowledge. To ensure the quality of posts, Q&amp;amp;A sites support and encourage collaborative editing. However, some undesired, inaccurate, or poor quality edits will be rejected by rollbacks. Most Q&amp;amp;A communities identify rollback edits by human review, which is not efficient and timely enough. To address this problem, we aim to construct a model that can automatically predict whether an edit … Cites: ‪Learning semantic representations of users and products for …‬</summary></entry><entry><title type="html">Integral Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/d27197a5e92d5fc5057860411be6f84c.html" rel="alternate" type="text/html" title="Integral Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/d27197a5e92d5fc5057860411be6f84c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/d27197a5e92d5fc5057860411be6f84c.html">&lt;p&gt;Modern object detectors have taken the advantages of pre-trained vision transformers by using them as backbone networks. However, except for the backbone networks, other detector components, such as the detector head and the feature pyramid network, remain randomly initialized, which hinders the consistency between detectors and pre-trained models. In this study, we propose to integrally migrate the pre-trained transformer encoder-decoders (imTED) for object detection … Cites: ‪A Simple Single-Scale Vision Transformer for Object Localization …‬&lt;/p&gt;</content><author><name>X Zhang, F Liu, Z Peng, Z Guo, F Wan, X Ji, Q Ye - arXiv preprint arXiv:2205.09613, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Modern object detectors have taken the advantages of pre-trained vision transformers by using them as backbone networks. However, except for the backbone networks, other detector components, such as the detector head and the feature pyramid network, remain randomly initialized, which hinders the consistency between detectors and pre-trained models. In this study, we propose to integrally migrate the pre-trained transformer encoder-decoders (imTED) for object detection … Cites: ‪A Simple Single-Scale Vision Transformer for Object Localization …‬</summary></entry><entry><title type="html">Construction of Engineering Material Demand Data Space Integrating Macroeconomic Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/d36600b04f81c892d691be1d25f83886.html" rel="alternate" type="text/html" title="Construction of Engineering Material Demand Data Space Integrating Macroeconomic Data" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/d36600b04f81c892d691be1d25f83886</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/d36600b04f81c892d691be1d25f83886.html">&lt;p&gt;Accurate prediction of material demand of engineering projects is helpful to reduce engineering construction costs. The materials demand is not only affected by internal factors, but also by external macro-economy, which mainly affects enterprise investment, planning, and construction. However, the material demand forecasting generally only considers the internal influencing factors, failing to adjust the material procurement plan in time depending on the macroeconomic policies changes … Cites: ‪Principles of dataspace systems‬&lt;/p&gt;</content><author><name>D Yang, S Zhao, D Liu, R Cheng, Y Zhao - 2022 IEEE 25th International Conference …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Accurate prediction of material demand of engineering projects is helpful to reduce engineering construction costs. The materials demand is not only affected by internal factors, but also by external macro-economy, which mainly affects enterprise investment, planning, and construction. However, the material demand forecasting generally only considers the internal influencing factors, failing to adjust the material procurement plan in time depending on the macroeconomic policies changes … Cites: ‪Principles of dataspace systems‬</summary></entry><entry><title type="html">Interactive Query-Assisted Summarization via Deep Reinforcement Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/dad61c20e604d01f28ea33fef2620e1d.html" rel="alternate" type="text/html" title="Interactive Query-Assisted Summarization via Deep Reinforcement Learning" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/dad61c20e604d01f28ea33fef2620e1d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/dad61c20e604d01f28ea33fef2620e1d.html">&lt;p&gt;Interactive summarization is a task that facilitates user-guided exploration of information within a document set. While one would like to employ state of the art neural models to improve the quality of interactive summarization, many such …&lt;/p&gt;</content><author><name>O Shapira, R Pasunuru, M Bansal, I Dagan…</name></author><category term="jekyll" /><category term="update" /><summary type="html">Interactive summarization is a task that facilitates user-guided exploration of information within a document set. While one would like to employ state of the art neural models to improve the quality of interactive summarization, many such …</summary></entry><entry><title type="html">Towards designing a generic and comprehensive deep reinforcement learning framework</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/db817fc5b55038e8e78c4664672269df.html" rel="alternate" type="text/html" title="Towards designing a generic and comprehensive deep reinforcement learning framework" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/db817fc5b55038e8e78c4664672269df</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/db817fc5b55038e8e78c4664672269df.html">&lt;p&gt;Reinforcement learning (RL) has emerged as an effective approach for building an intelligent system, which involves multiple self-operated agents to collectively accomplish a designated task. More importantly, there has been a renewed focus on RL since the introduction of deep learning that essentially makes RL feasible to operate in high-dimensional environments. However, there are many diversified research directions in the current literature, such as multi-agent and multi-objective … Cites: ‪Opponent modeling in deep reinforcement learning‬&lt;/p&gt;</content><author><name>ND Nguyen, TT Nguyen, NT Pham, H Nguyen… - Applied Intelligence, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Reinforcement learning (RL) has emerged as an effective approach for building an intelligent system, which involves multiple self-operated agents to collectively accomplish a designated task. More importantly, there has been a renewed focus on RL since the introduction of deep learning that essentially makes RL feasible to operate in high-dimensional environments. However, there are many diversified research directions in the current literature, such as multi-agent and multi-objective … Cites: ‪Opponent modeling in deep reinforcement learning‬</summary></entry><entry><title type="html">Systems and methods for aida campaign controller intelligent records</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/dcf5cf6b944817b81b6e92a1e2104415.html" rel="alternate" type="text/html" title="Systems and methods for aida campaign controller intelligent records" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/dcf5cf6b944817b81b6e92a1e2104415</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/dcf5cf6b944817b81b6e92a1e2104415.html">&lt;p&gt;Abstract Systems and methods, disclosed herein, of a campaign controller that stores information to a database about execution of multiple simulated phishing campaigns for multiple users, where each of the simulated phishing campaigns use one or more models for communicating simulated phishing communications. Based on this information, the campaign controller may determine a rate of success of the model, in causing a user to interact with a link in one of the simulated phishing campaigns, and … Cites: ‪Personalized email filtering‬&lt;/p&gt;</content><author><name>S Sjouwerman, E Sites - US Patent App. 17/361,185, 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract Systems and methods, disclosed herein, of a campaign controller that stores information to a database about execution of multiple simulated phishing campaigns for multiple users, where each of the simulated phishing campaigns use one or more models for communicating simulated phishing communications. Based on this information, the campaign controller may determine a rate of success of the model, in causing a user to interact with a link in one of the simulated phishing campaigns, and … Cites: ‪Personalized email filtering‬</summary></entry><entry><title type="html">Social influence-based contrast language analysis framework for clinical decision support systems</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/de2914658bf1b010119935ae9f76b20c.html" rel="alternate" type="text/html" title="Social influence-based contrast language analysis framework for clinical decision support systems" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/de2914658bf1b010119935ae9f76b20c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/de2914658bf1b010119935ae9f76b20c.html">&lt;p&gt;Depression is a leading mental health problem affecting 300 million people globally. Recent studies show that social networks provide a tremendous potential for mental health professionals as a source of supplemental information about their patients. This study presents a methodological framework for clinical decision support systems (CDSSs) through analysis of social network data to distinguish the language usage of individuals with early signs of depression (ie, contrast language analysis). By … Cites: ‪Beyond LDA: exploring supervised topic modeling for depression …‬&lt;/p&gt;</content><author><name>X Yang, A Joukova, A Ayanso, M Zihayat - Decision Support Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Depression is a leading mental health problem affecting 300 million people globally. Recent studies show that social networks provide a tremendous potential for mental health professionals as a source of supplemental information about their patients. This study presents a methodological framework for clinical decision support systems (CDSSs) through analysis of social network data to distinguish the language usage of individuals with early signs of depression (ie, contrast language analysis). By … Cites: ‪Beyond LDA: exploring supervised topic modeling for depression …‬</summary></entry><entry><title type="html">Debiasing Neural Retrieval via In-batch Balancing Regularization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/deefc860f23f013856d24be1f470a466.html" rel="alternate" type="text/html" title="Debiasing Neural Retrieval via In-batch Balancing Regularization" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/deefc860f23f013856d24be1f470a466</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/deefc860f23f013856d24be1f470a466.html">&lt;p&gt;People frequently interact with information retrieval (IR) systems, however, IR models exhibit biases and discrimination towards various demographics. The in-processing fair ranking methods provide a trade-offs between accuracy and fairness through adding a fairness-related regularization term in the loss function. However, there haven t been intuitive objective functions that depend on the click probability and user engagement to directly optimize towards this. In this work, we propose the In … Cites: ‪Well-read students learn better: On the importance of pre-training …‬&lt;/p&gt;</content><author><name>Y Li, X Wei, Z Wang, S Wang, P Bhatia, X Ma, A Arnold - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">People frequently interact with information retrieval (IR) systems, however, IR models exhibit biases and discrimination towards various demographics. The in-processing fair ranking methods provide a trade-offs between accuracy and fairness through adding a fairness-related regularization term in the loss function. However, there haven t been intuitive objective functions that depend on the click probability and user engagement to directly optimize towards this. In this work, we propose the In … Cites: ‪Well-read students learn better: On the importance of pre-training …‬</summary></entry><entry><title type="html">CHAMP: Channel Merging Process for Cost-Efficient Highly-Pruned CNN Acceleration</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/df07203bf8d5a1ad15e1670f01c7afbb.html" rel="alternate" type="text/html" title="CHAMP: Channel Merging Process for Cost-Efficient Highly-Pruned CNN Acceleration" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/df07203bf8d5a1ad15e1670f01c7afbb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/df07203bf8d5a1ad15e1670f01c7afbb.html">&lt;p&gt;This paper presents an advanced offline scheduling scheme to improve the accelerator efficiency, especially for the highly-pruned convolutional neural networks (HP-CNNs). Based on the existing outlier-aware accelerator design, we demonstrate the efficiency drop of HP-CNN processing for the first time, and element-wise channel merging is proposed to make a dense processing sequence even for the highly-pruned model. The dedicated hardware architecture is also presented to … Cites: ‪Coatnet: Marrying convolution and attention for all data sizes‬&lt;/p&gt;</content><author><name>H Kwon, Y Byun, S Kang, Y Lee - IEEE Transactions on Circuits and Systems I …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper presents an advanced offline scheduling scheme to improve the accelerator efficiency, especially for the highly-pruned convolutional neural networks (HP-CNNs). Based on the existing outlier-aware accelerator design, we demonstrate the efficiency drop of HP-CNN processing for the first time, and element-wise channel merging is proposed to make a dense processing sequence even for the highly-pruned model. The dedicated hardware architecture is also presented to … Cites: ‪Coatnet: Marrying convolution and attention for all data sizes‬</summary></entry><entry><title type="html">Pass off Fish Eyes for Pearls: Attacking Model Selection of Pre-trained Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e0248f554e5ccb6c36cc922f33332337.html" rel="alternate" type="text/html" title="Pass off Fish Eyes for Pearls: Attacking Model Selection of Pre-trained Models" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e0248f554e5ccb6c36cc922f33332337</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e0248f554e5ccb6c36cc922f33332337.html">&lt;p&gt;Selecting an appropriate pre-trained model (PTM) for a specific downstream task typically requires significant efforts of fine-tuning. To accelerate this process, researchers propose feature-based model selection (FMS) methods, which assess …&lt;/p&gt;</content><author><name>B Zhu, Y Qin, F Qi, Y Deng, Z Liu, M Sun, M Gu - … of the 60th Annual Meeting of the …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Selecting an appropriate pre-trained model (PTM) for a specific downstream task typically requires significant efforts of fine-tuning. To accelerate this process, researchers propose feature-based model selection (FMS) methods, which assess …</summary></entry><entry><title type="html">The Public Perception of the# GeneEditedBabies Event Across Multiple Social Media Platforms: Observational Study</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e111d1debf5db1175b9815fd123dfabf.html" rel="alternate" type="text/html" title="The Public Perception of the# GeneEditedBabies Event Across Multiple Social Media Platforms: Observational Study" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e111d1debf5db1175b9815fd123dfabf</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e111d1debf5db1175b9815fd123dfabf.html">&lt;p&gt;Abstract In November 2018, a Chinese researcher reported that his team had applied clustered regularly interspaced palindromic repeats or associated protein 9 to delete the gene CC chemokine receptor type 5 from embryos and claimed that the 2 newborns would have lifetime immunity from HIV infection, an event referred to as# GeneEditedBabies on social media platforms. Although this event stirred a worldwide debate on ethical and legal issues regarding clinical trials with embryonic … Cites: ‪Text summarization with pretrained encoders‬&lt;/p&gt;</content><author><name>EW Clayton, C Ni - Journal of Medical Internet Research, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract In November 2018, a Chinese researcher reported that his team had applied clustered regularly interspaced palindromic repeats or associated protein 9 to delete the gene CC chemokine receptor type 5 from embryos and claimed that the 2 newborns would have lifetime immunity from HIV infection, an event referred to as# GeneEditedBabies on social media platforms. Although this event stirred a worldwide debate on ethical and legal issues regarding clinical trials with embryonic … Cites: ‪Text summarization with pretrained encoders‬</summary></entry><entry><title type="html">Vulnerability Detection With Graph Attention Network And Metric Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e1782a2084e87a89bcedcf7bac547f75.html" rel="alternate" type="text/html" title="Vulnerability Detection With Graph Attention Network And Metric Learning" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e1782a2084e87a89bcedcf7bac547f75</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e1782a2084e87a89bcedcf7bac547f75.html">&lt;p&gt;Static code vulnerability detection is a critical topic in software security. Existing software analysis methods have a high rate of false positives and false negatives. Researchers are interested in employing deep learning to discover vulnerabilities automatically, thanks to the recent success of deep learning algorithms in other application domains. This paper aims at the problem of insufficient and effective extraction of syntax and semantics, the issue of data imbalance, and the problem of … Cites: ‪Graphcodebert: Pre-training code representations with data flow‬&lt;/p&gt;</content><author><name>C Zhang, B Liu, Q Fan, Y Xin, H Zhu - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Static code vulnerability detection is a critical topic in software security. Existing software analysis methods have a high rate of false positives and false negatives. Researchers are interested in employing deep learning to discover vulnerabilities automatically, thanks to the recent success of deep learning algorithms in other application domains. This paper aims at the problem of insufficient and effective extraction of syntax and semantics, the issue of data imbalance, and the problem of … Cites: ‪Graphcodebert: Pre-training code representations with data flow‬</summary></entry><entry><title type="html">Phylogeny-Inspired Adaptation of Multilingual Models to New Languages</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e4c6e0c74a3585a08cca7ca2f5be2887.html" rel="alternate" type="text/html" title="Phylogeny-Inspired Adaptation of Multilingual Models to New Languages" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e4c6e0c74a3585a08cca7ca2f5be2887</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e4c6e0c74a3585a08cca7ca2f5be2887.html">&lt;p&gt;Large pretrained multilingual models, trained on dozens of languages, have delivered promising results due to cross-lingual learning capabilities on variety of language tasks. Further adapting these models to specific languages, especially ones unseen during pre-training, is an important goal towards expanding the coverage of language technologies. In this study, we show how we can use language phylogenetic information to improve cross-lingual transfer leveraging … Cites: ‪Expanding Pretrained Models to Thousands More Languages via …‬&lt;/p&gt;</content><author><name>F Faisal, A Anastasopoulos - arXiv preprint arXiv:2205.09634, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Large pretrained multilingual models, trained on dozens of languages, have delivered promising results due to cross-lingual learning capabilities on variety of language tasks. Further adapting these models to specific languages, especially ones unseen during pre-training, is an important goal towards expanding the coverage of language technologies. In this study, we show how we can use language phylogenetic information to improve cross-lingual transfer leveraging … Cites: ‪Expanding Pretrained Models to Thousands More Languages via …‬</summary></entry><entry><title type="html">Prediction of protein–protein interaction using graph neural networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e711a4df8878d24b6c0650eb09922660.html" rel="alternate" type="text/html" title="Prediction of protein–protein interaction using graph neural networks" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e711a4df8878d24b6c0650eb09922660</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/e711a4df8878d24b6c0650eb09922660.html">&lt;p&gt;Proteins are the essential biological macromolecules required to perform nearly all biological processes, and cellular functions. Proteins rarely carry out their tasks in isolation but interact with other proteins (known as protein–protein interaction) present in their surroundings to complete biological activities. The knowledge of protein–protein interactions (PPIs) unravels the cellular behavior and its functionality. The computational methods automate the prediction of PPI and are less expensive … Cites: ‪Graph neural networks: A review of methods and applications‬&lt;/p&gt;</content><author><name>K Jha, S Saha, H Singh - Scientific Reports, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Proteins are the essential biological macromolecules required to perform nearly all biological processes, and cellular functions. Proteins rarely carry out their tasks in isolation but interact with other proteins (known as protein–protein interaction) present in their surroundings to complete biological activities. The knowledge of protein–protein interactions (PPIs) unravels the cellular behavior and its functionality. The computational methods automate the prediction of PPI and are less expensive … Cites: ‪Graph neural networks: A review of methods and applications‬</summary></entry><entry><title type="html">Log Analysis: Topic Modeling applications on fine-features data processing system</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ea3ee46a5814dbe37a31c959b75a105d.html" rel="alternate" type="text/html" title="Log Analysis: Topic Modeling applications on fine-features data processing system" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ea3ee46a5814dbe37a31c959b75a105d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ea3ee46a5814dbe37a31c959b75a105d.html">&lt;p&gt;Nowadays an ever-increasing number of operations is performed with the help of computer systems. They are everywhere around us and each of them produces a huge quantity of log files for each operation carried out. In this context, the aim of this project is to study and create an architecture able to read and categorize the logs produced by computer systems based on logs content. The outcomes of this project form the foundation of a subsequent task of anomaly detection, which is highly … Cites: ‪Reading tea leaves: How humans interpret topic models‬&lt;/p&gt;</content><author><name>D NAPOLITANO - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Nowadays an ever-increasing number of operations is performed with the help of computer systems. They are everywhere around us and each of them produces a huge quantity of log files for each operation carried out. In this context, the aim of this project is to study and create an architecture able to read and categorize the logs produced by computer systems based on logs content. The outcomes of this project form the foundation of a subsequent task of anomaly detection, which is highly … Cites: ‪Reading tea leaves: How humans interpret topic models‬</summary></entry><entry><title type="html">Deploying self-supervised learning in the wild for hybrid automatic speech recognition</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ec4003258c97fcd88a4b35cc0092d93a.html" rel="alternate" type="text/html" title="Deploying self-supervised learning in the wild for hybrid automatic speech recognition" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ec4003258c97fcd88a4b35cc0092d93a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ec4003258c97fcd88a4b35cc0092d93a.html">&lt;p&gt;Self-supervised learning (SSL) methods have proven to be very successful in automatic speech recognition (ASR). These great improvements have been reported mostly based on highly curated datasets such as LibriSpeech for non-streaming End-to-End ASR models. However, the pivotal characteristics of SSL is to be utilized for any untranscribed audio data. In this paper, we provide a full exploration on how to utilize uncurated audio data in SSL from data pre-processing to deploying an … Cites: ‪Pushing the limits of semi-supervised learning for automatic …‬&lt;/p&gt;</content><author><name>M Karimi, C Liu, K Kumatani, Y Qian, T Wu, J Wu - arXiv preprint arXiv:2205.08598, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Self-supervised learning (SSL) methods have proven to be very successful in automatic speech recognition (ASR). These great improvements have been reported mostly based on highly curated datasets such as LibriSpeech for non-streaming End-to-End ASR models. However, the pivotal characteristics of SSL is to be utilized for any untranscribed audio data. In this paper, we provide a full exploration on how to utilize uncurated audio data in SSL from data pre-processing to deploying an … Cites: ‪Pushing the limits of semi-supervised learning for automatic …‬</summary></entry><entry><title type="html">Improving Robustness against Real-World and Worst-Case Distribution Shifts through Decision Region Quantification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ee51c9d3bda7b03623c32da0f8055602.html" rel="alternate" type="text/html" title="Improving Robustness against Real-World and Worst-Case Distribution Shifts through Decision Region Quantification" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ee51c9d3bda7b03623c32da0f8055602</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/ee51c9d3bda7b03623c32da0f8055602.html">&lt;p&gt;The reliability of neural networks is essential for their use in safety-critical applications. Existing approaches generally aim at improving the robustness of neural networks to either real-world distribution shifts (eg, common corruptions and perturbations, spatial transformations, and natural adversarial examples) or worst-case distribution shifts (eg, optimized adversarial examples). In this work, we propose the Decision Region Quantification (DRQ) algorithm to improve the … Cites: ‪Understanding and mitigating the tradeoff between robustness and …‬&lt;/p&gt;</content><author><name>L Schwinn, L Bungert, A Nguyen, R Raab, F Pulsmeyer… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The reliability of neural networks is essential for their use in safety-critical applications. Existing approaches generally aim at improving the robustness of neural networks to either real-world distribution shifts (eg, common corruptions and perturbations, spatial transformations, and natural adversarial examples) or worst-case distribution shifts (eg, optimized adversarial examples). In this work, we propose the Decision Region Quantification (DRQ) algorithm to improve the … Cites: ‪Understanding and mitigating the tradeoff between robustness and …‬</summary></entry><entry><title type="html">An Efficient Asymmetric Nonlinear Activation Function for Deep Neural Networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f023726226f9861c516983e6c8875f93.html" rel="alternate" type="text/html" title="An Efficient Asymmetric Nonlinear Activation Function for Deep Neural Networks" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f023726226f9861c516983e6c8875f93</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f023726226f9861c516983e6c8875f93.html">&lt;p&gt;As a key step to endow the neural network with nonlinear factors, the activation function is crucial to the performance of the network. This paper proposes an Efficient Asymmetric Nonlinear Activation Function (EANAF) for deep neural networks. Compared with existing activation functions, the proposed EANAF requires less computational effort, and it is self-regularized, asymmetric and non-monotonic. These desired characteristics facilitate the outstanding performance of the proposed … Cites: ‪Long short-term memory-networks for machine reading‬&lt;/p&gt;</content><author><name>E Chai, W Yu, T Cui, J Ren, S Ding - Symmetry, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As a key step to endow the neural network with nonlinear factors, the activation function is crucial to the performance of the network. This paper proposes an Efficient Asymmetric Nonlinear Activation Function (EANAF) for deep neural networks. Compared with existing activation functions, the proposed EANAF requires less computational effort, and it is self-regularized, asymmetric and non-monotonic. These desired characteristics facilitate the outstanding performance of the proposed … Cites: ‪Long short-term memory-networks for machine reading‬</summary></entry><entry><title type="html">Document Image Classification with Vision Transformers</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f456a577bc309c0336508604cbd9d3ba.html" rel="alternate" type="text/html" title="Document Image Classification with Vision Transformers" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f456a577bc309c0336508604cbd9d3ba</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f456a577bc309c0336508604cbd9d3ba.html">&lt;p&gt;Document image classification has received huge interest in business automation processes. Therefore, document image classification plays an important role in the document image processing (DIP) systems. And it is necessary to develop an effective framework for this task. Many methods have been proposed for the classification of document images in literature. In this paper we propose an efficient document image classification task that uses vision transformers (ViTs) and benefits … Cites: ‪BERT: pre-training of deep bidirectional transformers for language …‬&lt;/p&gt;</content><author><name>S Sevim, Sİ Omurca, E Ekinci - International Congress of Electrical and Computer …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Document image classification has received huge interest in business automation processes. Therefore, document image classification plays an important role in the document image processing (DIP) systems. And it is necessary to develop an effective framework for this task. Many methods have been proposed for the classification of document images in literature. In this paper we propose an efficient document image classification task that uses vision transformers (ViTs) and benefits … Cites: ‪BERT: pre-training of deep bidirectional transformers for language …‬</summary></entry><entry><title type="html">Transformers as Neural Augmentors: Class Conditional Sentence Generation via Variational Bayes</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f4db5e4c0cf642a3f73547f5aebeb2d1.html" rel="alternate" type="text/html" title="Transformers as Neural Augmentors: Class Conditional Sentence Generation via Variational Bayes" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f4db5e4c0cf642a3f73547f5aebeb2d1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f4db5e4c0cf642a3f73547f5aebeb2d1.html">&lt;p&gt;Data augmentation methods for Natural Language Processing tasks are explored in recent years, however they are limited and it is hard to capture the diversity on sentence level. Besides, it is not always possible to perform data augmentation on supervised tasks. To address those problems, we propose a neural data augmentation method, which is a combination of Conditional Variational Autoencoder and encoder-decoder Transformer model. While encoding and … Cites: ‪Generative data augmentation for commonsense reasoning‬&lt;/p&gt;</content><author><name>MŞ Bilici, MF Amasyali - arXiv preprint arXiv:2205.09391, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Data augmentation methods for Natural Language Processing tasks are explored in recent years, however they are limited and it is hard to capture the diversity on sentence level. Besides, it is not always possible to perform data augmentation on supervised tasks. To address those problems, we propose a neural data augmentation method, which is a combination of Conditional Variational Autoencoder and encoder-decoder Transformer model. While encoding and … Cites: ‪Generative data augmentation for commonsense reasoning‬</summary></entry><entry><title type="html">MAGMA: An Optimization Framework for Mapping Multiple DNNs on Multiple Accelerator Cores</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f5a7f3d79cd351c6fb83b99d14399a2c.html" rel="alternate" type="text/html" title="MAGMA: An Optimization Framework for Mapping Multiple DNNs on Multiple Accelerator Cores" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f5a7f3d79cd351c6fb83b99d14399a2c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f5a7f3d79cd351c6fb83b99d14399a2c.html">&lt;p&gt;As Deep Learning continues to drive a variety of applications in edge and cloud data centers, there is a growing trend towards building large accelerators with several sub-accelerator cores/chiplets. This work looks at the problem of supporting multi-tenancy on such accelerators. In particular, we focus on the problem of mapping jobs from several DNNs simultaneously on an accelerator. Given the extremely large search space, we formulate the search as an optimization problem and develop an … Cites: ‪Unsupervised cross-lingual representation learning at scale‬&lt;/p&gt;</content><author><name>SC Kao, T Krishna - 2022 IEEE International Symposium on High …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As Deep Learning continues to drive a variety of applications in edge and cloud data centers, there is a growing trend towards building large accelerators with several sub-accelerator cores/chiplets. This work looks at the problem of supporting multi-tenancy on such accelerators. In particular, we focus on the problem of mapping jobs from several DNNs simultaneously on an accelerator. Given the extremely large search space, we formulate the search as an optimization problem and develop an … Cites: ‪Unsupervised cross-lingual representation learning at scale‬</summary></entry><entry><title type="html">Full Transformer Network with Masking Future for Word-Level Sign Language Recognition</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f63e5459740bba747fa37ae161adc5e5.html" rel="alternate" type="text/html" title="Full Transformer Network with Masking Future for Word-Level Sign Language Recognition" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f63e5459740bba747fa37ae161adc5e5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f63e5459740bba747fa37ae161adc5e5.html">&lt;p&gt;Word-level sign language recognition (SLR) is a significant task which transcribes a sign language video into a word. Currently, deep-learning-based frameworks mostly combine spatial feature extractors based on convolution neural networks (CNNs) and sequence learners. These methods either lack the sufficient capacity to establish the high-level vision semantic knowledge and incorporate the details in images or perform weak intelligence on video frame sequence comprehension. Focusing on … Cites: ‪Less is More: ClipBERT for Video-and-Language Learning via …‬&lt;/p&gt;</content><author><name>Y Du, P Xie, M Wang, X Hu, Z Zhao, J Liu - Neurocomputing, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Word-level sign language recognition (SLR) is a significant task which transcribes a sign language video into a word. Currently, deep-learning-based frameworks mostly combine spatial feature extractors based on convolution neural networks (CNNs) and sequence learners. These methods either lack the sufficient capacity to establish the high-level vision semantic knowledge and incorporate the details in images or perform weak intelligence on video frame sequence comprehension. Focusing on … Cites: ‪Less is More: ClipBERT for Video-and-Language Learning via …‬</summary></entry><entry><title type="html">Deep Learning Models for Tabular Data Curation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f8716ed6fea438478309f108a4a08abc.html" rel="alternate" type="text/html" title="Deep Learning Models for Tabular Data Curation" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f8716ed6fea438478309f108a4a08abc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f8716ed6fea438478309f108a4a08abc.html">&lt;p&gt;Data curation, defined as the problem of organizing and maintaining data so that they can be employed for data-centric tasks, is a pervasive and far-reaching subject, touching all fields from academia to industry. Data curation has a number of sides to it, and no good solution for all of them. Current solutions rely on manual work from domain users, but this does not scale with the number of datasets to clean. In the last few years, many challenging problems in the NLP and computer vision fields have … Cites: ‪Data integration: After the teenage years‬&lt;/p&gt;</content><author><name>R CAPPUZZO - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Data curation, defined as the problem of organizing and maintaining data so that they can be employed for data-centric tasks, is a pervasive and far-reaching subject, touching all fields from academia to industry. Data curation has a number of sides to it, and no good solution for all of them. Current solutions rely on manual work from domain users, but this does not scale with the number of datasets to clean. In the last few years, many challenging problems in the NLP and computer vision fields have … Cites: ‪Data integration: After the teenage years‬</summary></entry><entry><title type="html">PreQuEL: Quality Estimation of Machine Translation Outputs in Advance</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f9e4888d520fda3b3dfd63d98888447f.html" rel="alternate" type="text/html" title="PreQuEL: Quality Estimation of Machine Translation Outputs in Advance" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f9e4888d520fda3b3dfd63d98888447f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/f9e4888d520fda3b3dfd63d98888447f.html">&lt;p&gt;We present the task of PreQuEL, Pre-(Quality-Estimation) Learning. A PreQuEL system predicts how well a given sentence will be translated, without recourse to the actual translation, thus eschewing unnecessary resource allocation when translation quality is bound to be low. PreQuEL can be defined relative to a given MT system (eg, some industry service) or generally relative to the state-of-the-art. From a theoretical perspective, PreQuEL places the focus on the source text, tracing … Cites: ‪Muppet: Massive multi-task representations with pre-finetuning‬&lt;/p&gt;</content><author><name>S Don-Yehiya, L Choshen, O Abend - arXiv preprint arXiv:2205.09178, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present the task of PreQuEL, Pre-(Quality-Estimation) Learning. A PreQuEL system predicts how well a given sentence will be translated, without recourse to the actual translation, thus eschewing unnecessary resource allocation when translation quality is bound to be low. PreQuEL can be defined relative to a given MT system (eg, some industry service) or generally relative to the state-of-the-art. From a theoretical perspective, PreQuEL places the focus on the source text, tracing … Cites: ‪Muppet: Massive multi-task representations with pre-finetuning‬</summary></entry><entry><title type="html">Collaborative Decision-Reinforced Self-Supervision for Attributed Graph Clustering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/fae1c4d54d3b02e84ed4a3a257531caf.html" rel="alternate" type="text/html" title="Collaborative Decision-Reinforced Self-Supervision for Attributed Graph Clustering" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/fae1c4d54d3b02e84ed4a3a257531caf</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/fae1c4d54d3b02e84ed4a3a257531caf.html">&lt;p&gt;Attributed graph clustering aims to partition nodes of a graph structure into different groups. Recent works usually use variational graph autoencoder (VGAE) to make the node representations obey a specific distribution. Although they have shown promising results, how to introduce supervised information to guide the representation learning of graph nodes and improve clustering performance is still an open problem. In this article, we propose a Collaborative Decision-Reinforced … Cites: ‪Adaptive Graph Encoder for Attributed Graph Embedding‬&lt;/p&gt;</content><author><name>P Zhu, J Li, Y Wang, B Xiao, S Zhao, Q Hu - IEEE Transactions on Neural Networks …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Attributed graph clustering aims to partition nodes of a graph structure into different groups. Recent works usually use variational graph autoencoder (VGAE) to make the node representations obey a specific distribution. Although they have shown promising results, how to introduce supervised information to guide the representation learning of graph nodes and improve clustering performance is still an open problem. In this article, we propose a Collaborative Decision-Reinforced … Cites: ‪Adaptive Graph Encoder for Attributed Graph Embedding‬</summary></entry><entry><title type="html">Evaluation of Transfer Learning for Polish with a Text-to-Text Model</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/fc085819ec416f9c8e410a0dc2cdf827.html" rel="alternate" type="text/html" title="Evaluation of Transfer Learning for Polish with a Text-to-Text Model" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/fc085819ec416f9c8e410a0dc2cdf827</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/fc085819ec416f9c8e410a0dc2cdf827.html">&lt;p&gt;We introduce a new benchmark for assessing the quality of text-to-text models for Polish. The benchmark consists of diverse tasks and datasets: KLEJ benchmark adapted for text-to-text, en-pl translation, summarization, and question answering. In particular, since summarization and question answering lack benchmark datasets for the Polish language, we describe their construction and make them publicly available. Additionally, we present plT5-a general-purpose text-to-text model for … Cites: ‪Multilingual denoising pre-training for neural machine translation‬&lt;/p&gt;</content><author><name>A Chrabrowa, Ł Dragan, K Grzegorczyk, D Kajtoch… - arXiv preprint arXiv …, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We introduce a new benchmark for assessing the quality of text-to-text models for Polish. The benchmark consists of diverse tasks and datasets: KLEJ benchmark adapted for text-to-text, en-pl translation, summarization, and question answering. In particular, since summarization and question answering lack benchmark datasets for the Polish language, we describe their construction and make them publicly available. Additionally, we present plT5-a general-purpose text-to-text model for … Cites: ‪Multilingual denoising pre-training for neural machine translation‬</summary></entry><entry><title type="html">Rumor detection on social media using hierarchically aggregated feature via graph neural networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/fc4aa874c0490f74559a3b21583cd34c.html" rel="alternate" type="text/html" title="Rumor detection on social media using hierarchically aggregated feature via graph neural networks" /><published>2022-05-24T00:00:36-04:00</published><updated>2022-05-24T00:00:36-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/fc4aa874c0490f74559a3b21583cd34c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/24/fc4aa874c0490f74559a3b21583cd34c.html">&lt;p&gt;In the era of the Internet and big data, online social media platforms have been developing rapidly, which accelerate rumors circulation. Rumor detection on social media is a worldwide challenging task due to rumor s feature of high speed, fragmental information and extensive range. Most existing approaches identify rumors based on single-layered hybrid features like word features, sentiment features and user characteristics, or multimodal features like the combination of text … Cites: ‪CED: Credible early detection of social media rumors‬&lt;/p&gt;</content><author><name>S Xu, X Liu, K Ma, F Dong, B Riskhan, S Xiang, C Bing - Applied Intelligence, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In the era of the Internet and big data, online social media platforms have been developing rapidly, which accelerate rumors circulation. Rumor detection on social media is a worldwide challenging task due to rumor s feature of high speed, fragmental information and extensive range. Most existing approaches identify rumors based on single-layered hybrid features like word features, sentiment features and user characteristics, or multimodal features like the combination of text … Cites: ‪CED: Credible early detection of social media rumors‬</summary></entry><entry><title type="html">Task Generalisation in Multi-Agent Reinforcement Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/00396f9507f726c410ffc377d7a7e037.html" rel="alternate" type="text/html" title="Task Generalisation in Multi-Agent Reinforcement Learning" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/00396f9507f726c410ffc377d7a7e037</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/00396f9507f726c410ffc377d7a7e037.html">&lt;p&gt;Multi-agent reinforcement learning agents are typically trained in a single environment. As a consequence, they overfit to the training environment which results in sensitivity to perturbations and inability to generalise to similar environments. For multi-agent reinforcement learning approaches to be applicable in real-world scenarios, generalisation and robustness need to be addressed. However, unlike in supervised learning, generalisation lacks a clear definition in Cites: Decoupling exploration and exploitation for meta-reinforcement&lt;/p&gt;</content><author><name>L Schfer - Proceedings of the 21st International Conference on , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Multi-agent reinforcement learning agents are typically trained in a single environment. As a consequence, they overfit to the training environment which results in sensitivity to perturbations and inability to generalise to similar environments. For multi-agent reinforcement learning approaches to be applicable in real-world scenarios, generalisation and robustness need to be addressed. However, unlike in supervised learning, generalisation lacks a clear definition in Cites: Decoupling exploration and exploitation for meta-reinforcement</summary></entry><entry><title type="html">CounterGeDi: A controllable approach to generate polite, detoxified and emotional counterspeech</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/00f25cf982d9003b32776e4949fa6229.html" rel="alternate" type="text/html" title="CounterGeDi: A controllable approach to generate polite, detoxified and emotional counterspeech" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/00f25cf982d9003b32776e4949fa6229</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/00f25cf982d9003b32776e4949fa6229.html">&lt;p&gt;Recently, many studies have tried to create generation models to assist counter speakers by providing counterspeech suggestions for combating the explosive proliferation of online hate. However, since these suggestions are from a vanilla generation model, they might not include the appropriate properties required to counter a particular hate speech instance. In this paper, we propose CounterGeDi-an ensemble of generative discriminators (GeDi) to guide the generation of a DialoGPT Cites: Gedi: Generative discriminator guided sequence generation&lt;/p&gt;</content><author><name>P Saha, K Singh, A Kumar, B Mathew, A Mukherjee - arXiv preprint arXiv:2205.04304, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recently, many studies have tried to create generation models to assist counter speakers by providing counterspeech suggestions for combating the explosive proliferation of online hate. However, since these suggestions are from a vanilla generation model, they might not include the appropriate properties required to counter a particular hate speech instance. In this paper, we propose CounterGeDi-an ensemble of generative discriminators (GeDi) to guide the generation of a DialoGPT Cites: Gedi: Generative discriminator guided sequence generation</summary></entry><entry><title type="html">Static Analysis for AWS Best Practices in Python Code</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/03f4696ff465e47053b8fd41bd4787e8.html" rel="alternate" type="text/html" title="Static Analysis for AWS Best Practices in Python Code" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/03f4696ff465e47053b8fd41bd4787e8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/03f4696ff465e47053b8fd41bd4787e8.html">&lt;p&gt;Amazon Web Services (AWS) is a comprehensive and broadly adopted cloud provider, offering over 200 fully featured services, including compute, database, storage, networking and content delivery, machine learning, Internet of Things and many others. AWS SDKs provide access to AWS services through API endpoints. However, incorrect use of these APIs can lead to code defects, crashes, performance issues, and other problems. This paper presents automated static analysis rules Cites: Lambdanet: Probabilistic type inference using graph neural networks&lt;/p&gt;</content><author><name>R Mukherjee, O Tripp, B Liblit, M Wilson - arXiv preprint arXiv:2205.04432, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Amazon Web Services (AWS) is a comprehensive and broadly adopted cloud provider, offering over 200 fully featured services, including compute, database, storage, networking and content delivery, machine learning, Internet of Things and many others. AWS SDKs provide access to AWS services through API endpoints. However, incorrect use of these APIs can lead to code defects, crashes, performance issues, and other problems. This paper presents automated static analysis rules Cites: Lambdanet: Probabilistic type inference using graph neural networks</summary></entry><entry><title type="html">From Distillation to Hard Negative Sampling: Making Sparse Neural IR Models More Effective</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/087252c7d52a58fe5887ce14ca7cfe6d.html" rel="alternate" type="text/html" title="From Distillation to Hard Negative Sampling: Making Sparse Neural IR Models More Effective" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/087252c7d52a58fe5887ce14ca7cfe6d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/087252c7d52a58fe5887ce14ca7cfe6d.html">&lt;p&gt;Neural retrievers based on dense representations combined with Approximate Nearest Neighbors search have recently received a lot of attention, owing their success to distillation and/or better sampling of examples for training–while still relying on the same backbone architecture. In the meantime, sparse representation learning fueled by traditional inverted indexing techniques has seen a growing interest, inheriting from desirable IR priors such as explicit lexical matching. While Cites: Towards Unsupervised Dense Information Retrieval with&lt;/p&gt;</content><author><name>T Formal, C Lassance, B Piwowarski, S Clinchant - arXiv preprint arXiv:2205.04733, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Neural retrievers based on dense representations combined with Approximate Nearest Neighbors search have recently received a lot of attention, owing their success to distillation and/or better sampling of examples for training–while still relying on the same backbone architecture. In the meantime, sparse representation learning fueled by traditional inverted indexing techniques has seen a growing interest, inheriting from desirable IR priors such as explicit lexical matching. While Cites: Towards Unsupervised Dense Information Retrieval with</summary></entry><entry><title type="html">Integrating user-Group relationships under interest similarity constraints for social recommendation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/0a77fbb7adc66905e5a71ae791a14706.html" rel="alternate" type="text/html" title="Integrating user-Group relationships under interest similarity constraints for social recommendation" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/0a77fbb7adc66905e5a71ae791a14706</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/0a77fbb7adc66905e5a71ae791a14706.html">&lt;p&gt;Traditional collaborative filtering based recommender systems generally suffer from the interaction data sparsity problem. Therefore, social recommendation is proposed to mitigate the issue and improve recommendation performance by introducing social information. Existing social recommendation studies primarily focus on the direct connections between users, such as friendship or users  correlation. Unfortunately, there often is a severe data sparsity issue in above social data as well Cites: Recommender systems with social regularization&lt;/p&gt;</content><author><name>Y Chen, J Wang, Z Wu, Y Lin - Knowledge-Based Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Traditional collaborative filtering based recommender systems generally suffer from the interaction data sparsity problem. Therefore, social recommendation is proposed to mitigate the issue and improve recommendation performance by introducing social information. Existing social recommendation studies primarily focus on the direct connections between users, such as friendship or users correlation. Unfortunately, there often is a severe data sparsity issue in above social data as well Cites: Recommender systems with social regularization</summary></entry><entry><title type="html">The Road to Explainability is Paved with Bias: Measuring the Fairness of Explanations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/0bc1dc1fdbed7f309abe9910ce7dcb42.html" rel="alternate" type="text/html" title="The Road to Explainability is Paved with Bias: Measuring the Fairness of Explanations" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/0bc1dc1fdbed7f309abe9910ce7dcb42</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/0bc1dc1fdbed7f309abe9910ce7dcb42.html">&lt;p&gt;Machine learning models in safety-critical settings like healthcare are often blackboxes: they contain a large number of parameters which are not transparent to users. Post-hoc explainability methods where a simple, human-interpretable model imitates the behavior of these blackbox models are often proposed to help users trust model predictions. In this work, we audit the quality of such explanations for different protected subgroups using real data from four settings in finance, healthcare, college Cites: Does the whole exceed its parts? the effect of ai explanations on&lt;/p&gt;</content><author><name>A Balagopalan, H Zhang, K Hamidieh, T Hartvigsen - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Machine learning models in safety-critical settings like healthcare are often blackboxes: they contain a large number of parameters which are not transparent to users. Post-hoc explainability methods where a simple, human-interpretable model imitates the behavior of these blackbox models are often proposed to help users trust model predictions. In this work, we audit the quality of such explanations for different protected subgroups using real data from four settings in finance, healthcare, college Cites: Does the whole exceed its parts? the effect of ai explanations on</summary></entry><entry><title type="html">Knowledge Augmented Machine Learning with Applications in Autonomous Driving: A Survey</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/0f484778995e9256b53d4087c1e3e6c1.html" rel="alternate" type="text/html" title="Knowledge Augmented Machine Learning with Applications in Autonomous Driving: A Survey" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/0f484778995e9256b53d4087c1e3e6c1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/0f484778995e9256b53d4087c1e3e6c1.html">&lt;p&gt;The existence of representative datasets is a prerequisite of many successful artificial intelligence and machine learning models. However, the subsequent application of these models often involves scenarios that are inadequately represented in the data used for training. The reasons for this are manifold and range from time and cost constraints to ethical considerations. As a consequence, the reliable use of these models, especially in safety-critical applications, is a huge challenge. Leveraging Cites: Anchors: High-Precision Model-Agnostic Explanations&lt;/p&gt;</content><author><name>J Wrmann, D Bogdoll, E Bhrle, H Chen, EF Chuo - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The existence of representative datasets is a prerequisite of many successful artificial intelligence and machine learning models. However, the subsequent application of these models often involves scenarios that are inadequately represented in the data used for training. The reasons for this are manifold and range from time and cost constraints to ethical considerations. As a consequence, the reliable use of these models, especially in safety-critical applications, is a huge challenge. Leveraging Cites: Anchors: High-Precision Model-Agnostic Explanations</summary></entry><entry><title type="html">Polls, clickbait, and commemorative $2 bills</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/143fce89e21b5aaba22f5ae83f1af71d.html" rel="alternate" type="text/html" title="Polls, clickbait, and commemorative $2 bills" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/143fce89e21b5aaba22f5ae83f1af71d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/143fce89e21b5aaba22f5ae83f1af71d.html">&lt;p&gt;OUCI logo Search Analytics About   Polls, clickbait, and commemorative&lt;/p&gt;</content><author><name>E Zeng, M Wei, T Gregersen, T Kohno, F Roesner</name></author><category term="jekyll" /><category term="update" /><summary type="html">OUCI logo Search Analytics About Polls, clickbait, and commemorative</summary></entry><entry><title type="html">CLIP-CLOP: CLIP-Guided Collage and Photomontage</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/14b5482f334f5dfcd6c845090e473d2e.html" rel="alternate" type="text/html" title="CLIP-CLOP: CLIP-Guided Collage and Photomontage" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/14b5482f334f5dfcd6c845090e473d2e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/14b5482f334f5dfcd6c845090e473d2e.html">&lt;p&gt;The unabated mystique of large-scale neural networks, such as the CLIP dual image- and-text encoder, popularized automatically generated art. Increasingly more sophisticated generators enhanced the artworks  realism and visual appearance, and creative prompt engineering enabled stylistic expression. Guided by an artist-in- the-loop ideal, we design a gradient-based generator to produce collages. It requires the human artist to curate libraries of image patches and to describe (with prompts) Cites: On the opportunities and risks of foundation models&lt;/p&gt;</content><author><name>P Mirowski, D Banarse, M Malinowski, S Osindero - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The unabated mystique of large-scale neural networks, such as the CLIP dual image- and-text encoder, popularized automatically generated art. Increasingly more sophisticated generators enhanced the artworks realism and visual appearance, and creative prompt engineering enabled stylistic expression. Guided by an artist-in- the-loop ideal, we design a gradient-based generator to produce collages. It requires the human artist to curate libraries of image patches and to describe (with prompts) Cites: On the opportunities and risks of foundation models</summary></entry><entry><title type="html">Text Analytics</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/1eaa821126831b0b001ab7e5cc98815e.html" rel="alternate" type="text/html" title="Text Analytics" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/1eaa821126831b0b001ab7e5cc98815e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/1eaa821126831b0b001ab7e5cc98815e.html">&lt;p&gt;In the age of big data, organizations and businesses have had to manage and make sense of data generated by a wide variety of systems, processes and transactions. The data contained in traditional relational databases is rather small compared to various sensor or social media data. Cites: W., Lee, K., Toutanova, K.: BERT: Pre-training of Deep&lt;/p&gt;</content><author><name>MS Sivri, BS Korkmaz - Business Analytics for Professionals, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In the age of big data, organizations and businesses have had to manage and make sense of data generated by a wide variety of systems, processes and transactions. The data contained in traditional relational databases is rather small compared to various sensor or social media data. Cites: W., Lee, K., Toutanova, K.: BERT: Pre-training of Deep</summary></entry><entry><title type="html">Implicit Relation Inference with Deep Path Extraction for Commonsense Question Answering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/21d1e2adb73a0050236528f7e41e60a8.html" rel="alternate" type="text/html" title="Implicit Relation Inference with Deep Path Extraction for Commonsense Question Answering" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/21d1e2adb73a0050236528f7e41e60a8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/21d1e2adb73a0050236528f7e41e60a8.html">&lt;p&gt;Natural language inference plays an essential role in Commonsense Question Answering. Conventional models usually adopt keywords in questions and choices as queries to retrieve static and explicit evidence that is used to obtain final answers, where dynamic interaction between different keywords and implicit relations inference of deeper information are often neglected. In this paper, we propose a novel joint model, the Graph Relation retrieval Reasoning Network (GRRN), to Cites: Electra: Pre-training text encoders as discriminators rather than&lt;/p&gt;</content><author><name>P Yang, Z Liu, B Li, P Zhang - Neural Processing Letters, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Natural language inference plays an essential role in Commonsense Question Answering. Conventional models usually adopt keywords in questions and choices as queries to retrieve static and explicit evidence that is used to obtain final answers, where dynamic interaction between different keywords and implicit relations inference of deeper information are often neglected. In this paper, we propose a novel joint model, the Graph Relation retrieval Reasoning Network (GRRN), to Cites: Electra: Pre-training text encoders as discriminators rather than</summary></entry><entry><title type="html">Detecting and Understanding Harmful Memes: A Survey</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/21e443f6b52447281d0cfaab011cbe61.html" rel="alternate" type="text/html" title="Detecting and Understanding Harmful Memes: A Survey" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/21e443f6b52447281d0cfaab011cbe61</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/21e443f6b52447281d0cfaab011cbe61.html">&lt;p&gt;The automatic identification of harmful content online is of major concern for social media platforms, policymakers, and society. Researchers have studied textual, visual, and audio content, but typically in isolation. Yet, harmful content often&lt;/p&gt;</content><author><name>S Sharma, F Alam, M Akhtar, D Dimitrov, GDS Martino - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The automatic identification of harmful content online is of major concern for social media platforms, policymakers, and society. Researchers have studied textual, visual, and audio content, but typically in isolation. Yet, harmful content often</summary></entry><entry><title type="html">Learning Disentangled Textual Representations via Statistical Measures of Similarity</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/28513dd3800db07d1bf0a26dd97d4cbd.html" rel="alternate" type="text/html" title="Learning Disentangled Textual Representations via Statistical Measures of Similarity" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/28513dd3800db07d1bf0a26dd97d4cbd</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/28513dd3800db07d1bf0a26dd97d4cbd.html">&lt;p&gt;When working with textual data, a natural application of disentangled representations is fair classification where the goal is to make predictions without being biased (or influenced) by sensitive attributes that may be present in the data (eg, age, gender or race). Dominant approaches to disentangle a sensitive attribute from textual representations rely on learning simultaneously a penalization term that involves either an adversarial loss (eg, a discriminator) or an information measure Cites: Evaluating Gender Bias in Machine Translation&lt;/p&gt;</content><author><name>P Colombo, G Staerman, N Noiry, P Piantanida - arXiv preprint arXiv:2205.03589, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">When working with textual data, a natural application of disentangled representations is fair classification where the goal is to make predictions without being biased (or influenced) by sensitive attributes that may be present in the data (eg, age, gender or race). Dominant approaches to disentangle a sensitive attribute from textual representations rely on learning simultaneously a penalization term that involves either an adversarial loss (eg, a discriminator) or an information measure Cites: Evaluating Gender Bias in Machine Translation</summary></entry><entry><title type="html">Poster: Comparing Neural Network Solutions in Cryptographic API Completion</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/2cd659bfc722089b6f9f4d1395a2a974.html" rel="alternate" type="text/html" title="Poster: Comparing Neural Network Solutions in Cryptographic API Completion" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/2cd659bfc722089b6f9f4d1395a2a974</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/2cd659bfc722089b6f9f4d1395a2a974.html">&lt;p&gt;With the strong interest in neural network based software engineering approaches and a plethora of proposed solutions, we point out the need for measurement studies in this space. Focusing on a specific application scenario, Java cryptographic API code completion, we outline several potential measurement problems, ranging from embedding design and evaluation, to methodology development of models, and to metrics and benchmarks. Cites: Codebert: A pre-trained model for programming and natural&lt;/p&gt;</content><author><name>Y Xiao, S Ahmed, W Song, B Viswanath, N Meng</name></author><category term="jekyll" /><category term="update" /><summary type="html">With the strong interest in neural network based software engineering approaches and a plethora of proposed solutions, we point out the need for measurement studies in this space. Focusing on a specific application scenario, Java cryptographic API code completion, we outline several potential measurement problems, ranging from embedding design and evaluation, to methodology development of models, and to metrics and benchmarks. Cites: Codebert: A pre-trained model for programming and natural</summary></entry><entry><title type="html">A Song of (Dis) agreement: Evaluating the Evaluation of Explainable Artificial Intelligence in Natural Language Processing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/32d0231a400f54c0af2bc4944fb7020f.html" rel="alternate" type="text/html" title="A Song of (Dis) agreement: Evaluating the Evaluation of Explainable Artificial Intelligence in Natural Language Processing" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/32d0231a400f54c0af2bc4944fb7020f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/32d0231a400f54c0af2bc4944fb7020f.html">&lt;p&gt;There has been significant debate in the NLP community about whether or not attention weights can be used as an explanation-a mechanism for interpreting how important each input token is for a particular prediction. The validity of  attention as explanation  has so far been evaluated by computing the rank correlation between attention-based explanations and existing feature attribution explanations using LSTM-based models. In our work, we (i) compare the rank correlation between five Cites: ERASER: A benchmark to evaluate rationalized NLP models&lt;/p&gt;</content><author><name>M Neely, SF Schouten, M Bleeker, A Lucic - arXiv preprint arXiv:2205.04559, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">There has been significant debate in the NLP community about whether or not attention weights can be used as an explanation-a mechanism for interpreting how important each input token is for a particular prediction. The validity of attention as explanation has so far been evaluated by computing the rank correlation between attention-based explanations and existing feature attribution explanations using LSTM-based models. In our work, we (i) compare the rank correlation between five Cites: ERASER: A benchmark to evaluate rationalized NLP models</summary></entry><entry><title type="html">SYSTEM AND METHODS FOR TRAINING TASK-ORIENTED DIALOGUE (TOD) LANGUAGE MODELS</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/381ef63976171bf7e60da941e8d53b09.html" rel="alternate" type="text/html" title="SYSTEM AND METHODS FOR TRAINING TASK-ORIENTED DIALOGUE (TOD) LANGUAGE MODELS" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/381ef63976171bf7e60da941e8d53b09</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/381ef63976171bf7e60da941e8d53b09.html">&lt;p&gt;Embodiments described herein provide methods and systems for training task- oriented dialogue (TOD) language models. In some embodiments, a TOD language model may receive a TOD dataset including a plurality of dialogues and a model&lt;/p&gt;</content><author><name>C Wu, CH Hoi, R Socher, C Xiong - US Patent App. 17/088,206, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Embodiments described herein provide methods and systems for training task- oriented dialogue (TOD) language models. In some embodiments, a TOD language model may receive a TOD dataset including a plurality of dialogues and a model</summary></entry><entry><title type="html">Re-thinking Knowledge Graph Completion Evaluation from an Information Retrieval Perspective</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/394eaa7b0677804a6e15a9030d2c3596.html" rel="alternate" type="text/html" title="Re-thinking Knowledge Graph Completion Evaluation from an Information Retrieval Perspective" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/394eaa7b0677804a6e15a9030d2c3596</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/394eaa7b0677804a6e15a9030d2c3596.html">&lt;p&gt;Knowledge graph completion (KGC) aims to infer missing knowledge triples based on known facts in a knowledge graph. Current KGC research mostly follows an entity ranking protocol, wherein the effectiveness is measured by the predicted rank of a masked entity in a test triple. The overall performance is then given by a micro (- average) metric over all individual answer entities. Due to the incomplete nature of the large-scale knowledge bases, such an entity ranking setting is likely affected by Cites: Text generation from knowledge graphs with graph transformers&lt;/p&gt;</content><author><name>Y Zhou, X Chen, B He, Z Ye, L Sun - arXiv preprint arXiv:2205.04105, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Knowledge graph completion (KGC) aims to infer missing knowledge triples based on known facts in a knowledge graph. Current KGC research mostly follows an entity ranking protocol, wherein the effectiveness is measured by the predicted rank of a masked entity in a test triple. The overall performance is then given by a micro (- average) metric over all individual answer entities. Due to the incomplete nature of the large-scale knowledge bases, such an entity ranking setting is likely affected by Cites: Text generation from knowledge graphs with graph transformers</summary></entry><entry><title type="html">An occupant-centered approach to improve both his comfort and the energy efficiency of the building</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/3e5b5eabe30587a74f4ade343f0b530a.html" rel="alternate" type="text/html" title="An occupant-centered approach to improve both his comfort and the energy efficiency of the building" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/3e5b5eabe30587a74f4ade343f0b530a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/3e5b5eabe30587a74f4ade343f0b530a.html">&lt;p&gt;The accelerating depletion of fossil fuel reserves and the growing awareness about climate issues have put forth a plethora of interesting approaches that attempt to tackle the crucial problem of energy saving, specifically in buildings, known as a major energy consumer. Existing approaches tackle the problem of energy efficiency in buildings by proposing model-based approaches such as knowledge models (thermal, CO 2, cost, etc.) and regressive models. However, different factors make the Cites:   Why Should I Trust You? : Explaining the Predictions of Any&lt;/p&gt;</content><author><name>F Boulmaiz, P Reignier, S Ploix - Knowledge-Based Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The accelerating depletion of fossil fuel reserves and the growing awareness about climate issues have put forth a plethora of interesting approaches that attempt to tackle the crucial problem of energy saving, specifically in buildings, known as a major energy consumer. Existing approaches tackle the problem of energy efficiency in buildings by proposing model-based approaches such as knowledge models (thermal, CO 2, cost, etc.) and regressive models. However, different factors make the Cites: Why Should I Trust You? : Explaining the Predictions of Any</summary></entry><entry><title type="html">Building Machine Translation Systems for the Next Thousand Languages</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/405cfa8ec321d0eb02e7da97aa3b765f.html" rel="alternate" type="text/html" title="Building Machine Translation Systems for the Next Thousand Languages" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/405cfa8ec321d0eb02e7da97aa3b765f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/405cfa8ec321d0eb02e7da97aa3b765f.html">&lt;p&gt;In this paper we share findings from our effort to build practical machine translation (MT) systems capable of translating across over one thousand languages. We describe results in three research domains:(i) Building clean, web-mined datasets for 1500+ languages by leveraging semi-supervised pre-training for language identification and developing data-driven filtering techniques;(ii) Developing practical MT models for under-served languages by leveraging massively multilingual models Cites: AfroMT: Pretraining Strategies and Reproducible Benchmarks for&lt;/p&gt;</content><author><name>A Bapna, I Caswell, J Kreutzer, O Firat, D van Esch - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper we share findings from our effort to build practical machine translation (MT) systems capable of translating across over one thousand languages. We describe results in three research domains:(i) Building clean, web-mined datasets for 1500+ languages by leveraging semi-supervised pre-training for language identification and developing data-driven filtering techniques;(ii) Developing practical MT models for under-served languages by leveraging massively multilingual models Cites: AfroMT: Pretraining Strategies and Reproducible Benchmarks for</summary></entry><entry><title type="html">CogIntAc: Modeling the Relationships between Intention, Emotion and Action in Interactive Process from Cognitive Perspective</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/43befe2b37b65188caeeb78cffd8bb0d.html" rel="alternate" type="text/html" title="CogIntAc: Modeling the Relationships between Intention, Emotion and Action in Interactive Process from Cognitive Perspective" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/43befe2b37b65188caeeb78cffd8bb0d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/43befe2b37b65188caeeb78cffd8bb0d.html">&lt;p&gt;Intention, emotion and action are important psychological factors in human activities, which play an important role in the interaction between individuals. How to model the interaction process between individuals by analyzing the relationship of their intentions, emotions, and actions at the cognitive level is challenging. In this paper, we propose a novel cognitive framework of individual interaction. The core of the framework is that individuals achieve interaction through external action driven by Cites: Abductive commonsense reasoning&lt;/p&gt;</content><author><name>W Peng, Y Hu, Y Xie, L Xing, Y Sun - arXiv preprint arXiv:2205.03540, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Intention, emotion and action are important psychological factors in human activities, which play an important role in the interaction between individuals. How to model the interaction process between individuals by analyzing the relationship of their intentions, emotions, and actions at the cognitive level is challenging. In this paper, we propose a novel cognitive framework of individual interaction. The core of the framework is that individuals achieve interaction through external action driven by Cites: Abductive commonsense reasoning</summary></entry><entry><title type="html">Personalized Abstractive Opinion Tagging</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/46603e59e50f79b3fac04d8fa5421822.html" rel="alternate" type="text/html" title="Personalized Abstractive Opinion Tagging" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/46603e59e50f79b3fac04d8fa5421822</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/46603e59e50f79b3fac04d8fa5421822.html">&lt;p&gt;An opinion tag is a sequence of words on a specific aspect of a product or service. Opinion tags reflect key characteristics of product reviews and help users quickly understand their content in ecommerce portals. The task of abstractive opinion tagging has previously been proposed to automatically generate a ranked list of opinion tags for a given review. However, current models for opinion tagging are not personalized, even though personalization is an essential ingredient of engaging Cites: Few-shot learning for opinion summarization&lt;/p&gt;</content><author><name>M Zhao, Y Yang, M Li, J Wang, W Wu, P Ren - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">An opinion tag is a sequence of words on a specific aspect of a product or service. Opinion tags reflect key characteristics of product reviews and help users quickly understand their content in ecommerce portals. The task of abstractive opinion tagging has previously been proposed to automatically generate a ranked list of opinion tags for a given review. However, current models for opinion tagging are not personalized, even though personalization is an essential ingredient of engaging Cites: Few-shot learning for opinion summarization</summary></entry><entry><title type="html">When a sentence does not introduce a discourse entity, Transformer-based models still sometimes refer to it</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/496cd4b9845647d18073925df7eaebc7.html" rel="alternate" type="text/html" title="When a sentence does not introduce a discourse entity, Transformer-based models still sometimes refer to it" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/496cd4b9845647d18073925df7eaebc7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/496cd4b9845647d18073925df7eaebc7.html">&lt;p&gt;Understanding longer narratives or participating in conversations requires tracking of discourse entities that have been mentioned. Indefinite noun phrases (NPs), such as a dog , frequently introduce discourse entities but this behavior is modulated by sentential operators such as negation. For example, a dog in Arthur doesn t own a dog does not introduce a discourse entity due to the presence of negation. In this work, we adapt the psycholinguistic assessment of language models paradigm to Cites: PlotMachines: Outline-conditioned generation with dynamic plot&lt;/p&gt;</content><author><name>S Schuster, T Linzen - arXiv preprint arXiv:2205.03472, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Understanding longer narratives or participating in conversations requires tracking of discourse entities that have been mentioned. Indefinite noun phrases (NPs), such as a dog , frequently introduce discourse entities but this behavior is modulated by sentential operators such as negation. For example, a dog in Arthur doesn t own a dog does not introduce a discourse entity due to the presence of negation. In this work, we adapt the psycholinguistic assessment of language models paradigm to Cites: PlotMachines: Outline-conditioned generation with dynamic plot</summary></entry><entry><title type="html">Distributional Semantics Still Can t Account for Affordances</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/4c04220668f2794d38d9eeeabcc918c7.html" rel="alternate" type="text/html" title="Distributional Semantics Still Can t Account for Affordances" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/4c04220668f2794d38d9eeeabcc918c7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/4c04220668f2794d38d9eeeabcc918c7.html">&lt;p&gt;Can we know a word by the company it keeps? Aspects of meaning that concern physical interactions might be particularly difficult to learn from language alone. Glenberg and Robertson (2000) found that although human comprehenders were sensitive to the distinction between afforded and nonafforded actions, distributional semantic models were not. We tested whether technological advances have made distributional models more sensitive to affordances by replicating their experiment Cites: Experience grounds language&lt;/p&gt;</content><author><name>CR Jones, TA Chang, S Coulson, JA Michaelov, S Trott</name></author><category term="jekyll" /><category term="update" /><summary type="html">Can we know a word by the company it keeps? Aspects of meaning that concern physical interactions might be particularly difficult to learn from language alone. Glenberg and Robertson (2000) found that although human comprehenders were sensitive to the distinction between afforded and nonafforded actions, distributional semantic models were not. We tested whether technological advances have made distributional models more sensitive to affordances by replicating their experiment Cites: Experience grounds language</summary></entry><entry><title type="html">Scheduled Multi-task Learning for Neural Chat Translation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/4fd18eda19aa3242f0a37e67060c0513.html" rel="alternate" type="text/html" title="Scheduled Multi-task Learning for Neural Chat Translation" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/4fd18eda19aa3242f0a37e67060c0513</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/4fd18eda19aa3242f0a37e67060c0513.html">&lt;p&gt;Neural Chat Translation (NCT) aims to translate conversational text into different languages. Existing methods mainly focus on modeling the bilingual dialogue characteristics (eg, coherence) to improve chat translation via multi-task learning on small-scale chat translation data. Although the NCT models have achieved impressive success, it is still far from satisfactory due to insufficient chat translation data and simple joint training manners. To address the above issues, we propose a Cites: Automatic evaluation of text coherence: Models and representations&lt;/p&gt;</content><author><name>Y Liang, F Meng, J Xu, Y Chen, J Zhou - arXiv preprint arXiv:2205.03766, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Neural Chat Translation (NCT) aims to translate conversational text into different languages. Existing methods mainly focus on modeling the bilingual dialogue characteristics (eg, coherence) to improve chat translation via multi-task learning on small-scale chat translation data. Although the NCT models have achieved impressive success, it is still far from satisfactory due to insufficient chat translation data and simple joint training manners. To address the above issues, we propose a Cites: Automatic evaluation of text coherence: Models and representations</summary></entry><entry><title type="html">Automatic Noisy Label Correction for Fine-Grained Entity Typing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/5b730fe9cd56145b65f43982c527bd09.html" rel="alternate" type="text/html" title="Automatic Noisy Label Correction for Fine-Grained Entity Typing" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/5b730fe9cd56145b65f43982c527bd09</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/5b730fe9cd56145b65f43982c527bd09.html">&lt;p&gt;Fine-grained entity typing (FET) aims to assign proper semantic types to entity mentions according to their context, which is a fundamental task in various entity- leveraging applications. Current FET systems usually establish on large-scale weakly-supervised/distantly annotation data, which may contain abundant noise and thus severely hinder the performance of the FET task. Although previous studies have made great success in automatically identifying the noisy labels in FET, they Cites: Dividemix: Learning with noisy labels as semi-supervised learning&lt;/p&gt;</content><author><name>W Pan, W Wei, F Zhu - arXiv preprint arXiv:2205.03011, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Fine-grained entity typing (FET) aims to assign proper semantic types to entity mentions according to their context, which is a fundamental task in various entity- leveraging applications. Current FET systems usually establish on large-scale weakly-supervised/distantly annotation data, which may contain abundant noise and thus severely hinder the performance of the FET task. Although previous studies have made great success in automatically identifying the noisy labels in FET, they Cites: Dividemix: Learning with noisy labels as semi-supervised learning</summary></entry><entry><title type="html">Attribution-based Task-specific Pruning for Multi-task Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/5c007a9aaedd8d9f4ac7db57673548e0.html" rel="alternate" type="text/html" title="Attribution-based Task-specific Pruning for Multi-task Language Models" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/5c007a9aaedd8d9f4ac7db57673548e0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/5c007a9aaedd8d9f4ac7db57673548e0.html">&lt;p&gt;Multi-task language models show outstanding performance for various natural language understanding tasks with only a single model. However, these language models inevitably utilize unnecessary large-scale model parameters, even when they are used for only a specific task. In this paper, we propose a novel training-free task-specific pruning method for multi-task language models. Specifically, we utilize an attribution method to compute the importance of each neuron for performing a Cites: Mobilebert: a compact task-agnostic bert for resource-limited devices&lt;/p&gt;</content><author><name>N Yang, Y Jang, H Lee, S Jung, K Jung - arXiv preprint arXiv:2205.04157, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Multi-task language models show outstanding performance for various natural language understanding tasks with only a single model. However, these language models inevitably utilize unnecessary large-scale model parameters, even when they are used for only a specific task. In this paper, we propose a novel training-free task-specific pruning method for multi-task language models. Specifically, we utilize an attribution method to compute the importance of each neuron for performing a Cites: Mobilebert: a compact task-agnostic bert for resource-limited devices</summary></entry><entry><title type="html">Hierarchical Heterogeneous Graph Attention Network for Syntax-Aware Summarization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/5f17e3a2b0f3a080a49709c766749882.html" rel="alternate" type="text/html" title="Hierarchical Heterogeneous Graph Attention Network for Syntax-Aware Summarization" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/5f17e3a2b0f3a080a49709c766749882</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/5f17e3a2b0f3a080a49709c766749882.html">&lt;p&gt;The task of summarization often requires a non-trivial understanding of the given text at the semantic level. In this work, we essentially incorporate the constituent structure into the single document summarization via the Graph Neural Networks to learn the semantic meaning of tokens. More specifically, we propose a novel hierarchical heterogeneous graph attention network over constituency-based parse trees for syntax-aware summarization. This approach reflects psychological findings that Cites: Discourse-Aware Neural Extractive Text Summarization&lt;/p&gt;</content><author><name>Z Song, I King - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The task of summarization often requires a non-trivial understanding of the given text at the semantic level. In this work, we essentially incorporate the constituent structure into the single document summarization via the Graph Neural Networks to learn the semantic meaning of tokens. More specifically, we propose a novel hierarchical heterogeneous graph attention network over constituency-based parse trees for syntax-aware summarization. This approach reflects psychological findings that Cites: Discourse-Aware Neural Extractive Text Summarization</summary></entry><entry><title type="html">AI Governance in the System Development Life Cycle: Insights on Responsible Machine Learning Engineering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/63f4be2526541c8a29cc9f7fd4915574.html" rel="alternate" type="text/html" title="AI Governance in the System Development Life Cycle: Insights on Responsible Machine Learning Engineering" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/63f4be2526541c8a29cc9f7fd4915574</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/63f4be2526541c8a29cc9f7fd4915574.html">&lt;p&gt;In this study we explore the incorporation of artificial intelligence (AI) governance to system development life cycle (SDLC) models. We conducted expert interviews among AI and SDLC professionals and analyzed the interview data using qualitative coding and clustering to extract AI governance concepts. Subsequently, we mapped these concepts onto three stages in the machine learning (ML) system development process:(1) design,(2) development, and (3) operation. We discovered 20 Cites: Model-agnostic interpretability of machine learning&lt;/p&gt;</content><author><name>S Laato, T Birkstedt, M Mntymki, M Minkkinen - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this study we explore the incorporation of artificial intelligence (AI) governance to system development life cycle (SDLC) models. We conducted expert interviews among AI and SDLC professionals and analyzed the interview data using qualitative coding and clustering to extract AI governance concepts. Subsequently, we mapped these concepts onto three stages in the machine learning (ML) system development process:(1) design,(2) development, and (3) operation. We discovered 20 Cites: Model-agnostic interpretability of machine learning</summary></entry><entry><title type="html">A Survey on AI Sustainability: Emerging Trends on Learning Algorithms and Research Challenges</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/64174e99433f0b7380698050871047ca.html" rel="alternate" type="text/html" title="A Survey on AI Sustainability: Emerging Trends on Learning Algorithms and Research Challenges" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/64174e99433f0b7380698050871047ca</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/64174e99433f0b7380698050871047ca.html">&lt;p&gt;Artificial Intelligence (AI) is a fast-growing research and development (R&amp;amp;D) discipline which is attracting increasing attention because of its promises to bring vast benefits for consumers and businesses, with considerable benefits promised in productivity growth and innovation. To date it has reported significant accomplishments in many areas that have been deemed as challenging for machines, ranging from computer vision, natural language processing, audio Cites: Anchors: High-Precision Model-Agnostic Explanations&lt;/p&gt;</content><author><name>Z Chen, M Wu, A Chan, X Li, YS Ong - arXiv preprint arXiv:2205.03824, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Artificial Intelligence (AI) is a fast-growing research and development (R&amp;amp;D) discipline which is attracting increasing attention because of its promises to bring vast benefits for consumers and businesses, with considerable benefits promised in productivity growth and innovation. To date it has reported significant accomplishments in many areas that have been deemed as challenging for machines, ranging from computer vision, natural language processing, audio Cites: Anchors: High-Precision Model-Agnostic Explanations</summary></entry><entry><title type="html">Localized Adversarial Domain Generalization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/648d1c2663e923b0735e09448aa30857.html" rel="alternate" type="text/html" title="Localized Adversarial Domain Generalization" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/648d1c2663e923b0735e09448aa30857</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/648d1c2663e923b0735e09448aa30857.html">&lt;p&gt;Deep learning methods can struggle to handle domain shifts not seen in training data, which can cause them to not generalize well to unseen domains. This has led to research attention on domain generalization (DG), which aims to the model s generalization ability to out-of-distribution. Adversarial domain generalization is a popular approach to DG, but conventional approaches (1) struggle to sufficiently align features so that local neighborhoods are mixed across domains; and (2) can Cites: Wilds: A benchmark of in-the-wild distribution shifts&lt;/p&gt;</content><author><name>W Zhu, L Lu, J Xiao, M Han, J Luo, AP Harrison - arXiv preprint arXiv:2205.04114, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning methods can struggle to handle domain shifts not seen in training data, which can cause them to not generalize well to unseen domains. This has led to research attention on domain generalization (DG), which aims to the model s generalization ability to out-of-distribution. Adversarial domain generalization is a popular approach to DG, but conventional approaches (1) struggle to sufficiently align features so that local neighborhoods are mixed across domains; and (2) can Cites: Wilds: A benchmark of in-the-wild distribution shifts</summary></entry><entry><title type="html">A survey of Adversarial Defences and Robustness in NLP</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/64d6a42c450b4a3b5c719ebc3d9bde5e.html" rel="alternate" type="text/html" title="A survey of Adversarial Defences and Robustness in NLP" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/64d6a42c450b4a3b5c719ebc3d9bde5e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/64d6a42c450b4a3b5c719ebc3d9bde5e.html">&lt;p&gt;Authors  addresses: Shreya Goyal, Robert Bosch Centre for Data Science and AI, Indian Institute of Technology Madras, Bhupat and Jyoti Mehta School of Biosciences,, Chennai, Tamil Nadu, India, 600036; Sumanth Doddapaneni, Robert Bosch Centre for Data Science and AI, Indian Institute of Technology Madras, Bhupat and Jyoti Mehta School of Biosciences,, Chennai, Tamil Nadu, India, 600036; Mitesh M. Khapra, Robert Bosch Centre for Data Science and AI, Indian Institute of Cites: Avoiding the hypothesis-only bias in natural language inference&lt;/p&gt;</content><author><name>G SHREYA, MM KHAPRA - arXiv preprint arXiv:2203.06414, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Authors addresses: Shreya Goyal, Robert Bosch Centre for Data Science and AI, Indian Institute of Technology Madras, Bhupat and Jyoti Mehta School of Biosciences,, Chennai, Tamil Nadu, India, 600036; Sumanth Doddapaneni, Robert Bosch Centre for Data Science and AI, Indian Institute of Technology Madras, Bhupat and Jyoti Mehta School of Biosciences,, Chennai, Tamil Nadu, India, 600036; Mitesh M. Khapra, Robert Bosch Centre for Data Science and AI, Indian Institute of Cites: Avoiding the hypothesis-only bias in natural language inference</summary></entry><entry><title type="html">Explainable AI for Cheating Detection and Churn Prediction in Online Games</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/66a30fb44b02f30b311e705344712600.html" rel="alternate" type="text/html" title="Explainable AI for Cheating Detection and Churn Prediction in Online Games" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/66a30fb44b02f30b311e705344712600</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/66a30fb44b02f30b311e705344712600.html">&lt;p&gt;Online gaming is a multi-billion dollar industry that entertains a large, global population. Empowering online games with AI has made a great success, however, ignores the explainability of black-box model makes AI less responsible and hinders its further development. In this paper, we introduce and discuss the audience and the concept of XAI (eXplainable AI) in online games. We propose a GXAI workflow which combines the strong expressiveness of multi-view data sources and the clear Cites: Anchors: High-Precision Model-Agnostic Explanations&lt;/p&gt;</content><author><name>Y Xiong, J Tao, S Zhao, R Wu, X Shen, T Lyu, C Fan - IEEE Transactions on , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Online gaming is a multi-billion dollar industry that entertains a large, global population. Empowering online games with AI has made a great success, however, ignores the explainability of black-box model makes AI less responsible and hinders its further development. In this paper, we introduce and discuss the audience and the concept of XAI (eXplainable AI) in online games. We propose a GXAI workflow which combines the strong expressiveness of multi-view data sources and the clear Cites: Anchors: High-Precision Model-Agnostic Explanations</summary></entry><entry><title type="html">Dimension Reduction for Efficient Dense Retrieval via Conditional Autoencoder</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/66e59e2a72965f1f4cf66fec78114621.html" rel="alternate" type="text/html" title="Dimension Reduction for Efficient Dense Retrieval via Conditional Autoencoder" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/66e59e2a72965f1f4cf66fec78114621</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/66e59e2a72965f1f4cf66fec78114621.html">&lt;p&gt;Dense retrievers encode texts and map them in an embedding space using pre- trained language models. These embeddings are critical to keep high-dimensional for effectively training dense retrievers, but lead to a high cost of storing index and retrieval. To reduce the embedding dimensions of dense retrieval, this paper proposes a Conditional Autoencoder (ConAE) to compress the high-dimensional embeddings to maintain the same embedding distribution and better recover the Cites: Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, and Wentau&lt;/p&gt;</content><author><name>Z Liu, H Zhang, C Xiong, Z Liu, Y Gu, X Li - arXiv preprint arXiv:2205.03284, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Dense retrievers encode texts and map them in an embedding space using pre- trained language models. These embeddings are critical to keep high-dimensional for effectively training dense retrievers, but lead to a high cost of storing index and retrieval. To reduce the embedding dimensions of dense retrieval, this paper proposes a Conditional Autoencoder (ConAE) to compress the high-dimensional embeddings to maintain the same embedding distribution and better recover the Cites: Sewon Min, Ledell Wu, Sergey Edunov, Danqi Chen, and Wentau</summary></entry><entry><title type="html">RESIN-11: Schema-guided Event Prediction for 11 Newsworthy Scenarios</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/69a93412cad79ac11bcc438365ccf22b.html" rel="alternate" type="text/html" title="RESIN-11: Schema-guided Event Prediction for 11 Newsworthy Scenarios" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/69a93412cad79ac11bcc438365ccf22b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/69a93412cad79ac11bcc438365ccf22b.html">&lt;p&gt;We introduce RESIN-11, a new schema-guided event extraction and prediction system that can be applied to a large variety of newsworthy scenarios. The framework consists of two parts:(1) an open-domain end-to-end multimedia multilingual information extraction system with weak-supervision and zero-shot learningbased techniques.(2) a schema matching and schema-guided event prediction system based on our curated schema library. We build a demo website 1 Cites: The Future is not One-dimensional: Complex Event Schema&lt;/p&gt;</content><author><name>X Du, Z Zhang, S Li, P Yu, H Wang, TM Lai, X Lin - Proc. 2022 Annual , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We introduce RESIN-11, a new schema-guided event extraction and prediction system that can be applied to a large variety of newsworthy scenarios. The framework consists of two parts:(1) an open-domain end-to-end multimedia multilingual information extraction system with weak-supervision and zero-shot learningbased techniques.(2) a schema matching and schema-guided event prediction system based on our curated schema library. We build a demo website 1 Cites: The Future is not One-dimensional: Complex Event Schema</summary></entry><entry><title type="html">Better Retrieval May Not Lead to Better Question Answering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/70cae4557da1ea17919c06bd7e97d556.html" rel="alternate" type="text/html" title="Better Retrieval May Not Lead to Better Question Answering" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/70cae4557da1ea17919c06bd7e97d556</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/70cae4557da1ea17919c06bd7e97d556.html">&lt;p&gt;Considerable progress has been made recently in open-domain question answering (QA) problems, which require Information Retrieval (IR) and Reading Comprehension (RC). A popular approach to improve the system s performance is to improve the quality of the retrieved context from the IR stage. In this work we show that for StrategyQA, a challenging open-domain QA dataset that requires multi-hop reasoning, this common approach is surprisingly ineffective–improving the quality of Cites: Answering Open-Domain Questions of Varying Reasoning Steps&lt;/p&gt;</content><author><name>Z Liang, T Khot, S Bethard, M Surdeanu, A Sabharwal - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Considerable progress has been made recently in open-domain question answering (QA) problems, which require Information Retrieval (IR) and Reading Comprehension (RC). A popular approach to improve the system s performance is to improve the quality of the retrieved context from the IR stage. In this work we show that for StrategyQA, a challenging open-domain QA dataset that requires multi-hop reasoning, this common approach is surprisingly ineffective–improving the quality of Cites: Answering Open-Domain Questions of Varying Reasoning Steps</summary></entry><entry><title type="html">Graph Spectral Embedding using the Geodesic Betweeness Centrality</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/71abe5b8cb30664f52f8c334df5ddf93.html" rel="alternate" type="text/html" title="Graph Spectral Embedding using the Geodesic Betweeness Centrality" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/71abe5b8cb30664f52f8c334df5ddf93</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/71abe5b8cb30664f52f8c334df5ddf93.html">&lt;p&gt;We introduce the Graph Sylvester Embedding (GSE), an unsupervised graph representation of local similarity, connectivity, and global structure. GSE uses the solution of the Sylvester equation to capture both network structure and neighborhood proximity in a single representation. Unlike embeddings based on the eigenvectors of the Laplacian, GSE incorporates two or more basis functions, for instance using the Laplacian and the affinity matrix. Such basis functions are Cites: A regularization framework for learning from graph data&lt;/p&gt;</content><author><name>S Deutsch, S Soatto - arXiv preprint arXiv:2205.03544, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We introduce the Graph Sylvester Embedding (GSE), an unsupervised graph representation of local similarity, connectivity, and global structure. GSE uses the solution of the Sylvester equation to capture both network structure and neighborhood proximity in a single representation. Unlike embeddings based on the eigenvectors of the Laplacian, GSE incorporates two or more basis functions, for instance using the Laplacian and the affinity matrix. Such basis functions are Cites: A regularization framework for learning from graph data</summary></entry><entry><title type="html">Unsupervised Slot Schema Induction for Task-oriented Dialog</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/77244dc37593cdf8a01a930b227ad5bc.html" rel="alternate" type="text/html" title="Unsupervised Slot Schema Induction for Task-oriented Dialog" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/77244dc37593cdf8a01a930b227ad5bc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/77244dc37593cdf8a01a930b227ad5bc.html">&lt;p&gt;Carefully-designed schemas describing how to collect and annotate dialog corpora are a prerequisite towards building task-oriented dialog systems. In practical applications, manually designing schemas can be error-prone, laborious, iterative, and slow, especially when the schema is complicated. To alleviate this expensive and time consuming process, we propose an unsupervised approach for slot schema induction from unlabeled dialog corpora. Leveraging in-domain language models Cites: Unsupervised induction of semantic roles&lt;/p&gt;</content><author><name>D Yu, M Wang, Y Cao, I Shafran, LE Shafey, H Soltau - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Carefully-designed schemas describing how to collect and annotate dialog corpora are a prerequisite towards building task-oriented dialog systems. In practical applications, manually designing schemas can be error-prone, laborious, iterative, and slow, especially when the schema is complicated. To alleviate this expensive and time consuming process, we propose an unsupervised approach for slot schema induction from unlabeled dialog corpora. Leveraging in-domain language models Cites: Unsupervised induction of semantic roles</summary></entry><entry><title type="html">Encouraging Human Interaction with Robot Teams: Legible and Fair Subtask Allocations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/7801a6e515671538193c75423d508584.html" rel="alternate" type="text/html" title="Encouraging Human Interaction with Robot Teams: Legible and Fair Subtask Allocations" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/7801a6e515671538193c75423d508584</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/7801a6e515671538193c75423d508584.html">&lt;p&gt;Recent works explore collaboration between humans and teams of robots. These approaches make sense if the human is already working with the robot team; but how should robots encourage nearby humans to join their teams in the first place? Inspired by behavioral economics, we recognize that humans care about more than just team efficiency–humans also have biases and expectations for team dynamics. Our hypothesis is that the way inclusive robots divide the task (ie, how the robots split Cites: Legibility and predictability of robot motion&lt;/p&gt;</content><author><name>S Habibian, DP Losey - arXiv preprint arXiv:2205.03477, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent works explore collaboration between humans and teams of robots. These approaches make sense if the human is already working with the robot team; but how should robots encourage nearby humans to join their teams in the first place? Inspired by behavioral economics, we recognize that humans care about more than just team efficiency–humans also have biases and expectations for team dynamics. Our hypothesis is that the way inclusive robots divide the task (ie, how the robots split Cites: Legibility and predictability of robot motion</summary></entry><entry><title type="html">Functional Intelligence-Based Scene Recognition Scheme for MAV Environment-Adaptive Navigation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/7ddf994918ccdb71d485ae5f0c1e16c8.html" rel="alternate" type="text/html" title="Functional Intelligence-Based Scene Recognition Scheme for MAV Environment-Adaptive Navigation" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/7ddf994918ccdb71d485ae5f0c1e16c8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/7ddf994918ccdb71d485ae5f0c1e16c8.html">&lt;p&gt;Adaptive navigation is the core of micro aerial vehicles (MAVs) conducting autonomous flights in diverse environments. Different navigation techniques are adopted according to the availability of navigation signals in the environment. MAVs must navigate using scene recognition technology to ensure the continuity and reliability of the flight. Therefore, our work investigated the scene recognition method for MAV environment-adaptive navigation. First, we exploited the functional Cites: Learning phrase representations using RNN encoder-decoder for&lt;/p&gt;</content><author><name>L Wang, Y Liu, L Fu, Y Wang, N Tang - Drones, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Adaptive navigation is the core of micro aerial vehicles (MAVs) conducting autonomous flights in diverse environments. Different navigation techniques are adopted according to the availability of navigation signals in the environment. MAVs must navigate using scene recognition technology to ensure the continuity and reliability of the flight. Therefore, our work investigated the scene recognition method for MAV environment-adaptive navigation. First, we exploited the functional Cites: Learning phrase representations using RNN encoder-decoder for</summary></entry><entry><title type="html">Beyond backpropagation: implicit gradients for bilevel optimization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/82572b312b23cd59d4e7366089672b8a.html" rel="alternate" type="text/html" title="Beyond backpropagation: implicit gradients for bilevel optimization" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/82572b312b23cd59d4e7366089672b8a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/82572b312b23cd59d4e7366089672b8a.html">&lt;p&gt;This paper reviews gradient-based techniques to solve bilevel optimization problems. Bilevel optimization is a general way to frame the learning of systems that are implicitly defined through a quantity that they minimize. This characterization can be applied to neural networks, optimizers, algorithmic solvers and even physical systems, and allows for greater modeling flexibility compared to an explicit definition of such systems. Here we focus on gradient-based approaches that solve such Cites: A unified framework of online learning algorithms for training&lt;/p&gt;</content><author><name>N Zucchet, J Sacramento - arXiv preprint arXiv:2205.03076, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper reviews gradient-based techniques to solve bilevel optimization problems. Bilevel optimization is a general way to frame the learning of systems that are implicitly defined through a quantity that they minimize. This characterization can be applied to neural networks, optimizers, algorithmic solvers and even physical systems, and allows for greater modeling flexibility compared to an explicit definition of such systems. Here we focus on gradient-based approaches that solve such Cites: A unified framework of online learning algorithms for training</summary></entry><entry><title type="html">An Application-Oblivious Memory Scheduling System for DNN Accelerators</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/8555c1ceb50838dd2582d492981e8aee.html" rel="alternate" type="text/html" title="An Application-Oblivious Memory Scheduling System for DNN Accelerators" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/8555c1ceb50838dd2582d492981e8aee</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/8555c1ceb50838dd2582d492981e8aee.html">&lt;p&gt;Deep Neural Networks (DNNs) tend to go deeper and wider, which poses a significant challenge to the training of DNNs, due to the limited memory capacity of DNN accelerators. Existing solutions for memory-efficient DNN training are densely coupled with the application features of DNN workloads, eg, layer structures or computational graphs of DNNs are necessary for these solutions. This would result in weak versatility for DNNs with sophisticated layer structures or complicated Cites: BERT: pre-training of deep bidirectional transformers for language&lt;/p&gt;</content><author><name>J Li, X Wang, X Chen, G Li, X Dong, P Zhao, X Yu - ACM Transactions on , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep Neural Networks (DNNs) tend to go deeper and wider, which poses a significant challenge to the training of DNNs, due to the limited memory capacity of DNN accelerators. Existing solutions for memory-efficient DNN training are densely coupled with the application features of DNN workloads, eg, layer structures or computational graphs of DNNs are necessary for these solutions. This would result in weak versatility for DNNs with sophisticated layer structures or complicated Cites: BERT: pre-training of deep bidirectional transformers for language</summary></entry><entry><title type="html">Exploring Tourists Food and Beverage Spots in an Urban Destination Using a Spatialtemporal Approach</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/8a2384eefdd886a1ce3e92b207a6a0d2.html" rel="alternate" type="text/html" title="Exploring Tourists Food and Beverage Spots in an Urban Destination Using a Spatialtemporal Approach" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/8a2384eefdd886a1ce3e92b207a6a0d2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/8a2384eefdd886a1ce3e92b207a6a0d2.html">&lt;p&gt;An important part of planning a trip involves not only search for accommodation, but for food and beverage spots as well, to enhance the visitor s travel experience, especially when the trip involves visits to major urban centers. The agony and/or joy of tourists to meet the desired destinations can be seen nowadays in the continuous and overwhelming number of posts of their exact geographical position whereabouts together with evaluations of the provided travel services, using social networks and Cites: Automatic construction of travel itineraries using social breadcrumbs&lt;/p&gt;</content><author><name>IA Nikas, A Koutras, A Panagopoulos, A Vasileiadis - Transcending Borders in , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">An important part of planning a trip involves not only search for accommodation, but for food and beverage spots as well, to enhance the visitor s travel experience, especially when the trip involves visits to major urban centers. The agony and/or joy of tourists to meet the desired destinations can be seen nowadays in the continuous and overwhelming number of posts of their exact geographical position whereabouts together with evaluations of the provided travel services, using social networks and Cites: Automatic construction of travel itineraries using social breadcrumbs</summary></entry><entry><title type="html">Extraction of Competing Models using Distant Supervision and Graph Ranking</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/905ec9a72921877ee69226cc75e2e70d.html" rel="alternate" type="text/html" title="Extraction of Competing Models using Distant Supervision and Graph Ranking" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/905ec9a72921877ee69226cc75e2e70d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/905ec9a72921877ee69226cc75e2e70d.html">&lt;p&gt;We introduce the task of detection of competing model entities from scientific documents. We define competing models as those models that solve a particular task that is investigated in the target research document. The task is challenging due to the fact that contextual information is required from the entire target document to predict the model entities. Hence, traditional sequence labelling approaches fail in such settings. Furthermore, model entities themselves are long-tailed in nature, ie Cites: SciREX: A challenge dataset for document-level information&lt;/p&gt;</content><author><name>S Daw, V Pudi - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We introduce the task of detection of competing model entities from scientific documents. We define competing models as those models that solve a particular task that is investigated in the target research document. The task is challenging due to the fact that contextual information is required from the entire target document to predict the model entities. Hence, traditional sequence labelling approaches fail in such settings. Furthermore, model entities themselves are long-tailed in nature, ie Cites: SciREX: A challenge dataset for document-level information</summary></entry><entry><title type="html">ProQA: Structural Prompt-based Pre-training for Unified Question Answering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/91f8aff8daf06d5fefda1ff001677bdb.html" rel="alternate" type="text/html" title="ProQA: Structural Prompt-based Pre-training for Unified Question Answering" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/91f8aff8daf06d5fefda1ff001677bdb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/91f8aff8daf06d5fefda1ff001677bdb.html">&lt;p&gt;Question Answering (QA) is a longstanding challenge in natural language processing. Existing QA works mostly focus on specific question types, knowledge domains, or reasoning skills. The specialty in QA research hinders systems from modeling commonalities between tasks and generalization for wider applications. To address this issue, we present ProQA, a unified QA paradigm that solves various tasks through a single model. ProQA takes a unified structural prompt as the bridge Cites: BoolQ: Exploring the surprising difficulty of natural yes/no questions&lt;/p&gt;</content><author><name>W Zhong, Y Gao, N Ding, Y Qin, Z Liu, M Zhou, J Wang - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Question Answering (QA) is a longstanding challenge in natural language processing. Existing QA works mostly focus on specific question types, knowledge domains, or reasoning skills. The specialty in QA research hinders systems from modeling commonalities between tasks and generalization for wider applications. To address this issue, we present ProQA, a unified QA paradigm that solves various tasks through a single model. ProQA takes a unified structural prompt as the bridge Cites: BoolQ: Exploring the surprising difficulty of natural yes/no questions</summary></entry><entry><title type="html">EASE: Entity-Aware Contrastive Learning of Sentence Embedding</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a23f1dd0dea65151701ddb63738ac38a.html" rel="alternate" type="text/html" title="EASE: Entity-Aware Contrastive Learning of Sentence Embedding" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a23f1dd0dea65151701ddb63738ac38a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a23f1dd0dea65151701ddb63738ac38a.html">&lt;p&gt;We present EASE, a novel method for learning sentence embeddings via contrastive learning between sentences and their related entities. The advantage of using entity supervision is twofold:(1) entities have been shown to be a strong indicator of text semantics and thus should provide rich training signals for sentence embeddings;(2) entities are defined independently of languages and thus offer useful cross-lingual alignment supervision. We evaluate EASE against other unsupervised models both Cites: XTREME: A massively multilingual multi-task benchmark for&lt;/p&gt;</content><author><name>S Nishikawa, R Ri, I Yamada, Y Tsuruoka, I Echizen - arXiv preprint arXiv:2205.04260, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present EASE, a novel method for learning sentence embeddings via contrastive learning between sentences and their related entities. The advantage of using entity supervision is twofold:(1) entities have been shown to be a strong indicator of text semantics and thus should provide rich training signals for sentence embeddings;(2) entities are defined independently of languages and thus offer useful cross-lingual alignment supervision. We evaluate EASE against other unsupervised models both Cites: XTREME: A massively multilingual multi-task benchmark for</summary></entry><entry><title type="html">What Makes a Good and Useful Summary? Incorporating Users in Automatic Summarization Research</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a505ad7fb0a3c2f537bd6339df6da70f.html" rel="alternate" type="text/html" title="What Makes a Good and Useful Summary? Incorporating Users in Automatic Summarization Research" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a505ad7fb0a3c2f537bd6339df6da70f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a505ad7fb0a3c2f537bd6339df6da70f.html">&lt;p&gt;Automatic text summarization has enjoyed great progress over the years and is used in numerous applications, impacting the lives of many. Despite this development, there is little research that meaningfully investigates how the current research focus in automatic summarization aligns with users  needs. To bridge this gap, we propose a survey methodology that can be used to investigate the needs of users of automatically generated summaries. Importantly, these needs are dependent on the Cites: Discourse-Aware Neural Extractive Text Summarization&lt;/p&gt;</content><author><name>M ter Hoeve, J Kiseleva, M de Rijke</name></author><category term="jekyll" /><category term="update" /><summary type="html">Automatic text summarization has enjoyed great progress over the years and is used in numerous applications, impacting the lives of many. Despite this development, there is little research that meaningfully investigates how the current research focus in automatic summarization aligns with users needs. To bridge this gap, we propose a survey methodology that can be used to investigate the needs of users of automatically generated summaries. Importantly, these needs are dependent on the Cites: Discourse-Aware Neural Extractive Text Summarization</summary></entry><entry><title type="html">Next Word Prediction Using Hindi</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a55849fd9df656f616e4be01e477ed8d.html" rel="alternate" type="text/html" title="Next Word Prediction Using Hindi" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a55849fd9df656f616e4be01e477ed8d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a55849fd9df656f616e4be01e477ed8d.html">&lt;p&gt;Natural language generation is a process that concerns on generating human understandable language. This study provides method to guess next word from previous sequence of words that are in Hindi language. This process reduces the keystrokes of a user by predicting next word. In this two machine learning technology, BERT (Bidirectional Encoder Representations from Transformers) Model and ML (Masked Language) model is used to predict next word from previous words Cites: BERT: Pre-training of deep bidirectional transformers for language&lt;/p&gt;</content><author><name>S Agarwal, AS Sukritin, A Mishra -  and Computer Systems: Proceedings of RACCCS , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Natural language generation is a process that concerns on generating human understandable language. This study provides method to guess next word from previous sequence of words that are in Hindi language. This process reduces the keystrokes of a user by predicting next word. In this two machine learning technology, BERT (Bidirectional Encoder Representations from Transformers) Model and ML (Masked Language) model is used to predict next word from previous words Cites: BERT: Pre-training of deep bidirectional transformers for language</summary></entry><entry><title type="html">Weakly-supervised segmentation of referring expressions</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a60217143c5fde31add1cc4cf80cf6c3.html" rel="alternate" type="text/html" title="Weakly-supervised segmentation of referring expressions" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a60217143c5fde31add1cc4cf80cf6c3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a60217143c5fde31add1cc4cf80cf6c3.html">&lt;p&gt;Visual grounding localizes regions (boxes or segments) in the image corresponding to given referring expressions. In this work we address image segmentation from referring expressions, a problem that has so far only been addressed in a fully- supervised setting. A fully-supervised setup, however, requires pixel-wise supervision and is hard to scale given the expense of manual annotation. We therefore introduce a new task of weakly-supervised image segmentation from Cites: Well-read students learn better: The impact of student initialization&lt;/p&gt;</content><author><name>R Strudel, I Laptev, C Schmid - arXiv preprint arXiv:2205.04725, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Visual grounding localizes regions (boxes or segments) in the image corresponding to given referring expressions. In this work we address image segmentation from referring expressions, a problem that has so far only been addressed in a fully- supervised setting. A fully-supervised setup, however, requires pixel-wise supervision and is hard to scale given the expense of manual annotation. We therefore introduce a new task of weakly-supervised image segmentation from Cites: Well-read students learn better: The impact of student initialization</summary></entry><entry><title type="html">Prompt Distribution Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a679b8139858bf858ab6ea20348a056b.html" rel="alternate" type="text/html" title="Prompt Distribution Learning" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a679b8139858bf858ab6ea20348a056b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/a679b8139858bf858ab6ea20348a056b.html">&lt;p&gt;We present prompt distribution learning for effectively adapting a pre-trained vision- language model to address downstream recognition tasks. Our method not only learns low-bias prompts from a few samples but also captures the distribution of diverse prompts to handle the varying visual representations. In this way, we provide high-quality task-related content for facilitating recognition. This prompt distribution learning is realized by an efficient approach that learns the output embeddings of Cites: Contrastive learning of medical visual representations from paired&lt;/p&gt;</content><author><name>Y Lu, J Liu, Y Zhang, Y Liu, X Tian - arXiv preprint arXiv:2205.03340, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present prompt distribution learning for effectively adapting a pre-trained vision- language model to address downstream recognition tasks. Our method not only learns low-bias prompts from a few samples but also captures the distribution of diverse prompts to handle the varying visual representations. In this way, we provide high-quality task-related content for facilitating recognition. This prompt distribution learning is realized by an efficient approach that learns the output embeddings of Cites: Contrastive learning of medical visual representations from paired</summary></entry><entry><title type="html">Number Entity Recognition</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/ad68e7f7ed664c206bcd5b8a02bc6b3e.html" rel="alternate" type="text/html" title="Number Entity Recognition" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/ad68e7f7ed664c206bcd5b8a02bc6b3e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/ad68e7f7ed664c206bcd5b8a02bc6b3e.html">&lt;p&gt;Numbers are essential components of text, like any other word tokens, from which natural language processing (NLP) models are built and deployed. Though numbers are typically not accounted for distinctly in most NLP tasks, there is still an underlying amount of numeracy already exhibited by NLP models. In this work, we attempt to tap this potential of state-of-the-art NLP models and transfer their ability to boost performance in related tasks. Our proposed classification of numbers into entities Cites: Giving BERT a Calculator: Finding Operations and Arguments with&lt;/p&gt;</content><author><name>D Sundararaman, V Subramanian, G Wang, L Xu - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Numbers are essential components of text, like any other word tokens, from which natural language processing (NLP) models are built and deployed. Though numbers are typically not accounted for distinctly in most NLP tasks, there is still an underlying amount of numeracy already exhibited by NLP models. In this work, we attempt to tap this potential of state-of-the-art NLP models and transfer their ability to boost performance in related tasks. Our proposed classification of numbers into entities Cites: Giving BERT a Calculator: Finding Operations and Arguments with</summary></entry><entry><title type="html">BLINK with Elasticsearch for Efficient Entity Linking in Business Conversations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/ae7c3dcf9c381d5bed4be5a924358e90.html" rel="alternate" type="text/html" title="BLINK with Elasticsearch for Efficient Entity Linking in Business Conversations" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/ae7c3dcf9c381d5bed4be5a924358e90</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/ae7c3dcf9c381d5bed4be5a924358e90.html">&lt;p&gt;An Entity Linking system aligns the textual mentions of entities in a text to their corresponding entries in a knowledge base. However, deploying a neural entity linking system for efficient real-time inference in production environments is a challenging task. In this work, we present a neural entity linking system that connects the product and organization type entities in business conversations to their corresponding Wikipedia and Wikidata entries. The proposed system leverages Cites: Scalable zero-shot entity linking with dense entity retrieval&lt;/p&gt;</content><author><name>MTR Laskar, C Chen, A Martsinovich, J Johnston - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">An Entity Linking system aligns the textual mentions of entities in a text to their corresponding entries in a knowledge base. However, deploying a neural entity linking system for efficient real-time inference in production environments is a challenging task. In this work, we present a neural entity linking system that connects the product and organization type entities in business conversations to their corresponding Wikipedia and Wikidata entries. The proposed system leverages Cites: Scalable zero-shot entity linking with dense entity retrieval</summary></entry><entry><title type="html">GRAPHCACHE: Message Passing as Caching for Sentence-Level Relation Extraction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/b69f169fdacf020e4ba667f5d2beceed.html" rel="alternate" type="text/html" title="GRAPHCACHE: Message Passing as Caching for Sentence-Level Relation Extraction" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/b69f169fdacf020e4ba667f5d2beceed</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/b69f169fdacf020e4ba667f5d2beceed.html">&lt;p&gt;Entity types and textual context are essential properties for sentence-level relation extraction (RE). Existing work only encodes these properties within individual instances, which limits the performance of RE given the insufficient features in a single sentence. In contrast, we model these properties from the whole dataset and use the dataset-level information to enrich the semantics of every instance. We propose the GRAPHCACHE (Graph Neural Network as Caching) module, that Cites: Knowledge enhanced contextual word representations&lt;/p&gt;</content><author><name>Y Wang, M Chen, W Zhou, Y Cai, Y Liang, B Hooi - arXiv preprint arXiv:2205.03786, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Entity types and textual context are essential properties for sentence-level relation extraction (RE). Existing work only encodes these properties within individual instances, which limits the performance of RE given the insufficient features in a single sentence. In contrast, we model these properties from the whole dataset and use the dataset-level information to enrich the semantics of every instance. We propose the GRAPHCACHE (Graph Neural Network as Caching) module, that Cites: Knowledge enhanced contextual word representations</summary></entry><entry><title type="html">Cross-document Misinformation Detection based on Event Graph Reasoning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/b6d6ed4ae72426228f21bd62a148da6d.html" rel="alternate" type="text/html" title="Cross-document Misinformation Detection based on Event Graph Reasoning" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/b6d6ed4ae72426228f21bd62a148da6d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/b6d6ed4ae72426228f21bd62a148da6d.html">&lt;p&gt;For emerging events, human readers are often exposed to both real news and fake news. Multiple news articles may contain complementary or contradictory information that readers can leverage to help detect fake news. Inspired by this process, we propose a novel task of cross-document misinformation detection. Given a cluster of topically related news documents, we aim to detect misinformation at both document level and a more finegrained level, event level. Due to the lack of data, we generate Cites: Future is not one-dimensional: Graph modeling based complex&lt;/p&gt;</content><author><name>X Wu, KH Huang, Y Fung, H Ji</name></author><category term="jekyll" /><category term="update" /><summary type="html">For emerging events, human readers are often exposed to both real news and fake news. Multiple news articles may contain complementary or contradictory information that readers can leverage to help detect fake news. Inspired by this process, we propose a novel task of cross-document misinformation detection. Given a cluster of topically related news documents, we aim to detect misinformation at both document level and a more finegrained level, event level. Due to the lack of data, we generate Cites: Future is not one-dimensional: Graph modeling based complex</summary></entry><entry><title type="html">CODEC: Complex Document and Entity Collection</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/b8cd25d39783fc65d9226097f9cbec98.html" rel="alternate" type="text/html" title="CODEC: Complex Document and Entity Collection" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/b8cd25d39783fc65d9226097f9cbec98</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/b8cd25d39783fc65d9226097f9cbec98.html">&lt;p&gt;CODEC is a document and entity ranking benchmark that focuses on complex research topics. We target essay-style information needs of social science researchers, ie  How has the UK s Open Banking Regulation benefited Challenger Banks? . CODEC includes 42 topics developed by researchers and a new focused web corpus with semantic annotations including entity links. This resource includes expert judgments on 17,509 documents and entities (416.9 per topic) from diverse Cites: Autoregressive entity retrieval&lt;/p&gt;</content><author><name>I Mackie, P Owoicho, C Gemmell, S Fischer - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">CODEC is a document and entity ranking benchmark that focuses on complex research topics. We target essay-style information needs of social science researchers, ie How has the UK s Open Banking Regulation benefited Challenger Banks? . CODEC includes 42 topics developed by researchers and a new focused web corpus with semantic annotations including entity links. This resource includes expert judgments on 17,509 documents and entities (416.9 per topic) from diverse Cites: Autoregressive entity retrieval</summary></entry><entry><title type="html">A Data Cartography based MixUp for Pre-trained Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/b8f486a6025017068a7dd38c1e5b9917.html" rel="alternate" type="text/html" title="A Data Cartography based MixUp for Pre-trained Language Models" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/b8f486a6025017068a7dd38c1e5b9917</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/b8f486a6025017068a7dd38c1e5b9917.html">&lt;p&gt;MixUp is a data augmentation strategy where additional samples are generated during training by combining random pairs of training samples and their labels. However, selecting random pairs is not potentially an optimal choice. In this work, we propose TDMixUp, a novel MixUp strategy that leverages Training Dynamics and allows more informative samples to be combined for generating new data samples. Our proposed TDMixUp first measures confidence, variability,(Swayamdipta et al Cites: Calibration of Pre-trained Transformers&lt;/p&gt;</content><author><name>SY Park, C Caragea - arXiv preprint arXiv:2205.03403, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">MixUp is a data augmentation strategy where additional samples are generated during training by combining random pairs of training samples and their labels. However, selecting random pairs is not potentially an optimal choice. In this work, we propose TDMixUp, a novel MixUp strategy that leverages Training Dynamics and allows more informative samples to be combined for generating new data samples. Our proposed TDMixUp first measures confidence, variability,(Swayamdipta et al Cites: Calibration of Pre-trained Transformers</summary></entry><entry><title type="html">Automated Evaluation for Student Argumentative Writing: A Survey</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/bb1ed1a0a2bfd4afeaf1a45d395f015f.html" rel="alternate" type="text/html" title="Automated Evaluation for Student Argumentative Writing: A Survey" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/bb1ed1a0a2bfd4afeaf1a45d395f015f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/bb1ed1a0a2bfd4afeaf1a45d395f015f.html">&lt;p&gt;This paper surveys and organizes research works in an under-studied area, which we call automated evaluation for student argumentative writing. Unlike traditional automated writing evaluation that focuses on holistic essay scoring, this field is more specific: it focuses on evaluating argumentative essays and offers specific feedback, including argumentation structures, argument strength trait score, etc. The focused and detailed evaluation is useful for helping students acquire important Cites: A linear programming formulation for global inference in natural&lt;/p&gt;</content><author><name>X Wang, Y Lee, J Park - arXiv preprint arXiv:2205.04083, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper surveys and organizes research works in an under-studied area, which we call automated evaluation for student argumentative writing. Unlike traditional automated writing evaluation that focuses on holistic essay scoring, this field is more specific: it focuses on evaluating argumentative essays and offers specific feedback, including argumentation structures, argument strength trait score, etc. The focused and detailed evaluation is useful for helping students acquire important Cites: A linear programming formulation for global inference in natural</summary></entry><entry><title type="html">Data Augmentation with Paraphrase Generation and Entity Extraction for Multimodal Dialogue System</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/be6a030903653d5cbed4f4364d637d60.html" rel="alternate" type="text/html" title="Data Augmentation with Paraphrase Generation and Entity Extraction for Multimodal Dialogue System" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/be6a030903653d5cbed4f4364d637d60</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/be6a030903653d5cbed4f4364d637d60.html">&lt;p&gt;Contextually aware intelligent agents are often required to understand the users and their surroundings in real-time. Our goal is to build Artificial Intelligence (AI) systems that can assist children in their learning process. Within such complex frameworks, Spoken Dialogue Systems (SDS) are crucial building blocks to handle efficient task- oriented communication with children in game-based learning settings. We are working towards a multimodal dialogue system for younger kids learning basic math Cites: Composed variational natural language generation for few-shot&lt;/p&gt;</content><author><name>E Okur, S Sahay, L Nachman - arXiv preprint arXiv:2205.04006, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Contextually aware intelligent agents are often required to understand the users and their surroundings in real-time. Our goal is to build Artificial Intelligence (AI) systems that can assist children in their learning process. Within such complex frameworks, Spoken Dialogue Systems (SDS) are crucial building blocks to handle efficient task- oriented communication with children in game-based learning settings. We are working towards a multimodal dialogue system for younger kids learning basic math Cites: Composed variational natural language generation for few-shot</summary></entry><entry><title type="html">Low-rank Tensor Learning with Nonconvex Overlapped Nuclear Norm Regularization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/bf336fbea4b8eb17adf7cd459d561707.html" rel="alternate" type="text/html" title="Low-rank Tensor Learning with Nonconvex Overlapped Nuclear Norm Regularization" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/bf336fbea4b8eb17adf7cd459d561707</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/bf336fbea4b8eb17adf7cd459d561707.html">&lt;p&gt;Nonconvex regularization has been popularly used in low-rank matrix learning. However, extending it for low-rank tensor learning is still computationally expensive. To address this problem, we develop an efficient solver for use with a nonconvex extension of the overlapped nuclear norm regularizer. Based on the proximal average algorithm, the proposed algorithm can avoid expensive tensor folding/unfolding operations. A special  sparse plus low-rank  structure is maintained Cites: Representing Text for Joint Embedding of Text and Knowledge&lt;/p&gt;</content><author><name>Q Yao, Y Wang, B Han, J Kwok - arXiv preprint arXiv:2205.03059, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Nonconvex regularization has been popularly used in low-rank matrix learning. However, extending it for low-rank tensor learning is still computationally expensive. To address this problem, we develop an efficient solver for use with a nonconvex extension of the overlapped nuclear norm regularizer. Based on the proximal average algorithm, the proposed algorithm can avoid expensive tensor folding/unfolding operations. A special sparse plus low-rank structure is maintained Cites: Representing Text for Joint Embedding of Text and Knowledge</summary></entry><entry><title type="html">Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/c42a2ff8ec64693faf90637d378bd0fd.html" rel="alternate" type="text/html" title="Beyond Distributional Hypothesis: Let Language Models Learn Meaning-Text Correspondence" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/c42a2ff8ec64693faf90637d378bd0fd</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/c42a2ff8ec64693faf90637d378bd0fd.html">&lt;p&gt;The logical negation property (LNP), which implies generating different predictions for semantically opposite inputs, is an important property that a trustworthy language model must satisfy. However, much recent evidence shows that large-size pre- trained language models (PLMs) do not satisfy this property. In this paper, we perform experiments using probing tasks to assess PLM s LNP understanding. Unlike previous studies that only examined negation expressions, we expand the Cites: Neural text generation with unlikelihood training&lt;/p&gt;</content><author><name>M Jang, F Mtumbuka, T Lukasiewicz - arXiv preprint arXiv:2205.03815, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The logical negation property (LNP), which implies generating different predictions for semantically opposite inputs, is an important property that a trustworthy language model must satisfy. However, much recent evidence shows that large-size pre- trained language models (PLMs) do not satisfy this property. In this paper, we perform experiments using probing tasks to assess PLM s LNP understanding. Unlike previous studies that only examined negation expressions, we expand the Cites: Neural text generation with unlikelihood training</summary></entry><entry><title type="html">CompactIE: Compact Facts in Open Information Extraction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/c4caa270be0cf9609e7c10c81fa2ca6d.html" rel="alternate" type="text/html" title="CompactIE: Compact Facts in Open Information Extraction" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/c4caa270be0cf9609e7c10c81fa2ca6d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/c4caa270be0cf9609e7c10c81fa2ca6d.html">&lt;p&gt;A major drawback of modern neural OpenIE systems and benchmarks is that they prioritize high coverage of information in extractions over compactness of their constituents. This severely limits the usefulness of OpenIE extractions in many downstream tasks. The utility of extractions can be improved if extractions are compact and share constituents. To this end, we study the problem of identifying compact extractions with neural-based methods. We propose CompactIE, an OpenIE Cites: Open information extraction from the web&lt;/p&gt;</content><author><name>FF Bayat, N Bhutani, HV Jagadish - arXiv preprint arXiv:2205.02880, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A major drawback of modern neural OpenIE systems and benchmarks is that they prioritize high coverage of information in extractions over compactness of their constituents. This severely limits the usefulness of OpenIE extractions in many downstream tasks. The utility of extractions can be improved if extractions are compact and share constituents. To this end, we study the problem of identifying compact extractions with neural-based methods. We propose CompactIE, an OpenIE Cites: Open information extraction from the web</summary></entry><entry><title type="html">Improving negation detection with negation-focused pre-training</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/c8891906572a93c69a308ed581785450.html" rel="alternate" type="text/html" title="Improving negation detection with negation-focused pre-training" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/c8891906572a93c69a308ed581785450</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/c8891906572a93c69a308ed581785450.html">&lt;p&gt;Negation is a common linguistic feature that is crucial in many language understanding tasks, yet it remains a hard problem due to diversity in its expression in different types of text. Recent work has shown that state-of-the-art NLP models underperform on samples containing negation in various tasks, and that negation detection models do not transfer well across domains. We propose a new negation- focused pre-training strategy, involving targeted data augmentation and negation Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList&lt;/p&gt;</content><author><name>TH Truong, T Baldwin, T Cohn, K Verspoor - arXiv preprint arXiv:2205.04012, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Negation is a common linguistic feature that is crucial in many language understanding tasks, yet it remains a hard problem due to diversity in its expression in different types of text. Recent work has shown that state-of-the-art NLP models underperform on samples containing negation in various tasks, and that negation detection models do not transfer well across domains. We propose a new negation- focused pre-training strategy, involving targeted data augmentation and negation Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList</summary></entry><entry><title type="html">The Roles and Modes of Human Interactions with Automated Machine Learning Systems</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/cf126586e4b76372fb690ac5b336cc00.html" rel="alternate" type="text/html" title="The Roles and Modes of Human Interactions with Automated Machine Learning Systems" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/cf126586e4b76372fb690ac5b336cc00</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/cf126586e4b76372fb690ac5b336cc00.html">&lt;p&gt;As automated machine learning (AutoML) systems continue to progress in both sophistication and performance, it becomes important to understand thehow andwhy of human-computer interaction (HCI) within these frameworks, both current and expected. Such a discussion is necessary for optimal system design, leveraging advanced data-processing capabilities to support decision-making involving humans, but it is also key to identifying the opportunities and risks Cites: AlphaD3M: Machine learning pipeline synthesis&lt;/p&gt;</content><author><name>TT Khuat, DJ Kedziora, B Gabrys - arXiv preprint arXiv:2205.04139, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As automated machine learning (AutoML) systems continue to progress in both sophistication and performance, it becomes important to understand thehow andwhy of human-computer interaction (HCI) within these frameworks, both current and expected. Such a discussion is necessary for optimal system design, leveraging advanced data-processing capabilities to support decision-making involving humans, but it is also key to identifying the opportunities and risks Cites: AlphaD3M: Machine learning pipeline synthesis</summary></entry><entry><title type="html">Collective Relevance Labeling for Passage Retrieval</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/d800e9c99fc480664fc3807e0c36f53c.html" rel="alternate" type="text/html" title="Collective Relevance Labeling for Passage Retrieval" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/d800e9c99fc480664fc3807e0c36f53c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/d800e9c99fc480664fc3807e0c36f53c.html">&lt;p&gt;Deep learning for Information Retrieval (IR) requires a large amount of high-quality query-document relevance labels, but such labels are inherently sparse. Label smoothing redistributes some observed probability mass over unobserved instances, often uniformly, uninformed of the true distribution. In contrast, we propose knowledge distillation for informed labeling, without incurring high computation overheads at evaluation time. Our contribution is designing a simple but efficient Cites: Multi-stage document ranking with BERT&lt;/p&gt;</content><author><name>J Kim, M Kim, S Hwang - arXiv preprint arXiv:2205.03273, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning for Information Retrieval (IR) requires a large amount of high-quality query-document relevance labels, but such labels are inherently sparse. Label smoothing redistributes some observed probability mass over unobserved instances, often uniformly, uninformed of the true distribution. In contrast, we propose knowledge distillation for informed labeling, without incurring high computation overheads at evaluation time. Our contribution is designing a simple but efficient Cites: Multi-stage document ranking with BERT</summary></entry><entry><title type="html">A Recommender System: Challenges, Issues &amp;amp; Extensions</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/d907e3b103cbd4bb4ace2a953a228087.html" rel="alternate" type="text/html" title="A Recommender System: Challenges, Issues &amp;amp; Extensions" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/d907e3b103cbd4bb4ace2a953a228087</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/d907e3b103cbd4bb4ace2a953a228087.html">&lt;p&gt;Recommendations are long chains followed from traditional life to today s life. In everyday life, the chain of recommendation augments the social process via some physical media and digital applications. The issues and challenges of recommendation are still in the infancy due to the growth of technology. This article identifies the uncovered areas of concern and links them to novel solutions. We also provide an extensive literature with different dimension for the newbie to work with Cites: Getting recommender systems to think outside the box&lt;/p&gt;</content><author><name>DK Sahni - Mapana Journal of Sciences, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recommendations are long chains followed from traditional life to today s life. In everyday life, the chain of recommendation augments the social process via some physical media and digital applications. The issues and challenges of recommendation are still in the infancy due to the growth of technology. This article identifies the uncovered areas of concern and links them to novel solutions. We also provide an extensive literature with different dimension for the newbie to work with Cites: Getting recommender systems to think outside the box</summary></entry><entry><title type="html">ALLSH: Active Learning Guided by Local Sensitivity and Hardness</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/d9417126b55c9cbe428ecad3d73567ab.html" rel="alternate" type="text/html" title="ALLSH: Active Learning Guided by Local Sensitivity and Hardness" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/d9417126b55c9cbe428ecad3d73567ab</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/d9417126b55c9cbe428ecad3d73567ab.html">&lt;p&gt;Active learning, which effectively collects informative unlabeled data for annotation, reduces the demand for labeled data. In this work, we propose to retrieve unlabeled samples with a local sensitivity and hardness-aware acquisition function. The proposed method generates data copies through local perturbations and selects data points whose predictive likelihoods diverge the most from their copies. We further empower our acquisition function by injecting the select-worst case Cites: On the importance of adaptive data collection for extremely&lt;/p&gt;</content><author><name>S Zhang, C Gong, X Liu, P He, W Chen, M Zhou - arXiv preprint arXiv:2205.04980, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Active learning, which effectively collects informative unlabeled data for annotation, reduces the demand for labeled data. In this work, we propose to retrieve unlabeled samples with a local sensitivity and hardness-aware acquisition function. The proposed method generates data copies through local perturbations and selects data points whose predictive likelihoods diverge the most from their copies. We further empower our acquisition function by injecting the select-worst case Cites: On the importance of adaptive data collection for extremely</summary></entry><entry><title type="html">Pattern Mining and Genetic Improvement in Compilers and Interpreters/submitted by Oliver Krauss MSc</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/da823f4fd3643572da8c3646805d0545.html" rel="alternate" type="text/html" title="Pattern Mining and Genetic Improvement in Compilers and Interpreters/submitted by Oliver Krauss MSc" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/da823f4fd3643572da8c3646805d0545</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/da823f4fd3643572da8c3646805d0545.html">&lt;p&gt;Writing source code is a challenging task, requiring the understanding of complex concepts, algorithms and programming paradigms. This task becomes increasingly challenging when source code has to be optimized for non-functional properties such as run-time performance, memory usage or energy efficiency. These properties often depend on in-depth knowledge of the language, the compiler and even the hardware archhitecture te sourceb code wil e run on. Cites: Learning to Superoptimize Real-world Programs&lt;/p&gt;</content><author><name>O Krauss - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Writing source code is a challenging task, requiring the understanding of complex concepts, algorithms and programming paradigms. This task becomes increasingly challenging when source code has to be optimized for non-functional properties such as run-time performance, memory usage or energy efficiency. These properties often depend on in-depth knowledge of the language, the compiler and even the hardware archhitecture te sourceb code wil e run on. Cites: Learning to Superoptimize Real-world Programs</summary></entry><entry><title type="html">Machine/Deep Learning for Software Engineering: A Systematic Literature Review</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/e241b61d7365fe648fd573a3c0451094.html" rel="alternate" type="text/html" title="Machine/Deep Learning for Software Engineering: A Systematic Literature Review" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/e241b61d7365fe648fd573a3c0451094</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/e241b61d7365fe648fd573a3c0451094.html">&lt;p&gt;Since 2009, the deep learning revolution—which was triggered by the introduction of ImageNet—has stimulated the synergy between Software Engineering (SE) and Machine Learning (ML)/Deep Learning (DL). Meanwhile, critical reviews have emerged that suggest that ML/DL should be used cautiously. To improve the applicability and generalizability of ML/DL-related SE studies, we conducted a 12- year Systematic Literature Review (SLR) on 1,428 ML/DL-related SE papers Cites: A syntactic neural model for general-purpose code generation&lt;/p&gt;</content><author><name>S Wang, L Huang, A Gao, J Ge, T Zhang, H Feng - IEEE Transactions on , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Since 2009, the deep learning revolution—which was triggered by the introduction of ImageNet—has stimulated the synergy between Software Engineering (SE) and Machine Learning (ML)/Deep Learning (DL). Meanwhile, critical reviews have emerged that suggest that ML/DL should be used cautiously. To improve the applicability and generalizability of ML/DL-related SE studies, we conducted a 12- year Systematic Literature Review (SLR) on 1,428 ML/DL-related SE papers Cites: A syntactic neural model for general-purpose code generation</summary></entry><entry><title type="html">ISA-bEL: Intelligent Search Algorithm based on Entity Linking</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/e355b215437c14977ad3c67dbdc54439.html" rel="alternate" type="text/html" title="ISA-bEL: Intelligent Search Algorithm based on Entity Linking" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/e355b215437c14977ad3c67dbdc54439</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/e355b215437c14977ad3c67dbdc54439.html">&lt;p&gt;Nowadays, the way in which the people interact with computers has changed. Text- or voice-based interfaces are being widely applied in different industries. Among the most used ways of processing the user input are those based on intents or retrieval algorithms. In these solutions, important information of the user could be lost in the process. For the proposed natural language processing pipeline the entities are going to take a principal role, under the assumption that entities are where the Cites: Answering Complex Open-domain Questions Through Iterative&lt;/p&gt;</content><author><name>RG Sendino, M Ortega, C Carrasco - arXiv preprint arXiv:2205.04322, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Nowadays, the way in which the people interact with computers has changed. Text- or voice-based interfaces are being widely applied in different industries. Among the most used ways of processing the user input are those based on intents or retrieval algorithms. In these solutions, important information of the user could be lost in the process. For the proposed natural language processing pipeline the entities are going to take a principal role, under the assumption that entities are where the Cites: Answering Complex Open-domain Questions Through Iterative</summary></entry><entry><title type="html">Few-shot Mining of Naturally Occurring Inputs and Outputs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/e6070e40ee0a126c5d00d1b0830ef780.html" rel="alternate" type="text/html" title="Few-shot Mining of Naturally Occurring Inputs and Outputs" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/e6070e40ee0a126c5d00d1b0830ef780</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/e6070e40ee0a126c5d00d1b0830ef780.html">&lt;p&gt;Creating labeled natural language training data is expensive and requires significant human effort. We mine input output examples from large corpora using a supervised mining function trained using a small seed set of only 100 examples. The mining consists of two stages–(1) a biencoder-based recall-oriented dense search which pairs inputs with potential outputs, and (2) a crossencoder-based filter which re-ranks the output of the biencoder stage for better precision. Unlike model-generated data Cites: Generative data augmentation for commonsense reasoning&lt;/p&gt;</content><author><name>M Joshi, T Blevins, M Lewis, DS Weld, L Zettlemoyer - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Creating labeled natural language training data is expensive and requires significant human effort. We mine input output examples from large corpora using a supervised mining function trained using a small seed set of only 100 examples. The mining consists of two stages–(1) a biencoder-based recall-oriented dense search which pairs inputs with potential outputs, and (2) a crossencoder-based filter which re-ranks the output of the biencoder stage for better precision. Unlike model-generated data Cites: Generative data augmentation for commonsense reasoning</summary></entry><entry><title type="html">Learning structured embeddings of knowledge graphs with generative adversarial framework</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/e9b427ec6ca8160804902599f92fc8d3.html" rel="alternate" type="text/html" title="Learning structured embeddings of knowledge graphs with generative adversarial framework" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/e9b427ec6ca8160804902599f92fc8d3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/e9b427ec6ca8160804902599f92fc8d3.html">&lt;p&gt;Many large knowledge graphs are now available and ready to provide semantically structured information that is regarded as an important resource for question answering and decision support tasks. However, they are built on rigid symbolic frameworks which makes them hard to be used in other intelligent systems. Knowledge graph embedding approaches are gaining increasing attention, which embeds symbolic entities and relations into continuous vector spaces. Such graph Cites: Convolutional 2d knowledge graph embeddings&lt;/p&gt;</content><author><name>L Liu, J Zeng, X Zheng - Expert Systems with Applications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Many large knowledge graphs are now available and ready to provide semantically structured information that is regarded as an important resource for question answering and decision support tasks. However, they are built on rigid symbolic frameworks which makes them hard to be used in other intelligent systems. Knowledge graph embedding approaches are gaining increasing attention, which embeds symbolic entities and relations into continuous vector spaces. Such graph Cites: Convolutional 2d knowledge graph embeddings</summary></entry><entry><title type="html">KECP: Knowledge Enhanced Contrastive Prompting for Few-shot Extractive Question Answering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/f61fe27ea03ca407bcc28da4abe01e4a.html" rel="alternate" type="text/html" title="KECP: Knowledge Enhanced Contrastive Prompting for Few-shot Extractive Question Answering" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/f61fe27ea03ca407bcc28da4abe01e4a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/f61fe27ea03ca407bcc28da4abe01e4a.html">&lt;p&gt;Extractive Question Answering (EQA) is one of the most important tasks in Machine Reading Comprehension (MRC), which can be solved by fine-tuning the span selecting heads of Pre-trained Language Models (PLMs). However, most existing approaches for MRC may perform poorly in the few-shot learning scenario. To solve this issue, we propose a novel framework named Knowledge Enhanced Contrastive Prompt-tuning (KECP). Instead of adding pointer heads to PLMs, we introduce a Cites: Natural questions: a benchmark for question answering research&lt;/p&gt;</content><author><name>J Wang, C Wang, M Qiu, Q Shi, H Wang, J Huang - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Extractive Question Answering (EQA) is one of the most important tasks in Machine Reading Comprehension (MRC), which can be solved by fine-tuning the span selecting heads of Pre-trained Language Models (PLMs). However, most existing approaches for MRC may perform poorly in the few-shot learning scenario. To solve this issue, we propose a novel framework named Knowledge Enhanced Contrastive Prompt-tuning (KECP). Instead of adding pointer heads to PLMs, we introduce a Cites: Natural questions: a benchmark for question answering research</summary></entry><entry><title type="html">A semantic and syntactic enhanced neural model for financial sentiment analysis</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/f9fba8c582ffe771677c0ac4ef48fd98.html" rel="alternate" type="text/html" title="A semantic and syntactic enhanced neural model for financial sentiment analysis" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/f9fba8c582ffe771677c0ac4ef48fd98</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/f9fba8c582ffe771677c0ac4ef48fd98.html">&lt;p&gt;This paper studies the methodology of inferring bullish or bearish sentiments in the financial domain. The task aims to predict a real value to represent the sentiment intensity concerning a target (company or stock symbol) in a text. Previous researches have proved the validity of using deep neural networks to automatically learn semantic and syntactic information for sentiment prediction. Despite the promising performance, these approaches implicitly obtain the target-sentiment Cites: What does BERT look at? An analysis of BERT s attention&lt;/p&gt;</content><author><name>C Xiang, J Zhang, F Li, H Fei, D Ji - Information Processing &amp; Management, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper studies the methodology of inferring bullish or bearish sentiments in the financial domain. The task aims to predict a real value to represent the sentiment intensity concerning a target (company or stock symbol) in a text. Previous researches have proved the validity of using deep neural networks to automatically learn semantic and syntactic information for sentiment prediction. Despite the promising performance, these approaches implicitly obtain the target-sentiment Cites: What does BERT look at? An analysis of BERT s attention</summary></entry><entry><title type="html">Selectively Contextual Bandits</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/fb76adc21a8e9b24130cacc5de430895.html" rel="alternate" type="text/html" title="Selectively Contextual Bandits" /><published>2022-05-14T04:38:21-04:00</published><updated>2022-05-14T04:38:21-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/fb76adc21a8e9b24130cacc5de430895</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/14/fb76adc21a8e9b24130cacc5de430895.html">&lt;p&gt;Contextual bandits are widely used in industrial personalization systems. These online learning frameworks learn a treatment assignment policy in the presence of treatment effects that vary with the observed contextual features of the users. While personalization creates a rich user experience that reflect individual interests, there are benefits of a shared experience across a community that enable participation in the zeitgeist. Such benefits are emergent through network effects and are not Cites: Provably optimal algorithms for generalized linear contextual bandits&lt;/p&gt;</content><author><name>C Roberts, M Dimakopoulou, Q Qiao - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Contextual bandits are widely used in industrial personalization systems. These online learning frameworks learn a treatment assignment policy in the presence of treatment effects that vary with the observed contextual features of the users. While personalization creates a rich user experience that reflect individual interests, there are benefits of a shared experience across a community that enable participation in the zeitgeist. Such benefits are emergent through network effects and are not Cites: Provably optimal algorithms for generalized linear contextual bandits</summary></entry><entry><title type="html">Cross-Domain Deep Code Search with Meta Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/032c5c8ab271f173b57285dc52bf8538.html" rel="alternate" type="text/html" title="Cross-Domain Deep Code Search with Meta Learning" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/032c5c8ab271f173b57285dc52bf8538</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/032c5c8ab271f173b57285dc52bf8538.html">&lt;p&gt;Recently, pre-trained programming language models such as Code-BERT have demonstrated substantial gains in code search. Despite their success, they rely on the availability of large amounts of parallel data to fine-tune the semantic mappings between queries and code. This restricts their practicality in domain-specific languages that have relatively scarce and expensive data. In this paper, we propose CDCS, a novel approach for domain-specific code search. CDCS employs a transfer Cites: Codebert: A pre-trained model for programming and natural&lt;/p&gt;</content><author><name>Y Chai, H Zhang, B Shen, X Gu - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recently, pre-trained programming language models such as Code-BERT have demonstrated substantial gains in code search. Despite their success, they rely on the availability of large amounts of parallel data to fine-tune the semantic mappings between queries and code. This restricts their practicality in domain-specific languages that have relatively scarce and expensive data. In this paper, we propose CDCS, a novel approach for domain-specific code search. CDCS employs a transfer Cites: Codebert: A pre-trained model for programming and natural</summary></entry><entry><title type="html">Matching knowledge graphs with Compact Niching Evolutionary Algorithm</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/1b9278ae12a3c5045b44c5a95289fe31.html" rel="alternate" type="text/html" title="Matching knowledge graphs with Compact Niching Evolutionary Algorithm" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/1b9278ae12a3c5045b44c5a95289fe31</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/1b9278ae12a3c5045b44c5a95289fe31.html">&lt;p&gt;Abstract To address the Knowledge Graph (KG) heterogeneity issue, we need to determine a set of entity correspondences, which requires aggregating several complementary similarity measures to improve the confidence of the results. How to determine the suitable aggregating weights for the similarity measures to improve the KG alignment s quality is called the KG meta-matching problem, whose challenge of scalability remains significant in the Semantic Web (SW) domain. To face this Cites: Learning Knowledge Graphs for Question Answering through&lt;/p&gt;</content><author><name>X Xue, H Zhu - Expert Systems with Applications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract To address the Knowledge Graph (KG) heterogeneity issue, we need to determine a set of entity correspondences, which requires aggregating several complementary similarity measures to improve the confidence of the results. How to determine the suitable aggregating weights for the similarity measures to improve the KG alignment s quality is called the KG meta-matching problem, whose challenge of scalability remains significant in the Semantic Web (SW) domain. To face this Cites: Learning Knowledge Graphs for Question Answering through</summary></entry><entry><title type="html">Data is about Detail-An Empirical Investigation for Software Systems with NLP at Core</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/2433182a32c8b2465b9ed5689cc3025f.html" rel="alternate" type="text/html" title="Data is about Detail-An Empirical Investigation for Software Systems with NLP at Core" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/2433182a32c8b2465b9ed5689cc3025f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/2433182a32c8b2465b9ed5689cc3025f.html">&lt;p&gt;Businesses continue to operate under increasingly complex demands such as ever- evolving regulatory landscape, personalization requirements from software apps, and stricter governance with respect to security and privacy. In response to these challenges, large enterprises have been emphasizing automation across a wide range, starting with business processes all the way to customer experience. As AI continues to be a core component of software systems being developed, data Cites: Learning to simplify sentences with quasi-synchronous grammar&lt;/p&gt;</content><author><name>A Singhal, PR Anish, P Sonar, SS Ghaisas - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Businesses continue to operate under increasingly complex demands such as ever- evolving regulatory landscape, personalization requirements from software apps, and stricter governance with respect to security and privacy. In response to these challenges, large enterprises have been emphasizing automation across a wide range, starting with business processes all the way to customer experience. As AI continues to be a core component of software systems being developed, data Cites: Learning to simplify sentences with quasi-synchronous grammar</summary></entry><entry><title type="html">ERAKSInteractive Interface to Annotate Entities, Co-references, and Relationships</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/2b94ef6da1a843201099e392a4395fd7.html" rel="alternate" type="text/html" title="ERAKSInteractive Interface to Annotate Entities, Co-references, and Relationships" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/2b94ef6da1a843201099e392a4395fd7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/2b94ef6da1a843201099e392a4395fd7.html">&lt;p&gt;This paper aims to build a tool/an interface for automatic recognition of entities in a literary text and the relationships between them. The result of the practical work of three series master students of natural language processing was the creation of a manually annotated corpus from the Romanian version of the novel Quo Vadis by Henryk Sienkiewicz. It was previously annotated with a POS-tagger and received the sentences and words id. Entities, human characters, or gods, as well as geographic Cites: Simpler but more accurate semantic dependency parsing&lt;/p&gt;</content><author><name>C Maranduc, M Colhon, AD Bibiri - Intelligent Distributed Computing XIV</name></author><category term="jekyll" /><category term="update" /><summary type="html">This paper aims to build a tool/an interface for automatic recognition of entities in a literary text and the relationships between them. The result of the practical work of three series master students of natural language processing was the creation of a manually annotated corpus from the Romanian version of the novel Quo Vadis by Henryk Sienkiewicz. It was previously annotated with a POS-tagger and received the sentences and words id. Entities, human characters, or gods, as well as geographic Cites: Simpler but more accurate semantic dependency parsing</summary></entry><entry><title type="html">Uncovering Implicit Social Hierarchies in Political Discourse: A Cross-Disciplinary Analysis of the 2019 United States Democratic Party Presidential Primary Debates</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/31a30b877407d593e1ac3928db7d10ca.html" rel="alternate" type="text/html" title="Uncovering Implicit Social Hierarchies in Political Discourse: A Cross-Disciplinary Analysis of the 2019 United States Democratic Party Presidential Primary Debates" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/31a30b877407d593e1ac3928db7d10ca</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/31a30b877407d593e1ac3928db7d10ca.html">&lt;p&gt;This study takes a social constructivist approach in the examination of ideologies that position one person, or one group, above another in political discourse. I analyze social hierarchies in the eight 2019 Democratic Party primary debates leading up to the 2020 United States Presidential election in three textual forms: the video- recorded interaction, published transcripts, and online news media recontextualizations. Each dataset reveals a distinct group or category constructed Cites: Which words are hard to recognize? Prosodic, lexical, and&lt;/p&gt;</content><author><name>AM Janoff - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This study takes a social constructivist approach in the examination of ideologies that position one person, or one group, above another in political discourse. I analyze social hierarchies in the eight 2019 Democratic Party primary debates leading up to the 2020 United States Presidential election in three textual forms: the video- recorded interaction, published transcripts, and online news media recontextualizations. Each dataset reveals a distinct group or category constructed Cites: Which words are hard to recognize? Prosodic, lexical, and</summary></entry><entry><title type="html">Deep learning and RGB-D based human action, human-human and human-object interaction recognition: A survey</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/3950faaf68520c642fe246705414553d.html" rel="alternate" type="text/html" title="Deep learning and RGB-D based human action, human-human and human-object interaction recognition: A survey" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/3950faaf68520c642fe246705414553d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/3950faaf68520c642fe246705414553d.html">&lt;p&gt;Human activity recognition is one of the most studied topics in the field of computer vision. In recent years, with the availability of RGB-D sensors and powerful deep learning techniques, research on human activity recognition has gained momentum. From simple human atomic actions, the research has advanced towards recognizing more complex human activities using RGB-D data. This paper presents a comprehensive survey of the advanced deep learning based recognition methods Cites: Show, Attend and Tell: Neural Image Caption Generation with&lt;/p&gt;</content><author><name>P Khaire, P Kumar - Journal of Visual Communication and Image , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Human activity recognition is one of the most studied topics in the field of computer vision. In recent years, with the availability of RGB-D sensors and powerful deep learning techniques, research on human activity recognition has gained momentum. From simple human atomic actions, the research has advanced towards recognizing more complex human activities using RGB-D data. This paper presents a comprehensive survey of the advanced deep learning based recognition methods Cites: Show, Attend and Tell: Neural Image Caption Generation with</summary></entry><entry><title type="html">A Unified Model of Reasoning and Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/3c97eb1c38a6a21dba82a8609a1d7ac8.html" rel="alternate" type="text/html" title="A Unified Model of Reasoning and Learning" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/3c97eb1c38a6a21dba82a8609a1d7ac8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/3c97eb1c38a6a21dba82a8609a1d7ac8.html">&lt;p&gt;We present a novel approach to state space discretization for constructivist and reinforcement learning. Constructivist learning and reinforcement learning often operate on a predefined set of states and transitions (state space). AI researchers design algorithms to reach particular goal states in this state space (for example, visualized in the form of goal cells that a robot should reach in a grid). When the size and the dimensionality of the state space increases, however, finding goal states Cites: Differentiable reasoning on large knowledge bases and natural&lt;/p&gt;</content><author><name>P Wang - International Workshop on Self-Supervised Learning, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present a novel approach to state space discretization for constructivist and reinforcement learning. Constructivist learning and reinforcement learning often operate on a predefined set of states and transitions (state space). AI researchers design algorithms to reach particular goal states in this state space (for example, visualized in the form of goal cells that a robot should reach in a grid). When the size and the dimensionality of the state space increases, however, finding goal states Cites: Differentiable reasoning on large knowledge bases and natural</summary></entry><entry><title type="html">Not a Number: Identifying Instance Features for Capability-Oriented Evaluation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/3e8ccdb82dd7bd161de2119db50b52b0.html" rel="alternate" type="text/html" title="Not a Number: Identifying Instance Features for Capability-Oriented Evaluation" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/3e8ccdb82dd7bd161de2119db50b52b0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/3e8ccdb82dd7bd161de2119db50b52b0.html">&lt;p&gt;In AI evaluation, performance is often calculated by averaging across various instances. But to fully understand the capabilities of an AI system, we need to understand the factors that cause its pattern of success and failure. In this paper, we present a new methodology to identify and build informative instance features that can provide explanatory and predictive power to analyse the behaviour of AI systems more robustly. The methodology builds on these relevant features that should relate Cites: Dynabench: Rethinking benchmarking in NLP&lt;/p&gt;</content><author><name>R Burnell, J Burden, D Rutar, K Voudouris, L Cheke</name></author><category term="jekyll" /><category term="update" /><summary type="html">In AI evaluation, performance is often calculated by averaging across various instances. But to fully understand the capabilities of an AI system, we need to understand the factors that cause its pattern of success and failure. In this paper, we present a new methodology to identify and build informative instance features that can provide explanatory and predictive power to analyse the behaviour of AI systems more robustly. The methodology builds on these relevant features that should relate Cites: Dynabench: Rethinking benchmarking in NLP</summary></entry><entry><title type="html">Powering up causal generalization: A model of human conceptual bootstrapping with adaptor grammars</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/52057a30dcbf9031815732e296454c75.html" rel="alternate" type="text/html" title="Powering up causal generalization: A model of human conceptual bootstrapping with adaptor grammars" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/52057a30dcbf9031815732e296454c75</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/52057a30dcbf9031815732e296454c75.html">&lt;p&gt;Human learning and generalization benefit from bootstrapping: we arrive at complex concepts by starting small and building upon past successes. In this paper, we examine a computational account of causal conceptual bootstrapping, and describe a novel experiment in which the sequence of training data results in a dramatic order effect: participants succeed in identifying a compound concept only after experiencing training data in a helpful order. Our computational model represents Cites: Learning programs: A hierarchical Bayesian approach&lt;/p&gt;</content><author><name>B Zhao, NR Bramley, CG Lucas - PsyArXiv. May, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Human learning and generalization benefit from bootstrapping: we arrive at complex concepts by starting small and building upon past successes. In this paper, we examine a computational account of causal conceptual bootstrapping, and describe a novel experiment in which the sequence of training data results in a dramatic order effect: participants succeed in identifying a compound concept only after experiencing training data in a helpful order. Our computational model represents Cites: Learning programs: A hierarchical Bayesian approach</summary></entry><entry><title type="html">Real-Time Detection of COVID-19 Events From Twitter: A Spatial-Temporally Bursty-Aware Method</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/57de91acd72f3447750dde88be54a2a5.html" rel="alternate" type="text/html" title="Real-Time Detection of COVID-19 Events From Twitter: A Spatial-Temporally Bursty-Aware Method" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/57de91acd72f3447750dde88be54a2a5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/57de91acd72f3447750dde88be54a2a5.html">&lt;p&gt;In the last two years, the outbreak of COVID-19 has significantly affected human life, society, and the economy worldwide. To prevent people from contracting COVID-19 and mitigate its spread, it is crucial to timely distribute complete, accurate, and up-to- date information about the pandemic to the public. In this article, we propose a spatial-temporally bursty-aware method called STBA for real-time detection of COVID- 19 events from Twitter. STBA has three consecutive stages. In the first stage, STBA Cites: BERT: Pre-training of Deep Bidirectional Transformers for&lt;/p&gt;</content><author><name>G Fei, Y Cheng, W Ma, C Chen, S Wen, G Hu - IEEE Transactions on Computational , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In the last two years, the outbreak of COVID-19 has significantly affected human life, society, and the economy worldwide. To prevent people from contracting COVID-19 and mitigate its spread, it is crucial to timely distribute complete, accurate, and up-to- date information about the pandemic to the public. In this article, we propose a spatial-temporally bursty-aware method called STBA for real-time detection of COVID- 19 events from Twitter. STBA has three consecutive stages. In the first stage, STBA Cites: BERT: Pre-training of Deep Bidirectional Transformers for</summary></entry><entry><title type="html">iFeatureOmega: an integrative platform for engineering, visualization and analysis of features from molecular sequences, structural and ligand data sets</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/6482c314d13c890beb6abf0b39826adf.html" rel="alternate" type="text/html" title="iFeatureOmega: an integrative platform for engineering, visualization and analysis of features from molecular sequences, structural and ligand data sets" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/6482c314d13c890beb6abf0b39826adf</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/6482c314d13c890beb6abf0b39826adf.html">&lt;p&gt;The rapid accumulation of molecular data motivates development of innovative approaches to computationally characterize sequences, structures and functions of biological and chemical molecules in an efficient, accessible and accurate manner. Notwithstanding several computational tools that characterize protein or nucleic acids data, there are no one-stop computational toolkits that comprehensively characterize a wide range of biomolecules. We address this vital need by developing Cites: Structure-based protein function prediction using graph&lt;/p&gt;</content><author><name>Z Chen, X Liu, P Zhao, C Li, Y Wang, F Li, T Akutsu - Nucleic Acids Research, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The rapid accumulation of molecular data motivates development of innovative approaches to computationally characterize sequences, structures and functions of biological and chemical molecules in an efficient, accessible and accurate manner. Notwithstanding several computational tools that characterize protein or nucleic acids data, there are no one-stop computational toolkits that comprehensively characterize a wide range of biomolecules. We address this vital need by developing Cites: Structure-based protein function prediction using graph</summary></entry><entry><title type="html">Decoupled Graph Neural Networks based on Label Agreement Message Propagation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/66969946e98ac186b8b736de71475741.html" rel="alternate" type="text/html" title="Decoupled Graph Neural Networks based on Label Agreement Message Propagation" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/66969946e98ac186b8b736de71475741</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/66969946e98ac186b8b736de71475741.html">&lt;p&gt;Decoupling has become a new paradigm in Graph Neural Networks (GNNs) for its effectiveness and scalability. However, this paradigm still faces two several restrictions: unsatisfying propagation, caused by noisy or confused edges, could greatly degrade model performance; fixed aggregation schema with the same propagation steps and the same combination weights for each node limit achieving optimal performance. To address these problems, we propose a novel decoupled Cites: Learning with Local and Global Consistency.&lt;/p&gt;</content><author><name>Z An, Z Wu, B Hu, Z Zhang, JUN ZHOU, Y Wang - ICLR 2022 Workshop on , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Decoupling has become a new paradigm in Graph Neural Networks (GNNs) for its effectiveness and scalability. However, this paradigm still faces two several restrictions: unsatisfying propagation, caused by noisy or confused edges, could greatly degrade model performance; fixed aggregation schema with the same propagation steps and the same combination weights for each node limit achieving optimal performance. To address these problems, we propose a novel decoupled Cites: Learning with Local and Global Consistency.</summary></entry><entry><title type="html">Consumer Protection on the Web with Longitudinal Web Crawls and Analysis</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/67fd143c9e34e3c6ba11d004a6ee5801.html" rel="alternate" type="text/html" title="Consumer Protection on the Web with Longitudinal Web Crawls and Analysis" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/67fd143c9e34e3c6ba11d004a6ee5801</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/67fd143c9e34e3c6ba11d004a6ee5801.html">&lt;p&gt;The world wide web has brought with it new consumer protection hazards, such as deceptive reviews and online tracking. While many academics have studied consumer protection on the web at specific points in time, we approach this problem from a longitudinal perspective, exploring how consumers  rights to privacy and to be informed have been impacted by the web. Our work highlights the key role in study of consumer protection issues played by longitudinal analyses and longitudinal data Cites: Finding deceptive opinion spam by any stretch of the imagination&lt;/p&gt;</content><author><name>R Amos - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The world wide web has brought with it new consumer protection hazards, such as deceptive reviews and online tracking. While many academics have studied consumer protection on the web at specific points in time, we approach this problem from a longitudinal perspective, exploring how consumers rights to privacy and to be informed have been impacted by the web. Our work highlights the key role in study of consumer protection issues played by longitudinal analyses and longitudinal data Cites: Finding deceptive opinion spam by any stretch of the imagination</summary></entry><entry><title type="html">Variational Cold-start Resistant Recommendation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/6a68b486a6d659659733340f080cd456.html" rel="alternate" type="text/html" title="Variational Cold-start Resistant Recommendation" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/6a68b486a6d659659733340f080cd456</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/6a68b486a6d659659733340f080cd456.html">&lt;p&gt;Conventionally, cold-start limitations are managed by leveraging side information such as social-trust relationships. However, the relationships between users in social networks are complex, uncertain, and sparse. Therefore, it is necessary to extract beneficial social connections to make the recommendation models cold-start resistant. Towards this end, we propose a novel recommendation model called Variational Cold-start Resistant Recommendation (CORE-VAE). More concretely, we Cites: Recommender systems with social regularization&lt;/p&gt;</content><author><name>J Walker, F Zhang, T Zhong, F Zhou, EY Baagyere - Information Sciences, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Conventionally, cold-start limitations are managed by leveraging side information such as social-trust relationships. However, the relationships between users in social networks are complex, uncertain, and sparse. Therefore, it is necessary to extract beneficial social connections to make the recommendation models cold-start resistant. Towards this end, we propose a novel recommendation model called Variational Cold-start Resistant Recommendation (CORE-VAE). More concretely, we Cites: Recommender systems with social regularization</summary></entry><entry><title type="html">An adaptable, high-performance relation extraction system for complex sentences</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/8d666e35dead06f6bd1da511e6a4f1c3.html" rel="alternate" type="text/html" title="An adaptable, high-performance relation extraction system for complex sentences" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/8d666e35dead06f6bd1da511e6a4f1c3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/8d666e35dead06f6bd1da511e6a4f1c3.html">&lt;p&gt;The rapid proliferation of text data has lead to an increase in the use of Information Extraction (IE) techniques to automatically extract key information in a fast and effective manner. Relation Extraction (RE), a sub-task of IE focuses on extracting semantic relations from free natural language text and is crucial for further applications including Question Answering, Information Retrieval, Knowledge Base construction, Text Summarization, etc. Literature shows that supervised learning Cites: Open information extraction from the web&lt;/p&gt;</content><author><name>A Thomas, S Sangeetha - Knowledge-Based Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The rapid proliferation of text data has lead to an increase in the use of Information Extraction (IE) techniques to automatically extract key information in a fast and effective manner. Relation Extraction (RE), a sub-task of IE focuses on extracting semantic relations from free natural language text and is crucial for further applications including Question Answering, Information Retrieval, Knowledge Base construction, Text Summarization, etc. Literature shows that supervised learning Cites: Open information extraction from the web</summary></entry><entry><title type="html">Accurate and prompt answering framework based on customer reviews and question-answer pairs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/923f8ab8a63cc5d76758a659c4ece9fa.html" rel="alternate" type="text/html" title="Accurate and prompt answering framework based on customer reviews and question-answer pairs" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/923f8ab8a63cc5d76758a659c4ece9fa</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/923f8ab8a63cc5d76758a659c4ece9fa.html">&lt;p&gt;As e-commerce markets have gradually expanded, online shopping malls have provided various services aiming to secure competitiveness. A service for providing an accurate and prompt response when a customer writes an inquiry regarding a product represents a space directly connected to the customer and plays an important role, as it is directly related to product sales. However, the current online shopping mall answering service has disadvantages, eg, it takes time for an Cites: Learning sentiment-specific word embedding for twitter sentiment&lt;/p&gt;</content><author><name>E Kim, H Yoon, J Lee, M Kim - Expert Systems with Applications, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As e-commerce markets have gradually expanded, online shopping malls have provided various services aiming to secure competitiveness. A service for providing an accurate and prompt response when a customer writes an inquiry regarding a product represents a space directly connected to the customer and plays an important role, as it is directly related to product sales. However, the current online shopping mall answering service has disadvantages, eg, it takes time for an Cites: Learning sentiment-specific word embedding for twitter sentiment</summary></entry><entry><title type="html">Seeing the Forest for the Trees: Understanding Security Hazards in the 3GPP Ecosystem through Intelligent Analysis on Change Requests</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/b0c17979965db7bf9d1d73f461386329.html" rel="alternate" type="text/html" title="Seeing the Forest for the Trees: Understanding Security Hazards in the 3GPP Ecosystem through Intelligent Analysis on Change Requests" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/b0c17979965db7bf9d1d73f461386329</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/b0c17979965db7bf9d1d73f461386329.html">&lt;p&gt;With the recent report of erroneous content in 3GPP specifications leading to real- world vulnerabilities, attention has been drawn to not only the specifications but also the way they are maintained and adopted by manufacturers and carriers. In this paper, we report the first study on this 3GPP ecosystem, for the purpose of understanding its security hazards. Our research leverages 414,488 Change Requests (CRs) that document the problems discovered from specifications and Cites: BERT: Pre-training of Deep Bidirectional Transformers for&lt;/p&gt;</content><author><name>Y Chen, D Tang, Y Yao, M Zha, XF Wang, X Liu</name></author><category term="jekyll" /><category term="update" /><summary type="html">With the recent report of erroneous content in 3GPP specifications leading to real- world vulnerabilities, attention has been drawn to not only the specifications but also the way they are maintained and adopted by manufacturers and carriers. In this paper, we report the first study on this 3GPP ecosystem, for the purpose of understanding its security hazards. Our research leverages 414,488 Change Requests (CRs) that document the problems discovered from specifications and Cites: BERT: Pre-training of Deep Bidirectional Transformers for</summary></entry><entry><title type="html">SentieXLM: Uyghur enhanced sentiment analysis model based on XLM</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/c20aa8b8d4f15ce97babbd932de2e499.html" rel="alternate" type="text/html" title="SentieXLM: Uyghur enhanced sentiment analysis model based on XLM" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/c20aa8b8d4f15ce97babbd932de2e499</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/c20aa8b8d4f15ce97babbd932de2e499.html">&lt;p&gt;In the field of public opinion analysis, sentiment analysis is an important basic research branch. Previous studies have successfully proved that the advanced transformer pretraining model can be applied to this scenario in Uyghur and other lowresource language scenarios. However, the majority of these studies are based on the traditional language anchor point and rely on the pretraining model s cross lingual understanding ability. The SentieXLM model proposed in this paper Cites: Bert: Pre-training of deep bidirectional transformers for language&lt;/p&gt;</content><author><name>S Li, K Zhao, J Yang, X Jiang, Z Li, Z Ma - Electronics Letters</name></author><category term="jekyll" /><category term="update" /><summary type="html">In the field of public opinion analysis, sentiment analysis is an important basic research branch. Previous studies have successfully proved that the advanced transformer pretraining model can be applied to this scenario in Uyghur and other lowresource language scenarios. However, the majority of these studies are based on the traditional language anchor point and rely on the pretraining model s cross lingual understanding ability. The SentieXLM model proposed in this paper Cites: Bert: Pre-training of deep bidirectional transformers for language</summary></entry><entry><title type="html">DeepTrack: Lightweight Deep Learning for Vehicle Trajectory Prediction in Highways</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/c29375d088b27feea00fbd6df3565d2e.html" rel="alternate" type="text/html" title="DeepTrack: Lightweight Deep Learning for Vehicle Trajectory Prediction in Highways" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/c29375d088b27feea00fbd6df3565d2e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/c29375d088b27feea00fbd6df3565d2e.html">&lt;p&gt;Vehicle trajectory prediction is essential for enabling safety-critical intelligent transportation systems (ITS) applications used in management and operations. While there have been some promising advances in the field, there is a need for modern deep learning algorithms that allow real-time trajectory prediction on embedded IoT devices. This article presents DeepTrack, a novel deep learning algorithm customized for real-time vehicle trajectory prediction and monitoring applications in Cites: Empirical evaluation of gated recurrent neural networks on&lt;/p&gt;</content><author><name>V Katariya, M Baharani, N Morris, O Shoghli, H Tabkhi - IEEE Transactions on , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Vehicle trajectory prediction is essential for enabling safety-critical intelligent transportation systems (ITS) applications used in management and operations. While there have been some promising advances in the field, there is a need for modern deep learning algorithms that allow real-time trajectory prediction on embedded IoT devices. This article presents DeepTrack, a novel deep learning algorithm customized for real-time vehicle trajectory prediction and monitoring applications in Cites: Empirical evaluation of gated recurrent neural networks on</summary></entry><entry><title type="html">Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/cec234522f72bb3ace6c4835465d0150.html" rel="alternate" type="text/html" title="Certified Robustness of Nearest Neighbors against Data Poisoning and Backdoor Attacks" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/cec234522f72bb3ace6c4835465d0150</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/cec234522f72bb3ace6c4835465d0150.html">&lt;p&gt;Data poisoning attacks and backdoor attacks aim to corrupt a machine learning classifier via modifying, adding, and/or removing some carefully selected training examples, such that the corrupted classifier makes incorrect predictions as the attacker desires. The key idea of state-of-the-art certified defenses against data poisoning attacks and backdoor attacks is to create a majority vote mechanism to predict the label of a testing example. Moreover, each voter is a base classifier Cites: Certified defenses for data poisoning attacks&lt;/p&gt;</content><author><name>J Jia, Y Liu, X Cao, NZ Gong - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Data poisoning attacks and backdoor attacks aim to corrupt a machine learning classifier via modifying, adding, and/or removing some carefully selected training examples, such that the corrupted classifier makes incorrect predictions as the attacker desires. The key idea of state-of-the-art certified defenses against data poisoning attacks and backdoor attacks is to create a majority vote mechanism to predict the label of a testing example. Moreover, each voter is a base classifier Cites: Certified defenses for data poisoning attacks</summary></entry><entry><title type="html">Temporal convolution-based sorting feature repeat-explore network combining with multi-band information for remaining useful life estimation of equipment</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/d62edf5928075b64813364480fe54335.html" rel="alternate" type="text/html" title="Temporal convolution-based sorting feature repeat-explore network combining with multi-band information for remaining useful life estimation of equipment" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/d62edf5928075b64813364480fe54335</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/d62edf5928075b64813364480fe54335.html">&lt;p&gt;Remaining useful life (RUL) estimation of key components is a particularly important link in the reliability evaluation of overall unit. Due to complex nonlinearity and uncertainty in degradation process of mechanical systems, conventional methods are difficult to fulfil the accurate medium &amp;amp; long-term predictive maintenance tasks. To address this issue, this paper proposes a novel concurrent residual temporal convolution network in repeat-explore mode (CRTCN-RE Mode), which utilizes multi Cites: Effective approaches to attention-based neural machine translation&lt;/p&gt;</content><author><name>Y Chang, J Chen, Y Liu, E Xu, S He - Knowledge-Based Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Remaining useful life (RUL) estimation of key components is a particularly important link in the reliability evaluation of overall unit. Due to complex nonlinearity and uncertainty in degradation process of mechanical systems, conventional methods are difficult to fulfil the accurate medium &amp;amp; long-term predictive maintenance tasks. To address this issue, this paper proposes a novel concurrent residual temporal convolution network in repeat-explore mode (CRTCN-RE Mode), which utilizes multi Cites: Effective approaches to attention-based neural machine translation</summary></entry><entry><title type="html">Improving Diversity in Conversational Recipe Recommender through Dynamic Critiquing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/dba89b2fcfc50a2db6650d267cca07d9.html" rel="alternate" type="text/html" title="Improving Diversity in Conversational Recipe Recommender through Dynamic Critiquing" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/dba89b2fcfc50a2db6650d267cca07d9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/dba89b2fcfc50a2db6650d267cca07d9.html">&lt;p&gt;Diet diversification has been shown both to improve nutritional health outcomes and to promote greater enjoyment in food consumption. Conversational Recommender Systems (CRS) have a rich history in direct recommendation of recipes and meal planning, as well as conversational exploration of the possibilities for new food items. However, limited attention has been given to incorporating diversity outcomes as a primary factor in conversational critique for exploration. Critiquing as a method of Cites: Pareto-efficient hybridization for multi-objective recommender&lt;/p&gt;</content><author><name>F Abbas - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Diet diversification has been shown both to improve nutritional health outcomes and to promote greater enjoyment in food consumption. Conversational Recommender Systems (CRS) have a rich history in direct recommendation of recipes and meal planning, as well as conversational exploration of the possibilities for new food items. However, limited attention has been given to incorporating diversity outcomes as a primary factor in conversational critique for exploration. Critiquing as a method of Cites: Pareto-efficient hybridization for multi-objective recommender</summary></entry><entry><title type="html">Listwise Learning to Rank Based on Approximate Rank Indicators</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/e65a0fe9d0cad1344588b2ff10ea080d.html" rel="alternate" type="text/html" title="Listwise Learning to Rank Based on Approximate Rank Indicators" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/e65a0fe9d0cad1344588b2ff10ea080d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/e65a0fe9d0cad1344588b2ff10ea080d.html">&lt;p&gt;We study here a way to approximate information retrieval metrics through a softmax- based approximation of the rank indicator function. Indeed, this latter function is a key component in the design of information retrieval metrics, as well as in the design of the ranking and sorting functions. Obtaining a good approximation for it thus opens the door to differentiable approximations of many evaluation measures that can in turn be used in neural end-to-end approaches. We first prove theoretically that the Cites: BERT: Pre-training of Deep Bidirectional Transformers for&lt;/p&gt;</content><author><name>T Thonet, YG Cinar, E Gaussier, M Li, JM Renders - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We study here a way to approximate information retrieval metrics through a softmax- based approximation of the rank indicator function. Indeed, this latter function is a key component in the design of information retrieval metrics, as well as in the design of the ranking and sorting functions. Obtaining a good approximation for it thus opens the door to differentiable approximations of many evaluation measures that can in turn be used in neural end-to-end approaches. We first prove theoretically that the Cites: BERT: Pre-training of Deep Bidirectional Transformers for</summary></entry><entry><title type="html">Learning Fair Representations without Demographics</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/edb58767d54b434ca533fafc0fbab0cc.html" rel="alternate" type="text/html" title="Learning Fair Representations without Demographics" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/edb58767d54b434ca533fafc0fbab0cc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/edb58767d54b434ca533fafc0fbab0cc.html">&lt;p&gt;Due to hard accessibility, real-world adoption of fair representation learning algorithms lacks the prior knowledge of the sensitive attributes that we wish to be fair with. To address the challenge in fairness without explicit demographics, our solution is based on the idea of maximally randomizing the representation while being as informative as possible about the target task. We operationalize this goal through the concept of maximizing the entropy of the learned representation. For this purpose Cites: Fairness without demographics in repeated loss minimization&lt;/p&gt;</content><author><name>X Wang - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Due to hard accessibility, real-world adoption of fair representation learning algorithms lacks the prior knowledge of the sensitive attributes that we wish to be fair with. To address the challenge in fairness without explicit demographics, our solution is based on the idea of maximally randomizing the representation while being as informative as possible about the target task. We operationalize this goal through the concept of maximizing the entropy of the learned representation. For this purpose Cites: Fairness without demographics in repeated loss minimization</summary></entry><entry><title type="html">P $^ 3$ Ranker: Mitigating the Gaps between Pre-training and Ranking Fine-tuning with Prompt-based Learning and Pre-finetuning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/fd23807c9435c3f1af2785333e92180f.html" rel="alternate" type="text/html" title="P $^ 3$ Ranker: Mitigating the Gaps between Pre-training and Ranking Fine-tuning with Prompt-based Learning and Pre-finetuning" /><published>2022-05-12T04:06:18-04:00</published><updated>2022-05-12T04:06:18-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/fd23807c9435c3f1af2785333e92180f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/12/fd23807c9435c3f1af2785333e92180f.html">&lt;p&gt;Compared to other language tasks, applying pre-trained language models (PLMs) for search ranking often requires more nuances and training signals. In this paper, we identify and study the two mismatches between pre-training and ranking fine&lt;/p&gt;</content><author><name>X Hu, S Yu, C Xiong, Z Liu, Z Liu, G Yu - arXiv preprint arXiv:2205.01886, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Compared to other language tasks, applying pre-trained language models (PLMs) for search ranking often requires more nuances and training signals. In this paper, we identify and study the two mismatches between pre-training and ranking fine</summary></entry><entry><title type="html">Explainable NLP for Human-AI Collaboration</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/021178952087d34003be35a85cce4172.html" rel="alternate" type="text/html" title="Explainable NLP for Human-AI Collaboration" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/021178952087d34003be35a85cce4172</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/021178952087d34003be35a85cce4172.html">&lt;p&gt;With more data and computing resources available these days, we have seen many novel Natural Language Processing (NLP) models breaking one performance record after another. Some of them even outperform human performance in some specific tasks. Meanwhile, many researchers have revealed weaknesses and irrationality of such models, eg, having biases against some sub-populations, producing inconsistent predictions, and failing to work effectively in the wild due to overfitting Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList&lt;/p&gt;</content><author><name>P Lertvittayakumjorn - 2021</name></author><category term="jekyll" /><category term="update" /><summary type="html">With more data and computing resources available these days, we have seen many novel Natural Language Processing (NLP) models breaking one performance record after another. Some of them even outperform human performance in some specific tasks. Meanwhile, many researchers have revealed weaknesses and irrationality of such models, eg, having biases against some sub-populations, producing inconsistent predictions, and failing to work effectively in the wild due to overfitting Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList</summary></entry><entry><title type="html">On Continual Model Refinement in Out-of-Distribution Data Streams</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/04139ba644310677666014626e11507b.html" rel="alternate" type="text/html" title="On Continual Model Refinement in Out-of-Distribution Data Streams" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/04139ba644310677666014626e11507b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/04139ba644310677666014626e11507b.html">&lt;p&gt;Real-world natural language processing (NLP) models need to be continually updated to fix the prediction errors in out-of-distribution (OOD) data streams while overcoming catastrophic forgetting. However, existing continual learning (CL)&lt;/p&gt;</content><author><name>B Yuchen Lin, S Wang, XV Lin, R Jia, L Xiao, X Ren - arXiv e-prints, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Real-world natural language processing (NLP) models need to be continually updated to fix the prediction errors in out-of-distribution (OOD) data streams while overcoming catastrophic forgetting. However, existing continual learning (CL)</summary></entry><entry><title type="html">Learning Competitive Equilibria in Exchange Economies with Bandit Feedback</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/04c53e20a32250c0a215b2ef8ccfc6b5.html" rel="alternate" type="text/html" title="Learning Competitive Equilibria in Exchange Economies with Bandit Feedback" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/04c53e20a32250c0a215b2ef8ccfc6b5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/04c53e20a32250c0a215b2ef8ccfc6b5.html">&lt;p&gt;The sharing of scarce resources among multiple rational agents is one of the classical problems in economics. In exchange economies, which are used to model such situations, agents begin with an initial endowment of resources and exchange them in a way that is mutually beneficial until they reach a competitive equilibrium (CE). The allocations at a CE are Pareto efficient and fair. Consequently, they are used widely in designing mechanisms for fair division. However, computing CEs Cites: Provably optimal algorithms for generalized linear contextual bandits&lt;/p&gt;</content><author><name>W Guo, K Kandasamy, J Gonzalez, M Jordan, I Stoica - International Conference on , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The sharing of scarce resources among multiple rational agents is one of the classical problems in economics. In exchange economies, which are used to model such situations, agents begin with an initial endowment of resources and exchange them in a way that is mutually beneficial until they reach a competitive equilibrium (CE). The allocations at a CE are Pareto efficient and fair. Consequently, they are used widely in designing mechanisms for fair division. However, computing CEs Cites: Provably optimal algorithms for generalized linear contextual bandits</summary></entry><entry><title type="html">Word Tour: One-dimensional Word Embeddings via the Traveling Salesman Problem</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/0724ee2ad53c5f564c1bd3e920f80ce4.html" rel="alternate" type="text/html" title="Word Tour: One-dimensional Word Embeddings via the Traveling Salesman Problem" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/0724ee2ad53c5f564c1bd3e920f80ce4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/0724ee2ad53c5f564c1bd3e920f80ce4.html">&lt;p&gt;Word embeddings are one of the most fundamental technologies used in natural language processing. Existing word embeddings are high-dimensional and consume considerable computational resources. In this study, we propose WordTour, unsupervised one-dimensional word embeddings. To achieve the challenging goal, we propose a decomposition of the desiderata of word embeddings into two parts, completeness and soundness, and focus on soundness Cites: Linguistic regularities in continuous space word representations&lt;/p&gt;</content><author><name>R Sato - arXiv preprint arXiv:2205.01954, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Word embeddings are one of the most fundamental technologies used in natural language processing. Existing word embeddings are high-dimensional and consume considerable computational resources. In this study, we propose WordTour, unsupervised one-dimensional word embeddings. To achieve the challenging goal, we propose a decomposition of the desiderata of word embeddings into two parts, completeness and soundness, and focus on soundness Cites: Linguistic regularities in continuous space word representations</summary></entry><entry><title type="html">Topological methods for analysis and design of coordination polymers</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/09ca14a9dc974ebd9b4feb7d896423f7.html" rel="alternate" type="text/html" title="Topological methods for analysis and design of coordination polymers" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/09ca14a9dc974ebd9b4feb7d896423f7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/09ca14a9dc974ebd9b4feb7d896423f7.html">&lt;p&gt;A comprehensive review of the methods for topological analysis of crystalline compounds as applied to the structures of coordination polymers is presented for the first time. The basic concepts of reticular chemistry, a new branch of science, which combines methods of synthetic chemistry with methods for topological design of polymer compounds, are considered. Reticular chemistry methods are illustrated with examples of the analysis and design of coordination polymers. The most Cites: Theoretical limits of hydrogen storage in metalorganic&lt;/p&gt;</content><author><name>EV Alexandrov, AP Shevchenko, NA Nekrasova - Russian Chemical Reviews, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A comprehensive review of the methods for topological analysis of crystalline compounds as applied to the structures of coordination polymers is presented for the first time. The basic concepts of reticular chemistry, a new branch of science, which combines methods of synthetic chemistry with methods for topological design of polymer compounds, are considered. Reticular chemistry methods are illustrated with examples of the analysis and design of coordination polymers. The most Cites: Theoretical limits of hydrogen storage in metalorganic</summary></entry><entry><title type="html">On Continual Model Refinement in Out-of-Distribution Data Streams</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/09f85019048d34c1a94feb68b6f09303.html" rel="alternate" type="text/html" title="On Continual Model Refinement in Out-of-Distribution Data Streams" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/09f85019048d34c1a94feb68b6f09303</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/09f85019048d34c1a94feb68b6f09303.html">&lt;p&gt;Real-world natural language processing (NLP) models need to be continually updated to fix the prediction errors in out-of-distribution (OOD) data streams while overcoming catastrophic forgetting. However, existing continual learning (CL) problem setups cannot cover such a realistic and complex scenario. In response to this, we propose a new CL problem formulation dubbed continual model refinement (CMR). Compared to prior CL settings, CMR is more practical and introduces unique Cites: Fast model editing at scale&lt;/p&gt;</content><author><name>BY Lin, S Wang, XV Lin, R Jia, L Xiao, X Ren, W Yih - arXiv preprint arXiv:2205.02014, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Real-world natural language processing (NLP) models need to be continually updated to fix the prediction errors in out-of-distribution (OOD) data streams while overcoming catastrophic forgetting. However, existing continual learning (CL) problem setups cannot cover such a realistic and complex scenario. In response to this, we propose a new CL problem formulation dubbed continual model refinement (CMR). Compared to prior CL settings, CMR is more practical and introduces unique Cites: Fast model editing at scale</summary></entry><entry><title type="html">Are All the Datasets in Benchmark Necessary? A Pilot Study of Dataset Evaluation for Text Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/1aed9312c0d08f093ec7d72c23886326.html" rel="alternate" type="text/html" title="Are All the Datasets in Benchmark Necessary? A Pilot Study of Dataset Evaluation for Text Classification" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/1aed9312c0d08f093ec7d72c23886326</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/1aed9312c0d08f093ec7d72c23886326.html">&lt;p&gt;In this paper, we ask the research question of whether all the datasets in the benchmark are necessary. We approach this by first characterizing the distinguishability of datasets when comparing different systems. Experiments on 9 datasets and 36 systems show that several existing benchmark datasets contribute little to discriminating top-scoring systems, while those less used datasets exhibit impressive discriminative power. We further, taking the text classification task as a Cites: DataLab: A Platform for Data Analysis and Intervention&lt;/p&gt;</content><author><name>Y Xiao, J Fu, SK Ng, P Liu - arXiv preprint arXiv:2205.02129, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In this paper, we ask the research question of whether all the datasets in the benchmark are necessary. We approach this by first characterizing the distinguishability of datasets when comparing different systems. Experiments on 9 datasets and 36 systems show that several existing benchmark datasets contribute little to discriminating top-scoring systems, while those less used datasets exhibit impressive discriminative power. We further, taking the text classification task as a Cites: DataLab: A Platform for Data Analysis and Intervention</summary></entry><entry><title type="html">Improving Multi-Document Summarization through Referenced Flexible Extraction with Credit-Awareness</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/1d7a0b8c7fd670280e9afa1ee8508442.html" rel="alternate" type="text/html" title="Improving Multi-Document Summarization through Referenced Flexible Extraction with Credit-Awareness" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/1d7a0b8c7fd670280e9afa1ee8508442</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/1d7a0b8c7fd670280e9afa1ee8508442.html">&lt;p&gt;A notable challenge in Multi-Document Summarization (MDS) is the extremely-long length of the input. In this paper, we present an extract-then-abstract Transformer framework to overcome the problem. Specifically, we leverage pre-trained language models to construct a hierarchical extractor for salient sentence selection across documents and an abstractor for rewriting the selected contents as summaries. However, learning such a framework is challenging since the optimal contents for the Cites: Learning Opinion Summarizers by Selecting Informative Reviews&lt;/p&gt;</content><author><name>YZ Song, YS Chen, HH Shuai - arXiv preprint arXiv:2205.01889, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A notable challenge in Multi-Document Summarization (MDS) is the extremely-long length of the input. In this paper, we present an extract-then-abstract Transformer framework to overcome the problem. Specifically, we leverage pre-trained language models to construct a hierarchical extractor for salient sentence selection across documents and an abstractor for rewriting the selected contents as summaries. However, learning such a framework is challenging since the optimal contents for the Cites: Learning Opinion Summarizers by Selecting Informative Reviews</summary></entry><entry><title type="html">Off-Policy Risk Assessment for Markov Decision Processes</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/22c837267b71e673bcbe3fc33bc12a2a.html" rel="alternate" type="text/html" title="Off-Policy Risk Assessment for Markov Decision Processes" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/22c837267b71e673bcbe3fc33bc12a2a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/22c837267b71e673bcbe3fc33bc12a2a.html">&lt;p&gt;Addressing such diverse ends as mitigating safety risks, aligning agent behavior with human preferences, and improving the efficiency of learning, an emerging line of reinforcement learning research addresses the entire distribution of returns and various risk functionals that depend upon it. In the contextual bandit setting, recently work on off-policy risk assessment estimates the target policy s CDF of returns, providing finite sample guarantees that extend to (and hold simultaneously over) Cites: Breaking the curse of horizon: Infinite-horizon off-policy estimation&lt;/p&gt;</content><author><name>A Huang, L Leqi, Z Lipton, K Azizzadenesheli - International Conference on Artificial , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Addressing such diverse ends as mitigating safety risks, aligning agent behavior with human preferences, and improving the efficiency of learning, an emerging line of reinforcement learning research addresses the entire distribution of returns and various risk functionals that depend upon it. In the contextual bandit setting, recently work on off-policy risk assessment estimates the target policy s CDF of returns, providing finite sample guarantees that extend to (and hold simultaneously over) Cites: Breaking the curse of horizon: Infinite-horizon off-policy estimation</summary></entry><entry><title type="html">Rethinking Classifier And Adversarial Attack</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/2548400fef8a2f465e69b5115e92ffd4.html" rel="alternate" type="text/html" title="Rethinking Classifier And Adversarial Attack" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/2548400fef8a2f465e69b5115e92ffd4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/2548400fef8a2f465e69b5115e92ffd4.html">&lt;p&gt;Various defense models have been proposed to resist adversarial attack algorithms, but existing adversarial robustness evaluation methods always overestimate the adversarial robustness of these models (ie not approaching the lower bound of robustness). To solve this problem, this paper first uses the Decouple Space method to divide the classifier into two parts: non-linear and linear. On this basis, this paper defines the representation vector of original example (and its space, ie, the Cites: Unlabeled data improves adversarial robustness&lt;/p&gt;</content><author><name>Y Yang, L Sun, L Dai, S Guo, X Mao, X Wang, B Xu - arXiv preprint arXiv:2205.02743, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Various defense models have been proposed to resist adversarial attack algorithms, but existing adversarial robustness evaluation methods always overestimate the adversarial robustness of these models (ie not approaching the lower bound of robustness). To solve this problem, this paper first uses the Decouple Space method to divide the classifier into two parts: non-linear and linear. On this basis, this paper defines the representation vector of original example (and its space, ie, the Cites: Unlabeled data improves adversarial robustness</summary></entry><entry><title type="html">CODE-MVP: Learning to Represent Source Code from Multiple Views with Contrastive Pre-Training</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/268ea221a408bc340b6f97deaf504b15.html" rel="alternate" type="text/html" title="CODE-MVP: Learning to Represent Source Code from Multiple Views with Contrastive Pre-Training" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/268ea221a408bc340b6f97deaf504b15</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/268ea221a408bc340b6f97deaf504b15.html">&lt;p&gt;Recent years have witnessed increasing interest in code representation learning, which aims to represent the semantics of source code into distributed vectors. Currently, various works have been proposed to represent the complex semantics of source code from different views, including plain text, Abstract Syntax Tree (AST), and several kinds of code graphs (eg, Control/Data Flow Graph). However, most of them only consider a single view of source code independently, ignoring the Cites: Learning to mine aligned code and natural language pairs from&lt;/p&gt;</content><author><name>X Wang, Y Wang, Y Wan, J Wang, P Zhou, L Li, H Wu - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent years have witnessed increasing interest in code representation learning, which aims to represent the semantics of source code into distributed vectors. Currently, various works have been proposed to represent the complex semantics of source code from different views, including plain text, Abstract Syntax Tree (AST), and several kinds of code graphs (eg, Control/Data Flow Graph). However, most of them only consider a single view of source code independently, ignoring the Cites: Learning to mine aligned code and natural language pairs from</summary></entry><entry><title type="html">EllSeg-Gen, towards Domain Generalization for head-mounted eyetracking</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/2e535aeb4156764d6cc8f78783a32f3c.html" rel="alternate" type="text/html" title="EllSeg-Gen, towards Domain Generalization for head-mounted eyetracking" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/2e535aeb4156764d6cc8f78783a32f3c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/2e535aeb4156764d6cc8f78783a32f3c.html">&lt;p&gt;The study of human gaze behavior in natural contexts requires algorithms for gaze estimation that are robust to a wide range of imaging conditions. However, algorithms often fail to identify features such as the iris and pupil centroid in the presence of reflective artifacts and occlusions. Previous work has shown that convolutional networks excel at extracting gaze features despite the presence of such artifacts. However, these networks often perform poorly on data unseen during Cites: Understanding and mitigating the tradeoff between robustness and&lt;/p&gt;</content><author><name>RS Kothari, RJ Bailey, C Kanan, JB Pelz, GJ Diaz - arXiv preprint arXiv:2205.01947, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The study of human gaze behavior in natural contexts requires algorithms for gaze estimation that are robust to a wide range of imaging conditions. However, algorithms often fail to identify features such as the iris and pupil centroid in the presence of reflective artifacts and occlusions. Previous work has shown that convolutional networks excel at extracting gaze features despite the presence of such artifacts. However, these networks often perform poorly on data unseen during Cites: Understanding and mitigating the tradeoff between robustness and</summary></entry><entry><title type="html">Systems and methods for interactive large-scale data search and profiling</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/334cb5036686ca17f543e96a3f6a859b.html" rel="alternate" type="text/html" title="Systems and methods for interactive large-scale data search and profiling" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/334cb5036686ca17f543e96a3f6a859b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/334cb5036686ca17f543e96a3f6a859b.html">&lt;p&gt;Described herein are systems and methods for profiling structured or semi-structured datasets. An example computer-implemented method includes grouping, using a machine learning classifier, a plurality of tables in a dataset that are associated with an object into a cluster, where each of the tables of the cluster includes respective data and respective metadata, the respective metadata including at least one respective attribute, generating a metadata-profile for the cluster, where the metadata Cites: Dark Data: Are we solving the right problems?&lt;/p&gt;</content><author><name>M Gubanov - US Patent App. 17/503,572, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Described herein are systems and methods for profiling structured or semi-structured datasets. An example computer-implemented method includes grouping, using a machine learning classifier, a plurality of tables in a dataset that are associated with an object into a cluster, where each of the tables of the cluster includes respective data and respective metadata, the respective metadata including at least one respective attribute, generating a metadata-profile for the cluster, where the metadata Cites: Dark Data: Are we solving the right problems?</summary></entry><entry><title type="html">Effective use of BERT in graph embeddings for sparse knowledge graph completion</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/36ee8bf00eb16c3163485163f349cd8b.html" rel="alternate" type="text/html" title="Effective use of BERT in graph embeddings for sparse knowledge graph completion" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/36ee8bf00eb16c3163485163f349cd8b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/36ee8bf00eb16c3163485163f349cd8b.html">&lt;p&gt;Graph embedding methods have emerged as effective solutions for knowledge graph completion. However, such methods are typically tested on benchmark datasets such as Freebase, but show limited performance when applied on sparse knowledge graphs with orders of magnitude lower density. To compensate for the lack of structure in a sparse graph, low dimensional representations of textual information such as word2vec or BERT embeddings have been used. This paper Cites: Graph-based reasoning over heterogeneous external knowledge&lt;/p&gt;</content><author><name>X Liu, H Hussain, H Razouk, R Kern - Proceedings of the 37th ACM/SIGAPP , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Graph embedding methods have emerged as effective solutions for knowledge graph completion. However, such methods are typically tested on benchmark datasets such as Freebase, but show limited performance when applied on sparse knowledge graphs with orders of magnitude lower density. To compensate for the lack of structure in a sparse graph, low dimensional representations of textual information such as word2vec or BERT embeddings have been used. This paper Cites: Graph-based reasoning over heterogeneous external knowledge</summary></entry><entry><title type="html">Improving knowledge capture and retrieval in the BIM environment: Combining case-based reasoning and natural language processing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/380341c3b6c48cf9d01b9ad7a4b65436.html" rel="alternate" type="text/html" title="Improving knowledge capture and retrieval in the BIM environment: Combining case-based reasoning and natural language processing" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/380341c3b6c48cf9d01b9ad7a4b65436</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/380341c3b6c48cf9d01b9ad7a4b65436.html">&lt;p&gt;Most knowledge management (KM) techniques capture knowledge at the end of a project, leading to knowledge loss. Building information modeling (BIM) is a building information management process throughout the project lifecycle. This study uses BIM for lifecycle knowledge capture to address knowledge loss. Knowledge in construction projects is intricate, intensifying the challenges of knowledge retrieval. This study combines natural language processing (NLP) and case-based reasoning Cites: Emergent linguistic structure in artificial neural networks trained by&lt;/p&gt;</content><author><name>H Wang, X Meng, X Zhu - Automation in Construction, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Most knowledge management (KM) techniques capture knowledge at the end of a project, leading to knowledge loss. Building information modeling (BIM) is a building information management process throughout the project lifecycle. This study uses BIM for lifecycle knowledge capture to address knowledge loss. Knowledge in construction projects is intricate, intensifying the challenges of knowledge retrieval. This study combines natural language processing (NLP) and case-based reasoning Cites: Emergent linguistic structure in artificial neural networks trained by</summary></entry><entry><title type="html">Optimizing Mixture of Experts using Dynamic Recompilations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/42d3238f953ccef8c531143f41c96b87.html" rel="alternate" type="text/html" title="Optimizing Mixture of Experts using Dynamic Recompilations" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/42d3238f953ccef8c531143f41c96b87</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/42d3238f953ccef8c531143f41c96b87.html">&lt;p&gt;The Mixture of Experts architecture allows for outrageously large neural networks by scaling model parameter size independently from computational demand (FLOPs). However, current DNN frameworks cannot effectively support the dynamic data flow in Mixture of Experts, and implementations on top of these frameworks need to use workarounds that introduce significant overheads. To address the limitation of these frameworks, we present DynaMoE, a DNN library that uses dynamic recompilations Cites: Dynet: The dynamic neural network toolkit&lt;/p&gt;</content><author><name>F Kossmann, Z Jia, A Aiken - arXiv preprint arXiv:2205.01848, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The Mixture of Experts architecture allows for outrageously large neural networks by scaling model parameter size independently from computational demand (FLOPs). However, current DNN frameworks cannot effectively support the dynamic data flow in Mixture of Experts, and implementations on top of these frameworks need to use workarounds that introduce significant overheads. To address the limitation of these frameworks, we present DynaMoE, a DNN library that uses dynamic recompilations Cites: Dynet: The dynamic neural network toolkit</summary></entry><entry><title type="html">Language Models in the Loop: Incorporating Prompting into Weak Supervision</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/4470e2cb21fa7b722a7656961a27463f.html" rel="alternate" type="text/html" title="Language Models in the Loop: Incorporating Prompting into Weak Supervision" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/4470e2cb21fa7b722a7656961a27463f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/4470e2cb21fa7b722a7656961a27463f.html">&lt;p&gt;We propose a new strategy for applying large pre-trained language models to novel tasks when labeled training data is limited. Rather than apply the model in a typical zero-shot or few-shot fashion, we treat the model as the basis for labeling functions in a weak supervision framework. To create a classifier, we first prompt the model to answer multiple distinct queries about an example and define how the possible responses should be mapped to votes for labels and abstentions. We then denoise Cites: ZeroGen: Efficient Zero-shot Learning via Dataset Generation&lt;/p&gt;</content><author><name>R Smith, JA Fries, B Hancock, SH Bach - arXiv preprint arXiv:2205.02318, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose a new strategy for applying large pre-trained language models to novel tasks when labeled training data is limited. Rather than apply the model in a typical zero-shot or few-shot fashion, we treat the model as the basis for labeling functions in a weak supervision framework. To create a classifier, we first prompt the model to answer multiple distinct queries about an example and define how the possible responses should be mapped to votes for labels and abstentions. We then denoise Cites: ZeroGen: Efficient Zero-shot Learning via Dataset Generation</summary></entry><entry><title type="html">Masked Summarization to Generate Factually Inconsistent Summaries for Improved Factual Consistency Checking</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/45eddee3ef7fa4efda4b164a0800af9d.html" rel="alternate" type="text/html" title="Masked Summarization to Generate Factually Inconsistent Summaries for Improved Factual Consistency Checking" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/45eddee3ef7fa4efda4b164a0800af9d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/45eddee3ef7fa4efda4b164a0800af9d.html">&lt;p&gt;Despite the recent advances in abstractive summarization systems, it is still difficult to determine whether a generated summary is factual consistent with the source text. To this end, the latest approach is to train a factual consistency classifier on factually consistent and inconsistent summaries. Luckily, the former is readily available as reference summaries in existing summarization datasets. However, generating the latter remains a challenge, as they need to be factually inconsistent, yet closely Cites: Don t give me the details, just the summary! topic-aware&lt;/p&gt;</content><author><name>H Lee, KM Yoo, J Park, H Lee, K Jung - arXiv preprint arXiv:2205.02035, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Despite the recent advances in abstractive summarization systems, it is still difficult to determine whether a generated summary is factual consistent with the source text. To this end, the latest approach is to train a factual consistency classifier on factually consistent and inconsistent summaries. Luckily, the former is readily available as reference summaries in existing summarization datasets. However, generating the latter remains a challenge, as they need to be factually inconsistent, yet closely Cites: Don t give me the details, just the summary! topic-aware</summary></entry><entry><title type="html">Unified Semantic Typing with Meaningful Label Inference</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/4b727313747ba225c6a61e700d2a0fb3.html" rel="alternate" type="text/html" title="Unified Semantic Typing with Meaningful Label Inference" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/4b727313747ba225c6a61e700d2a0fb3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/4b727313747ba225c6a61e700d2a0fb3.html">&lt;p&gt;Semantic typing aims at classifying tokens or spans of interest in a textual context into semantic categories such as relations, entity types, and event types. The inferred labels of semantic categories meaningfully interpret how machines understand components of text. In this paper, we present UniST, a unified framework for semantic typing that captures label semantics by projecting both inputs and labels into a joint semantic embedding space. To formulate different lexical and relational semantic Cites: K-adapter: Infusing knowledge into pre-trained models with adapters&lt;/p&gt;</content><author><name>JY Huang, B Li, J Xu, M Chen - arXiv preprint arXiv:2205.01826, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Semantic typing aims at classifying tokens or spans of interest in a textual context into semantic categories such as relations, entity types, and event types. The inferred labels of semantic categories meaningfully interpret how machines understand components of text. In this paper, we present UniST, a unified framework for semantic typing that captures label semantics by projecting both inputs and labels into a joint semantic embedding space. To formulate different lexical and relational semantic Cites: K-adapter: Infusing knowledge into pre-trained models with adapters</summary></entry><entry><title type="html">Target-level sentiment analysis for news articles</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/4cce87ae3f713a24099bd53d22ec12d7.html" rel="alternate" type="text/html" title="Target-level sentiment analysis for news articles" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/4cce87ae3f713a24099bd53d22ec12d7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/4cce87ae3f713a24099bd53d22ec12d7.html">&lt;p&gt;The rapid growth of social media, news sites, and blogs increases the opportunity to express and share an opinion on the Internet. Researchers from different fields take advantage of nearly limitless data. Thus, in the past decade, opinion mining or sentiment analysis has become an important research discipline. In this paper, we focus on the target-level sentiment analysis, wherein the task is to predict the sentiment concerning specific (multiple) entities that appear as coreference mentions Cites: Stanza: A python natural language processing toolkit for many&lt;/p&gt;</content><author><name>S itnik, N Blagus, M Bajec - Knowledge-Based Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The rapid growth of social media, news sites, and blogs increases the opportunity to express and share an opinion on the Internet. Researchers from different fields take advantage of nearly limitless data. Thus, in the past decade, opinion mining or sentiment analysis has become an important research discipline. In this paper, we focus on the target-level sentiment analysis, wherein the task is to predict the sentiment concerning specific (multiple) entities that appear as coreference mentions Cites: Stanza: A python natural language processing toolkit for many</summary></entry><entry><title type="html">CATs are Fuzzy PETs: A Corpus and Analysis of Potentially Euphemistic Terms</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/5296cfbdab8750d9dc623306d46f9710.html" rel="alternate" type="text/html" title="CATs are Fuzzy PETs: A Corpus and Analysis of Potentially Euphemistic Terms" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/5296cfbdab8750d9dc623306d46f9710</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/5296cfbdab8750d9dc623306d46f9710.html">&lt;p&gt;Euphemisms have not received much attention in natural language processing, despite being an important element of polite and figurative language. Euphemisms prove to be a difficult topic, not only because they are subject to language change, but also because humans may not agree on what is a euphemism and what is not. Nevertheless, the first step to tackling the issue is to collect and analyze examples of euphemisms. We present a corpus of potentially euphemistic terms (PETs) along Cites: Politeness Transfer: A Tag and Generate Approach&lt;/p&gt;</content><author><name>M Gavidia, P Lee, A Feldman, J Peng - arXiv preprint arXiv:2205.02728, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Euphemisms have not received much attention in natural language processing, despite being an important element of polite and figurative language. Euphemisms prove to be a difficult topic, not only because they are subject to language change, but also because humans may not agree on what is a euphemism and what is not. Nevertheless, the first step to tackling the issue is to collect and analyze examples of euphemisms. We present a corpus of potentially euphemistic terms (PETs) along Cites: Politeness Transfer: A Tag and Generate Approach</summary></entry><entry><title type="html">Deep learning-based approach for Arabic open domain question answering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/53572d091151f9bd96d763e37616d6ef.html" rel="alternate" type="text/html" title="Deep learning-based approach for Arabic open domain question answering" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/53572d091151f9bd96d763e37616d6ef</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/53572d091151f9bd96d763e37616d6ef.html">&lt;p&gt;Open-domain question answering (OpenQA) is one of the most challenging yet widely investigated problems in natural language processing. It aims at building a system that can answer any given question from large-scale unstructured text or structured knowledge-base. To solve this problem, researchers traditionally use information retrieval methods to retrieve the most relevant documents and then use answer extractions techniques to extract the answer or passage from the candidate Cites: Dense Passage Retrieval for Open-Domain Question Answering&lt;/p&gt;</content><author><name>K Alsubhi, A Jamal, A Alhothali - PeerJ Computer Science, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Open-domain question answering (OpenQA) is one of the most challenging yet widely investigated problems in natural language processing. It aims at building a system that can answer any given question from large-scale unstructured text or structured knowledge-base. To solve this problem, researchers traditionally use information retrieval methods to retrieve the most relevant documents and then use answer extractions techniques to extract the answer or passage from the candidate Cites: Dense Passage Retrieval for Open-Domain Question Answering</summary></entry><entry><title type="html">Column Type Detection Based on Pretrained Language Models with Various Column Encodings</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/54bdce37c2e119e6d9bfa2c1e7a08b4c.html" rel="alternate" type="text/html" title="Column Type Detection Based on Pretrained Language Models with Various Column Encodings" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/54bdce37c2e119e6d9bfa2c1e7a08b4c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/54bdce37c2e119e6d9bfa2c1e7a08b4c.html">&lt;p&gt;Real-world tables provide valuable long-tailed facts, and detecting semantic types of table columns is important for table understanding and associated tasks. However, existing methods are often built on heavily-engineered features, such as statistical features and straightforward string matching, which are not robust to dirty data and lack of extensibility. Deep learning models in the field of natural language processing have been successfully adopted to various sequence prediction tasks. In this paper Cites: Turl: Table understanding through representation learning&lt;/p&gt;</content><author><name>P LI, M IWAIHARA</name></author><category term="jekyll" /><category term="update" /><summary type="html">Real-world tables provide valuable long-tailed facts, and detecting semantic types of table columns is important for table understanding and associated tasks. However, existing methods are often built on heavily-engineered features, such as statistical features and straightforward string matching, which are not robust to dirty data and lack of extensibility. Deep learning models in the field of natural language processing have been successfully adopted to various sequence prediction tasks. In this paper Cites: Turl: Table understanding through representation learning</summary></entry><entry><title type="html">KenSwQuAD–A Question Answering Dataset for Swahili Low Resource Language</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/58cfd86a0d330f484fae08888d2ae5bb.html" rel="alternate" type="text/html" title="KenSwQuAD–A Question Answering Dataset for Swahili Low Resource Language" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/58cfd86a0d330f484fae08888d2ae5bb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/58cfd86a0d330f484fae08888d2ae5bb.html">&lt;p&gt;This research developed a Kencorpus Swahili Question Answering Dataset KenSwQuAD from raw data of Swahili language, which is a low resource language predominantly spoken in Eastern African and also has speakers in other parts of the world. Question Answering datasets are important for machine comprehension of natural language processing tasks such as internet search and dialog systems. However, before such machine learning systems can perform these tasks, they need Cites: WikiQA: A challenge dataset for open-domain question answering&lt;/p&gt;</content><author><name>B Wanjawa, L Wanzare, F Indede, O McOnyango - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This research developed a Kencorpus Swahili Question Answering Dataset KenSwQuAD from raw data of Swahili language, which is a low resource language predominantly spoken in Eastern African and also has speakers in other parts of the world. Question Answering datasets are important for machine comprehension of natural language processing tasks such as internet search and dialog systems. However, before such machine learning systems can perform these tasks, they need Cites: WikiQA: A challenge dataset for open-domain question answering</summary></entry><entry><title type="html">Faster Rates, Adaptive Algorithms, and Finite-Time Bounds for Linear Composition Optimization and Gradient TD Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/5fbb96f3891c1a6c868512001ced0815.html" rel="alternate" type="text/html" title="Faster Rates, Adaptive Algorithms, and Finite-Time Bounds for Linear Composition Optimization and Gradient TD Learning" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/5fbb96f3891c1a6c868512001ced0815</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/5fbb96f3891c1a6c868512001ced0815.html">&lt;p&gt;Gradient temporal difference (GTD) algorithms are provably convergent policy evaluation methods for off-policy reinforcement learning. Despite much progress, proper tuning of the stochastic approximation methods used to solve the resulting saddle point optimization problem requires the knowledge of several (unknown) problem-dependent parameters. In this paper we apply adaptive step-size tuning strategies to greatly reduce this dependence on prior knowledge, and provide Cites: Stochastic variance reduction methods for policy evaluation&lt;/p&gt;</content><author><name>A Raj, P Joulani, A Gyorgy, C Szepesvari - International Conference on Artificial , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Gradient temporal difference (GTD) algorithms are provably convergent policy evaluation methods for off-policy reinforcement learning. Despite much progress, proper tuning of the stochastic approximation methods used to solve the resulting saddle point optimization problem requires the knowledge of several (unknown) problem-dependent parameters. In this paper we apply adaptive step-size tuning strategies to greatly reduce this dependence on prior knowledge, and provide Cites: Stochastic variance reduction methods for policy evaluation</summary></entry><entry><title type="html">MULTIMODAL SENTIMENT ANALYSIS OF MEMES</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/61300c3d9ac435f64ffba24d4248236e.html" rel="alternate" type="text/html" title="MULTIMODAL SENTIMENT ANALYSIS OF MEMES" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/61300c3d9ac435f64ffba24d4248236e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/61300c3d9ac435f64ffba24d4248236e.html">&lt;p&gt;Memes are a popular form of conveying information online. However, due to their multimodal nature, they can be hard to analyse. We explore some methods of analysis, focusing on the specific case of detecting hateful memes from the Facebook Hateful Memes Dataset. Namely, BERT, BERT with RAG, VGG19, VGG19 with pretraining and UNITER are tested. We find that overall, BERT with RAG performs best at 0.842 AUC and 0.788 accuracy. This is possibly due to the additional Cites: Retrieval-augmented generation for knowledge-intensive NLP tasks&lt;/p&gt;</content><author><name>J Lim, A Kuek</name></author><category term="jekyll" /><category term="update" /><summary type="html">Memes are a popular form of conveying information online. However, due to their multimodal nature, they can be hard to analyse. We explore some methods of analysis, focusing on the specific case of detecting hateful memes from the Facebook Hateful Memes Dataset. Namely, BERT, BERT with RAG, VGG19, VGG19 with pretraining and UNITER are tested. We find that overall, BERT with RAG performs best at 0.842 AUC and 0.788 accuracy. This is possibly due to the additional Cites: Retrieval-augmented generation for knowledge-intensive NLP tasks</summary></entry><entry><title type="html">Porous porphyrin-based metal-organic frameworks: synthesis, structure, sorption properties and application prospects</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/63693e7bc91072fa8766a6ef21739126.html" rel="alternate" type="text/html" title="Porous porphyrin-based metal-organic frameworks: synthesis, structure, sorption properties and application prospects" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/63693e7bc91072fa8766a6ef21739126</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/63693e7bc91072fa8766a6ef21739126.html">&lt;p&gt;The unique properties of porous metal-organic frameworks are responsible for the increasing research interest in the design and synthesis of this type of materials. A general strategy towards targeted design of metal-organic frameworks possessing desired properties is a choice of optimal linkers, which are usually represented by polytopic organic ligands. Porphyrins are promising building blocks for such frameworks due to their tunable physicochemical properties and wide possibilities of Cites: Theoretical limits of hydrogen storage in metalorganic&lt;/p&gt;</content><author><name>YG Gorbunova, YY Enakieva, MV Volostnykh - Russian Chemical Reviews, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The unique properties of porous metal-organic frameworks are responsible for the increasing research interest in the design and synthesis of this type of materials. A general strategy towards targeted design of metal-organic frameworks possessing desired properties is a choice of optimal linkers, which are usually represented by polytopic organic ligands. Porphyrins are promising building blocks for such frameworks due to their tunable physicochemical properties and wide possibilities of Cites: Theoretical limits of hydrogen storage in metalorganic</summary></entry><entry><title type="html">EVALUATING THE EFFECTIVENESS OF TOPIC GUIDANCE FOR ABSTRACTIVE SUMMARISATION</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/6afc9900ee1b613575d0bc4ea254a4f6.html" rel="alternate" type="text/html" title="EVALUATING THE EFFECTIVENESS OF TOPIC GUIDANCE FOR ABSTRACTIVE SUMMARISATION" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/6afc9900ee1b613575d0bc4ea254a4f6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/6afc9900ee1b613575d0bc4ea254a4f6.html">&lt;p&gt;Current abstractive summarization models are flexible and can produce fluent summaries, but they can contain unfaithful content and may be unrelated to the content of the document that users are interested in. Although guided summarisation frameworks have been proposed to address these shortcomings, they rely on users providing inputs specific to the document, making them potentially impractical in real applications. Therefore, we propose the use of topic-guided summarisation, allowing Cites: Dont Give Me the Details, Just the Summary!&lt;/p&gt;</content><author><name>TH Xi, NSC Gregory, CH Leong, SBC Vincent</name></author><category term="jekyll" /><category term="update" /><summary type="html">Current abstractive summarization models are flexible and can produce fluent summaries, but they can contain unfaithful content and may be unrelated to the content of the document that users are interested in. Although guided summarisation frameworks have been proposed to address these shortcomings, they rely on users providing inputs specific to the document, making them potentially impractical in real applications. Therefore, we propose the use of topic-guided summarisation, allowing Cites: Dont Give Me the Details, Just the Summary!</summary></entry><entry><title type="html">METGEN: A Module-Based Entailment Tree Generation Framework for Answer Explanation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/71624d8c2eac5c1c28c91e5606ff7df6.html" rel="alternate" type="text/html" title="METGEN: A Module-Based Entailment Tree Generation Framework for Answer Explanation" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/71624d8c2eac5c1c28c91e5606ff7df6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/71624d8c2eac5c1c28c91e5606ff7df6.html">&lt;p&gt;Knowing the reasoning chains from knowledge to the predicted answers can help construct an explainable question answering (QA) system. Advances on QA explanation propose to explain the answers with entailment trees composed of multiple entailment steps. While current work proposes to generate entailment trees with end-to-end generative models, the steps in the generated trees are not constrained and could be unreliable. In this paper, we propose METGEN, a Module Cites: Flexible generation of natural language deductions&lt;/p&gt;</content><author><name>R Hong, H Zhang, X Yu, C Zhang - arXiv preprint arXiv:2205.02593, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Knowing the reasoning chains from knowledge to the predicted answers can help construct an explainable question answering (QA) system. Advances on QA explanation propose to explain the answers with entailment trees composed of multiple entailment steps. While current work proposes to generate entailment trees with end-to-end generative models, the steps in the generated trees are not constrained and could be unreliable. In this paper, we propose METGEN, a Module Cites: Flexible generation of natural language deductions</summary></entry><entry><title type="html">RaFoLa: A Rationale-Annotated Corpus for Detecting Indicators of Forced Labour</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/71b5d45d699acdff267b16b6b32c83ab.html" rel="alternate" type="text/html" title="RaFoLa: A Rationale-Annotated Corpus for Detecting Indicators of Forced Labour" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/71b5d45d699acdff267b16b6b32c83ab</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/71b5d45d699acdff267b16b6b32c83ab.html">&lt;p&gt;Forced labour is the most common type of modern slavery, and it is increasingly gaining the attention of the research and social community. Recent studies suggest that artificial intelligence (AI) holds immense potential for augmenting anti-slavery action. However, AI tools need to be developed transparently in cooperation with different stakeholders. Such tools are contingent on the availability and access to domain-specific data, which are scarce due to the near-invisible nature of forced Cites: ERASER: A benchmark to evaluate rationalized NLP models&lt;/p&gt;</content><author><name>EM Guzman, V Schlegel, R Batista-Navarro - arXiv preprint arXiv:2205.02684, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Forced labour is the most common type of modern slavery, and it is increasingly gaining the attention of the research and social community. Recent studies suggest that artificial intelligence (AI) holds immense potential for augmenting anti-slavery action. However, AI tools need to be developed transparently in cooperation with different stakeholders. Such tools are contingent on the availability and access to domain-specific data, which are scarce due to the near-invisible nature of forced Cites: ERASER: A benchmark to evaluate rationalized NLP models</summary></entry><entry><title type="html">Optimising Equal Opportunity Fairness in Model Training</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/74416a6d94529664de7652e14937ee9d.html" rel="alternate" type="text/html" title="Optimising Equal Opportunity Fairness in Model Training" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/74416a6d94529664de7652e14937ee9d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/74416a6d94529664de7652e14937ee9d.html">&lt;p&gt;Real-world datasets often encode stereotypes and societal biases. Such biases can be implicitly captured by trained models, leading to biased predictions and exacerbating existing societal preconceptions. Existing debiasing methods, such as adversarial training and removing protected information from representations, have been shown to reduce bias. However, a disconnect between fairness criteria and training objectives makes it difficult to reason theoretically about the effectiveness of Cites: Dataset cartography: Mapping and diagnosing datasets with&lt;/p&gt;</content><author><name>A Shen, X Han, T Cohn, T Baldwin, L Frermann - arXiv preprint arXiv:2205.02393, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Real-world datasets often encode stereotypes and societal biases. Such biases can be implicitly captured by trained models, leading to biased predictions and exacerbating existing societal preconceptions. Existing debiasing methods, such as adversarial training and removing protected information from representations, have been shown to reduce bias. However, a disconnect between fairness criteria and training objectives makes it difficult to reason theoretically about the effectiveness of Cites: Dataset cartography: Mapping and diagnosing datasets with</summary></entry><entry><title type="html">A mental state Knowledgeaware and Contrastive Network for early stress and depression detection on social media</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/7696a25f635862c75a64869d8f0b0de5.html" rel="alternate" type="text/html" title="A mental state Knowledgeaware and Contrastive Network for early stress and depression detection on social media" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/7696a25f635862c75a64869d8f0b0de5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/7696a25f635862c75a64869d8f0b0de5.html">&lt;p&gt;Stress and depression detection on social media aim at the analysis of stress and identification of depression tendency from social media posts, which provide assistance for the early detection of mental health conditions. Existing methods mainly model the mental states of the post speaker implicitly. They also lack the ability to mentalise for complex mental state reasoning. Besides, they are not designed to explicitly capture class-specific features. To resolve the above issues Cites: Atomic: An atlas of machine commonsense for if-then reasoning&lt;/p&gt;</content><author><name>K Yang, T Zhang, S Ananiadou - Information Processing &amp; Management, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Stress and depression detection on social media aim at the analysis of stress and identification of depression tendency from social media posts, which provide assistance for the early detection of mental health conditions. Existing methods mainly model the mental states of the post speaker implicitly. They also lack the ability to mentalise for complex mental state reasoning. Besides, they are not designed to explicitly capture class-specific features. To resolve the above issues Cites: Atomic: An atlas of machine commonsense for if-then reasoning</summary></entry><entry><title type="html">Implicit N-grams Induced by Recurrence</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/79abd3c86ddfdfe3246d7ca1605cbc3e.html" rel="alternate" type="text/html" title="Implicit N-grams Induced by Recurrence" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/79abd3c86ddfdfe3246d7ca1605cbc3e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/79abd3c86ddfdfe3246d7ca1605cbc3e.html">&lt;p&gt;Although self-attention based models such as Transformers have achieved remarkable successes on natural language processing (NLP) tasks, recent studies reveal that they have limitations on modeling sequential transformations (Hahn, 2020), which may prompt re-examinations of recurrent neural networks (RNNs) that demonstrated impressive results on handling sequential data. Despite many prior attempts to interpret RNNs, their internal mechanisms have not been fully Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList&lt;/p&gt;</content><author><name>X Sun, W Lu - arXiv preprint arXiv:2205.02724, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Although self-attention based models such as Transformers have achieved remarkable successes on natural language processing (NLP) tasks, recent studies reveal that they have limitations on modeling sequential transformations (Hahn, 2020), which may prompt re-examinations of recurrent neural networks (RNNs) that demonstrated impressive results on handling sequential data. Despite many prior attempts to interpret RNNs, their internal mechanisms have not been fully Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList</summary></entry><entry><title type="html">Relation Extraction as Open-book Examination: Retrieval-enhanced Prompt Tuning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/79f57a413ee936e36fbae828945bc25e.html" rel="alternate" type="text/html" title="Relation Extraction as Open-book Examination: Retrieval-enhanced Prompt Tuning" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/79f57a413ee936e36fbae828945bc25e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/79f57a413ee936e36fbae828945bc25e.html">&lt;p&gt;Pre-trained language models have contributed significantly to relation extraction by demonstrating remarkable few-shot learning abilities. However, prompt tuning methods for relation extraction may still fail to generalize to those rare or hard patterns. Note that the previous parametric learning paradigm can be viewed as memorization regarding training data as a book and inference as the close-book test. Those long-tailed or hard patterns can hardly be memorized in parameters given few Cites: Efficient Nearest Neighbor Language Models&lt;/p&gt;</content><author><name>X Chen, L Li, N Zhang, C Tan, F Huang, L Si, H Chen - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pre-trained language models have contributed significantly to relation extraction by demonstrating remarkable few-shot learning abilities. However, prompt tuning methods for relation extraction may still fail to generalize to those rare or hard patterns. Note that the previous parametric learning paradigm can be viewed as memorization regarding training data as a book and inference as the close-book test. Those long-tailed or hard patterns can hardly be memorized in parameters given few Cites: Efficient Nearest Neighbor Language Models</summary></entry><entry><title type="html">Quantifying Language Variation Acoustically with Few Resources</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/7dd6fa5c90092e7432fe56a9046d38ec.html" rel="alternate" type="text/html" title="Quantifying Language Variation Acoustically with Few Resources" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/7dd6fa5c90092e7432fe56a9046d38ec</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/7dd6fa5c90092e7432fe56a9046d38ec.html">&lt;p&gt;Deep acoustic models represent linguistic information based on massive amounts of data. Unfortunately, for regional languages and dialects such resources are mostly not available. However, deep acoustic models might have learned linguistic information that transfers to low-resource languages. In this study, we evaluate whether this is the case through the task of distinguishing low-resource (Dutch) regional varieties. By extracting embeddings from the hidden layers of various Cites: Universal phone recognition with a multilingual allophone system&lt;/p&gt;</content><author><name>M Bartelds, M Wieling - arXiv preprint arXiv:2205.02694, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep acoustic models represent linguistic information based on massive amounts of data. Unfortunately, for regional languages and dialects such resources are mostly not available. However, deep acoustic models might have learned linguistic information that transfers to low-resource languages. In this study, we evaluate whether this is the case through the task of distinguishing low-resource (Dutch) regional varieties. By extracting embeddings from the hidden layers of various Cites: Universal phone recognition with a multilingual allophone system</summary></entry><entry><title type="html">LUNA: Learning Slot-Turn Alignment for Dialogue State Tracking</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/803d045ba1466edcb151ba31d6c17fd3.html" rel="alternate" type="text/html" title="LUNA: Learning Slot-Turn Alignment for Dialogue State Tracking" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/803d045ba1466edcb151ba31d6c17fd3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/803d045ba1466edcb151ba31d6c17fd3.html">&lt;p&gt;Dialogue state tracking (DST) aims to predict the current dialogue state given the dialogue history. Existing methods generally exploit the utterances of all dialogue turns to assign value for each slot. This could lead to suboptimal results due to the information introduced from irrelevant utterances in the dialogue history, which may be useless and can even cause confusion. To address this problem, we propose LUNA, a sLot-tUrN Alignment enhanced approach. It first explicitly aligns each slot Cites: A simple language model for task-oriented dialogue&lt;/p&gt;</content><author><name>Y Wang, J Zhao, J Bao, C Duan, Y Wu, X He - arXiv preprint arXiv:2205.02550, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Dialogue state tracking (DST) aims to predict the current dialogue state given the dialogue history. Existing methods generally exploit the utterances of all dialogue turns to assign value for each slot. This could lead to suboptimal results due to the information introduced from irrelevant utterances in the dialogue history, which may be useless and can even cause confusion. To address this problem, we propose LUNA, a sLot-tUrN Alignment enhanced approach. It first explicitly aligns each slot Cites: A simple language model for task-oriented dialogue</summary></entry><entry><title type="html">Sampling for Scientific Data Analysis and Reduction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/814f35e1fa4f6cd07b9aac43416f3bb0.html" rel="alternate" type="text/html" title="Sampling for Scientific Data Analysis and Reduction" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/814f35e1fa4f6cd07b9aac43416f3bb0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/814f35e1fa4f6cd07b9aac43416f3bb0.html">&lt;p&gt;With exascale supercomputers on the horizon, data-driven in situ data reduction is a very important topic that potentially enables post hoc data visualization, reconstruction, and exploration with the goal of minimal information loss. Sophisticated sampling methods provide a fast approximation to the data that can be used as a preview to the simulation output without the need for full data reconstruction. More detailed analysis can then be performed by reconstructing the Cites: Visualization-aware sampling for very large databases&lt;/p&gt;</content><author><name>A Biswas, S Dutta, TL Turton, J Ahrens - In Situ Visualization for Computational , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">With exascale supercomputers on the horizon, data-driven in situ data reduction is a very important topic that potentially enables post hoc data visualization, reconstruction, and exploration with the goal of minimal information loss. Sophisticated sampling methods provide a fast approximation to the data that can be used as a preview to the simulation output without the need for full data reconstruction. More detailed analysis can then be performed by reconstructing the Cites: Visualization-aware sampling for very large databases</summary></entry><entry><title type="html">A Qualitative Case Study on the Validation of Automatically Generated Multiple-Choice Questions from Science Textbooks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/82797fea78c0d67bf0836948ff1a9a08.html" rel="alternate" type="text/html" title="A Qualitative Case Study on the Validation of Automatically Generated Multiple-Choice Questions from Science Textbooks" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/82797fea78c0d67bf0836948ff1a9a08</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/82797fea78c0d67bf0836948ff1a9a08.html">&lt;p&gt;In a concept learning scenario, any Technology Supported Learning System must provide students with mechanisms that help them with the acquisition of the concepts to be learned. For the technology supported learning systems to be successful in this task, the development of didactic material is crucial; a hard task that could be alleviated by means of an automation process. In this proposal, two systems which have been previously developed, ArikIturri and DOM-Sortze, are combined to Cites: Quiz-style question generation for news stories&lt;/p&gt;</content><author><name>M Larranaga, I Aldabe, A Arruarte, JA Elorriaga - IEEE Transactions on , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In a concept learning scenario, any Technology Supported Learning System must provide students with mechanisms that help them with the acquisition of the concepts to be learned. For the technology supported learning systems to be successful in this task, the development of didactic material is crucial; a hard task that could be alleviated by means of an automation process. In this proposal, two systems which have been previously developed, ArikIturri and DOM-Sortze, are combined to Cites: Quiz-style question generation for news stories</summary></entry><entry><title type="html">Efficient Few-Shot Fine-Tuning for Opinion Summarization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/85535d99eb8d0e9c941f24d96e9c569d.html" rel="alternate" type="text/html" title="Efficient Few-Shot Fine-Tuning for Opinion Summarization" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/85535d99eb8d0e9c941f24d96e9c569d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/85535d99eb8d0e9c941f24d96e9c569d.html">&lt;p&gt;Abstractive summarization models are typically pre-trained on large amounts of generic texts, then fine-tuned on tens or hundreds of thousands of annotated samples. However, in opinion summarization, large annotated datasets of reviews paired with reference summaries are not available and would be expensive to create. This calls for fine-tuning methods robust to overfitting on small datasets. In addition, generically pre-trained models are often not accustomed to the specifics of Cites: Aspect-controllable opinion summarization&lt;/p&gt;</content><author><name>A Brainskas, R Nallapati, M Bansal, M Dreyer - arXiv preprint arXiv:2205.02170, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstractive summarization models are typically pre-trained on large amounts of generic texts, then fine-tuned on tens or hundreds of thousands of annotated samples. However, in opinion summarization, large annotated datasets of reviews paired with reference summaries are not available and would be expensive to create. This calls for fine-tuning methods robust to overfitting on small datasets. In addition, generically pre-trained models are often not accustomed to the specifics of Cites: Aspect-controllable opinion summarization</summary></entry><entry><title type="html">The Limits of Word Level Differential Privacy</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/87e85f4eb1ccbe9dfea9420c99218df7.html" rel="alternate" type="text/html" title="The Limits of Word Level Differential Privacy" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/87e85f4eb1ccbe9dfea9420c99218df7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/87e85f4eb1ccbe9dfea9420c99218df7.html">&lt;p&gt;As the issues of privacy and trust are receiving increasing attention within the research community, various attempts have been made to anonymize textual data. A significant subset of these approaches incorporate differentially private mechanisms to perturb word embeddings, thus replacing individual words in a sentence. While these methods represent very important contributions, have various advantages over other techniques and do show anonymization capabilities, they have several Cites: Large language models can be strong differentially private learners&lt;/p&gt;</content><author><name>J Mattern, B Weggenmann, F Kerschbaum - arXiv preprint arXiv:2205.02130, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As the issues of privacy and trust are receiving increasing attention within the research community, various attempts have been made to anonymize textual data. A significant subset of these approaches incorporate differentially private mechanisms to perturb word embeddings, thus replacing individual words in a sentence. While these methods represent very important contributions, have various advantages over other techniques and do show anonymization capabilities, they have several Cites: Large language models can be strong differentially private learners</summary></entry><entry><title type="html">Strings for Temporal Annotation and Semantic Representation of Events</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8980246949710779396869afbc322e59.html" rel="alternate" type="text/html" title="Strings for Temporal Annotation and Semantic Representation of Events" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8980246949710779396869afbc322e59</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8980246949710779396869afbc322e59.html">&lt;p&gt;This work describes the use of strings as models for the representation of temporal datathat is, events and times, and their linear ordering and temporal inter-relations to form the basis of a framework for reasoning about that data and using it to aid in the creation or validation of semantic temporal annotation. Some of the relevant motivating literature is examined, in particular Allen (1983) s interval algebra and relation set and the TimeML Cites: Discourse representation structure parsing with recurrent neural&lt;/p&gt;</content><author><name>DA Woods - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This work describes the use of strings as models for the representation of temporal datathat is, events and times, and their linear ordering and temporal inter-relations to form the basis of a framework for reasoning about that data and using it to aid in the creation or validation of semantic temporal annotation. Some of the relevant motivating literature is examined, in particular Allen (1983) s interval algebra and relation set and the TimeML Cites: Discourse representation structure parsing with recurrent neural</summary></entry><entry><title type="html">A Dataset for N-ary Relation Extraction of Drug Combinations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8ade2eb29dfbe7b54a40198ba0177436.html" rel="alternate" type="text/html" title="A Dataset for N-ary Relation Extraction of Drug Combinations" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8ade2eb29dfbe7b54a40198ba0177436</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8ade2eb29dfbe7b54a40198ba0177436.html">&lt;p&gt;Combination therapies have become the standard of care for diseases such as cancer, tuberculosis, malaria and HIV. However, the combinatorial set of available multi-drug treatments creates a challenge in identifying effective combination therapies available in a situation. To assist medical professionals in identifying beneficial drug-combinations, we construct an expert-annotated dataset for extracting information about the efficacy of drug combinations from the scientific Cites: Cross-sentence n-ary relation extraction with graph lstms&lt;/p&gt;</content><author><name>A Tiktinsky, V Viswanathan, D Niezni, DM Azagury - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Combination therapies have become the standard of care for diseases such as cancer, tuberculosis, malaria and HIV. However, the combinatorial set of available multi-drug treatments creates a challenge in identifying effective combination therapies available in a situation. To assist medical professionals in identifying beneficial drug-combinations, we construct an expert-annotated dataset for extracting information about the efficacy of drug combinations from the scientific Cites: Cross-sentence n-ary relation extraction with graph lstms</summary></entry><entry><title type="html">On Evaluating the Robustness of Language Models with Tuning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8d37c825a19b160ec197bb90901969b4.html" rel="alternate" type="text/html" title="On Evaluating the Robustness of Language Models with Tuning" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8d37c825a19b160ec197bb90901969b4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8d37c825a19b160ec197bb90901969b4.html">&lt;p&gt;Prompt tuning and prefix tuning are two effective mechanisms to leverage frozen language models to perform downstream tasks. Robustness reflects models resilience of output under a change or noise in the input. In this paper, we analyze the robustness of natural language models using various tuning methods with respect to a domain shift (ie training on a domain but evaluating on out-of-domain data). We apply both prompt tuning and prefix tuning on T5 models for reading Cites: Xi Victoria Lin, Caiming Xiong, and Richard Socher. 2020&lt;/p&gt;</content><author><name>C Wang, L Wang, Y Luo</name></author><category term="jekyll" /><category term="update" /><summary type="html">Prompt tuning and prefix tuning are two effective mechanisms to leverage frozen language models to perform downstream tasks. Robustness reflects models resilience of output under a change or noise in the input. In this paper, we analyze the robustness of natural language models using various tuning methods with respect to a domain shift (ie training on a domain but evaluating on out-of-domain data). We apply both prompt tuning and prefix tuning on T5 models for reading Cites: Xi Victoria Lin, Caiming Xiong, and Richard Socher. 2020</summary></entry><entry><title type="html">SMLT: A Serverless Framework for Scalable and Adaptive Machine Learning Design and Training</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8d600457225d470b88a5f38ed594dc1d.html" rel="alternate" type="text/html" title="SMLT: A Serverless Framework for Scalable and Adaptive Machine Learning Design and Training" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8d600457225d470b88a5f38ed594dc1d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8d600457225d470b88a5f38ed594dc1d.html">&lt;p&gt;In today s production machine learning (ML) systems, models are continuously trained, improved, and deployed. ML design and training are becoming a continuous workflow of various tasks that have dynamic resource demands. Serverless computing is an emerging cloud paradigm that provides transparent resource management and scaling for users and has the potential to revolutionize the routine of ML design and training. However, hosting modern ML workflows on existing Cites: Well-read students learn better: On the importance of pre-training&lt;/p&gt;</content><author><name>A Ali, S Zawad, P Aditya, IE Akkus, R Chen, F Yan - arXiv preprint arXiv:2205.01853, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In today s production machine learning (ML) systems, models are continuously trained, improved, and deployed. ML design and training are becoming a continuous workflow of various tasks that have dynamic resource demands. Serverless computing is an emerging cloud paradigm that provides transparent resource management and scaling for users and has the potential to revolutionize the routine of ML design and training. However, hosting modern ML workflows on existing Cites: Well-read students learn better: On the importance of pre-training</summary></entry><entry><title type="html">Offline Policy Evaluation for Learning-based Deep Brain Stimulation Controllers</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8e5ddc0974318e860cfaae23b09f1eba.html" rel="alternate" type="text/html" title="Offline Policy Evaluation for Learning-based Deep Brain Stimulation Controllers" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8e5ddc0974318e860cfaae23b09f1eba</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/8e5ddc0974318e860cfaae23b09f1eba.html">&lt;p&gt;Millions of individuals in the US are affected by nervous system disorders, such as Parkinson s disease (PD)[34] and epilepsy [14]. Deep brain stimulation (DBS) is effective in treating such disorders by delivering electric pulses to the basal ganglia (BG) region of the brain through an implantable device [4, 12, 13, 37], as illustrated Cites: Doubly robust bias reduction in infinite horizon off-policy estimation&lt;/p&gt;</content><author><name>Q Gao, SL Schmidt, K Kamaravelu, DA Turner, WM Grill</name></author><category term="jekyll" /><category term="update" /><summary type="html">Millions of individuals in the US are affected by nervous system disorders, such as Parkinson s disease (PD)[34] and epilepsy [14]. Deep brain stimulation (DBS) is effective in treating such disorders by delivering electric pulses to the basal ganglia (BG) region of the brain through an implantable device [4, 12, 13, 37], as illustrated Cites: Doubly robust bias reduction in infinite horizon off-policy estimation</summary></entry><entry><title type="html">Robust Conversational Agents against Imperceptible Toxicity Triggers</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/90e1a6ab35f14a4cfe6b16add7ea1181.html" rel="alternate" type="text/html" title="Robust Conversational Agents against Imperceptible Toxicity Triggers" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/90e1a6ab35f14a4cfe6b16add7ea1181</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/90e1a6ab35f14a4cfe6b16add7ea1181.html">&lt;p&gt;Warning: this paper contains content that maybe offensive or upsetting. Recent research in Natural Language Processing (NLP) has advanced the development of various toxicity detection models with the intention of identifying and mitigating toxic language from existing systems. Despite the abundance of research in this area, less attention has been given to adversarial attacks that force the system to generate toxic language and the defense against them. Existing work to generate such attacks is Cites: Realtoxicityprompts: Evaluating neural toxic degeneration in&lt;/p&gt;</content><author><name>N Mehrabi, A Beirami, F Morstatter, A Galstyan - arXiv preprint arXiv:2205.02392, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Warning: this paper contains content that maybe offensive or upsetting. Recent research in Natural Language Processing (NLP) has advanced the development of various toxicity detection models with the intention of identifying and mitigating toxic language from existing systems. Despite the abundance of research in this area, less attention has been given to adversarial attacks that force the system to generate toxic language and the defense against them. Existing work to generate such attacks is Cites: Realtoxicityprompts: Evaluating neural toxic degeneration in</summary></entry><entry><title type="html">Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/91153ff994327153ee3d6de010901fc4.html" rel="alternate" type="text/html" title="Hybrid Transformer with Multi-level Fusion for Multimodal Knowledge Graph Completion" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/91153ff994327153ee3d6de010901fc4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/91153ff994327153ee3d6de010901fc4.html">&lt;p&gt;Multimodal Knowledge Graphs (MKGs), which organize visual-text factual knowledge, have recently been successfully applied to tasks such as information retrieval, question answering, and recommendation system. Since most MKGs are far from complete, extensive knowledge graph completion studies have been proposed focusing on the multimodal entity, relation extraction and link prediction. However, different tasks and modalities require changes to the model architecture, and not all Cites: Prefix-tuning: Optimizing continuous prompts for generation&lt;/p&gt;</content><author><name>X Chen, N Zhang, L Li, S Deng, C Tan, C Xu, F Huang - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Multimodal Knowledge Graphs (MKGs), which organize visual-text factual knowledge, have recently been successfully applied to tasks such as information retrieval, question answering, and recommendation system. Since most MKGs are far from complete, extensive knowledge graph completion studies have been proposed focusing on the multimodal entity, relation extraction and link prediction. However, different tasks and modalities require changes to the model architecture, and not all Cites: Prefix-tuning: Optimizing continuous prompts for generation</summary></entry><entry><title type="html">Determining containment policy impacts on public sentiment during the pandemic using social media data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/9ea4ac975f90c1925dff1043489fcb33.html" rel="alternate" type="text/html" title="Determining containment policy impacts on public sentiment during the pandemic using social media data" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/9ea4ac975f90c1925dff1043489fcb33</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/9ea4ac975f90c1925dff1043489fcb33.html">&lt;p&gt;Stringent containment and closure policies have been widely implemented by governments to prevent the transmission of COVID-19. Yet, such policies have significant impacts on people s emotions and mental well-being. Here, we study the effects of pandemic containment policies on public sentiment in Singapore. We computed daily sentiment values scaled from 1 to 1, using high-frequency data of 240,000 posts from highly followed public Facebook groups during January to Cites: BERT: pre-training of deep bidirectional transformers for language&lt;/p&gt;</content><author><name>PC Sukhwal, A Kankanhalli - Proceedings of the National Academy of Sciences, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Stringent containment and closure policies have been widely implemented by governments to prevent the transmission of COVID-19. Yet, such policies have significant impacts on people s emotions and mental well-being. Here, we study the effects of pandemic containment policies on public sentiment in Singapore. We computed daily sentiment values scaled from 1 to 1, using high-frequency data of 240,000 posts from highly followed public Facebook groups during January to Cites: BERT: pre-training of deep bidirectional transformers for language</summary></entry><entry><title type="html">Diversifying Neural Dialogue Generation via Negative Distillation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a2b60f4c42a373b47bddf82fba642696.html" rel="alternate" type="text/html" title="Diversifying Neural Dialogue Generation via Negative Distillation" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a2b60f4c42a373b47bddf82fba642696</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a2b60f4c42a373b47bddf82fba642696.html">&lt;p&gt;Generative dialogue models suffer badly from the generic response problem, limiting their applications to a few toy scenarios. Recently, an interesting approach, namely negative training, has been proposed to alleviate this problem by reminding the model not to generate high-frequency responses during training. However, its performance is hindered by two issues, ignoring low-frequency but generic responses and bringing low-frequency but meaningless responses. In this paper, we Cites: Don t Say That! Making Inconsistent Dialogue Unlikely with&lt;/p&gt;</content><author><name>Y Li, S Feng, B Sun, K Li - arXiv preprint arXiv:2205.02795, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Generative dialogue models suffer badly from the generic response problem, limiting their applications to a few toy scenarios. Recently, an interesting approach, namely negative training, has been proposed to alleviate this problem by reminding the model not to generate high-frequency responses during training. However, its performance is hindered by two issues, ignoring low-frequency but generic responses and bringing low-frequency but meaningless responses. In this paper, we Cites: Don t Say That! Making Inconsistent Dialogue Unlikely with</summary></entry><entry><title type="html">Hybrid Model for Detection of Cervical Cancer Using Causal Analysis and Machine Learning Techniques</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a381db5a8bb0ca6b3b31aecc162c86b0.html" rel="alternate" type="text/html" title="Hybrid Model for Detection of Cervical Cancer Using Causal Analysis and Machine Learning Techniques" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a381db5a8bb0ca6b3b31aecc162c86b0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a381db5a8bb0ca6b3b31aecc162c86b0.html">&lt;p&gt;Cervical cancer has become the third most common form of cancer in the in- universe, after the widespread breast cancer. Human papillomavirus risk of infection is linked to the majority of cancer cases. Preventive care, the most expensive way of fighting cancer, can protect about 37% of cancer cases. The Pap smear examination is a standard screening procedure for the initial screening of cervical cancer. However, this manual test procedure generates many false-positive outcomes due to Cites: Improving the ability of deep neural networks to use information&lt;/p&gt;</content><author><name>UK Lilhore, M Poongodi, A Kaur, S Simaiya, AD Algarni -  and Mathematical Methods , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Cervical cancer has become the third most common form of cancer in the in- universe, after the widespread breast cancer. Human papillomavirus risk of infection is linked to the majority of cancer cases. Preventive care, the most expensive way of fighting cancer, can protect about 37% of cancer cases. The Pap smear examination is a standard screening procedure for the initial screening of cervical cancer. However, this manual test procedure generates many false-positive outcomes due to Cites: Improving the ability of deep neural networks to use information</summary></entry><entry><title type="html">DeepFD: Automated Fault Diagnosis and Localization for Deep Learning Programs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a3fc62d1270e463c2ff94ff0ed804a32.html" rel="alternate" type="text/html" title="DeepFD: Automated Fault Diagnosis and Localization for Deep Learning Programs" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a3fc62d1270e463c2ff94ff0ed804a32</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a3fc62d1270e463c2ff94ff0ed804a32.html">&lt;p&gt;As Deep Learning (DL) systems are widely deployed for mission-critical applications, debugging such systems becomes essential. Most existing works identify and repair suspicious neurons on the trained Deep Neural Network (DNN), which, unfortunately, might be a detour. Specifically, several existing studies have reported that many unsatisfactory behaviors are actually originated from the faults residing in DL programs. Besides, locating faulty neurons is not actionable for developers, while Cites: AlphaD3M: Machine learning pipeline synthesis&lt;/p&gt;</content><author><name>J Cao, M Li, X Chen, M Wen, Y Tian, B Wu, SC Cheung - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As Deep Learning (DL) systems are widely deployed for mission-critical applications, debugging such systems becomes essential. Most existing works identify and repair suspicious neurons on the trained Deep Neural Network (DNN), which, unfortunately, might be a detour. Specifically, several existing studies have reported that many unsatisfactory behaviors are actually originated from the faults residing in DL programs. Besides, locating faulty neurons is not actionable for developers, while Cites: AlphaD3M: Machine learning pipeline synthesis</summary></entry><entry><title type="html">Crystal Twins: Self-supervised Learning for Crystalline Material Property Prediction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a608e0e3c170a04849746d0b427b1da6.html" rel="alternate" type="text/html" title="Crystal Twins: Self-supervised Learning for Crystalline Material Property Prediction" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a608e0e3c170a04849746d0b427b1da6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a608e0e3c170a04849746d0b427b1da6.html">&lt;p&gt;Machine learning (ML) models have been widely successful in the prediction of material properties. However, large labeled datasets required for training accurate ML models are elusive and computationally expensive to generate. Recent advances in Self-Supervised Learning (SSL) frameworks capable of training ML models on unlabeled data have mitigated this problem and demonstrated superior performance in computer vision and natural language processing tasks. Drawing Cites: Strategies for pre-training graph neural networks&lt;/p&gt;</content><author><name>R Magar, Y Wang, AB Farimani - arXiv preprint arXiv:2205.01893, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Machine learning (ML) models have been widely successful in the prediction of material properties. However, large labeled datasets required for training accurate ML models are elusive and computationally expensive to generate. Recent advances in Self-Supervised Learning (SSL) frameworks capable of training ML models on unlabeled data have mitigated this problem and demonstrated superior performance in computer vision and natural language processing tasks. Drawing Cites: Strategies for pre-training graph neural networks</summary></entry><entry><title type="html">Low-resource Entity Set Expansion: A Comprehensive Study on User-generated Text</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a76ddc98e14fe5a8156c193e7acbeee7.html" rel="alternate" type="text/html" title="Low-resource Entity Set Expansion: A Comprehensive Study on User-generated Text" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a76ddc98e14fe5a8156c193e7acbeee7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a76ddc98e14fe5a8156c193e7acbeee7.html">&lt;p&gt;Entity set expansion (ESE) aims at obtaining a more complete set of entities given a textual corpus and a seed set of entities of a concept. Although it is a critical task in many NLP applications, existing benchmarks are limited to well-formed text (eg, Wikipedia) and welldefined concepts (eg, countries and diseases). Furthermore, only a small number of predictions are evaluated compared to the actual size of an entity set. A rigorous assessment of ESE methods warrants more comprehensive Cites: Few-shot learning for opinion summarization&lt;/p&gt;</content><author><name>Y Shao, N Bhutani, S Rahman, E Hruschka</name></author><category term="jekyll" /><category term="update" /><summary type="html">Entity set expansion (ESE) aims at obtaining a more complete set of entities given a textual corpus and a seed set of entities of a concept. Although it is a critical task in many NLP applications, existing benchmarks are limited to well-formed text (eg, Wikipedia) and welldefined concepts (eg, countries and diseases). Furthermore, only a small number of predictions are evaluated compared to the actual size of an entity set. A rigorous assessment of ESE methods warrants more comprehensive Cites: Few-shot learning for opinion summarization</summary></entry><entry><title type="html">Representative Data Selection for Sequence-to-Sequence Pre-training</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a92c626e2efde920f23cff3e9079bce0.html" rel="alternate" type="text/html" title="Representative Data Selection for Sequence-to-Sequence Pre-training" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a92c626e2efde920f23cff3e9079bce0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a92c626e2efde920f23cff3e9079bce0.html">&lt;p&gt;Pre-trained sequence-to-sequence models such as BART [1] have helped improve natural language generation quality. However, training large models is resourceconsuming. We propose a data selection algorithm that selects a tiny but representative subset from billion-scale datasets. Experimental results show that pre- training with 0. 26% data and 4. 4% energy consumption achieves about 90% BLEU scores onmachine translation (MT) tasks and ROUGE scores on text summarization Cites: Overview of the 6th workshop on Asian translation&lt;/p&gt;</content><author><name>H Song, R Dabre, Z Mao, C Chu, S Kurohashi</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pre-trained sequence-to-sequence models such as BART [1] have helped improve natural language generation quality. However, training large models is resourceconsuming. We propose a data selection algorithm that selects a tiny but representative subset from billion-scale datasets. Experimental results show that pre- training with 0. 26% data and 4. 4% energy consumption achieves about 90% BLEU scores onmachine translation (MT) tasks and ROUGE scores on text summarization Cites: Overview of the 6th workshop on Asian translation</summary></entry><entry><title type="html">Open Relation Extraction with Non-Existent and Multi-Span Relationships</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a97e6d4009dd868f6595775a1973add9.html" rel="alternate" type="text/html" title="Open Relation Extraction with Non-Existent and Multi-Span Relationships" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a97e6d4009dd868f6595775a1973add9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/a97e6d4009dd868f6595775a1973add9.html">&lt;p&gt;Open relation extraction (ORE) aims to assign semantic relationships among arguments, essential to the automatic construction of knowledge graphs (KG). The previous ORE methods and some benchmark datasets consider a relation between two arguments as definitely existing and in a simple single-span form, neglecting possible non-existent relationships and flexible, expressive multi-span relations. However, detecting non-existent relations is necessary for a pipelined information Cites: Open information extraction from the web&lt;/p&gt;</content><author><name>H Yang, DW Li, Z Li, D Yang, B Wu - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Open relation extraction (ORE) aims to assign semantic relationships among arguments, essential to the automatic construction of knowledge graphs (KG). The previous ORE methods and some benchmark datasets consider a relation between two arguments as definitely existing and in a simple single-span form, neglecting possible non-existent relationships and flexible, expressive multi-span relations. However, detecting non-existent relations is necessary for a pipelined information Cites: Open information extraction from the web</summary></entry><entry><title type="html">Measuring and Improving Compositional Generalization in Text-to-SQL via Component Alignment</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/ad661b97f3746f5ed444496a77330a1f.html" rel="alternate" type="text/html" title="Measuring and Improving Compositional Generalization in Text-to-SQL via Component Alignment" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/ad661b97f3746f5ed444496a77330a1f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/ad661b97f3746f5ed444496a77330a1f.html">&lt;p&gt;In text-to-SQL tasks–as in much of NLP–compositional generalization is a major challenge: neural networks struggle with compositional generalization where training and test distributions differ. However, most recent attempts to improve this are based on word-level synthetic data or specific dataset splits to generate compositional biases. In this work, we propose a clause-level compositional example generation method. We first split the sentences in the Spider text-to-SQL dataset into sub Cites: Meta-Learning to Compositionally Generalize&lt;/p&gt;</content><author><name>Y Gan, X Chen, Q Huang, M Purver - arXiv preprint arXiv:2205.02054, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In text-to-SQL tasks–as in much of NLP–compositional generalization is a major challenge: neural networks struggle with compositional generalization where training and test distributions differ. However, most recent attempts to improve this are based on word-level synthetic data or specific dataset splits to generate compositional biases. In this work, we propose a clause-level compositional example generation method. We first split the sentences in the Spider text-to-SQL dataset into sub Cites: Meta-Learning to Compositionally Generalize</summary></entry><entry><title type="html">Low-Code Programming Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/b06b1ab8419711b4b526c06e496de2f0.html" rel="alternate" type="text/html" title="Low-Code Programming Models" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/b06b1ab8419711b4b526c06e496de2f0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/b06b1ab8419711b4b526c06e496de2f0.html">&lt;p&gt;Traditionally, computer programming has been the prerogative of professional developers using textual programming languages such as C, Java, or Python. Low- code programming promises an alternative: letting citizen developers create programs using visual abstractions, demonstrations, or natural language. While low- code programming is currently getting a lot of attention in industry, the relevant research literature is scattered, and in fact, rarely uses the term  low-code . This Cites: A syntactic neural model for general-purpose code generation&lt;/p&gt;</content><author><name>M Hirzel - arXiv preprint arXiv:2205.02282, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Traditionally, computer programming has been the prerogative of professional developers using textual programming languages such as C, Java, or Python. Low- code programming promises an alternative: letting citizen developers create programs using visual abstractions, demonstrations, or natural language. While low- code programming is currently getting a lot of attention in industry, the relevant research literature is scattered, and in fact, rarely uses the term low-code . This Cites: A syntactic neural model for general-purpose code generation</summary></entry><entry><title type="html">Transform Your Risk Processes Using Neural Networks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/b214930008f72afd5ee3323f79042515.html" rel="alternate" type="text/html" title="Transform Your Risk Processes Using Neural Networks" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/b214930008f72afd5ee3323f79042515</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/b214930008f72afd5ee3323f79042515.html">&lt;p&gt;As individuals and communities interact in and with an environment that is increasingly virtual, they are often vulnerable to the commodification of their digital footprint. Concepts and behavior that are ambiguous in nature are captured in this environment, quantified, and used to categorize, sort, recommend, or make decisions about people s lives. While many organizations seek to utilize this information in a responsible manner, biases remain endemic across technology processes and can Cites: On the opportunities and risks of foundation models&lt;/p&gt;</content><author><name>R Ferguson</name></author><category term="jekyll" /><category term="update" /><summary type="html">As individuals and communities interact in and with an environment that is increasingly virtual, they are often vulnerable to the commodification of their digital footprint. Concepts and behavior that are ambiguous in nature are captured in this environment, quantified, and used to categorize, sort, recommend, or make decisions about people s lives. While many organizations seek to utilize this information in a responsible manner, biases remain endemic across technology processes and can Cites: On the opportunities and risks of foundation models</summary></entry><entry><title type="html">Exploring National Park Visitors Judgements from Social Media: The Case Study of Plitvice Lakes National Park</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/b226b169bef22b7f32cf4e6993b9fa31.html" rel="alternate" type="text/html" title="Exploring National Park Visitors Judgements from Social Media: The Case Study of Plitvice Lakes National Park" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/b226b169bef22b7f32cf4e6993b9fa31</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/b226b169bef22b7f32cf4e6993b9fa31.html">&lt;p&gt;This study aims to conduct a survey of visitor reviews of the Plitvice Lakes National Park in Croatia to detect strengths and weaknesses of the park. In total, 15,673 reviews written in the period between 2007 and 2021 were scraped from the social media platform TripAdvisor. The research applies a comprehensive combination of multidimensional scaling, sentiment analysis, and natural language processing approaches to a sample area of international naturalistic interest. Analyzing the Cites: Twitter sentiment in New York City parks as measure of well-being&lt;/p&gt;</content><author><name>C Sergiacomi, D Vuleti, A Paletto, E Barbierato - Forests, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">This study aims to conduct a survey of visitor reviews of the Plitvice Lakes National Park in Croatia to detect strengths and weaknesses of the park. In total, 15,673 reviews written in the period between 2007 and 2021 were scraped from the social media platform TripAdvisor. The research applies a comprehensive combination of multidimensional scaling, sentiment analysis, and natural language processing approaches to a sample area of international naturalistic interest. Analyzing the Cites: Twitter sentiment in New York City parks as measure of well-being</summary></entry><entry><title type="html">Towards consistent document-level entity linking: Joint Models for entity linking and coreference resolution</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/bf0eb8f6757d4b0b277f462ab75b5b58.html" rel="alternate" type="text/html" title="Towards consistent document-level entity linking: Joint Models for entity linking and coreference resolution" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/bf0eb8f6757d4b0b277f462ab75b5b58</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/bf0eb8f6757d4b0b277f462ab75b5b58.html">&lt;p&gt;We consider the task of document-level entity linking (EL), where it is important to make consistent decisions for entity mentions over the full document jointly. We aim to leverage explicit connections among mentions within the document itself: we propose to join EL and coreference resolution (coref) in a single structured prediction task over directed trees and use a globally normalized model to solve it. This contrasts with related works where two separate models are trained for each of the Cites: A Joint Model for Entity Analysis: Coreference, Typing, and Linking&lt;/p&gt;</content><author><name>Y Jiang, K Zaporojets, J Deleu, T Demeester - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We consider the task of document-level entity linking (EL), where it is important to make consistent decisions for entity mentions over the full document jointly. We aim to leverage explicit connections among mentions within the document itself: we propose to join EL and coreference resolution (coref) in a single structured prediction task over directed trees and use a globally normalized model to solve it. This contrasts with related works where two separate models are trained for each of the Cites: A Joint Model for Entity Analysis: Coreference, Typing, and Linking</summary></entry><entry><title type="html">Explain and Conquer: Personalised Text-based Reviews to Achieve Transparency</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/c14cffcbf15381501407d8c5d5858cf8.html" rel="alternate" type="text/html" title="Explain and Conquer: Personalised Text-based Reviews to Achieve Transparency" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/c14cffcbf15381501407d8c5d5858cf8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/c14cffcbf15381501407d8c5d5858cf8.html">&lt;p&gt;There are many contexts where dyadic data is present. Social networking is a well- known example, where transparency has grown on importance. In these contexts, pairs of items are linked building a network where interactions play a crucial role. Explaining why these relationships are established is core to address transparency. These explanations are often presented using text, thanks to the spread of the natural language understanding tasks. We have focused on the TripAdvisor platform Cites: BERT: pre-training of deep bidirectional transformers for language&lt;/p&gt;</content><author><name>ILR Botana, V Boln-Canedo, B Guijarro-Berdias - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">There are many contexts where dyadic data is present. Social networking is a well- known example, where transparency has grown on importance. In these contexts, pairs of items are linked building a network where interactions play a crucial role. Explaining why these relationships are established is core to address transparency. These explanations are often presented using text, thanks to the spread of the natural language understanding tasks. We have focused on the TripAdvisor platform Cites: BERT: pre-training of deep bidirectional transformers for language</summary></entry><entry><title type="html">A Simple Contrastive Learning Objective for Alleviating Neural Text Degeneration</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/c3627735eb5d12b087423fcf4bb749c8.html" rel="alternate" type="text/html" title="A Simple Contrastive Learning Objective for Alleviating Neural Text Degeneration" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/c3627735eb5d12b087423fcf4bb749c8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/c3627735eb5d12b087423fcf4bb749c8.html">&lt;p&gt;The cross-entropy objective has proved to be an all-purpose training objective for autoregressive language models (LMs). However, without considering the penalization of problematic tokens, LMs trained using cross-entropy exhibit text degeneration. To address this, unlikelihood training has been proposed to force unlikely tokens to be assigned a low probability by a LM. But unlikelihood does not consider the relationship between the label tokens and the unlikely token Cites: Neural text generation with unlikelihood training&lt;/p&gt;</content><author><name>S Jiang, R Zhang, S Vakulenko, M de Rijke - arXiv preprint arXiv:2205.02517, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The cross-entropy objective has proved to be an all-purpose training objective for autoregressive language models (LMs). However, without considering the penalization of problematic tokens, LMs trained using cross-entropy exhibit text degeneration. To address this, unlikelihood training has been proposed to force unlikely tokens to be assigned a low probability by a LM. But unlikelihood does not consider the relationship between the label tokens and the unlikely token Cites: Neural text generation with unlikelihood training</summary></entry><entry><title type="html">Aligning to Social Norms and Values in Interactive Narratives</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/c437139d6661128dafc7b8e39f9ed3a5.html" rel="alternate" type="text/html" title="Aligning to Social Norms and Values in Interactive Narratives" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/c437139d6661128dafc7b8e39f9ed3a5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/c437139d6661128dafc7b8e39f9ed3a5.html">&lt;p&gt;We focus on creating agents that act in alignment with socially beneficial norms and values in interactive narratives or text-based games–environments wherein an agent perceives and interacts with a world through natural language. Such interactive&lt;/p&gt;</content><author><name>P Ammanabrolu, L Jiang, M Sap, H Hajishirzi, Y Choi - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We focus on creating agents that act in alignment with socially beneficial norms and values in interactive narratives or text-based games–environments wherein an agent perceives and interacts with a world through natural language. Such interactive</summary></entry><entry><title type="html">A comparative study of name entity recognition techniques in software engineering texts</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/c7f07b52c5bcdfab83e7df43814dfc24.html" rel="alternate" type="text/html" title="A comparative study of name entity recognition techniques in software engineering texts" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/c7f07b52c5bcdfab83e7df43814dfc24</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/c7f07b52c5bcdfab83e7df43814dfc24.html">&lt;p&gt;ABSTRACT Named Entity Recognition (NER) is an essential sub-task for many important tasks in software engineering (SE), such as automated requirement analysis, opinion mining, question answering, knowledge base construction, and information retrieval. As existing domain-independent NER approaches perform low when applied in the SE domain, we observe the development of different tools and techniques for NER in this domain recently. Despite those developments, we lack our Cites: Unsupervised named-entity extraction from the web: An&lt;/p&gt;</content><author><name>MY Chew, YJ Cheng, O Mahan, MR Islam - Proceedings of the 37th ACM/SIGAPP , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">ABSTRACT Named Entity Recognition (NER) is an essential sub-task for many important tasks in software engineering (SE), such as automated requirement analysis, opinion mining, question answering, knowledge base construction, and information retrieval. As existing domain-independent NER approaches perform low when applied in the SE domain, we observe the development of different tools and techniques for NER in this domain recently. Despite those developments, we lack our Cites: Unsupervised named-entity extraction from the web: An</summary></entry><entry><title type="html">Language models for patents: exploring prompt engineering for the patent domain</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/cd01f9b12885ae38247ba035973349dd.html" rel="alternate" type="text/html" title="Language models for patents: exploring prompt engineering for the patent domain" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/cd01f9b12885ae38247ba035973349dd</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/cd01f9b12885ae38247ba035973349dd.html">&lt;p&gt;Abstract in italiano I modelli linguistici applicati al dominio dei brevetti rappresentano una grande sfida a causa della complessit e delle competenze specifiche richieste. Questo lavoro ha sviluppato una soluzione che estende la fase di pre-formazione dei modelli linguistici in questo dominio. La soluzione implementata sfrutta il modello GPT-2 per creare un modello linguistico multitasking per il dominio dei brevetti basato su un approccio di tipo prompt-engineering, utilizzando 11, 8 milioni di Cites: Ctrl: A conditional transformer language model for controllable&lt;/p&gt;</content><author><name>A BERRIOS TORRES - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Abstract in italiano I modelli linguistici applicati al dominio dei brevetti rappresentano una grande sfida a causa della complessit e delle competenze specifiche richieste. Questo lavoro ha sviluppato una soluzione che estende la fase di pre-formazione dei modelli linguistici in questo dominio. La soluzione implementata sfrutta il modello GPT-2 per creare un modello linguistico multitasking per il dominio dei brevetti basato su un approccio di tipo prompt-engineering, utilizzando 11, 8 milioni di Cites: Ctrl: A conditional transformer language model for controllable</summary></entry><entry><title type="html">Method and system for domain agnostic knowledge extraction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/cd3113cf57ba954aef596b92822a5939.html" rel="alternate" type="text/html" title="Method and system for domain agnostic knowledge extraction" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/cd3113cf57ba954aef596b92822a5939</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/cd3113cf57ba954aef596b92822a5939.html">&lt;p&gt;A system and method of extracting knowledge from a plurality of documents by at least one processor may include: receiving a domain-specific schema data structure, comprising a definition of one or more domain entity types; using at least one first machine-learning (ML) based model to fetch one or more mentions from the plurality of documents; using at least one second ML model to extract, from the one or more mentions, at least one domain entity that corresponds to the one or more domain Cites: Zero-Shot Entity Linking by Reading Entity Descriptions&lt;/p&gt;</content><author><name>A Genkin, S Klarman - US Patent 11,321,615, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A system and method of extracting knowledge from a plurality of documents by at least one processor may include: receiving a domain-specific schema data structure, comprising a definition of one or more domain entity types; using at least one first machine-learning (ML) based model to fetch one or more mentions from the plurality of documents; using at least one second ML model to extract, from the one or more mentions, at least one domain entity that corresponds to the one or more domain Cites: Zero-Shot Entity Linking by Reading Entity Descriptions</summary></entry><entry><title type="html">An Exploration of Consistency Learning with Data Augmentation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/cd8eec84848f969c03b0daca9ddb4a9e.html" rel="alternate" type="text/html" title="An Exploration of Consistency Learning with Data Augmentation" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/cd8eec84848f969c03b0daca9ddb4a9e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/cd8eec84848f969c03b0daca9ddb4a9e.html">&lt;p&gt;Deep Learning has achieved remarkable success with Supervised Learning. Nearly all of these successes require very large manually annotated datasets. Data augmentation has enabled Supervised Learning with less labeled data, while avoiding the pitfalls of overfitting. However, Supervised Learning still fails to be Robust, making different predictions for original and augmented data points. We study the addition of a Consistency Loss between representations of original and Cites: Wilds: A benchmark of in-the-wild distribution shifts&lt;/p&gt;</content><author><name>C Shorten, TM Khoshgoftaar - The International FLAIRS Conference Proceedings, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep Learning has achieved remarkable success with Supervised Learning. Nearly all of these successes require very large manually annotated datasets. Data augmentation has enabled Supervised Learning with less labeled data, while avoiding the pitfalls of overfitting. However, Supervised Learning still fails to be Robust, making different predictions for original and augmented data points. We study the addition of a Consistency Loss between representations of original and Cites: Wilds: A benchmark of in-the-wild distribution shifts</summary></entry><entry><title type="html">i-Code: An Integrative and Composable Multimodal Learning Framework</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/cebc41a41043dadeda6ccd72fc0e3ba2.html" rel="alternate" type="text/html" title="i-Code: An Integrative and Composable Multimodal Learning Framework" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/cebc41a41043dadeda6ccd72fc0e3ba2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/cebc41a41043dadeda6ccd72fc0e3ba2.html">&lt;p&gt;Human intelligence is multimodal; we integrate visual, linguistic, and acoustic signals to maintain a holistic worldview. Most current pretraining methods, however, are limited to one or two modalities. We present i-Code, a self-supervised pretraining framework where users may flexibly combine the modalities of vision, speech, and language into unified and general-purpose vector representations. In this framework, data from each modality are first given to pretrained single-modality encoders. The Cites: MERLOT Reserve: Neural Script Knowledge through Vision and&lt;/p&gt;</content><author><name>Z Yang, Y Fang, C Zhu, R Pryzant, D Chen, Y Shi, Y Xu - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Human intelligence is multimodal; we integrate visual, linguistic, and acoustic signals to maintain a holistic worldview. Most current pretraining methods, however, are limited to one or two modalities. We present i-Code, a self-supervised pretraining framework where users may flexibly combine the modalities of vision, speech, and language into unified and general-purpose vector representations. In this framework, data from each modality are first given to pretrained single-modality encoders. The Cites: MERLOT Reserve: Neural Script Knowledge through Vision and</summary></entry><entry><title type="html">Learning causal representations for multi-hop question answering over knowledge graphs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/d0e411a5fbecc002fa83cbe82e6ac84a.html" rel="alternate" type="text/html" title="Learning causal representations for multi-hop question answering over knowledge graphs" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/d0e411a5fbecc002fa83cbe82e6ac84a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/d0e411a5fbecc002fa83cbe82e6ac84a.html">&lt;p&gt;To improve the performance of knowledge graph-based question answering system (KGQA), several approaches have been developed to construct a semantic parser based on entity linking, relation identification and logical/numerical structure identification. However, existing methods arrive at answers only by maximizing the data likelihood only on the sparse or imbalanced explicit relations, ignoring the potentially large number of latent relations. It makes KGQA suffer from a high level of Cites: Qa-gnn: Reasoning with language models and knowledge graphs&lt;/p&gt;</content><author><name>Y Sui, S Feng, H Zhang, J Cao, L Hu, N Zhu - Knowledge-Based Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">To improve the performance of knowledge graph-based question answering system (KGQA), several approaches have been developed to construct a semantic parser based on entity linking, relation identification and logical/numerical structure identification. However, existing methods arrive at answers only by maximizing the data likelihood only on the sparse or imbalanced explicit relations, ignoring the potentially large number of latent relations. It makes KGQA suffer from a high level of Cites: Qa-gnn: Reasoning with language models and knowledge graphs</summary></entry><entry><title type="html">Lexical Knowledge Internalization for Neural Dialog Generation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/d437f3754726c0a0388942a96df4703a.html" rel="alternate" type="text/html" title="Lexical Knowledge Internalization for Neural Dialog Generation" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/d437f3754726c0a0388942a96df4703a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/d437f3754726c0a0388942a96df4703a.html">&lt;p&gt;We propose knowledge internalization (KI), which aims to complement the lexical knowledge into neural dialog models. Instead of further conditioning the knowledge- grounded dialog (KGD) models on externally retrieved knowledge, we seek to integrate knowledge about each input token internally into the model s parameters. To tackle the challenge due to the large scale of lexical knowledge, we adopt the contrastive learning approach and create an effective token-level lexical knowledge Cites: How can we know what language models know?&lt;/p&gt;</content><author><name>Z Wu, W Bi, X Li, L Kong, B Kao - arXiv preprint arXiv:2205.01941, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We propose knowledge internalization (KI), which aims to complement the lexical knowledge into neural dialog models. Instead of further conditioning the knowledge- grounded dialog (KGD) models on externally retrieved knowledge, we seek to integrate knowledge about each input token internally into the model s parameters. To tackle the challenge due to the large scale of lexical knowledge, we adopt the contrastive learning approach and create an effective token-level lexical knowledge Cites: How can we know what language models know?</summary></entry><entry><title type="html">DeepBayes–an estimator for parameter estimation in stochastic nonlinear dynamical models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/db3204942d07d376df842204e2cbf519.html" rel="alternate" type="text/html" title="DeepBayes–an estimator for parameter estimation in stochastic nonlinear dynamical models" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/db3204942d07d376df842204e2cbf519</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/db3204942d07d376df842204e2cbf519.html">&lt;p&gt;Stochastic nonlinear dynamical systems are ubiquitous in modern, real-world applications. Yet, estimating the unknown parameters of stochastic, nonlinear dynamical models remains a challenging problem. The majority of existing methods employ maximum likelihood or Bayesian estimation. However, these methods suffer from some limitations, most notably the substantial computational time for inference coupled with limited flexibility in application. In this work, we propose DeepBayes Cites: Document modeling with gated recurrent neural network for&lt;/p&gt;</content><author><name>A Ghosh, M Abdalmoaty, S Chatterjee, H Hjalmarsson - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Stochastic nonlinear dynamical systems are ubiquitous in modern, real-world applications. Yet, estimating the unknown parameters of stochastic, nonlinear dynamical models remains a challenging problem. The majority of existing methods employ maximum likelihood or Bayesian estimation. However, these methods suffer from some limitations, most notably the substantial computational time for inference coupled with limited flexibility in application. In this work, we propose DeepBayes Cites: Document modeling with gated recurrent neural network for</summary></entry><entry><title type="html">A Computational Inflection for Scientific Discovery</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/dee3b406dc5eea268628e4ee48250353.html" rel="alternate" type="text/html" title="A Computational Inflection for Scientific Discovery" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/dee3b406dc5eea268628e4ee48250353</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/dee3b406dc5eea268628e4ee48250353.html">&lt;p&gt;We stand at the foot of a significant inflection in the trajectory of scientific discovery. As society continues on its fast-paced digital transformation, so does humankind s collective scientific knowledge and discourse. We now read and write papers in digitized form, and a great deal of the formal and informal processes of science are captured digitally–including papers, preprints and books, code and datasets, conference presentations, and interactions in social networks and communication Cites: LinkBERT: Pretraining Language Models with Document Links&lt;/p&gt;</content><author><name>T Hope, D Downey, O Etzioni, DS Weld, E Horvitz - arXiv preprint arXiv:2205.02007, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We stand at the foot of a significant inflection in the trajectory of scientific discovery. As society continues on its fast-paced digital transformation, so does humankind s collective scientific knowledge and discourse. We now read and write papers in digitized form, and a great deal of the formal and informal processes of science are captured digitally–including papers, preprints and books, code and datasets, conference presentations, and interactions in social networks and communication Cites: LinkBERT: Pretraining Language Models with Document Links</summary></entry><entry><title type="html">AdaSL: An Unsupervised Domain Adaptation framework for Arabic multi-dialectal Sequence Labeling</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e00a5750ffac7ae5b2d4d37e97d50b72.html" rel="alternate" type="text/html" title="AdaSL: An Unsupervised Domain Adaptation framework for Arabic multi-dialectal Sequence Labeling" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e00a5750ffac7ae5b2d4d37e97d50b72</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e00a5750ffac7ae5b2d4d37e97d50b72.html">&lt;p&gt;Dialectal Arabic (DA) refers to varieties of everyday spoken languages in the Arab world. These dialects differ according to the country and region of the speaker, and their textual content is constantly growing with the rise of social media networks and web blogs. Although research on Natural Language Processing (NLP) on standard Arabic, namely Modern Standard Arabic (MSA), has witnessed remarkable progress, research efforts on DA are rather limited. This is due to numerous challenges, such Cites: Don t stop pretraining: adapt language models to domains and tasks&lt;/p&gt;</content><author><name>A El Mekki, A El Mahdaouy, I Berrada, A Khoumsi - Information Processing &amp; , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Dialectal Arabic (DA) refers to varieties of everyday spoken languages in the Arab world. These dialects differ according to the country and region of the speaker, and their textual content is constantly growing with the rise of social media networks and web blogs. Although research on Natural Language Processing (NLP) on standard Arabic, namely Modern Standard Arabic (MSA), has witnessed remarkable progress, research efforts on DA are rather limited. This is due to numerous challenges, such Cites: Don t stop pretraining: adapt language models to domains and tasks</summary></entry><entry><title type="html">ViQuAE, a Dataset for Knowledge-based Visual Question Answering about Named Entities</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e103205f16d84b0935ac2997886cc169.html" rel="alternate" type="text/html" title="ViQuAE, a Dataset for Knowledge-based Visual Question Answering about Named Entities" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e103205f16d84b0935ac2997886cc169</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e103205f16d84b0935ac2997886cc169.html">&lt;p&gt;Whether to retrieve, answer, translate, or reason, multimodality opens up new challenges and perspectives. In this context, we are interested in answering questions about named entities grounded in a visual context using a Knowledge Base (KB). To benchmark this task, called KVQAE (Knowledge-based Visual Question Answering about named Entities), we provide ViQuAE, a dataset of 3.7 K questions paired with images. This is the first KVQAE dataset to cover a wide range Cites: Multimodalqa: Complex question answering over text, tables and&lt;/p&gt;</content><author><name>P Lerner, O Ferret, C Guinaudeau, H Le Borgne - ACM SIGIR Conference on , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Whether to retrieve, answer, translate, or reason, multimodality opens up new challenges and perspectives. In this context, we are interested in answering questions about named entities grounded in a visual context using a Knowledge Base (KB). To benchmark this task, called KVQAE (Knowledge-based Visual Question Answering about named Entities), we provide ViQuAE, a dataset of 3.7 K questions paired with images. This is the first KVQAE dataset to cover a wide range Cites: Multimodalqa: Complex question answering over text, tables and</summary></entry><entry><title type="html">Knowing What to Say: Towards knowledge grounded code-mixed response generation for open-domain conversations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e1b200d5251bcfd03d88eea631611403.html" rel="alternate" type="text/html" title="Knowing What to Say: Towards knowledge grounded code-mixed response generation for open-domain conversations" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e1b200d5251bcfd03d88eea631611403</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e1b200d5251bcfd03d88eea631611403.html">&lt;p&gt;Inculcating knowledge in the dialogue agents is an important step towards creating any agent more human-like. Hence, the use of knowledge while conversing is crucial for building interactive and engaging systems. Most existing works for developing social conversation systems focus on monolingual discussions, with little research on multilingual or code-mixed conversations. Therefore, in this work, we propose generating knowledge-aware code-mixed responses for building end-to-end code Cites: UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge&lt;/p&gt;</content><author><name>GV Singh, M Firdaus, S Mishra, A Ekbal - Knowledge-Based Systems, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Inculcating knowledge in the dialogue agents is an important step towards creating any agent more human-like. Hence, the use of knowledge while conversing is crucial for building interactive and engaging systems. Most existing works for developing social conversation systems focus on monolingual discussions, with little research on multilingual or code-mixed conversations. Therefore, in this work, we propose generating knowledge-aware code-mixed responses for building end-to-end code Cites: UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge</summary></entry><entry><title type="html">PREME: Preference-based Meeting Exploration through an Interactive Questionnaire</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e2c9659c6bcebec900307d15f24d77e7.html" rel="alternate" type="text/html" title="PREME: Preference-based Meeting Exploration through an Interactive Questionnaire" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e2c9659c6bcebec900307d15f24d77e7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e2c9659c6bcebec900307d15f24d77e7.html">&lt;p&gt;The recent increase in the volume of online meetings necessitates automated tools for managing and organizing the material, especially when an attendee has missed the discussion and needs assistance in quickly exploring it. In this work, we propose a novel end-to-end framework for generating interactive questionnaires for preference-based meeting exploration. As a result, users are supplied with a list of suggested questions reflecting their preferences. Since the task is new, we introduce Cites: QMSum: A New Benchmark for Query-based Multi-domain Meeting&lt;/p&gt;</content><author><name>N Arabzadeh, A Ahmadvand, J Kiseleva, Y Liu - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The recent increase in the volume of online meetings necessitates automated tools for managing and organizing the material, especially when an attendee has missed the discussion and needs assistance in quickly exploring it. In this work, we propose a novel end-to-end framework for generating interactive questionnaires for preference-based meeting exploration. As a result, users are supplied with a list of suggested questions reflecting their preferences. Since the task is new, we introduce Cites: QMSum: A New Benchmark for Query-based Multi-domain Meeting</summary></entry><entry><title type="html">Modeling Task Interactions in Document-Level Joint Entity and Relation Extraction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e94e1ef70b1633165400716f612f3268.html" rel="alternate" type="text/html" title="Modeling Task Interactions in Document-Level Joint Entity and Relation Extraction" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e94e1ef70b1633165400716f612f3268</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/e94e1ef70b1633165400716f612f3268.html">&lt;p&gt;We target on the document-level relation extraction in an end-to-end setting, where the model needs to jointly perform mention extraction, coreference resolution (COREF) and relation extraction (RE) at once, and gets evaluated in an entity-centric way. Especially, we address the two-way interaction between COREF and RE that has not been the focus by previous work, and propose to introduce explicit interaction namely Graph Compatibility (GC) that is specifically designed to leverage Cites: Higher-order Coreference Resolution with Coarse-to-fine Inference&lt;/p&gt;</content><author><name>L Xu, JD Choi - arXiv preprint arXiv:2205.01909, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We target on the document-level relation extraction in an end-to-end setting, where the model needs to jointly perform mention extraction, coreference resolution (COREF) and relation extraction (RE) at once, and gets evaluated in an entity-centric way. Especially, we address the two-way interaction between COREF and RE that has not been the focus by previous work, and propose to introduce explicit interaction namely Graph Compatibility (GC) that is specifically designed to leverage Cites: Higher-order Coreference Resolution with Coarse-to-fine Inference</summary></entry><entry><title type="html">Semi-Supervised Cascaded Clustering for Classification of Noisy Label Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/ee6f228ae8d8f69842903aa5e3a7e44d.html" rel="alternate" type="text/html" title="Semi-Supervised Cascaded Clustering for Classification of Noisy Label Data" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/ee6f228ae8d8f69842903aa5e3a7e44d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/ee6f228ae8d8f69842903aa5e3a7e44d.html">&lt;p&gt;The performance of supervised classification techniques often deteriorates when the data has noisy labels. Even the semi-supervised classification approaches have largely focused only on the problem of handling missing labels. Most of the approaches addressing the noisy label data rely on deep neural networks (DNN) that require huge datasets for classification tasks. This poses a serious challenge especially in process and manufacturing industries, where the data is limited and Cites: Dividemix: Learning with noisy labels as semi-supervised learning&lt;/p&gt;</content><author><name>A Gupta, A Deodhar, T Mukherjee, V Runkana - arXiv preprint arXiv:2205.02209, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The performance of supervised classification techniques often deteriorates when the data has noisy labels. Even the semi-supervised classification approaches have largely focused only on the problem of handling missing labels. Most of the approaches addressing the noisy label data rely on deep neural networks (DNN) that require huge datasets for classification tasks. This poses a serious challenge especially in process and manufacturing industries, where the data is limited and Cites: Dividemix: Learning with noisy labels as semi-supervised learning</summary></entry><entry><title type="html">BORT: Back and Denoising Reconstruction for End-to-End Task-Oriented Dialog</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/f56f228e8f592fc336336f55e3d8fcd9.html" rel="alternate" type="text/html" title="BORT: Back and Denoising Reconstruction for End-to-End Task-Oriented Dialog" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/f56f228e8f592fc336336f55e3d8fcd9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/f56f228e8f592fc336336f55e3d8fcd9.html">&lt;p&gt;A typical end-to-end task-oriented dialog system transfers context into dialog state, and upon which generates a response, which usually faces the problem of error propagation from both previously generated inaccurate dialog states and responses, especially in low-resource scenarios. To alleviate these issues, we propose BORT, a back and denoising reconstruction approach for end-to-end task-oriented dialog system. Squarely, to improve the accuracy of dialog states, back reconstruction is Cites: Detecting formal thought disorder by deep contextualized word&lt;/p&gt;</content><author><name>H Sun, J Bao, Y Wu, X He - arXiv preprint arXiv:2205.02471, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A typical end-to-end task-oriented dialog system transfers context into dialog state, and upon which generates a response, which usually faces the problem of error propagation from both previously generated inaccurate dialog states and responses, especially in low-resource scenarios. To alleviate these issues, we propose BORT, a back and denoising reconstruction approach for end-to-end task-oriented dialog system. Squarely, to improve the accuracy of dialog states, back reconstruction is Cites: Detecting formal thought disorder by deep contextualized word</summary></entry><entry><title type="html">Antonin Bergeaud</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/f7991a699489d4ad7898afac56881db4.html" rel="alternate" type="text/html" title="Antonin Bergeaud" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/f7991a699489d4ad7898afac56881db4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/f7991a699489d4ad7898afac56881db4.html">&lt;p&gt;Innovation is an important driver of potential growth but quantitative evidence on the dynamics of innovative activities in the long-run are hardly documented due to the lack of data, especially in Europe. In this paper, we introduce PatentCity, a novel dataset on the location and nature of patentees from the 19th century using information derived from an automated extraction of relevant information from patent documents published by the German, French, British and US Intellectual Property Cites: Unsupervised named-entity extraction from the web: An&lt;/p&gt;</content><author><name>C Verluise - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Innovation is an important driver of potential growth but quantitative evidence on the dynamics of innovative activities in the long-run are hardly documented due to the lack of data, especially in Europe. In this paper, we introduce PatentCity, a novel dataset on the location and nature of patentees from the 19th century using information derived from an automated extraction of relevant information from patent documents published by the German, French, British and US Intellectual Property Cites: Unsupervised named-entity extraction from the web: An</summary></entry><entry><title type="html">Natural Language Inference with Self-Attention for Veracity Assessment of Pandemic Claims</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/f9beba1e0bdf8d8860a88c5d26eb267c.html" rel="alternate" type="text/html" title="Natural Language Inference with Self-Attention for Veracity Assessment of Pandemic Claims" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/f9beba1e0bdf8d8860a88c5d26eb267c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/f9beba1e0bdf8d8860a88c5d26eb267c.html">&lt;p&gt;We present a comprehensive work on automated veracity assessment from dataset creation to developing novel methods based on Natural Language Inference (NLI), focusing on misinformation related to the COVID-19 pandemic. We first describe the construction of the novel PANACEA dataset consisting of heterogeneous claims on COVID-19 and their respective information sources. The dataset construction includes work on retrieval techniques and similarity measurements to ensure a Cites: Reasoning over semantic-level graph for fact checking&lt;/p&gt;</content><author><name>M Arana-Catania, E Kochkina, A Zubiaga, M Liakata - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We present a comprehensive work on automated veracity assessment from dataset creation to developing novel methods based on Natural Language Inference (NLI), focusing on misinformation related to the COVID-19 pandemic. We first describe the construction of the novel PANACEA dataset consisting of heterogeneous claims on COVID-19 and their respective information sources. The dataset construction includes work on retrieval techniques and similarity measurements to ensure a Cites: Reasoning over semantic-level graph for fact checking</summary></entry><entry><title type="html">Decoupled Reinforcement Learning to Stabilise Intrinsically-Motivated Exploration</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/fe44e5898e7b8fd4d716444cf09344ab.html" rel="alternate" type="text/html" title="Decoupled Reinforcement Learning to Stabilise Intrinsically-Motivated Exploration" /><published>2022-05-10T03:22:04-04:00</published><updated>2022-05-10T03:22:04-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/fe44e5898e7b8fd4d716444cf09344ab</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/10/fe44e5898e7b8fd4d716444cf09344ab.html">&lt;p&gt;Intrinsic rewards can improve exploration in reinforcement learning, but the exploration process may suffer from instability caused by non-stationary reward shaping and strong dependency on hyperparameters. In this work, we introduce Decoupled RL (DeRL) as a general framework which trains separate policies for intrinsicallymotivated exploration and exploitation. Such decoupling allows DeRL to leverage the benefits of intrinsic rewards for exploration while demonstrating Cites: Decoupling exploration and exploitation for meta-reinforcement&lt;/p&gt;</content><author><name>L Schfer, F Christianos, JP Hanna, SV Albrecht</name></author><category term="jekyll" /><category term="update" /><summary type="html">Intrinsic rewards can improve exploration in reinforcement learning, but the exploration process may suffer from instability caused by non-stationary reward shaping and strong dependency on hyperparameters. In this work, we introduce Decoupled RL (DeRL) as a general framework which trains separate policies for intrinsicallymotivated exploration and exploitation. Such decoupling allows DeRL to leverage the benefits of intrinsic rewards for exploration while demonstrating Cites: Decoupling exploration and exploitation for meta-reinforcement</summary></entry><entry><title type="html">Inducing and Using Alignments for Transition-based AMR Parsing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/011462abedc47d6f48f2a74d94acb7f4.html" rel="alternate" type="text/html" title="Inducing and Using Alignments for Transition-based AMR Parsing" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/011462abedc47d6f48f2a74d94acb7f4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/011462abedc47d6f48f2a74d94acb7f4.html">&lt;p&gt;Transition-based parsers for Abstract Meaning Representation (AMR) rely on node- to-word alignments. These alignments are learned separately from parser training and require a complex pipeline of rule-based components, pre-processing, and post- processing to satisfy domain-specific constraints. Parsers also train on a point- estimate of the alignment pipeline, neglecting the uncertainty due to the inherent ambiguity of alignment. In this work we explore two avenues for overcoming these Cites: Compositional Generalization for Neural Semantic Parsing via&lt;/p&gt;</content><author><name>A Drozdov, J Zhou, R Florian, A McCallum, T Naseem - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Transition-based parsers for Abstract Meaning Representation (AMR) rely on node- to-word alignments. These alignments are learned separately from parser training and require a complex pipeline of rule-based components, pre-processing, and post- processing to satisfy domain-specific constraints. Parsers also train on a point- estimate of the alignment pipeline, neglecting the uncertainty due to the inherent ambiguity of alignment. In this work we explore two avenues for overcoming these Cites: Compositional Generalization for Neural Semantic Parsing via</summary></entry><entry><title type="html">Faithful to the Document or to the World? Mitigating Hallucinations via Entity-linked Knowledge in Abstractive Summarization</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/098220f336d563fe94f475a1e1021416.html" rel="alternate" type="text/html" title="Faithful to the Document or to the World? Mitigating Hallucinations via Entity-linked Knowledge in Abstractive Summarization" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/098220f336d563fe94f475a1e1021416</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/098220f336d563fe94f475a1e1021416.html">&lt;p&gt;Despite recent advances in abstractive summarization, current summarization systems still suffer from content hallucinations where models generate text that is either irrelevant or contradictory to the source document. However, prior work has been predicated on the assumption that any generated facts not appearing explicitly in the source are undesired hallucinations. Methods have been proposed to address this scenario by ultimately improvingfaithfulness  to the source document, but in Cites: Retrieval-augmented generation for knowledge-intensive NLP tasks&lt;/p&gt;</content><author><name>Y Dong, J Wieting, P Verga - arXiv preprint arXiv:2204.13761, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Despite recent advances in abstractive summarization, current summarization systems still suffer from content hallucinations where models generate text that is either irrelevant or contradictory to the source document. However, prior work has been predicated on the assumption that any generated facts not appearing explicitly in the source are undesired hallucinations. Methods have been proposed to address this scenario by ultimately improvingfaithfulness to the source document, but in Cites: Retrieval-augmented generation for knowledge-intensive NLP tasks</summary></entry><entry><title type="html">A Unified Approach to Semantic Information and Communication based on Probabilistic Logic</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/121c09cf6b09d94be675c4fe6a1f459b.html" rel="alternate" type="text/html" title="A Unified Approach to Semantic Information and Communication based on Probabilistic Logic" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/121c09cf6b09d94be675c4fe6a1f459b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/121c09cf6b09d94be675c4fe6a1f459b.html">&lt;p&gt;Traditionally, studies on technical communication (TC) are based on stochastic modeling and manipulation. This is not sufficient for semantic communication (SC) where semantic elements are logically connected, rather than stochastically correlated. To fill this void, by leveraging a logical programming language called probabilistic logic (ProbLog), we propose a unified approach to semantic information and communication through the interplay between TC and SC. On top of the well Cites: Symbolic knowledge distillation: from general language models to&lt;/p&gt;</content><author><name>J Choi, SW Loke, J Park - arXiv preprint arXiv:2205.00621, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Traditionally, studies on technical communication (TC) are based on stochastic modeling and manipulation. This is not sufficient for semantic communication (SC) where semantic elements are logically connected, rather than stochastically correlated. To fill this void, by leveraging a logical programming language called probabilistic logic (ProbLog), we propose a unified approach to semantic information and communication through the interplay between TC and SC. On top of the well Cites: Symbolic knowledge distillation: from general language models to</summary></entry><entry><title type="html">Explaining Artificial Intelligence Generation and Creativity</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/1b9435e91c515f2779e00f78574d60f3.html" rel="alternate" type="text/html" title="Explaining Artificial Intelligence Generation and Creativity" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/1b9435e91c515f2779e00f78574d60f3</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/1b9435e91c515f2779e00f78574d60f3.html">&lt;p&gt;Creativity is often thought of as the pinnacle of human achievement, but artificial intelligence (AI) is now starting to play a central role in creative processes, whether autonomously or in collaboration with people. Widespread deployment is now pushing for explanations on how creative AI is working, whether to engender trust, enable action, provide a basis for evaluation, or for intrinsic reasons. In this article, we review various motivations, algorithms, and methods for explaining either the Cites: On the opportunities and risks of foundation models&lt;/p&gt;</content><author><name>P Das, LR Varshney - IEEE Signal Processing Magazine, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Creativity is often thought of as the pinnacle of human achievement, but artificial intelligence (AI) is now starting to play a central role in creative processes, whether autonomously or in collaboration with people. Widespread deployment is now pushing for explanations on how creative AI is working, whether to engender trust, enable action, provide a basis for evaluation, or for intrinsic reasons. In this article, we review various motivations, algorithms, and methods for explaining either the Cites: On the opportunities and risks of foundation models</summary></entry><entry><title type="html">MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/1fdf7ab1311c3abe87a1bb872a7bbcda.html" rel="alternate" type="text/html" title="MRKL Systems: A modular, neuro-symbolic architecture that combines large language models, external knowledge sources and discrete reasoning" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/1fdf7ab1311c3abe87a1bb872a7bbcda</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/1fdf7ab1311c3abe87a1bb872a7bbcda.html">&lt;p&gt;Huge language models (LMs) have ushered in a new era for AI, serving as a gateway to natural-language-based knowledge tasks. Although an essential element of modern AI, LMs are also inherently limited in a number of ways. We discuss these limitations and how they can be avoided by adopting a systems approach. Conceptualizing the challenge as one that involves knowledge and reasoning in addition to linguistic processing, we define a flexible architecture with multiple neural Cites: Bert: Pre-training of deep bidirectional transformers for language&lt;/p&gt;</content><author><name>E Karpas, O Abend, Y Belinkov, B Lenz, O Lieber - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Huge language models (LMs) have ushered in a new era for AI, serving as a gateway to natural-language-based knowledge tasks. Although an essential element of modern AI, LMs are also inherently limited in a number of ways. We discuss these limitations and how they can be avoided by adopting a systems approach. Conceptualizing the challenge as one that involves knowledge and reasoning in addition to linguistic processing, we define a flexible architecture with multiple neural Cites: Bert: Pre-training of deep bidirectional transformers for language</summary></entry><entry><title type="html">Clues Before Answers: Generation-Enhanced Multiple-Choice QA</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2000604476404367c46d5304779ce8ef.html" rel="alternate" type="text/html" title="Clues Before Answers: Generation-Enhanced Multiple-Choice QA" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2000604476404367c46d5304779ce8ef</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2000604476404367c46d5304779ce8ef.html">&lt;p&gt;A trending paradigm for multiple-choice question answering (MCQA) is using a text- to-text framework. By unifying data in different tasks into a single text-to-text format, it trains a generative encoder-decoder model which is both powerful and universal. However, a side effect of twisting a generation target to fit the classification nature of MCQA is the under-utilization of the decoder and the knowledge that can be decoded. To exploit the generation capability and underlying knowledge of a pre Cites: Explain yourself! leveraging language models for commonsense&lt;/p&gt;</content><author><name>Z Huang, A Wu, J Zhou, Y Gu, Y Zhao, G Cheng - arXiv preprint arXiv:2205.00274, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A trending paradigm for multiple-choice question answering (MCQA) is using a text- to-text framework. By unifying data in different tasks into a single text-to-text format, it trains a generative encoder-decoder model which is both powerful and universal. However, a side effect of twisting a generation target to fit the classification nature of MCQA is the under-utilization of the decoder and the knowledge that can be decoded. To exploit the generation capability and underlying knowledge of a pre Cites: Explain yourself! leveraging language models for commonsense</summary></entry><entry><title type="html">BERTops: Studying BERT Representations under a Topological Lens</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/29c7bd7ca9f530b585dbbe0432eeef6b.html" rel="alternate" type="text/html" title="BERTops: Studying BERT Representations under a Topological Lens" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/29c7bd7ca9f530b585dbbe0432eeef6b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/29c7bd7ca9f530b585dbbe0432eeef6b.html">&lt;p&gt;Proposing scoring functions to effectively understand, analyze and learn various properties of high dimensional hidden representations of large-scale transformer models like BERT can be a challenging task. In this work, we explore a new direction by studying the topological features of BERT hidden representations using persistent homology (PH). We propose a novel scoring function named  persistence scoring function (PSF)  which:(i) accurately captures the homology of the high-dimensional Cites: What does BERT look at? An analysis of BERT s attention&lt;/p&gt;</content><author><name>J Chauhan, M Kaul - arXiv preprint arXiv:2205.00953, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Proposing scoring functions to effectively understand, analyze and learn various properties of high dimensional hidden representations of large-scale transformer models like BERT can be a challenging task. In this work, we explore a new direction by studying the topological features of BERT hidden representations using persistent homology (PH). We propose a novel scoring function named persistence scoring function (PSF) which:(i) accurately captures the homology of the high-dimensional Cites: What does BERT look at? An analysis of BERT s attention</summary></entry><entry><title type="html">What do we Really Know about State of the Art NER?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2d171ee18af3793fabcc9b8a861539a7.html" rel="alternate" type="text/html" title="What do we Really Know about State of the Art NER?" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2d171ee18af3793fabcc9b8a861539a7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2d171ee18af3793fabcc9b8a861539a7.html">&lt;p&gt;Named Entity Recognition (NER) is a well researched NLP task and is widely used in real world NLP scenarios. NER research typically focuses on the creation of new ways of training NER, with relatively less emphasis on resources and evaluation. Further, state of the art (SOTA) NER models, trained on standard datasets, typically report only a single performance measure (F-score) and we don t really know how well they do for different entity types and genres of text, or how robust are they to Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList&lt;/p&gt;</content><author><name>S Vajjala, R Balasubramaniam - arXiv preprint arXiv:2205.00034, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Named Entity Recognition (NER) is a well researched NLP task and is widely used in real world NLP scenarios. NER research typically focuses on the creation of new ways of training NER, with relatively less emphasis on resources and evaluation. Further, state of the art (SOTA) NER models, trained on standard datasets, typically report only a single performance measure (F-score) and we don t really know how well they do for different entity types and genres of text, or how robust are they to Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList</summary></entry><entry><title type="html">SparCAssist: A Model Risk Assessment Assistant Based on Sparse Generated Counterfactuals</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2d5f60ed4281378253dba35e6ed7782b.html" rel="alternate" type="text/html" title="SparCAssist: A Model Risk Assessment Assistant Based on Sparse Generated Counterfactuals" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2d5f60ed4281378253dba35e6ed7782b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2d5f60ed4281378253dba35e6ed7782b.html">&lt;p&gt;We introduce SparcAssist, a general-purpose risk assessment tool for the machine learning models trained for language tasks. It evaluates models  risk by inspecting their behavior on counterfactuals, namely out-of-distribution instances generated based on the given data instance. The counterfactuals are generated by replacing tokens in rational subsequences identified by ExPred, while the replacements are retrieved using HotFlip or Masked-Language-Model-based algorithms. The main Cites: Anchors: High-Precision Model-Agnostic Explanations&lt;/p&gt;</content><author><name>Z Zhang, V Setty, A Anand - arXiv preprint arXiv:2205.01588, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We introduce SparcAssist, a general-purpose risk assessment tool for the machine learning models trained for language tasks. It evaluates models risk by inspecting their behavior on counterfactuals, namely out-of-distribution instances generated based on the given data instance. The counterfactuals are generated by replacing tokens in rational subsequences identified by ExPred, while the replacements are retrieved using HotFlip or Masked-Language-Model-based algorithms. The main Cites: Anchors: High-Precision Model-Agnostic Explanations</summary></entry><entry><title type="html">Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2e5163be8995ef73a044d6c76c69a6a9.html" rel="alternate" type="text/html" title="Logiformer: A Two-Branch Graph Transformer Network for Interpretable Logical Reasoning" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2e5163be8995ef73a044d6c76c69a6a9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2e5163be8995ef73a044d6c76c69a6a9.html">&lt;p&gt;Machine reading comprehension has aroused wide concerns, since it explores the potential of model for text understanding. To further equip the machine with the reasoning capability, the challenging task of logical reasoning is proposed. Previous works on logical reasoning have proposed some strategies to extract the logical units from different aspects. However, there still remains a challenge to model the long distance dependency among the logical units. Also, it is demanding to uncover the Cites: Logic-driven context extension and data augmentation for logical&lt;/p&gt;</content><author><name>F Xu, Q Lin, J Liu, Y Pan, L Zhang - arXiv preprint arXiv:2205.00731, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Machine reading comprehension has aroused wide concerns, since it explores the potential of model for text understanding. To further equip the machine with the reasoning capability, the challenging task of logical reasoning is proposed. Previous works on logical reasoning have proposed some strategies to extract the logical units from different aspects. However, there still remains a challenge to model the long distance dependency among the logical units. Also, it is demanding to uncover the Cites: Logic-driven context extension and data augmentation for logical</summary></entry><entry><title type="html">A Library Perspective on Nearly-Unsupervised Information Extraction Workflows in Digital Libraries</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2ec1173a72843f5880546195725ef810.html" rel="alternate" type="text/html" title="A Library Perspective on Nearly-Unsupervised Information Extraction Workflows in Digital Libraries" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2ec1173a72843f5880546195725ef810</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/2ec1173a72843f5880546195725ef810.html">&lt;p&gt;Information extraction can support novel and effective access paths for digital libraries. Nevertheless, designing reliable extraction workflows can be cost-intensive in practice. On the one hand, suitable extraction methods rely on domain-specific training data. On the other hand, unsupervised and open extraction methods usually produce not-canonicalized extraction results. This paper tackles the question how digital libraries can handle such extractions and if their quality is sufficient in practice Cites: Stanza: A python natural language processing toolkit for many&lt;/p&gt;</content><author><name>H Kroll, J Pirklbauer, F Pltzky, WT Balke - arXiv preprint arXiv:2205.00716, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Information extraction can support novel and effective access paths for digital libraries. Nevertheless, designing reliable extraction workflows can be cost-intensive in practice. On the one hand, suitable extraction methods rely on domain-specific training data. On the other hand, unsupervised and open extraction methods usually produce not-canonicalized extraction results. This paper tackles the question how digital libraries can handle such extractions and if their quality is sufficient in practice Cites: Stanza: A python natural language processing toolkit for many</summary></entry><entry><title type="html">Dynamic Programming in Rank Space: Scaling Structured Inference with Low-Rank HMMs and PCFGs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/30afdcf5593f1c2abb66cad53ae482d9.html" rel="alternate" type="text/html" title="Dynamic Programming in Rank Space: Scaling Structured Inference with Low-Rank HMMs and PCFGs" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/30afdcf5593f1c2abb66cad53ae482d9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/30afdcf5593f1c2abb66cad53ae482d9.html">&lt;p&gt;Hidden Markov Models (HMMs) and Probabilistic Context-Free Grammars (PCFGs) are widely used structured models, both of which can be represented as factor graph grammars (FGGs), a powerful formalism capable of describing a wide range of models. Recent research found it beneficial to use large state spaces for HMMs and PCFGs. However, inference with large state spaces is computationally demanding, especially for PCFGs. To tackle this challenge, we leverage tensor rank Cites: Scaling Structured Inference with Randomization&lt;/p&gt;</content><author><name>S Yang, W Liu, K Tu - arXiv preprint arXiv:2205.00484, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Hidden Markov Models (HMMs) and Probabilistic Context-Free Grammars (PCFGs) are widely used structured models, both of which can be represented as factor graph grammars (FGGs), a powerful formalism capable of describing a wide range of models. Recent research found it beneficial to use large state spaces for HMMs and PCFGs. However, inference with large state spaces is computationally demanding, especially for PCFGs. To tackle this challenge, we leverage tensor rank Cites: Scaling Structured Inference with Randomization</summary></entry><entry><title type="html">Neurocompositional computing in human and machine intelligence: A tutorial</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/36fe7e937fae86f8231865fe349a3180.html" rel="alternate" type="text/html" title="Neurocompositional computing in human and machine intelligence: A tutorial" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/36fe7e937fae86f8231865fe349a3180</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/36fe7e937fae86f8231865fe349a3180.html">&lt;p&gt;The past decade has produced a revolution in Artificial Intelligence (AI), after a halfcentury of AI repeatedly failing to meet expectations. What explains the dramatic change from 20th-century to 21st-century AI, and how can remaining limitations of current AI be overcome? Until now, the widely accepted narrative has attributed the recent progress in AI to technical engineering advances that have yielded massive increases in the quantity of computational resources and training data available to Cites: Scarecrow: A framework for scrutinizing machine text&lt;/p&gt;</content><author><name>P Smolensky, RT McCoy, R Fernandez, M Goldrick - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The past decade has produced a revolution in Artificial Intelligence (AI), after a halfcentury of AI repeatedly failing to meet expectations. What explains the dramatic change from 20th-century to 21st-century AI, and how can remaining limitations of current AI be overcome? Until now, the widely accepted narrative has attributed the recent progress in AI to technical engineering advances that have yielded massive increases in the quantity of computational resources and training data available to Cites: Scarecrow: A framework for scrutinizing machine text</summary></entry><entry><title type="html">Answer Consolidation: Formulation and Benchmarking</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/3f07ca086913cb81b1abe2af880cb772.html" rel="alternate" type="text/html" title="Answer Consolidation: Formulation and Benchmarking" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/3f07ca086913cb81b1abe2af880cb772</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/3f07ca086913cb81b1abe2af880cb772.html">&lt;p&gt;Current question answering (QA) systems primarily consider the single-answer scenario, where each question is assumed to be paired with one correct answer. However, in many real-world QA applications, multiple answer scenarios arise where consolidating answers into a comprehensive and non-redundant set of answers is a more efficient user interface. In this paper, we formulate the problem of answer consolidation, where answers are partitioned into multiple groups, each representing Cites: Joint passage ranking for diverse multi-answer retrieval&lt;/p&gt;</content><author><name>W Zhou, Q Ning, H Elfardy, K Small, M Chen - arXiv preprint arXiv:2205.00042, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Current question answering (QA) systems primarily consider the single-answer scenario, where each question is assumed to be paired with one correct answer. However, in many real-world QA applications, multiple answer scenarios arise where consolidating answers into a comprehensive and non-redundant set of answers is a more efficient user interface. In this paper, we formulate the problem of answer consolidation, where answers are partitioned into multiple groups, each representing Cites: Joint passage ranking for diverse multi-answer retrieval</summary></entry><entry><title type="html">KAHAN: Knowledge-Aware Hierarchical Attention Network for Fake News detection on Social Media</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/40b8f5ca2821ad5af5097bbcc16dd75b.html" rel="alternate" type="text/html" title="KAHAN: Knowledge-Aware Hierarchical Attention Network for Fake News detection on Social Media" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/40b8f5ca2821ad5af5097bbcc16dd75b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/40b8f5ca2821ad5af5097bbcc16dd75b.html">&lt;p&gt;In recent years, fake news detection has attracted a great deal of attention due to the myriad amounts of misinformation. Some previous methods have focused on modeling the news content, while others have combined user comments and user information on social media. However, existing methods ignore some important clues for detecting fake news, such as temporal information on social media and external knowledge related to the news. To this end, we propose a Knowledge-Aware Cites: Compare to The Knowledge: Graph Neural Fake News Detection&lt;/p&gt;</content><author><name>YW Tseng, HK Yang, WY Wang, WC Peng - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In recent years, fake news detection has attracted a great deal of attention due to the myriad amounts of misinformation. Some previous methods have focused on modeling the news content, while others have combined user comments and user information on social media. However, existing methods ignore some important clues for detecting fake news, such as temporal information on social media and external knowledge related to the news. To this end, we propose a Knowledge-Aware Cites: Compare to The Knowledge: Graph Neural Fake News Detection</summary></entry><entry><title type="html">A Word is Worth A Thousand Dollars: Adversarial Attack on Tweets Fools Stock Prediction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/40ee5b96439c1210f521b3c9dd4fe069.html" rel="alternate" type="text/html" title="A Word is Worth A Thousand Dollars: Adversarial Attack on Tweets Fools Stock Prediction" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/40ee5b96439c1210f521b3c9dd4fe069</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/40ee5b96439c1210f521b3c9dd4fe069.html">&lt;p&gt;More and more investors and machine learning models rely on social media (eg, Twitter and Reddit) to gather real-time information and sentiment to predict stock price movements. Although text-based models are known to be vulnerable to adversarial attacks, whether stock prediction models have similar vulnerability is underexplored. In this paper, we experiment with a variety of adversarial attack configurations to fool three stock prediction victim models. We address the task of Cites: Semantically Equivalent Adversarial Rules for Debugging NLP&lt;/p&gt;</content><author><name>Y Xie, D Wang, PY Chen, J Xiong, S Liu, S Koyejo - arXiv preprint arXiv:2205.01094, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">More and more investors and machine learning models rely on social media (eg, Twitter and Reddit) to gather real-time information and sentiment to predict stock price movements. Although text-based models are known to be vulnerable to adversarial attacks, whether stock prediction models have similar vulnerability is underexplored. In this paper, we experiment with a variety of adversarial attack configurations to fool three stock prediction victim models. We address the task of Cites: Semantically Equivalent Adversarial Rules for Debugging NLP</summary></entry><entry><title type="html">Nearest Neighbor Knowledge Distillation for Neural Machine Translation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/4c72d6c615a7cbe882a47c02e27b29d8.html" rel="alternate" type="text/html" title="Nearest Neighbor Knowledge Distillation for Neural Machine Translation" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/4c72d6c615a7cbe882a47c02e27b29d8</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/4c72d6c615a7cbe882a47c02e27b29d8.html">&lt;p&gt;k-nearest-neighbor machine translation (NN-MT), proposed by Khandelwal et al.(2021), has achieved many state-of-the-art results in machine translation tasks. Although effective, NN-MT requires conducting NN searches through the large datastore for each decoding step during inference, prohibitively increasing the decoding cost and thus leading to the difficulty for the deployment in real-world applications. In this paper, we propose to move the time-consuming NN search Cites: BAM! Born-Again Multi-Task Networks for Natural Language&lt;/p&gt;</content><author><name>Z Yang, R Sun, X Wan - arXiv preprint arXiv:2205.00479, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">k-nearest-neighbor machine translation (NN-MT), proposed by Khandelwal et al.(2021), has achieved many state-of-the-art results in machine translation tasks. Although effective, NN-MT requires conducting NN searches through the large datastore for each decoding step during inference, prohibitively increasing the decoding cost and thus leading to the difficulty for the deployment in real-world applications. In this paper, we propose to move the time-consuming NN search Cites: BAM! Born-Again Multi-Task Networks for Natural Language</summary></entry><entry><title type="html">LIDER: An Efficient High-dimensional Learned Index for Large-scale Dense Passage Retrieval</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/4eda3391ea29659432fe7b40f53ed69a.html" rel="alternate" type="text/html" title="LIDER: An Efficient High-dimensional Learned Index for Large-scale Dense Passage Retrieval" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/4eda3391ea29659432fe7b40f53ed69a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/4eda3391ea29659432fe7b40f53ed69a.html">&lt;p&gt;Text retrieval using dense embeddings generated from deep neural models is called  dense passage retrieval . Dense passage retrieval systems normally deploy a deep neural model followed by an approximate nearest neighbor (ANN) search module. The model generates text embeddings, which are then indexed by the ANN module. With the increasing data scale, the ANN module unavoidably becomes the bottleneck on efficiency, because of its linear or sublinear time complexity with data Cites: Efficient passage retrieval with hashing for open-domain question&lt;/p&gt;</content><author><name>Y Wang, H Ma, DZ Wang - arXiv preprint arXiv:2205.00970, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Text retrieval using dense embeddings generated from deep neural models is called dense passage retrieval . Dense passage retrieval systems normally deploy a deep neural model followed by an approximate nearest neighbor (ANN) search module. The model generates text embeddings, which are then indexed by the ANN module. With the increasing data scale, the ANN module unavoidably becomes the bottleneck on efficiency, because of its linear or sublinear time complexity with data Cites: Efficient passage retrieval with hashing for open-domain question</summary></entry><entry><title type="html">Textual Entailment for Event Argument Extraction: Zero-and Few-Shot with Multi-Source Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/4f498fb7fae02d44a26be37811c086ac.html" rel="alternate" type="text/html" title="Textual Entailment for Event Argument Extraction: Zero-and Few-Shot with Multi-Source Learning" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/4f498fb7fae02d44a26be37811c086ac</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/4f498fb7fae02d44a26be37811c086ac.html">&lt;p&gt;Recent work has shown that NLP tasks such as Relation Extraction (RE) can be recasted as Textual Entailment tasks using verbalizations, with strong performance in zero-shot and few-shot settings thanks to pre-trained entailment models. The fact that relations in current RE datasets are easily verbalized casts doubts on whether entailment would be effective in more complex tasks. In this work we show that entailment is also effective in Event Argument Extraction (EAE), reducing the need of Cites: Universal natural language processing with limited annotations&lt;/p&gt;</content><author><name>O Sainz, I Gonzalez-Dios, OL de Lacalle, B Min - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent work has shown that NLP tasks such as Relation Extraction (RE) can be recasted as Textual Entailment tasks using verbalizations, with strong performance in zero-shot and few-shot settings thanks to pre-trained entailment models. The fact that relations in current RE datasets are easily verbalized casts doubts on whether entailment would be effective in more complex tasks. In this work we show that entailment is also effective in Event Argument Extraction (EAE), reducing the need of Cites: Universal natural language processing with limited annotations</summary></entry><entry><title type="html">Evaluating the Practical Utility of Confidence-score based Techniques for Unsupervised Open-world Intent Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/4f6b24fa9941f38961b3b201924a70e7.html" rel="alternate" type="text/html" title="Evaluating the Practical Utility of Confidence-score based Techniques for Unsupervised Open-world Intent Classification" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/4f6b24fa9941f38961b3b201924a70e7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/4f6b24fa9941f38961b3b201924a70e7.html">&lt;p&gt;Open-world classification in dialog systems require models to detect open intents, while ensuring the quality of in-domain (ID) intent classification. In this work, we revisit methods that leverage distance-based statistics for unsupervised out-of- domain (OOD) detection. We show that despite their superior performance on threshold-independent metrics like AUROC on test-set, threshold values chosen based on the performance on a validation-set do not generalize well to the test-set Cites: Discriminative nearest neighbor few-shot intent detection by&lt;/p&gt;</content><author><name>S Khosla, R Gangadharaiah</name></author><category term="jekyll" /><category term="update" /><summary type="html">Open-world classification in dialog systems require models to detect open intents, while ensuring the quality of in-domain (ID) intent classification. In this work, we revisit methods that leverage distance-based statistics for unsupervised out-of- domain (OOD) detection. We show that despite their superior performance on threshold-independent metrics like AUROC on test-set, threshold values chosen based on the performance on a validation-set do not generalize well to the test-set Cites: Discriminative nearest neighbor few-shot intent detection by</summary></entry><entry><title type="html">Feature Specialization and Clustering Improves Hierarchical Subtask Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/51e19e74f5b056ad255b576199669726.html" rel="alternate" type="text/html" title="Feature Specialization and Clustering Improves Hierarchical Subtask Learning" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/51e19e74f5b056ad255b576199669726</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/51e19e74f5b056ad255b576199669726.html">&lt;p&gt;Eigendecomposition methods have been shown to generate sets of useful options which improve learning speed when used in hierarchical reinforcement learning. However, these methods focus on navigation by learning reward-agnostic representations and struggle when presented with environments with dynamic reward structures, such as adversarial agents. Taking inspiration from mammals, which are known to maintain specialized groupings of cells to perform complex Cites: Explore, discover and learn: Unsupervised discovery of state&lt;/p&gt;</content><author><name>N Van Stralen, SH Kim, HT Tran, G Chowdhary</name></author><category term="jekyll" /><category term="update" /><summary type="html">Eigendecomposition methods have been shown to generate sets of useful options which improve learning speed when used in hierarchical reinforcement learning. However, these methods focus on navigation by learning reward-agnostic representations and struggle when presented with environments with dynamic reward structures, such as adversarial agents. Taking inspiration from mammals, which are known to maintain specialized groupings of cells to perform complex Cites: Explore, discover and learn: Unsupervised discovery of state</summary></entry><entry><title type="html">Semantic Diversity in Dialogue with Natural Language Inference</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/52eb1a0f5be3aff884251b729d1cbd8a.html" rel="alternate" type="text/html" title="Semantic Diversity in Dialogue with Natural Language Inference" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/52eb1a0f5be3aff884251b729d1cbd8a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/52eb1a0f5be3aff884251b729d1cbd8a.html">&lt;p&gt;Generating diverse, interesting responses to chitchat conversations is a problem for neural conversational agents. This paper makes two substantial contributions to improving diversity in dialogue generation. First, we propose a novel metric which uses Natural Language Inference (NLI) to measure the semantic diversity of a set of model responses for a conversation. We evaluate this metric using an established framework (Tevet and Berant, 2021) and find strong evidence indicating NLI Diversity Cites: Choose your own adventure: Paired suggestions in collaborative&lt;/p&gt;</content><author><name>K Stasaski, MA Hearst - arXiv preprint arXiv:2205.01497, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Generating diverse, interesting responses to chitchat conversations is a problem for neural conversational agents. This paper makes two substantial contributions to improving diversity in dialogue generation. First, we propose a novel metric which uses Natural Language Inference (NLI) to measure the semantic diversity of a set of model responses for a conversation. We evaluate this metric using an established framework (Tevet and Berant, 2021) and find strong evidence indicating NLI Diversity Cites: Choose your own adventure: Paired suggestions in collaborative</summary></entry><entry><title type="html">A Survey of Machine Narrative Reading Comprehension Assessments</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/551bd948fe59a6a4a982612db8dd69fd.html" rel="alternate" type="text/html" title="A Survey of Machine Narrative Reading Comprehension Assessments" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/551bd948fe59a6a4a982612db8dd69fd</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/551bd948fe59a6a4a982612db8dd69fd.html">&lt;p&gt;As the body of research on machine narrative comprehension grows, there is a critical need for consideration of performance assessment strategies as well as the depth and scope of different benchmark tasks. Based on narrative theories, reading comprehension theories, as well as existing machine narrative reading comprehension tasks and datasets, we propose a typology that captures the main similarities and differences among assessment tasks; and discuss the implications of Cites: Fantastic Questions and Where to Find Them: FairytaleQA–An&lt;/p&gt;</content><author><name>Y Sang, X Mou, J Li, J Stanton, M Yu - arXiv preprint arXiv:2205.00299, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">As the body of research on machine narrative comprehension grows, there is a critical need for consideration of performance assessment strategies as well as the depth and scope of different benchmark tasks. Based on narrative theories, reading comprehension theories, as well as existing machine narrative reading comprehension tasks and datasets, we propose a typology that captures the main similarities and differences among assessment tasks; and discuss the implications of Cites: Fantastic Questions and Where to Find Them: FairytaleQA–An</summary></entry><entry><title type="html">Inferring Implicit Relations with Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5799b819f54611d681dafa0e2fdad785.html" rel="alternate" type="text/html" title="Inferring Implicit Relations with Language Models" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5799b819f54611d681dafa0e2fdad785</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5799b819f54611d681dafa0e2fdad785.html">&lt;p&gt;A prominent challenge for modern language understanding systems is the ability to answer implicit reasoning questions, where the required reasoning steps for answering the question are not mentioned in the text explicitly. In this work, we investigate why current models struggle with implicit reasoning question answering (QA) tasks, by decoupling inference of reasoning steps from their execution. We define a new task of implicit relation inference and construct a benchmark Cites: Qa-gnn: Reasoning with language models and knowledge graphs&lt;/p&gt;</content><author><name>U Katz, M Geva, J Berant - arXiv preprint arXiv:2204.13778, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">A prominent challenge for modern language understanding systems is the ability to answer implicit reasoning questions, where the required reasoning steps for answering the question are not mentioned in the text explicitly. In this work, we investigate why current models struggle with implicit reasoning question answering (QA) tasks, by decoupling inference of reasoning steps from their execution. We define a new task of implicit relation inference and construct a benchmark Cites: Qa-gnn: Reasoning with language models and knowledge graphs</summary></entry><entry><title type="html">Hidden behind the obvious: misleading keywords and implicitly abusive language on social media</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5b7d6bcb16f52e5fa8eea1b2438b4123.html" rel="alternate" type="text/html" title="Hidden behind the obvious: misleading keywords and implicitly abusive language on social media" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5b7d6bcb16f52e5fa8eea1b2438b4123</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5b7d6bcb16f52e5fa8eea1b2438b4123.html">&lt;p&gt;While social media offers freedom of self-expression, abusive language carry significant negative social impact. Driven by the importance of the issue, research in the automated detection of abusive language has witnessed growth and improvement. However, these detection models display a reliance on strongly indicative keywords, such as slurs and profanity. This means that they can falsely (1a) miss abuse without such keywords or (1b) flag non-abuse with such keywords Cites: BERT: pre-training of deep bidirectional transformers for language&lt;/p&gt;</content><author><name>W Yin, A Zubiaga - arXiv preprint arXiv:2205.01374, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">While social media offers freedom of self-expression, abusive language carry significant negative social impact. Driven by the importance of the issue, research in the automated detection of abusive language has witnessed growth and improvement. However, these detection models display a reliance on strongly indicative keywords, such as slurs and profanity. This means that they can falsely (1a) miss abuse without such keywords or (1b) flag non-abuse with such keywords Cites: BERT: pre-training of deep bidirectional transformers for language</summary></entry><entry><title type="html">How Much Do Modifications to Transformer Language Models Affect Their Ability to Learn Linguistic Knowledge?</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5cb1e6a7d785b6a64004656971597fc5.html" rel="alternate" type="text/html" title="How Much Do Modifications to Transformer Language Models Affect Their Ability to Learn Linguistic Knowledge?" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5cb1e6a7d785b6a64004656971597fc5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5cb1e6a7d785b6a64004656971597fc5.html">&lt;p&gt;Recent progress in large pretrained language models (LMs) has led to a growth of analyses examining what kinds of linguistic knowledge are encoded by these models. Due to computational constraints, existing analyses are mostly conducted on&lt;/p&gt;</content><author><name>S Sun, B Dillon, M Iyyer</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent progress in large pretrained language models (LMs) has led to a growth of analyses examining what kinds of linguistic knowledge are encoded by these models. Due to computational constraints, existing analyses are mostly conducted on</summary></entry><entry><title type="html">Learning Label Initialization for Time-Dependent Harmonic Extension</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5d050efcd75de4acfb1ddb8e9adf789f.html" rel="alternate" type="text/html" title="Learning Label Initialization for Time-Dependent Harmonic Extension" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5d050efcd75de4acfb1ddb8e9adf789f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5d050efcd75de4acfb1ddb8e9adf789f.html">&lt;p&gt;Node classification on graphs can be formulated as the Dirichlet problem on graphs where the signal is given at the labeled nodes, and the harmonic extension is done on the unlabeled nodes. This paper considers a time-dependent version of the Dirichlet problem on graphs and shows how to improve its solution by learning the proper initialization vector on the unlabeled nodes. Further, we show that the improved solution is at par with state-of-the-art methods used for node classification Cites: Regularization on discrete spaces&lt;/p&gt;</content><author><name>A Azad - arXiv preprint arXiv:2205.01358, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Node classification on graphs can be formulated as the Dirichlet problem on graphs where the signal is given at the labeled nodes, and the harmonic extension is done on the unlabeled nodes. This paper considers a time-dependent version of the Dirichlet problem on graphs and shows how to improve its solution by learning the proper initialization vector on the unlabeled nodes. Further, we show that the improved solution is at par with state-of-the-art methods used for node classification Cites: Regularization on discrete spaces</summary></entry><entry><title type="html">Positive-Unlabeled Learning with Adversarial Data Augmentation for Knowledge Graph Completion</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5ef82eb40bac8744fecf26e042411b15.html" rel="alternate" type="text/html" title="Positive-Unlabeled Learning with Adversarial Data Augmentation for Knowledge Graph Completion" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5ef82eb40bac8744fecf26e042411b15</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5ef82eb40bac8744fecf26e042411b15.html">&lt;p&gt;Most real-world knowledge graphs (KG) are far from complete and comprehensive. This problem has motivated efforts in predicting the most plausible missing facts to complete a given KG, ie, knowledge graph completion (KGC). However, existing KGC methods suffer from two main issues, 1) the false negative issue, ie, the candidates for sampling negative training instances include potential true facts; and 2) the data sparsity issue, ie, true facts account for only a tiny part of all possible facts Cites: Representing Text for Joint Embedding of Text and Knowledge&lt;/p&gt;</content><author><name>Z Tang, S Pei, Z Zhang, Y Zhu, F Zhuang, R Hoehndorf - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Most real-world knowledge graphs (KG) are far from complete and comprehensive. This problem has motivated efforts in predicting the most plausible missing facts to complete a given KG, ie, knowledge graph completion (KGC). However, existing KGC methods suffer from two main issues, 1) the false negative issue, ie, the candidates for sampling negative training instances include potential true facts; and 2) the data sparsity issue, ie, true facts account for only a tiny part of all possible facts Cites: Representing Text for Joint Embedding of Text and Knowledge</summary></entry><entry><title type="html">AN EXPLORATION OF BARRIERS TO OFFENDER REINTEGRATION: PROBATION AND PRISON OFFICER OPINIONS VS PUBLIC OPINION</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5face5130889e57fbcc99b03c242da02.html" rel="alternate" type="text/html" title="AN EXPLORATION OF BARRIERS TO OFFENDER REINTEGRATION: PROBATION AND PRISON OFFICER OPINIONS VS PUBLIC OPINION" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5face5130889e57fbcc99b03c242da02</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/5face5130889e57fbcc99b03c242da02.html">&lt;p&gt;Stigmatization has been a major hindrance to successful reintegration of released offenders into the community primarily due to increased ostracism and anxiety of the wider community relative to recidivism and public security. This study, therefore, evaluated the position of the general public and probation and prison officers in driving successful reintegration of offenders by assessing their opinions and perceptions towards social reintegration to isolate barriers to successful social Cites: Abductive commonsense reasoning&lt;/p&gt;</content><author><name>SMN Sakib - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Stigmatization has been a major hindrance to successful reintegration of released offenders into the community primarily due to increased ostracism and anxiety of the wider community relative to recidivism and public security. This study, therefore, evaluated the position of the general public and probation and prison officers in driving successful reintegration of offenders by assessing their opinions and perceptions towards social reintegration to isolate barriers to successful social Cites: Abductive commonsense reasoning</summary></entry><entry><title type="html">Neural language models for network configuration: Opportunities and reality check</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/61b62fcc340b6583e6ee7bea85ed5f0d.html" rel="alternate" type="text/html" title="Neural language models for network configuration: Opportunities and reality check" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/61b62fcc340b6583e6ee7bea85ed5f0d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/61b62fcc340b6583e6ee7bea85ed5f0d.html">&lt;p&gt;Boosted by deep learning, natural language processing (NLP) techniques have recently seen spectacular progress, mainly fueled by breakthroughs both in representation learning with word embeddings (eg word2vec) as well as novel architectures (eg transformers). This success quickly invited researchers to explore the use of NLP techniques to other field, such as computer programming languages, with the promise to automate tasks in software programming (bug detection, code Cites: Break-It-Fix-It: Unsupervised Learning for Program Repair&lt;/p&gt;</content><author><name>ZB Houidi, D Rossi - arXiv preprint arXiv:2205.01398, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Boosted by deep learning, natural language processing (NLP) techniques have recently seen spectacular progress, mainly fueled by breakthroughs both in representation learning with word embeddings (eg word2vec) as well as novel architectures (eg transformers). This success quickly invited researchers to explore the use of NLP techniques to other field, such as computer programming languages, with the promise to automate tasks in software programming (bug detection, code Cites: Break-It-Fix-It: Unsupervised Learning for Program Repair</summary></entry><entry><title type="html">Adversarial Training for High-Stakes Reliability</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/62dc2429e71ce32b8918730ecf06798a.html" rel="alternate" type="text/html" title="Adversarial Training for High-Stakes Reliability" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/62dc2429e71ce32b8918730ecf06798a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/62dc2429e71ce32b8918730ecf06798a.html">&lt;p&gt;In the future, powerful AI systems may be deployed in high-stakes settings, where a single failure could be catastrophic. One technique for improving AI safety in high- stakes settings is adversarial training, which uses an adversary to generate examples to train on in order to achieve better worst-case performance. In this work, we used a language generation task as a testbed for achieving high reliability through adversarial training. We created a series of adversarial training techniques Cites: Distributionally robust neural networks for group shifts: On the&lt;/p&gt;</content><author><name>DM Ziegler, S Nix, L Chan, T Bauman - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In the future, powerful AI systems may be deployed in high-stakes settings, where a single failure could be catastrophic. One technique for improving AI safety in high- stakes settings is adversarial training, which uses an adversary to generate examples to train on in order to achieve better worst-case performance. In this work, we used a language generation task as a testbed for achieving high reliability through adversarial training. We created a series of adversarial training techniques Cites: Distributionally robust neural networks for group shifts: On the</summary></entry><entry><title type="html">Revisiting brassinosteroids signaling in plants: current advances and challenges</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/63959891270fe45d485c3d0ca4ec195a.html" rel="alternate" type="text/html" title="Revisiting brassinosteroids signaling in plants: current advances and challenges" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/63959891270fe45d485c3d0ca4ec195a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/63959891270fe45d485c3d0ca4ec195a.html">&lt;p&gt;Brassinosteroids (BRs) are a group of polyhydroxylated plant steroid hormones with similar structures to animals  steroid hormones that are crucial for many aspects of a plant s life. Their characteristic feature is their resemblance to plant sterols like sitosterol and campesterol. BR was recognized as a regulator of transcription and translation thereby changing the expression pattern of total proteins, enzymes, and photosynthetic rate, and finally the seed yield, at harvest. Physiologically they have Cites: BRL1 and BRL3 are novel brassinosteroid receptors that function&lt;/p&gt;</content><author><name>EA Khan, TK Upadhyay, RK Prajapat, M Mathur - Brassinosteroids in Plant , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Brassinosteroids (BRs) are a group of polyhydroxylated plant steroid hormones with similar structures to animals steroid hormones that are crucial for many aspects of a plant s life. Their characteristic feature is their resemblance to plant sterols like sitosterol and campesterol. BR was recognized as a regulator of transcription and translation thereby changing the expression pattern of total proteins, enzymes, and photosynthetic rate, and finally the seed yield, at harvest. Physiologically they have Cites: BRL1 and BRL3 are novel brassinosteroid receptors that function</summary></entry><entry><title type="html">Unified Abstract Syntax Tree Representation Learning for Cross-Language Program Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/64f77724beb4091411f3d2aecf451010.html" rel="alternate" type="text/html" title="Unified Abstract Syntax Tree Representation Learning for Cross-Language Program Classification" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/64f77724beb4091411f3d2aecf451010</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/64f77724beb4091411f3d2aecf451010.html">&lt;p&gt;Program classification can be regarded as a high-level abstraction of code, laying a foundation for various tasks related to source code comprehension, and has a very wide range of applications in the field of software engineering, such as code clone detection, code smell classification, defects classification, etc. The cross-language program classification can realize code transfer in different programming languages, and can also promote cross-language code reuse, thereby helping developers to Cites: Codebert: A pre-trained model for programming and natural&lt;/p&gt;</content><author><name>K Wang, M Yan, H Zhang, H Hu - arXiv preprint arXiv:2205.00424, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Program classification can be regarded as a high-level abstraction of code, laying a foundation for various tasks related to source code comprehension, and has a very wide range of applications in the field of software engineering, such as code clone detection, code smell classification, defects classification, etc. The cross-language program classification can realize code transfer in different programming languages, and can also promote cross-language code reuse, thereby helping developers to Cites: Codebert: A pre-trained model for programming and natural</summary></entry><entry><title type="html">Designing for Responsible Trust in AI Systems: A Communication Perspective</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/66f61b14742a4de92720692598eb39b4.html" rel="alternate" type="text/html" title="Designing for Responsible Trust in AI Systems: A Communication Perspective" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/66f61b14742a4de92720692598eb39b4</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/66f61b14742a4de92720692598eb39b4.html">&lt;p&gt;Current literature and public discourse on  trust in AI  are often focused on the principles underlying trustworthy AI, with insufficient attention paid to how people develop trust. Given that AI systems differ in their level of trustworthiness, two open questions come to the fore: how should AI trustworthiness be responsibly communicated to ensure appropriate and equitable trust judgments by different users, and how can we protect users from deceptive attempts to earn their trust? We Cites: Does the Whole Exceed its Parts? The Effect of AI Explanations on&lt;/p&gt;</content><author><name>QV Liao, SS Sundar - arXiv preprint arXiv:2204.13828, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Current literature and public discourse on trust in AI are often focused on the principles underlying trustworthy AI, with insufficient attention paid to how people develop trust. Given that AI systems differ in their level of trustworthiness, two open questions come to the fore: how should AI trustworthiness be responsibly communicated to ensure appropriate and equitable trust judgments by different users, and how can we protect users from deceptive attempts to earn their trust? We Cites: Does the Whole Exceed its Parts? The Effect of AI Explanations on</summary></entry><entry><title type="html">QRelScore: Better Evaluating Generated Questions with Deeper Understanding of Context-aware Relevance</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6a31d24d5c12edb2c14ebd69c530ab5e.html" rel="alternate" type="text/html" title="QRelScore: Better Evaluating Generated Questions with Deeper Understanding of Context-aware Relevance" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6a31d24d5c12edb2c14ebd69c530ab5e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6a31d24d5c12edb2c14ebd69c530ab5e.html">&lt;p&gt;Existing metrics for assessing question generation not only require costly human reference but also fail to take into account the input context of generation, rendering the lack of deep understanding of the relevance between the generated questions and input contexts. As a result, they may wrongly penalize a legitimate and reasonable candidate question when it (i) involves complicated reasoning with the context or (ii) can be grounded by multiple evidences in the context. In this paper, we Cites: Evaluating the factual consistency of abstractive text summarization&lt;/p&gt;</content><author><name>X Wang, B Liu, S Tang, L Wu - arXiv preprint arXiv:2204.13921, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Existing metrics for assessing question generation not only require costly human reference but also fail to take into account the input context of generation, rendering the lack of deep understanding of the relevance between the generated questions and input contexts. As a result, they may wrongly penalize a legitimate and reasonable candidate question when it (i) involves complicated reasoning with the context or (ii) can be grounded by multiple evidences in the context. In this paper, we Cites: Evaluating the factual consistency of abstractive text summarization</summary></entry><entry><title type="html">TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6d8579d6395aeecd67edb6a6a938e9a9.html" rel="alternate" type="text/html" title="TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6d8579d6395aeecd67edb6a6a938e9a9</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6d8579d6395aeecd67edb6a6a938e9a9.html">&lt;p&gt;Language Models (LMs) become outdated as the world changes; they often fail to perform tasks requiring recent factual information which was absent or different during training, a phenomenon called temporal misalignment. This is especially a challenging problem because the research community still lacks a coherent dataset for assessing the adaptability of LMs to frequently-updated knowledge corpus such as Wikipedia. To this end, we introduce TemporalWiki, a lifelong benchmark for ever Cites: FRUIT: Faithfully Reflecting Updated Information in Text&lt;/p&gt;</content><author><name>J Jang, S Ye, C Lee, S Yang, J Shin, J Han, G Kim - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Language Models (LMs) become outdated as the world changes; they often fail to perform tasks requiring recent factual information which was absent or different during training, a phenomenon called temporal misalignment. This is especially a challenging problem because the research community still lacks a coherent dataset for assessing the adaptability of LMs to frequently-updated knowledge corpus such as Wikipedia. To this end, we introduce TemporalWiki, a lifelong benchmark for ever Cites: FRUIT: Faithfully Reflecting Updated Information in Text</summary></entry><entry><title type="html">Modular Domain Adaptation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6e3c443169b03bdc8862ba5caa5eaf8d.html" rel="alternate" type="text/html" title="Modular Domain Adaptation" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6e3c443169b03bdc8862ba5caa5eaf8d</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6e3c443169b03bdc8862ba5caa5eaf8d.html">&lt;p&gt;Off-the-shelf models are widely used by computational social science researchers to measure properties of text, such as sentiment. However, without access to source data it is difficult to account for domain shift, which represents a threat to validity. Here, we treat domain adaptation as a modular process that involves separate model producers and model consumers, and show how they can independently cooperate to facilitate more accurate measurements of text. We introduce two lightweight Cites: Understanding self-training for gradual domain adaptation&lt;/p&gt;</content><author><name>JK Chen, D Card, D Jurafsky - arXiv preprint arXiv:2204.14213, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Off-the-shelf models are widely used by computational social science researchers to measure properties of text, such as sentiment. However, without access to source data it is difficult to account for domain shift, which represents a threat to validity. Here, we treat domain adaptation as a modular process that involves separate model producers and model consumers, and show how they can independently cooperate to facilitate more accurate measurements of text. We introduce two lightweight Cites: Understanding self-training for gradual domain adaptation</summary></entry><entry><title type="html">A Two-Stream AMR-enhanced Model for Document-level Event Argument Extraction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6ed0586a3d0c574a38894032f79211be.html" rel="alternate" type="text/html" title="A Two-Stream AMR-enhanced Model for Document-level Event Argument Extraction" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6ed0586a3d0c574a38894032f79211be</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6ed0586a3d0c574a38894032f79211be.html">&lt;p&gt;Most previous studies aim at extracting events from a single sentence, while document-level event extraction still remains under-explored. In this paper, we focus on extracting event arguments from an entire document, which mainly faces two critical problems: a) the long-distance dependency between trigger and arguments over sentences; b) the distracting context towards an event in the document. To address these issues, we propose a Two-Stream Abstract meaning Representation Cites: Entity, relation, and event extraction with contextualized span&lt;/p&gt;</content><author><name>R Xu, P Wang, T Liu, S Zeng, B Chang, Z Sui - arXiv preprint arXiv:2205.00241, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Most previous studies aim at extracting events from a single sentence, while document-level event extraction still remains under-explored. In this paper, we focus on extracting event arguments from an entire document, which mainly faces two critical problems: a) the long-distance dependency between trigger and arguments over sentences; b) the distracting context towards an event in the document. To address these issues, we propose a Two-Stream Abstract meaning Representation Cites: Entity, relation, and event extraction with contextualized span</summary></entry><entry><title type="html">Repro: An Open-Source Library for Improving the Reproducibility and Usability of Publicly Available Research Code</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6f55636b355f66294ef7bc943435d649.html" rel="alternate" type="text/html" title="Repro: An Open-Source Library for Improving the Reproducibility and Usability of Publicly Available Research Code" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6f55636b355f66294ef7bc943435d649</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/6f55636b355f66294ef7bc943435d649.html">&lt;p&gt;We introduce Repro, an open-source library which aims at improving the reproducibility and usability of research code. The library provides a lightweight Python API for running software released by researchers within Docker containers&lt;/p&gt;</content><author><name>D Deutsch, D Roth - arXiv preprint arXiv:2204.13848, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We introduce Repro, an open-source library which aims at improving the reproducibility and usability of research code. The library provides a lightweight Python API for running software released by researchers within Docker containers</summary></entry><entry><title type="html">Embedding Hallucination for Few-Shot Language Fine-tuning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7357fe95f341624d2ed4eaa665430f94.html" rel="alternate" type="text/html" title="Embedding Hallucination for Few-Shot Language Fine-tuning" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7357fe95f341624d2ed4eaa665430f94</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7357fe95f341624d2ed4eaa665430f94.html">&lt;p&gt;Few-shot language learners adapt knowledge from a pre-trained model to recognize novel classes from a few-labeled sentences. In such settings, fine-tuning a pre- trained language model can cause severe over-fitting. In this paper, we propose an Embedding Hallucination (EmbedHalluc) method, which generates auxiliary embedding-label pairs to expand the fine-tuning dataset. The hallucinator is trained by playing an adversarial game with the discriminator, such that the hallucinated Cites: Mixout: Effective regularization to finetune large-scale pretrained&lt;/p&gt;</content><author><name>Y Jian, C Gao, S Vosoughi - arXiv preprint arXiv:2205.01307, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Few-shot language learners adapt knowledge from a pre-trained model to recognize novel classes from a few-labeled sentences. In such settings, fine-tuning a pre- trained language model can cause severe over-fitting. In this paper, we propose an Embedding Hallucination (EmbedHalluc) method, which generates auxiliary embedding-label pairs to expand the fine-tuning dataset. The hallucinator is trained by playing an adversarial game with the discriminator, such that the hallucinated Cites: Mixout: Effective regularization to finetune large-scale pretrained</summary></entry><entry><title type="html">Learning to Transfer Prompts for Text Generation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/74d3c6eca24a31e476e4d37cd7f2e7ff.html" rel="alternate" type="text/html" title="Learning to Transfer Prompts for Text Generation" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/74d3c6eca24a31e476e4d37cd7f2e7ff</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/74d3c6eca24a31e476e4d37cd7f2e7ff.html">&lt;p&gt;Pretrained language models (PLMs) have made remarkable progress in text generation tasks via fine-tuning. While, it is challenging to fine-tune PLMs in a data- scarce situation. Therefore, it is non-trivial to develop a general and lightweight model that can adapt to various text generation tasks based on PLMs. To fulfill this purpose, the recent prompt-based learning offers a potential solution. In this paper, we improve this technique and propose a novel prompt-based method (PTG) for text Cites: Don t give me the details, just the summary! topic-aware&lt;/p&gt;</content><author><name>J Li, T Tang, JY Nie, JR Wen, WX Zhao - arXiv preprint arXiv:2205.01543, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pretrained language models (PLMs) have made remarkable progress in text generation tasks via fine-tuning. While, it is challenging to fine-tune PLMs in a data- scarce situation. Therefore, it is non-trivial to develop a general and lightweight model that can adapt to various text generation tasks based on PLMs. To fulfill this purpose, the recent prompt-based learning offers a potential solution. In this paper, we improve this technique and propose a novel prompt-based method (PTG) for text Cites: Don t give me the details, just the summary! topic-aware</summary></entry><entry><title type="html">OPT: Open Pre-trained Transformer Language Models</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/78d64b27cbf35744555c6c4dce51e6c2.html" rel="alternate" type="text/html" title="OPT: Open Pre-trained Transformer Language Models" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/78d64b27cbf35744555c6c4dce51e6c2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/78d64b27cbf35744555c6c4dce51e6c2.html">&lt;p&gt;Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero-and few-shot learning. Given their computational cost, these models are difficult to replicate without&lt;/p&gt;</content><author><name>S Zhang, S Roller, N Goyal, M Artetxe, M Chen, S Chen - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Large language models, which are often trained for hundreds of thousands of compute days, have shown remarkable capabilities for zero-and few-shot learning. Given their computational cost, these models are difficult to replicate without</summary></entry><entry><title type="html">Training Language Models with Natural Language Feedback</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7bb68185910e6bd40b83ab0d2ee2137a.html" rel="alternate" type="text/html" title="Training Language Models with Natural Language Feedback" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7bb68185910e6bd40b83ab0d2ee2137a</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7bb68185910e6bd40b83ab0d2ee2137a.html">&lt;p&gt;Pretrained language models often do not perform tasks in ways that are in line with our preferences, eg, generating offensive text or factually incorrect summaries. Recent work approaches the above issue by learning from a simple form of human evaluation: comparisons between pairs of model-generated task outputs. Comparison feedback conveys limited information about human preferences per human evaluation. Here, we propose to learn from natural language feedback, which Cites: Realtoxicityprompts: Evaluating neural toxic degeneration in&lt;/p&gt;</content><author><name>J Scheurer, JA Campos, JS Chan, A Chen, K Cho - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Pretrained language models often do not perform tasks in ways that are in line with our preferences, eg, generating offensive text or factually incorrect summaries. Recent work approaches the above issue by learning from a simple form of human evaluation: comparisons between pairs of model-generated task outputs. Comparison feedback conveys limited information about human preferences per human evaluation. Here, we propose to learn from natural language feedback, which Cites: Realtoxicityprompts: Evaluating neural toxic degeneration in</summary></entry><entry><title type="html">On the Effect of Information Asymmetry in Human-AI Teams</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7d134beb729be03baa314d4c22a7c403.html" rel="alternate" type="text/html" title="On the Effect of Information Asymmetry in Human-AI Teams" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7d134beb729be03baa314d4c22a7c403</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7d134beb729be03baa314d4c22a7c403.html">&lt;p&gt;Over the last years, the rising capabilities of artificial intelligence (AI) have improved human decision-making in many application areas. Teaming between AI and humans may even lead to complementary team performance (CTP), ie, a level of performance beyond the ones that can be reached by AI or humans individually. Many researchers have proposed using explainable AI (XAI) to enable humans to rely on AI advice appropriately and thereby reach CTP. However, CTP is rarely Cites: Does the Whole Exceed its Parts? The Effect of AI Explanations on&lt;/p&gt;</content><author><name>P Hemmer, M Schemmer, N Khl, M Vssing - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Over the last years, the rising capabilities of artificial intelligence (AI) have improved human decision-making in many application areas. Teaming between AI and humans may even lead to complementary team performance (CTP), ie, a level of performance beyond the ones that can be reached by AI or humans individually. Many researchers have proposed using explainable AI (XAI) to enable humans to rely on AI advice appropriately and thereby reach CTP. However, CTP is rarely Cites: Does the Whole Exceed its Parts? The Effect of AI Explanations on</summary></entry><entry><title type="html">Training Naturalized Semantic Parsers with Very Little Data</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7e55d249484529c570bfaa7a2b5723a2.html" rel="alternate" type="text/html" title="Training Naturalized Semantic Parsers with Very Little Data" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7e55d249484529c570bfaa7a2b5723a2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7e55d249484529c570bfaa7a2b5723a2.html">&lt;p&gt;Semantic parsing is an important NLP problem, particularly for voice assistants such as Alexa and Google Assistant. State-of-the-art (SOTA) semantic parsers are seq2seq architectures based on large language models that have been pretrained on vast amounts of text. To better leverage that pretraining, recent work has explored a reformulation of semantic parsing whereby the output sequences are themselves natural language sentences, but in a controlled fragment of natural language. This Cites: Xi Victoria Lin, Bailin Wang, Yi Chern Tan, Xinyi Yang, Dragomir&lt;/p&gt;</content><author><name>S Rongali, K Arkoudas, M Rubino, W Hamza - arXiv preprint arXiv:2204.14243, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Semantic parsing is an important NLP problem, particularly for voice assistants such as Alexa and Google Assistant. State-of-the-art (SOTA) semantic parsers are seq2seq architectures based on large language models that have been pretrained on vast amounts of text. To better leverage that pretraining, recent work has explored a reformulation of semantic parsing whereby the output sequences are themselves natural language sentences, but in a controlled fragment of natural language. This Cites: Xi Victoria Lin, Bailin Wang, Yi Chern Tan, Xinyi Yang, Dragomir</summary></entry><entry><title type="html">Extension-Compression Learning: A deep learning code search method that simulates reading habits</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7f0034a303442b210fdc8e27a48d8e4e.html" rel="alternate" type="text/html" title="Extension-Compression Learning: A deep learning code search method that simulates reading habits" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7f0034a303442b210fdc8e27a48d8e4e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7f0034a303442b210fdc8e27a48d8e4e.html">&lt;p&gt;To speed up the efficiency of software development, the ability to retrieve codes through natural language is fundamental. At present, the approach of code search based on deep learning has been extensively researched and achieved a lot of results. However, these models are much complex and the training relies on artificially extracted features. Different from other deep learning models, we simulate people s reading habit of expanding content first and then refining content when Cites: Learning to mine aligned code and natural language pairs from&lt;/p&gt;</content><author><name>L Gu, Z Wang, J Liu, Y Zhang, D Yang, W Dong - 2022 26th International Conference , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">To speed up the efficiency of software development, the ability to retrieve codes through natural language is fundamental. At present, the approach of code search based on deep learning has been extensively researched and achieved a lot of results. However, these models are much complex and the training relies on artificially extracted features. Different from other deep learning models, we simulate people s reading habit of expanding content first and then refining content when Cites: Learning to mine aligned code and natural language pairs from</summary></entry><entry><title type="html">Instilling Type Knowledge in Language Models via Multi-Task QA</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7f66b5f09ee2ec4c1542dbfab3abbdf2.html" rel="alternate" type="text/html" title="Instilling Type Knowledge in Language Models via Multi-Task QA" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7f66b5f09ee2ec4c1542dbfab3abbdf2</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/7f66b5f09ee2ec4c1542dbfab3abbdf2.html">&lt;p&gt;Understanding human language often necessitates understanding entities and their place in a taxonomy of knowledge–their types. Previous methods to learn entity types rely on training classifiers on datasets with coarse, noisy, and incomplete labels. We introduce a method to instill fine-grained type knowledge in language models with text-to-text pre-training on type-centric questions leveraging knowledge base documents and knowledge graphs. We create the WikiWiki dataset: entities and Cites: REALM: Retrieval-Augmented Language Model Pre-Training&lt;/p&gt;</content><author><name>S Li, M Sridhar, CS Prakash, J Cao, W Hamza - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Understanding human language often necessitates understanding entities and their place in a taxonomy of knowledge–their types. Previous methods to learn entity types rely on training classifiers on datasets with coarse, noisy, and incomplete labels. We introduce a method to instill fine-grained type knowledge in language models with text-to-text pre-training on type-centric questions leveraging knowledge base documents and knowledge graphs. We create the WikiWiki dataset: entities and Cites: REALM: Retrieval-Augmented Language Model Pre-Training</summary></entry><entry><title type="html">Paragraph-based Transformer Pre-training for Multi-Sentence Inference</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/8013bcbf9cc9740334f03ae6c1110d84.html" rel="alternate" type="text/html" title="Paragraph-based Transformer Pre-training for Multi-Sentence Inference" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/8013bcbf9cc9740334f03ae6c1110d84</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/8013bcbf9cc9740334f03ae6c1110d84.html">&lt;p&gt;Inference tasks such as answer sentence selection (AS2) or fact verification are typically solved by fine-tuning transformer-based models as individual sentence-pair classifiers. Recent studies show that these tasks benefit from modeling dependencies across multiple candidate sentences jointly. In this paper, we first show that popular pre-trained transformers perform poorly when used for fine-tuning on multi-candidate inference tasks. We then propose a new pre-training objective Cites: Reasoning over semantic-level graph for fact checking&lt;/p&gt;</content><author><name>L Di Liello, S Garg, L Soldaini, A Moschitti - arXiv preprint arXiv:2205.01228, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Inference tasks such as answer sentence selection (AS2) or fact verification are typically solved by fine-tuning transformer-based models as individual sentence-pair classifiers. Recent studies show that these tasks benefit from modeling dependencies across multiple candidate sentences jointly. In this paper, we first show that popular pre-trained transformers perform poorly when used for fine-tuning on multi-candidate inference tasks. We then propose a new pre-training objective Cites: Reasoning over semantic-level graph for fact checking</summary></entry><entry><title type="html">EasyNLP: A Comprehensive and Easy-to-use Toolkit for Natural Language Processing</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/813e3b982f43ac83d20ca21e14bddc62.html" rel="alternate" type="text/html" title="EasyNLP: A Comprehensive and Easy-to-use Toolkit for Natural Language Processing" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/813e3b982f43ac83d20ca21e14bddc62</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/813e3b982f43ac83d20ca21e14bddc62.html">&lt;p&gt;The success of Pre-Trained Models (PTMs) has reshaped the development of Natural Language Processing (NLP). Yet, it is not easy to obtain high-performing models and deploy them online for industrial practitioners. To bridge this gap, EasyNLP is designed to make it easy to build NLP applications, which supports a comprehensive suite of NLP algorithms. It further features knowledge-enhanced pre- training, knowledge distillation and few-shot learning functionalities for large-scale Cites: Pre-train, prompt, and predict: A systematic survey of prompting&lt;/p&gt;</content><author><name>C Wang, M Qiu, T Zhang, T Liu, L Li, J Wang, M Wang - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The success of Pre-Trained Models (PTMs) has reshaped the development of Natural Language Processing (NLP). Yet, it is not easy to obtain high-performing models and deploy them online for industrial practitioners. To bridge this gap, EasyNLP is designed to make it easy to build NLP applications, which supports a comprehensive suite of NLP algorithms. It further features knowledge-enhanced pre- training, knowledge distillation and few-shot learning functionalities for large-scale Cites: Pre-train, prompt, and predict: A systematic survey of prompting</summary></entry><entry><title type="html">Quality-Aware Decoding for Neural Machine Translation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/8c4d88b37f4ed279eb5cddebd0b30462.html" rel="alternate" type="text/html" title="Quality-Aware Decoding for Neural Machine Translation" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/8c4d88b37f4ed279eb5cddebd0b30462</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/8c4d88b37f4ed279eb5cddebd0b30462.html">&lt;p&gt;Despite the progress in machine translation quality estimation and evaluation in the last years, decoding in neural machine translation (NMT) is mostly oblivious to this and centers around finding the most probable translation according to the model&lt;/p&gt;</content><author><name>P Fernandes, A Farinhas, R Rei, JGC de Souza - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Despite the progress in machine translation quality estimation and evaluation in the last years, decoding in neural machine translation (NMT) is mostly oblivious to this and centers around finding the most probable translation according to the model</summary></entry><entry><title type="html">ExSum: From Local Explanations to Model Understanding</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/93cea3aa523eadb77f4f042b6e7c7e42.html" rel="alternate" type="text/html" title="ExSum: From Local Explanations to Model Understanding" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/93cea3aa523eadb77f4f042b6e7c7e42</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/93cea3aa523eadb77f4f042b6e7c7e42.html">&lt;p&gt;Interpretability methods are developed to understand the working mechanisms of black-box models, which is crucial to their responsible deployment. Fulfilling this goal requires both that the explanations generated by these methods are correct and that people can easily and reliably understand them. While the former has been addressed in prior work, the latter is often overlooked, resulting in informal model understanding derived from a handful of local explanations. In this paper, we Cites: Polyjuice: Generating Counterfactuals for Explaining, Evaluating&lt;/p&gt;</content><author><name>Y Zhou, MT Ribeiro, J Shah - arXiv preprint arXiv:2205.00130, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Interpretability methods are developed to understand the working mechanisms of black-box models, which is crucial to their responsible deployment. Fulfilling this goal requires both that the explanations generated by these methods are correct and that people can easily and reliably understand them. While the former has been addressed in prior work, the latter is often overlooked, resulting in informal model understanding derived from a handful of local explanations. In this paper, we Cites: Polyjuice: Generating Counterfactuals for Explaining, Evaluating</summary></entry><entry><title type="html">CUP: Curriculum Learning based Prompt Tuning for Implicit Event Argument Extraction</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9a6447e011481dcb71996b89ef3cff81.html" rel="alternate" type="text/html" title="CUP: Curriculum Learning based Prompt Tuning for Implicit Event Argument Extraction" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9a6447e011481dcb71996b89ef3cff81</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9a6447e011481dcb71996b89ef3cff81.html">&lt;p&gt;Implicit event argument extraction (EAE) aims to identify arguments that could scatter over the document. Most previous work focuses on learning the direct relations between arguments and the given trigger, while the implicit relations with long-range dependency are not well studied. Moreover, recent neural network based approaches rely on a large amount of labeled data for training, which is unavailable due to the high labelling cost. In this paper, we propose a Curriculum learning based Cites: Higher-order Coreference Resolution with Coarse-to-fine Inference&lt;/p&gt;</content><author><name>J Lin, Q Chen, J Zhou, J Jin, L He - arXiv preprint arXiv:2205.00498, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Implicit event argument extraction (EAE) aims to identify arguments that could scatter over the document. Most previous work focuses on learning the direct relations between arguments and the given trigger, while the implicit relations with long-range dependency are not well studied. Moreover, recent neural network based approaches rely on a large amount of labeled data for training, which is unavailable due to the high labelling cost. In this paper, we propose a Curriculum learning based Cites: Higher-order Coreference Resolution with Coarse-to-fine Inference</summary></entry><entry><title type="html">Debiased Contrastive Learning of Unsupervised Sentence Representations</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9b46b3313070480017f4969adbd4a6d1.html" rel="alternate" type="text/html" title="Debiased Contrastive Learning of Unsupervised Sentence Representations" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9b46b3313070480017f4969adbd4a6d1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9b46b3313070480017f4969adbd4a6d1.html">&lt;p&gt;Recently, contrastive learning has been shown to be effective in improving pre- trained language models (PLM) to derive high-quality sentence representations. It aims to pull close positive examples to enhance the alignment while push apart irrelevant negatives for the uniformity of the whole representation space. However, previous works mostly adopt in-batch negatives or sample from training data at random. Such a way may cause the sampling bias that improper negatives (eg false Cites: Whiteningbert: An easy unsupervised sentence embedding&lt;/p&gt;</content><author><name>K Zhou, B Zhang, WX Zhao, JR Wen - arXiv preprint arXiv:2205.00656, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recently, contrastive learning has been shown to be effective in improving pre- trained language models (PLM) to derive high-quality sentence representations. It aims to pull close positive examples to enhance the alignment while push apart irrelevant negatives for the uniformity of the whole representation space. However, previous works mostly adopt in-batch negatives or sample from training data at random. Such a way may cause the sampling bias that improper negatives (eg false Cites: Whiteningbert: An easy unsupervised sentence embedding</summary></entry><entry><title type="html">Quantum Robustness Verification: A Hybrid Quantum-Classical Neural Network Certification Algorithm</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9ca120a382fd1e7e1ff80b4c17df9904.html" rel="alternate" type="text/html" title="Quantum Robustness Verification: A Hybrid Quantum-Classical Neural Network Certification Algorithm" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9ca120a382fd1e7e1ff80b4c17df9904</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9ca120a382fd1e7e1ff80b4c17df9904.html">&lt;p&gt;In recent years, quantum computers and algorithms have made significant progress indicating the prospective importance of quantum computing (QC). Especially combinatorial optimization has gained a lot of attention as an application field for near-term quantum computers, both by using gate-based QC via the Quantum Approximate Optimization Algorithm and by quantum annealing using the Ising model. However, demonstrating an advantage over classical methods in real-world Cites: Enabling certification of verification-agnostic networks via memory&lt;/p&gt;</content><author><name>N Franco, T Wollschlaeger, N Gao, JM Lorenz - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In recent years, quantum computers and algorithms have made significant progress indicating the prospective importance of quantum computing (QC). Especially combinatorial optimization has gained a lot of attention as an application field for near-term quantum computers, both by using gate-based QC via the Quantum Approximate Optimization Algorithm and by quantum annealing using the Ising model. However, demonstrating an advantage over classical methods in real-world Cites: Enabling certification of verification-agnostic networks via memory</summary></entry><entry><title type="html">Neurocompositional computing: From the Central Paradox of Cognition to a new generation of AI systems</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9d492f3cfdcc9d67c83e3e4c2827b68c.html" rel="alternate" type="text/html" title="Neurocompositional computing: From the Central Paradox of Cognition to a new generation of AI systems" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9d492f3cfdcc9d67c83e3e4c2827b68c</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9d492f3cfdcc9d67c83e3e4c2827b68c.html">&lt;p&gt;What explains the dramatic progress from 20th-century to 21st-century AI, and how can the remaining limitations of current AI be overcome? The widely accepted narrative attributes this progress to massive increases in the quantity of computational and data resources available to support statistical learning in deep artificial neural networks. We show that an additional crucial factor is the development of a new type of computation. Neurocompositional computing adopts Cites: Rat-sql: Relation-aware schema encoding and linking for text-to&lt;/p&gt;</content><author><name>P Smolensky, RT McCoy, R Fernandez, M Goldrick - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">What explains the dramatic progress from 20th-century to 21st-century AI, and how can the remaining limitations of current AI be overcome? The widely accepted narrative attributes this progress to massive increases in the quantity of computational and data resources available to support statistical learning in deep artificial neural networks. We show that an additional crucial factor is the development of a new type of computation. Neurocompositional computing adopts Cites: Rat-sql: Relation-aware schema encoding and linking for text-to</summary></entry><entry><title type="html">Large-Scale Multi-Document Summarization with Information Extraction and Compression</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9f000996983f6fd3e0dd6f2179dddc43.html" rel="alternate" type="text/html" title="Large-Scale Multi-Document Summarization with Information Extraction and Compression" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9f000996983f6fd3e0dd6f2179dddc43</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/9f000996983f6fd3e0dd6f2179dddc43.html">&lt;p&gt;We develop an abstractive summarization framework independent of labeled data for multiple heterogeneous documents. Unlike existing multi-document summarization methods, our framework processes documents telling different stories instead of documents on the same topic. We also enhance an existing sentence fusion method with a uni-directional language model to prioritize fused sentences with higher sentence probability with the goal of increasing readability. Lastly, we construct a Cites: Sentence centrality revisited for unsupervised summarization&lt;/p&gt;</content><author><name>N Wang, H Liu, D Klabjan - arXiv preprint arXiv:2205.00548, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We develop an abstractive summarization framework independent of labeled data for multiple heterogeneous documents. Unlike existing multi-document summarization methods, our framework processes documents telling different stories instead of documents on the same topic. We also enhance an existing sentence fusion method with a uni-directional language model to prioritize fused sentences with higher sentence probability with the goal of increasing readability. Lastly, we construct a Cites: Sentence centrality revisited for unsupervised summarization</summary></entry><entry><title type="html">ELQA: A Corpus of Questions and Answers about the English Language</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/a08f3434333e2aa24c14bae869f314d7.html" rel="alternate" type="text/html" title="ELQA: A Corpus of Questions and Answers about the English Language" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/a08f3434333e2aa24c14bae869f314d7</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/a08f3434333e2aa24c14bae869f314d7.html">&lt;p&gt;We introduce a community-sourced dataset for English Language Question Answering (ELQA), which consists of more than 180k questions and answers on numerous topics about English language such as grammar, meaning, fluency, and etymology. The ELQA corpus will enable new NLP applications for language learners. We introduce three tasks based on the ELQA corpus: 1) answer quality classification, 2) semantic search for finding similar questions, and 3) answer Cites: Bidimensional Leaderboards: Generate and Evaluate Language&lt;/p&gt;</content><author><name>S Behzad, K Sakaguchi, N Schneider, A Zeldes - arXiv preprint arXiv:2205.00395, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We introduce a community-sourced dataset for English Language Question Answering (ELQA), which consists of more than 180k questions and answers on numerous topics about English language such as grammar, meaning, fluency, and etymology. The ELQA corpus will enable new NLP applications for language learners. We introduce three tasks based on the ELQA corpus: 1) answer quality classification, 2) semantic search for finding similar questions, and 3) answer Cites: Bidimensional Leaderboards: Generate and Evaluate Language</summary></entry><entry><title type="html">Retrieval-Enhanced Machine Learning</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/a149bc2229439a8c85682c17725e0b85.html" rel="alternate" type="text/html" title="Retrieval-Enhanced Machine Learning" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/a149bc2229439a8c85682c17725e0b85</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/a149bc2229439a8c85682c17725e0b85.html">&lt;p&gt;Although information access systems have long supported people in accomplishing a wide range of tasks, we propose broadening the scope of users of information access systems to include task-driven machines, such as machine learning models. In this way, the core principles of indexing, representation, retrieval, and ranking can be applied and extended to substantially improve model generalization, scalability, robustness, and interpretability. We describe a generic retrieval-enhanced machine Cites: Retrieval augmented language model pre-training&lt;/p&gt;</content><author><name>H Zamani, F Diaz, M Dehghani, D Metzler - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Although information access systems have long supported people in accomplishing a wide range of tasks, we propose broadening the scope of users of information access systems to include task-driven machines, such as machine learning models. In this way, the core principles of indexing, representation, retrieval, and ranking can be applied and extended to substantially improve model generalization, scalability, robustness, and interpretability. We describe a generic retrieval-enhanced machine Cites: Retrieval augmented language model pre-training</summary></entry><entry><title type="html">Supporting Complex Information-Seeking Tasks with Implicit Constraints</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/aa8c72a8d8a91a792ad655cdf76f8f0f.html" rel="alternate" type="text/html" title="Supporting Complex Information-Seeking Tasks with Implicit Constraints" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/aa8c72a8d8a91a792ad655cdf76f8f0f</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/aa8c72a8d8a91a792ad655cdf76f8f0f.html">&lt;p&gt;Current interactive systems with natural language interface lack an ability to understand a complex information-seeking request which expresses several implicit constraints at once, and there is no prior information about user preferences, eg,  find hiking trails around San Francisco which are accessible with toddlers and have beautiful scenery in summer , where output is a list of possible suggestions for users to start their exploration. In such scenarios, the user requests can be issued at once Cites: Natural questions: a benchmark for question answering research&lt;/p&gt;</content><author><name>A Ahmadvand, N Arabzadeh, J Kiseleva, PF Sanz - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Current interactive systems with natural language interface lack an ability to understand a complex information-seeking request which expresses several implicit constraints at once, and there is no prior information about user preferences, eg, find hiking trails around San Francisco which are accessible with toddlers and have beautiful scenery in summer , where output is a list of possible suggestions for users to start their exploration. In such scenarios, the user requests can be issued at once Cites: Natural questions: a benchmark for question answering research</summary></entry><entry><title type="html">End-to-end Spoken Conversational Question Answering: Task, Dataset and Model</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/af535b17cd3f323ab78a55b16c9bec47.html" rel="alternate" type="text/html" title="End-to-end Spoken Conversational Question Answering: Task, Dataset and Model" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/af535b17cd3f323ab78a55b16c9bec47</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/af535b17cd3f323ab78a55b16c9bec47.html">&lt;p&gt;In spoken question answering, the systems are designed to answer questions from contiguous text spans within the related speech transcripts. However, the most natural way that human seek or test their knowledge is via human conversations. Therefore, we propose a new Spoken Conversational Question Answering task (SCQA), aiming at enabling the systems to model complex dialogue flows given the speech documents. In this task, our main objective is to build the system to deal with Cites: Coqa: A conversational question answering challenge&lt;/p&gt;</content><author><name>C You, N Chen, F Liu, S Ge, X Wu, Y Zou - arXiv preprint arXiv:2204.14272, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In spoken question answering, the systems are designed to answer questions from contiguous text spans within the related speech transcripts. However, the most natural way that human seek or test their knowledge is via human conversations. Therefore, we propose a new Spoken Conversational Question Answering task (SCQA), aiming at enabling the systems to model complex dialogue flows given the speech documents. In this task, our main objective is to build the system to deal with Cites: Coqa: A conversational question answering challenge</summary></entry><entry><title type="html">High-dimensional Asymptotics of Feature Learning: How One Gradient Step Improves the Representation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/ba4e92caf69f46b8dc4238b885e44c7b.html" rel="alternate" type="text/html" title="High-dimensional Asymptotics of Feature Learning: How One Gradient Step Improves the Representation" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/ba4e92caf69f46b8dc4238b885e44c7b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/ba4e92caf69f46b8dc4238b885e44c7b.html">&lt;p&gt;We study the first gradient descent step on the first-layer parameters $ boldsymbol {W} $ in a two-layer neural network: $ f ( boldsymbol {x})= frac {1}{ sqrt {N}} boldsymbol {a}^ top sigma ( boldsymbol {W}^ top boldsymbol {x}) $, where $ boldsymbol {W} in mathbb {R}^{d times N}, boldsymbol {a} in mathbb {R}^{N} $ are randomly initialized, and the training objective is the empirical MSE loss: $ frac {1}{n} sum_ {i= 1}^ n (f ( boldsymbol {x} _i)-y_i)^ 2$. In the proportional asymptotic Cites: The break-even point on optimization trajectories of deep neural&lt;/p&gt;</content><author><name>J Ba, MA Erdogdu, T Suzuki, Z Wang, D Wu, G Yang - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">We study the first gradient descent step on the first-layer parameters $ boldsymbol {W} $ in a two-layer neural network: $ f ( boldsymbol {x})= frac {1}{ sqrt {N}} boldsymbol {a}^ top sigma ( boldsymbol {W}^ top boldsymbol {x}) $, where $ boldsymbol {W} in mathbb {R}^{d times N}, boldsymbol {a} in mathbb {R}^{N} $ are randomly initialized, and the training objective is the empirical MSE loss: $ frac {1}{n} sum_ {i= 1}^ n (f ( boldsymbol {x} _i)-y_i)^ 2$. In the proportional asymptotic Cites: The break-even point on optimization trajectories of deep neural</summary></entry><entry><title type="html">The Implicit Length Bias of Label Smoothing on Beam Search Decoding</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/c490c76eafd91788775a9f42fa710eeb.html" rel="alternate" type="text/html" title="The Implicit Length Bias of Label Smoothing on Beam Search Decoding" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/c490c76eafd91788775a9f42fa710eeb</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/c490c76eafd91788775a9f42fa710eeb.html">&lt;p&gt;Label smoothing is ubiquitously applied in Neural Machine Translation (NMT) training. While label smoothing offers a desired regularization effect during model training, in this paper we demonstrate that it nevertheless introduces length biases in the beam search decoding procedure. Our analysis shows that label smoothing implicitly applies a length penalty term to output sequence, causing a bias towards shorter translations. We also show that for a model fully optimized with label Cites: Characterizing and addressing the issue of oversmoothing in&lt;/p&gt;</content><author><name>B Liang, P Wang, Y Cao - arXiv preprint arXiv:2205.00659, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Label smoothing is ubiquitously applied in Neural Machine Translation (NMT) training. While label smoothing offers a desired regularization effect during model training, in this paper we demonstrate that it nevertheless introduces length biases in the beam search decoding procedure. Our analysis shows that label smoothing implicitly applies a length penalty term to output sequence, causing a bias towards shorter translations. We also show that for a model fully optimized with label Cites: Characterizing and addressing the issue of oversmoothing in</summary></entry><entry><title type="html">Sibylvariant Transformations for Robust Text Classification</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/c53deafe43a7c7c458cbcd4441d5cbc5.html" rel="alternate" type="text/html" title="Sibylvariant Transformations for Robust Text Classification" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/c53deafe43a7c7c458cbcd4441d5cbc5</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/c53deafe43a7c7c458cbcd4441d5cbc5.html">&lt;p&gt;The vast majority of text transformation techniques in NLP are inherently limited in their ability to expand input space coverage due to an implicit constraint to preserve the original class label. In this work, we propose the notion of sibylvariance (SIB) to describe the broader set of transforms that relax the labelpreserving constraint, knowably vary the expected class, and lead to significantly more diverse input distributions. We offer a unified framework to organize all data transformations Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList&lt;/p&gt;</content><author><name>F Harel-Canada, MA Gulzar, N Peng, M Kim</name></author><category term="jekyll" /><category term="update" /><summary type="html">The vast majority of text transformation techniques in NLP are inherently limited in their ability to expand input space coverage due to an implicit constraint to preserve the original class label. In this work, we propose the notion of sibylvariance (SIB) to describe the broader set of transforms that relax the labelpreserving constraint, knowably vary the expected class, and lead to significantly more diverse input distributions. We offer a unified framework to organize all data transformations Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList</summary></entry><entry><title type="html">HatCUP: Hybrid Analysis and Attention based Just-In-Time Comment Updating</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/c7a4b93f6eddb8450993e4d53354c278.html" rel="alternate" type="text/html" title="HatCUP: Hybrid Analysis and Attention based Just-In-Time Comment Updating" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/c7a4b93f6eddb8450993e4d53354c278</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/c7a4b93f6eddb8450993e4d53354c278.html">&lt;p&gt;When changing code, developers sometimes neglect updating the related comments, bringing inconsistent or outdated comments. These comments increase the cost of program understanding and greatly reduce software maintainability. Researchers have put forward some solutions, such as CUP and HEBCUP, which update comments efficiently for simple code changes (ie modifying of a single token), but not good enough for complex ones. In this paper, we propose an approach Cites: Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang, and Ming&lt;/p&gt;</content><author><name>H Zhu, X He, L Xu - arXiv preprint arXiv:2205.00600, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">When changing code, developers sometimes neglect updating the related comments, bringing inconsistent or outdated comments. These comments increase the cost of program understanding and greatly reduce software maintainability. Researchers have put forward some solutions, such as CUP and HEBCUP, which update comments efficiently for simple code changes (ie modifying of a single token), but not good enough for complex ones. In this paper, we propose an approach Cites: Dawn Drain, Neel Sundaresan, Jian Yin, Daxin Jiang, and Ming</summary></entry><entry><title type="html">OPERA: Operation-Pivoted Discrete Reasoning over Text</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/ceb0575cd224e1ad0926f05d6a1e3557.html" rel="alternate" type="text/html" title="OPERA: Operation-Pivoted Discrete Reasoning over Text" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/ceb0575cd224e1ad0926f05d6a1e3557</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/ceb0575cd224e1ad0926f05d6a1e3557.html">&lt;p&gt;Machine reading comprehension (MRC) that requires discrete reasoning involving symbolic operations, eg, addition, sorting, and counting, is a challenging task. According to this nature, semantic parsing-based methods predict interpretable but complex logical forms. However, logical form generation is nontrivial and even a little perturbation in a logical form will lead to wrong answers. To alleviate this issue, multi- predictor-based methods are proposed to directly predict different types of answers Cites: Giving BERT a Calculator: Finding Operations and Arguments with&lt;/p&gt;</content><author><name>Y Zhou, J Bao, C Duan, H Sun, J Liang, Y Wang - arXiv preprint arXiv , 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Machine reading comprehension (MRC) that requires discrete reasoning involving symbolic operations, eg, addition, sorting, and counting, is a challenging task. According to this nature, semantic parsing-based methods predict interpretable but complex logical forms. However, logical form generation is nontrivial and even a little perturbation in a logical form will lead to wrong answers. To alleviate this issue, multi- predictor-based methods are proposed to directly predict different types of answers Cites: Giving BERT a Calculator: Finding Operations and Arguments with</summary></entry><entry><title type="html">Trustworthy AI and robotics: Implications for the AEC industry</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/d02c51f5b4eec6582197f9dbde6498b0.html" rel="alternate" type="text/html" title="Trustworthy AI and robotics: Implications for the AEC industry" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/d02c51f5b4eec6582197f9dbde6498b0</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/d02c51f5b4eec6582197f9dbde6498b0.html">&lt;p&gt;Human-technology interaction is concerned with trust as an inevitable user acceptance requirement. As the applications of artificial intelligence (AI) and robotics emerge in the architecture, engineering, and construction (AEC) industry, there is an immediate need to study trust in such systems. This paper presents the results of a systematic review of the literature published in the last two decades on (1) trust in AI and AI-powered robotics and (2) AI and robotics applications in the AEC industry Cites:   Why Should I Trust You? : Explaining the Predictions of Any&lt;/p&gt;</content><author><name>N Emaminejad, R Akhavian - Automation in Construction, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Human-technology interaction is concerned with trust as an inevitable user acceptance requirement. As the applications of artificial intelligence (AI) and robotics emerge in the architecture, engineering, and construction (AEC) industry, there is an immediate need to study trust in such systems. This paper presents the results of a systematic review of the literature published in the last two decades on (1) trust in AI and AI-powered robotics and (2) AI and robotics applications in the AEC industry Cites: Why Should I Trust You? : Explaining the Predictions of Any</summary></entry><entry><title type="html">Learn To Remember: Transformer with Recurrent Memory for Document-Level Machine Translation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/d58f7cb480437886b25b50bfc691dfea.html" rel="alternate" type="text/html" title="Learn To Remember: Transformer with Recurrent Memory for Document-Level Machine Translation" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/d58f7cb480437886b25b50bfc691dfea</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/d58f7cb480437886b25b50bfc691dfea.html">&lt;p&gt;The Transformer architecture has led to significant gains in machine translation. However, most studies focus on only sentence-level translation without considering the context dependency within documents, leading to the inadequacy of document- level coherence. Some recent research tried to mitigate this issue by introducing an additional context encoder or translating with multiple sentences or even the entire document. Such methods may lose the information on the target side or have an Cites: Blockwise Self-Attention for Long Document Understanding&lt;/p&gt;</content><author><name>Y Feng, F Li, Z Song, B Zheng, P Koehn - arXiv preprint arXiv:2205.01546, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">The Transformer architecture has led to significant gains in machine translation. However, most studies focus on only sentence-level translation without considering the context dependency within documents, leading to the inadequacy of document- level coherence. Some recent research tried to mitigate this issue by introducing an additional context encoder or translating with multiple sentences or even the entire document. Such methods may lose the information on the target side or have an Cites: Blockwise Self-Attention for Long Document Understanding</summary></entry><entry><title type="html">Graph-level Semantic Matching model for Knowledge base Aggregate Question Answering</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/d70e2586e874c19c1eb94a2cf10f97b1.html" rel="alternate" type="text/html" title="Graph-level Semantic Matching model for Knowledge base Aggregate Question Answering" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/d70e2586e874c19c1eb94a2cf10f97b1</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/d70e2586e874c19c1eb94a2cf10f97b1.html">&lt;p&gt;In knowledge base question answering, complex question always has long-distance dependencies, especially aggregate question, which affects query graph matching. Many previous approaches have made conspicuous progress in complex question answering. However, they mostly only compare based on the textual similarity of the predicate sequences, ignoring the degree of semantic information either questions or query graphs. In this paper, we propose a Graph-level Semantic Matching (GSM) Cites: Semantic Parsing via Staged Query Graph Generation: Question&lt;/p&gt;</content><author><name>Y Liu, S Wu, J Zhang, L Han, X Zhang, Y Yu, Z Feng - 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In knowledge base question answering, complex question always has long-distance dependencies, especially aggregate question, which affects query graph matching. Many previous approaches have made conspicuous progress in complex question answering. However, they mostly only compare based on the textual similarity of the predicate sequences, ignoring the degree of semantic information either questions or query graphs. In this paper, we propose a Graph-level Semantic Matching (GSM) Cites: Semantic Parsing via Staged Query Graph Generation: Question</summary></entry><entry><title type="html">Doubting AI Predictions: Influence-Driven Second Opinion Recommendation</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/dd9933f0f0f53d77c6531c9cebe5c02e.html" rel="alternate" type="text/html" title="Doubting AI Predictions: Influence-Driven Second Opinion Recommendation" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/dd9933f0f0f53d77c6531c9cebe5c02e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/dd9933f0f0f53d77c6531c9cebe5c02e.html">&lt;p&gt;Effective human-AI collaboration requires a system design that provides humans with meaningful ways to make sense of and critically evaluate algorithmic recommendations. In this paper, we propose a way to augment human-AI collaboration by building on a common organizational practice: identifying experts who are likely to provide complementary opinions. When machine learning algorithms are trained to predict human-generated assessments, experts  rich Cites: Does the Whole Exceed its Parts? The Effect of AI Explanations on&lt;/p&gt;</content><author><name>M De-Arteaga, A Chouldechova, A Dubrawski - arXiv preprint arXiv:2205.00072, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Effective human-AI collaboration requires a system design that provides humans with meaningful ways to make sense of and critically evaluate algorithmic recommendations. In this paper, we propose a way to augment human-AI collaboration by building on a common organizational practice: identifying experts who are likely to provide complementary opinions. When machine learning algorithms are trained to predict human-generated assessments, experts rich Cites: Does the Whole Exceed its Parts? The Effect of AI Explanations on</summary></entry><entry><title type="html">Towards Process-Oriented, Modular, and Versatile Question Generation that Meets Educational Needs</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/dddac9590c58a942a38f851ddaf0b42b.html" rel="alternate" type="text/html" title="Towards Process-Oriented, Modular, and Versatile Question Generation that Meets Educational Needs" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/dddac9590c58a942a38f851ddaf0b42b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/dddac9590c58a942a38f851ddaf0b42b.html">&lt;p&gt;NLP-powered automatic question generation (QG) techniques carry great pedagogical potential of saving educators  time and benefiting student learning. Yet, QG systems have not been widely adopted in classrooms to date. In this work, we aim to pinpoint key impediments and investigate how to improve the usability of automatic QG techniques for educational purposes by understanding how instructors construct questions and identifying touch points to enhance the underlying NLP Cites: AI Chains: Transparent and Controllable Human-AI Interaction by&lt;/p&gt;</content><author><name>X Wang, S Fan, J Houghton, L Wang - arXiv preprint arXiv:2205.00355, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">NLP-powered automatic question generation (QG) techniques carry great pedagogical potential of saving educators time and benefiting student learning. Yet, QG systems have not been widely adopted in classrooms to date. In this work, we aim to pinpoint key impediments and investigate how to improve the usability of automatic QG techniques for educational purposes by understanding how instructors construct questions and identifying touch points to enhance the underlying NLP Cites: AI Chains: Transparent and Controllable Human-AI Interaction by</summary></entry><entry><title type="html">Adapting and Evaluating Influence-Estimation Methods for Gradient-Boosted Decision Trees</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/e508bdf706b725b2ab3ce8e61f2fbe60.html" rel="alternate" type="text/html" title="Adapting and Evaluating Influence-Estimation Methods for Gradient-Boosted Decision Trees" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/e508bdf706b725b2ab3ce8e61f2fbe60</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/e508bdf706b725b2ab3ce8e61f2fbe60.html">&lt;p&gt;Influence estimation analyzes how changes to the training data can lead to different model predictions; this analysis can help us better understand these predictions, the models making those predictions, and the data sets they re trained on. However, most influence-estimation techniques are designed for deep learning models with continuous parameters. Gradient-boosted decision trees (GBDTs) are a powerful and widely-used class of models; however, these models are black boxes with opaque Cites: Dataset cartography: Mapping and diagnosing datasets with&lt;/p&gt;</content><author><name>J Brophy, Z Hammoudeh, D Lowd - arXiv preprint arXiv:2205.00359, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Influence estimation analyzes how changes to the training data can lead to different model predictions; this analysis can help us better understand these predictions, the models making those predictions, and the data sets they re trained on. However, most influence-estimation techniques are designed for deep learning models with continuous parameters. Gradient-boosted decision trees (GBDTs) are a powerful and widely-used class of models; however, these models are black boxes with opaque Cites: Dataset cartography: Mapping and diagnosing datasets with</summary></entry><entry><title type="html">Domain Adaptation meets Individual Fairness. And they get along</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/e7e76d1acc2ae8df7288b28f7ad57c17.html" rel="alternate" type="text/html" title="Domain Adaptation meets Individual Fairness. And they get along" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/e7e76d1acc2ae8df7288b28f7ad57c17</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/e7e76d1acc2ae8df7288b28f7ad57c17.html">&lt;p&gt;Many instances of algorithmic bias are caused by distributional shifts. For example, machine learning (ML) models often perform worse on demographic groups that are underrepresented in the training data. In this paper, we leverage this connection between algorithmic fairness and distribution shifts to show that algorithmic fairness interventions can help ML models overcome distribution shifts, and that domain adaptation methods (for overcoming distribution shifts) can mitigate algorithmic Cites: Wilds: A benchmark of in-the-wild distribution shifts&lt;/p&gt;</content><author><name>D Mukherjee, F Petersen, M Yurochkin, Y Sun - arXiv preprint arXiv:2205.00504, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Many instances of algorithmic bias are caused by distributional shifts. For example, machine learning (ML) models often perform worse on demographic groups that are underrepresented in the training data. In this paper, we leverage this connection between algorithmic fairness and distribution shifts to show that algorithmic fairness interventions can help ML models overcome distribution shifts, and that domain adaptation methods (for overcoming distribution shifts) can mitigate algorithmic Cites: Wilds: A benchmark of in-the-wild distribution shifts</summary></entry><entry><title type="html">Annotating Column Type Utilizing BERT and Knowledge Graph Over Wikipedia Categories and Lists</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f149f3f3713bdefb766edb0a399f73ab.html" rel="alternate" type="text/html" title="Annotating Column Type Utilizing BERT and Knowledge Graph Over Wikipedia Categories and Lists" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f149f3f3713bdefb766edb0a399f73ab</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f149f3f3713bdefb766edb0a399f73ab.html">&lt;p&gt;Automatically annotating semantic type of table column task plays a vital role in the process of information retrieval and NLP tasks. In this paper, given an entity column of a table without a header, we study the problem of predicting its column type using both finetuning on pre-trained BERT model and knowledge graph lookup, integrating the two methods to complement each other s shortcomings. A data augmentation method utilizing similar entities in Wikipedia categories and lists is proposed to fine Cites: Turl: Table understanding through representation learning&lt;/p&gt;</content><author><name>J QIN, M IWAIHARA</name></author><category term="jekyll" /><category term="update" /><summary type="html">Automatically annotating semantic type of table column task plays a vital role in the process of information retrieval and NLP tasks. In this paper, given an entity column of a table without a header, we study the problem of predicting its column type using both finetuning on pre-trained BERT model and knowledge graph lookup, integrating the two methods to complement each other s shortcomings. A data augmentation method utilizing similar entities in Wikipedia categories and lists is proposed to fine Cites: Turl: Table understanding through representation learning</summary></entry><entry><title type="html">Meta Learning for Natural Language Processing: A Survey</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f348f947261d65133e01739ff480e15b.html" rel="alternate" type="text/html" title="Meta Learning for Natural Language Processing: A Survey" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f348f947261d65133e01739ff480e15b</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f348f947261d65133e01739ff480e15b.html">&lt;p&gt;Deep learning has been the mainstream technique in natural language processing (NLP) area. However, the techniques require many labeled data and are less generalizable across domains. Meta-learning is an arising field in machine learning studying approaches to learn better learning algorithms. Approaches aim at improving algorithms in various aspects, including data efficiency and generalizability. Efficacy of approaches has been shown in many NLP tasks, but Cites: Coupling retrieval and meta-learning for context-dependent&lt;/p&gt;</content><author><name>H Lee, SW Li, NT Vu - arXiv preprint arXiv:2205.01500, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Deep learning has been the mainstream technique in natural language processing (NLP) area. However, the techniques require many labeled data and are less generalizable across domains. Meta-learning is an arising field in machine learning studying approaches to learn better learning algorithms. Approaches aim at improving algorithms in various aspects, including data efficiency and generalizability. Efficacy of approaches has been shown in many NLP tasks, but Cites: Coupling retrieval and meta-learning for context-dependent</summary></entry><entry><title type="html">SemAttack: Natural Textual Attacks via Different Semantic Spaces</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f47636c1a0ec86eb8f07c65a1e478a5e.html" rel="alternate" type="text/html" title="SemAttack: Natural Textual Attacks via Different Semantic Spaces" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f47636c1a0ec86eb8f07c65a1e478a5e</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f47636c1a0ec86eb8f07c65a1e478a5e.html">&lt;p&gt;Recent studies show that pre-trained language models (LMs) are vulnerable to textual adversarial attacks. However, existing attack methods either suffer from low attack success rates or fail to search efficiently in the exponentially large perturbation space. We propose an efficient and effective framework SemAttack to generate natural adversarial text by constructing different semantic perturbation functions. In particular, SemAttack optimizes the generated perturbations constrained on generic Cites: A structural probe for finding syntax in word representations&lt;/p&gt;</content><author><name>B Wang, C Xu, X Liu, Y Cheng, B Li - arXiv preprint arXiv:2205.01287, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Recent studies show that pre-trained language models (LMs) are vulnerable to textual adversarial attacks. However, existing attack methods either suffer from low attack success rates or fail to search efficiently in the exponentially large perturbation space. We propose an efficient and effective framework SemAttack to generate natural adversarial text by constructing different semantic perturbation functions. In particular, SemAttack optimizes the generated perturbations constrained on generic Cites: A structural probe for finding syntax in word representations</summary></entry><entry><title type="html">A Theory of Natural Intelligence</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f47dc443642c11c7e52a48e655dabeea.html" rel="alternate" type="text/html" title="A Theory of Natural Intelligence" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f47dc443642c11c7e52a48e655dabeea</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f47dc443642c11c7e52a48e655dabeea.html">&lt;p&gt;Introduction: In contrast to current AI technology, natural intelligence–the kind of autonomous intelligence that is realized in the brains of animals and humans to attain in their natural environment goals defined by a repertoire of innate behavioral schemata–is far superior in terms of learning speed, generalization capabilities, autonomy and creativity. How are these strengths, by what means are ideas and imagination produced in natural neural networks? Methods: Reviewing the literature Cites: Piglet: Language grounding through neuro-symbolic interaction in&lt;/p&gt;</content><author><name>C von der Malsburg, T Stadelmann, BF Grewe - arXiv preprint arXiv:2205.00002, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Introduction: In contrast to current AI technology, natural intelligence–the kind of autonomous intelligence that is realized in the brains of animals and humans to attain in their natural environment goals defined by a repertoire of innate behavioral schemata–is far superior in terms of learning speed, generalization capabilities, autonomy and creativity. How are these strengths, by what means are ideas and imagination produced in natural neural networks? Methods: Reviewing the literature Cites: Piglet: Language grounding through neuro-symbolic interaction in</summary></entry><entry><title type="html">A Survey of Deep Learning Models for Structural Code Understanding</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f6ccc7d3af260af4c779e32a3ac81fcc.html" rel="alternate" type="text/html" title="A Survey of Deep Learning Models for Structural Code Understanding" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f6ccc7d3af260af4c779e32a3ac81fcc</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f6ccc7d3af260af4c779e32a3ac81fcc.html">&lt;p&gt;In recent years, the rise of deep learning and automation requirements in the software industry has elevated Intelligent Software Engineering to new heights. The number of approaches and applications in code understanding is growing, with deep learning techniques being used in many of them to better capture the information in code data. In this survey, we present a comprehensive overview of the structures formed from code data. We categorize the models for understanding code in recent Cites: Dawn Drain&lt;/p&gt;</content><author><name>R Wu, Y Zhang, Q Peng, L Chen, Z Zheng - arXiv preprint arXiv:2205.01293, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">In recent years, the rise of deep learning and automation requirements in the software industry has elevated Intelligent Software Engineering to new heights. The number of approaches and applications in code understanding is growing, with deep learning techniques being used in many of them to better capture the information in code data. In this survey, we present a comprehensive overview of the structures formed from code data. We categorize the models for understanding code in recent Cites: Dawn Drain</summary></entry><entry><title type="html">AdapterBias: Parameter-efficient Token-dependent Representation Shift for Adapters in NLP Tasks</title><link href="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f80b30c790adccc635e37d101bfd22e6.html" rel="alternate" type="text/html" title="AdapterBias: Parameter-efficient Token-dependent Representation Shift for Adapters in NLP Tasks" /><published>2022-05-07T02:52:45-04:00</published><updated>2022-05-07T02:52:45-04:00</updated><id>https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f80b30c790adccc635e37d101bfd22e6</id><content type="html" xml:base="https://xiang-deng.github.io/docs/jekyll/update/2022/05/07/f80b30c790adccc635e37d101bfd22e6.html">&lt;p&gt;Transformer-based pre-trained models with millions of parameters require large storage. Recent approaches tackle this shortcoming by training adapters, but these approaches still require a relatively large number of parameters. In this study, AdapterBias, a surprisingly simple yet effective adapter architecture, is proposed. AdapterBias adds a token-dependent shift to the hidden output of transformer layers to adapt to downstream tasks with only a vector and a linear layer. Extensive Cites: AdapterFusion: Non-destructive task composition for transfer learning&lt;/p&gt;</content><author><name>CL Fu, ZC Chen, YR Lee, H Lee - arXiv preprint arXiv:2205.00305, 2022</name></author><category term="jekyll" /><category term="update" /><summary type="html">Transformer-based pre-trained models with millions of parameters require large storage. Recent approaches tackle this shortcoming by training adapters, but these approaches still require a relatively large number of parameters. In this study, AdapterBias, a surprisingly simple yet effective adapter architecture, is proposed. AdapterBias adds a token-dependent shift to the hidden output of transformer layers to adapt to downstream tasks with only a vector and a linear layer. Extensive Cites: AdapterFusion: Non-destructive task composition for transfer learning</summary></entry></feed>