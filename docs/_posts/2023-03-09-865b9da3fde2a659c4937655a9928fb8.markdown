--- 
layout: post 
title: "Study of Distractors in Neural Models of Code" 
date: 2023-03-09 05:52:34 -0400 
categories: jekyll update 
author: "MRI Rabin, A Hussain, S Suneja, MA Alipour - arXiv preprint arXiv:2303.01739, 2023" 
--- 
Finding important features that contribute to the prediction of neural models is an active area of research in explainable AI. Neural models are opaque and finding such features sheds light on a better understanding of their predictions. In contrast, in this work, we present an inverse perspective of distractor features: features that cast doubt about the prediction by affecting the model s confidence in its prediction. Understanding distractors provide a complementary view of the features relevance Cites: Codexglue: A machine learning benchmark dataset for code