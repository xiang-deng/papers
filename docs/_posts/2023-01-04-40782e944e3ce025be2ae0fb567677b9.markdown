---
layout: post
title:  "Benchmark tasks for evaluation of language models"
date:   2023-01-04 14:44:31 -0400
categories: jekyll update
author: "S Hamotskyi"
---
Language models (LMs) are an integral part of NLP, with their importance sharply increasing in recent years with the advent of large generalized LMs (such as OpenAI GPT and BERT) that reach and in some cases surpass the level of nonexpert humans. A wide array of methods for LM evaluation exist, reflecting different tasks, model types. This paper explores different LM evaluation strategies, from probability-based ones (with a focus on perplexity) to complex multi-task benchmarks that …
Cites: ‪Language models as knowledge bases?‬