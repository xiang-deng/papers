--- 
layout: post 
title: "XDoc: Unified Pre-training for Cross-Format Document Understanding" 
date: 2022-10-10 14:05:52 -0400 
categories: jekyll update 
author: "J Chen, T Lv, L Cui, C Zhang, F Wei - arXiv preprint arXiv:2210.02849, 2022" 
--- 
The surge of pre-training has witnessed the rapid development of document understanding recently. Pre-training and fine-tuning framework has been effectively used to tackle texts in various formats, including plain texts, document texts, and web texts. Despite achieving promising performance, existing pre-trained models usually target one specific document format at one time, making it difficult to combine knowledge from multiple document formats. To address this, we propose XDoc, a  Cites: SpanBERT: Improving Pre-training by Representing and Predicting