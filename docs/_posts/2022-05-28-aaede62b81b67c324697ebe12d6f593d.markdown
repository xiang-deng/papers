---
layout: post
title:  "Few-shot learning with language models: Learning from instructions and contexts"
date:   2022-05-28 02:05:27 -0400
categories: jekyll update
author: "T Schick - 2022"
---
Pretraining deep neural networks to perform language modeling–that is, to reconstruct missing words from incomplete pieces of text–has brought large improvements throughout natural language processing (NLP). However, even pretrained models typically do not achieve satisfactory performance in few-shot settings, where only a limited number of examples is available. This is an important issue not only because the need to annotate thousands of examples is a barrier to … Cites: ‪Noisy channel language model prompting for few-shot text …‬