--- 
layout: post 
title: "Ignore Previous Prompt: Attack Techniques For Language Models" 
date: 2022-11-22 02:23:19 -0400 
categories: jekyll update 
author: "F Perez, I Ribeiro - arXiv preprint arXiv:2211.09527, 2022" 
--- 
Transformer-based large language models (LLMs) provide a powerful foundation for natural language tasks in large-scale customer-facing applications. However, studies that explore their vulnerabilities emerging from malicious user interaction are scarce. By proposing PromptInject, a prosaic alignment framework for mask-based iterative adversarial prompt composition, we examine how GPT-3, the most widely deployed language model in production, can be easily misaligned by simple handcrafted  Cites: Realtoxicityprompts: Evaluating neural toxic degeneration in