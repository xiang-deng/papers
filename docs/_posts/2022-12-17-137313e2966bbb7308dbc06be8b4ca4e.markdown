--- 
layout: post 
title: "Topic-aware hierarchical multi-attention network for text classification" 
date: 2022-12-17 01:50:56 -0400 
categories: jekyll update 
author: "Y Jiang, Y Wang - International Journal of Machine Learning and , 2022" 
--- 
Neural networks, primarily recurrent and convolutional Neural networks, have been proven successful in text classification. However, convolutional models could be limited when classification tasks are determined by long-range semantic dependency. While the recurrent ones can capture long-range dependency, the sequential architecture of which could constrain the training speed. Meanwhile, traditional networks encode the entire document in a single pass, which omits the  Cites: Don t give me the details, just the summary! topic-aware