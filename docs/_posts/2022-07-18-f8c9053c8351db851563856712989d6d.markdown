--- 
layout: post 
title: "Topic Embedded Representation Enhanced Variational Wasserstein Autoencoder for Text Modeling" 
date: 2022-07-18 23:00:30 -0400 
categories: jekyll update 
author: "Z Xiang, X Liu, G Yang, Y Liu - 2022 IEEE 5th International Conference on , 2022" 
--- 
Variational Autoencoder (VAE) is now popular in text modeling and language generation tasks, which need to pay attention to the diversity of generation results. The existing models are insufficient in capturing the built-in relationships between topic representation and sequential words. At the same time, there is a massive contradiction between the commonly used simple Gaussian prior and the actual complex distribution of language texts. To address the above problems, we introduce  Cites: Cached Long Short-Term Memory Neural Networks for Document