---
layout: post
title:  "PredNAS: A Universal and Sample Efficient Neural Architecture Search Framework"
date:   2022-11-01 03:49:43 -0400
categories: jekyll update
author: "L Yuan, Z Huang, N Wang - arXiv preprint arXiv:2210.14460, 2022"
---
In this paper, we present a general and effective framework for Neural Architecture Search (NAS), named PredNAS. The motivation is that given a differentiable performance estimation function, we can directly optimize the architecture towards higher performance by simple gradient ascent. Specifically, we adopt a neural predictor as the performance predictor. Surprisingly, PredNAS can achieve state-of-the-art performances on NAS benchmarks with only a few training samples (less than …
Cites: ‪Bignas: Scaling up neural architecture search with big single-stage …‬