---
layout: post
title:  "Do Vision-Language Pretrained Models Learn Primitive Concepts?"
date:   2022-06-20 23:00:52 -0400
categories: jekyll update
author: "U Bhalla - 2022"
---
Vision-language pretrained models have achieved impressive performance on multimodal reasoning and zero-shot recognition tasks. Many of these VL models are pretrained on naturally labeled image and caption pairs from the internet. In this paper, we study whether the notion of primitive concepts, such as color and shape attributes, emerges automatically from these pretrained VL models and whether or not those concepts provide a naturally interpretable interface for humans to interact …
Cites: ‪Vinvl: Revisiting visual representations in vision-language models‬  