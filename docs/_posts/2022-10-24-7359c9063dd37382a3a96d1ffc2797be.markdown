---
layout: post
title:  "Disentangling Reasoning Capabilities from Language Models with Compositional Reasoning Transformers"
date:   2022-10-24 23:22:19 -0400
categories: jekyll update
author: "W Zhong, T Ma, J Wang, J Yin, T Zhao, CY Lin, N Duan - arXiv preprint arXiv …, 2022"
---
This paper presents ReasonFormer, a unified reasoning framework for mirroring the modular and compositional reasoning process of humans in complex decision making. Inspired by dual-process theory in cognitive science, the representation module (automatic thinking) and reasoning modules (controlled thinking) are disentangled to capture different levels of cognition. Upon the top of the representation module, the pre-trained reasoning modules are modular and …
Cites: ‪Demix layers: Disentangling domains for modular language …‬