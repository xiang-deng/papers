---
layout: post
title:  "Predicting Efficiency/Effectiveness Trade-offs for Dense vs. Sparse Retrieval Strategy Selection"
date:   2021-09-28 14:54:04 -0400
categories: jekyll update
author: "N Arabzadeh, X Yan, CLA Clarke - arXiv preprint arXiv:2109.10739, 2021"
---
Over the last few years, contextualized pre-trained transformer models such as BERT have provided substantial improvements on information retrieval tasks. Recent approaches based on pre-trained transformer models such as BERT, fine-tune dense low-dimensional contextualized representations of queries and documents in embedding space. While these dense retrievers enjoy substantial retrieval effectiveness improvements compared to sparse retrievers, they are computationally Cites: Dense Passage Retrieval for Open-Domain Question Answering