---
layout: post
title:  "LEARNING WITH AND BEYOND VISUAL KNOWLEDGE"
date:   2022-09-22 02:02:39 -0400
categories: jekyll update
author: "B Li - 2022"
---
A key innovation that enabled the undeniable success of deep learning is the internal normalization of activations. Although normalizing inputs had always been one of the “tricks of the trade” for training neural networks [92], batch normalization (BN)[71] extended this practice to every layer, which turned out to have crucial benefits for deep networks. While the success of normalization methods was initially attributed to “reducing internal covariate shift” in hidden layers [71, 95], an array of …
Cites: ‪Deep Unordered Composition Rivals Syntactic Methods for Text …‬