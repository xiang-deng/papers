---
layout: post
title:  "Uncertainty-aware Self-training for Low-resource Neural Sequence Labeling"
date:   2023-02-23 04:09:00 -0400
categories: jekyll update
author: "J Wang, C Wang, J Huang, M Gao, A Zhou - arXiv preprint arXiv:2302.08659, 2023"
---
Neural sequence labeling (NSL) aims at assigning labels for input language tokens, which covers a broad range of applications, such as named entity recognition (NER) and slot filling, etc. However, the satisfying results achieved by traditional supervised-based approaches heavily depend on the large amounts of human annotation data, which may not be feasible in real-world scenarios due to data privacy and computation efficiency issues. This paper presents SeqUST, a novel uncertain-aware …
Cites: ‪Semi-supervised sequence modeling with cross-view training‬