--- 
layout: post 
title: "The Web Can Be Your Oyster for Improving Large Language Models" 
date: 2023-05-23 02:52:43 -0400 
categories: jekyll update 
author: "J Li, T Tang, WX Zhao, J Wang, JY Nie, JR Wen - arXiv preprint arXiv:2305.10998, 2023" 
--- 
Large language models (LLMs) encode a large amount of world knowledge. However, as such knowledge is frozen at the time of model training, the models become static and limited by the training data at that time. In order to further improve the capacity of LLMs for knowledge-intensive tasks, we consider augmenting LLMs with the large-scale web using search engine. Unlike previous augmentation sources (eg, Wikipedia data dump), the web provides broader, more comprehensive Cites: Few-shot learning with retrieval augmented language models