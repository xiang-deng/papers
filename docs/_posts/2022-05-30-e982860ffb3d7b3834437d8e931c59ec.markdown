--- 
layout: post 
title: "Certified Robustness Against Natural Language Attacks by Causal Intervention" 
date: 2022-05-30 22:20:45 -0400 
categories: jekyll update 
author: "H Zhao, C Ma, X Dong, AT Luu, ZH Deng, H Zhang - arXiv preprint arXiv:2205.12331, 2022" 
--- 
Deep learning models have achieved great success in many fields, yet they are vulnerable to adversarial examples. This paper follows a causal perspective to look into the adversarial vulnerability and proposes Causal Intervention by Semantic Smoothing (CISS), a novel framework towards robustness against natural language attacks. Instead of merely fitting observational data, CISS learns causal effects p (y| do (x)) by smoothing in the latent semantic space to make robust predictions, which Cites: Semantically Equivalent Adversarial Rules for Debugging NLP