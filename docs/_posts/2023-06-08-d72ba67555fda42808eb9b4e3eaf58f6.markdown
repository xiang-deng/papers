--- 
layout: post 
title: "KNOW How to Make Up Your Mind! Adversarially Detecting and Alleviating Inconsistencies in Natural Language Explanations" 
date: 2023-06-08 03:52:18 -0400 
categories: jekyll update 
author: "M Jang, BP Majumder, J McAuley, T Lukasiewicz - arXiv preprint arXiv , 2023" 
--- 
While recent works have been considerably improving the quality of the natural language explanations (NLEs) generated by a model to justify its predictions, there is very limited research in detecting and alleviating inconsistencies among generated NLEs. In this work, we leverage external knowledge bases to significantly improve on an existing adversarial attack for detecting inconsistent NLEs. We apply our attack to high-performing NLE models and show that models with higher NLE quality do not  Cites: Measuring association between labels and free-text rationales