---
layout: post
title:  "How Language Model Hallucinations Can Snowball"
date:   2023-05-27 10:00:59 -0400
categories: jekyll update
author: "M Zhang, O Press, W Merrill, A Liu, NA Smith - arXiv preprint arXiv:2305.13534, 2023"
---
A major risk of using language models in practical applications is their tendency to hallucinate incorrect statements. Hallucinations are often attributed to knowledge gaps in LMs, but we hypothesize that in some cases, when justifying previously â€¦
