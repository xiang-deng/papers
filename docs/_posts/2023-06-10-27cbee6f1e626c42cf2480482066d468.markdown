---
layout: post
title:  "Revisiting Out-of-distribution Robustness in NLP: Benchmark, Analysis, and LLMs Evaluations"
date:   2023-06-10 05:24:39 -0400
categories: jekyll update
author: "L Yuan, Y Chen, G Cui, H Gao, F Zou, X Cheng, H Ji… - arXiv preprint arXiv …, 2023"
---
This paper reexamines the research on out-of-distribution (OOD) robustness in the field of NLP. We find that the distribution shift settings in previous studies commonly lack adequate challenges, hindering the accurate evaluation of OOD robustness. To address these issues, we propose a benchmark construction protocol that ensures clear differentiation and challenging distribution shifts. Then we introduce BOSS, a Benchmark suite for Out-of-distribution robustneSS evaluation covering 5 tasks and …
Cites: ‪Beat the AI: Investigating adversarial human annotation for reading …‬