---
layout: post
title:  "PANGUBOT: Efficient Generative Dialogue Pre-training from Pre-trained Language Model"
date:   2022-04-04 16:51:29 -0400
categories: jekyll update
author: "F Mi, Y Li, Y Zeng, J Zhou, Y Wang, C Xu, L Shang - arXiv preprint arXiv , 2022"
---
In this paper, we introduce PANGUBOT, a Chinese pre-trained open-domain dialogue generation model based on a large pre-trained language model (PLM) PANGU-alpha (Zeng et al., 2021). Different from other pre-trained dialogue models trained over a massive amount of dialogue data from scratch, we aim to build a powerful dialogue model with relatively fewer data and computation costs by inheriting valuable language capabilities and knowledge from PLMs. To this end, we Cites: Retrieval-augmented generation for knowledge-intensive nlp tasks