---
layout: post
title:  "Adapting Self-Supervised Vision Transformers by Probing Attention-Conditioned Masking Consistency"
date:   2022-06-19 07:39:02 -0400
categories: jekyll update
author: "V Prabhu, S Yenamandra, A Singh, J Hoffman - arXiv preprint arXiv:2206.08222, 2022"
---
Visual domain adaptation (DA) seeks to transfer trained models to unseen, unlabeled domains across distribution shift, but approaches typically focus on adapting convolutional neural network architectures initialized with supervised ImageNet representations. In this work, we shift focus to adapting modern architectures for object recognition--the increasingly popular Vision Transformer (ViT)--and modern pretraining based on self-supervised learning (SSL). Inspired by …
Cites: ‪Connect, not collapse: Explaining contrastive learning for …‬  