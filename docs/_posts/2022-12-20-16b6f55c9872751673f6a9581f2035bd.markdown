--- 
layout: post 
title: "Tensions Between the Proxies of Human Values in AI" 
date: 2022-12-20 02:26:19 -0400 
categories: jekyll update 
author: "T Datta, D Nissani, M Cembalest, A Khanna, H Massa - arXiv preprint arXiv , 2022" 
--- 
Motivated by mitigating potentially harmful impacts of technologies, the AI community has formulated and accepted mathematical definitions for certain pillars of accountability: eg privacy, fairness, and model transparency. Yet, we argue this is fundamentally misguided because these definitions are imperfect, siloed constructions of the human values they hope to proxy, while giving the guise that those values are sufficiently embedded in our technologies. Under popularized  Cites: Why Should I Trust You? : Explaining the Predictions of Any