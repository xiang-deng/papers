--- 
layout: post 
title: "A Unified Continuous Learning Framework for Multi-modal Knowledge Discovery and Pre-training" 
date: 2022-06-18 03:19:09 -0400 
categories: jekyll update 
author: "Z Fan, Z Wei, J Chen, S Wang, Z Li, J Xu, X Huang - arXiv preprint arXiv:2206.05555, 2022" 
--- 
Multi-modal pre-training and knowledge discovery are two important research topics in multi-modal machine learning. Nevertheless, none of existing works make attempts to link knowledge discovery with knowledge guided multi-modal pre-training. In this paper, we propose to unify them into a continuous learning framework for mutual improvement. Taking the open-domain uni-modal datasets of images and texts as input, we maintain a knowledge graph as the foundation to support these two Cites: LXMERT: Learning Cross-Modality Encoder Representations from