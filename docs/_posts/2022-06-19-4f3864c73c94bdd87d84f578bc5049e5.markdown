---
layout: post
title:  "ELUDE: Generating interpretable explanations via a decomposition into labelled and unlabelled features"
date:   2022-06-19 07:39:02 -0400
categories: jekyll update
author: "VV Ramaswamy, SSY Kim, N Meister, R Fong - arXiv preprint arXiv , 2022"
---
Deep learning models have achieved remarkable success in different areas of machine learning over the past decade; however, the size and complexity of these models make them difficult to understand. In an effort to make them more interpretable, several recent works focus on explaining parts of a deep neural network through human-interpretable, semantic attributes. However, it may be impossible to completely explain complex models using only semantic attributes. In 
Cites: Concept bottleneck models