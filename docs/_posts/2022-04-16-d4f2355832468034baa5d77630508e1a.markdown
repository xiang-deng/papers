---
layout: post
title:  "Non-autoregressive ASR Modeling using Pre-trained Language Models for Chinese Speech Recognition"
date:   2022-04-16 01:25:48 -0400
categories: jekyll update
author: "FH Yu, KY Chen, KH Lu - IEEE/ACM Transactions on Audio, Speech, and , 2022"
---
Transformer-based models have led to significant innovation in various classic and practical subjects, including speech processing, natural language processing, and computer vision. On top of the Transformer, attention-based end-to-end automatic speech recognition (ASR) models have become a popular fashion in recent years. Specifically, an emergent research topic is non-autoregressive modeling, which can achieve fast inference speed and obtain competitive performance when compared Cites: Dense Passage Retrieval for Open-Domain Question Answering