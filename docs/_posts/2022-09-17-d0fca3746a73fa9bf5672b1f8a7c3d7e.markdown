--- 
layout: post 
title: "If Influence Functions are the Answer, Then What is the Question?" 
date: 2022-09-17 00:49:30 -0400 
categories: jekyll update 
author: "J Bae, N Ng, A Lo, M Ghassemi, R Grosse - arXiv preprint arXiv:2209.05364, 2022" 
--- 
Influence functions efficiently estimate the effect of removing a single training data point on a model s learned parameters. While influence estimates align well with leave-one-out retraining for linear models, recent works have shown this alignment is often poor in neural networks. In this work, we investigate the specific factors that cause this discrepancy by decomposing it into five separate terms. We study the contributions of each term on a variety of architectures and datasets and how they Cites: Stronger data poisoning attacks break data sanitization defenses