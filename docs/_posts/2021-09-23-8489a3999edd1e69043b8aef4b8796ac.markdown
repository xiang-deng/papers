--- 
layout: post 
title: "Transformers4Rec: Bridging the Gap between NLP and Sequential/Session-Based Recommendation" 
date: 2021-09-23 17:17:49 -0400 
categories: jekyll update 
author: "G de Souza Pereira Moreira, S Rabhi, JM Lee, R Ak - Fifteenth ACM Conference , 2021" 
--- 
Much of the recent progress in sequential and session-based recommendation has been driven by improvements in model architecture and pretraining techniques originating in the field of Natural Language Processing. Transformer architectures in particular have facilitated building higher-capacity models and provided data augmentation and training techniques which demonstrably improve the effectiveness of sequential recommendation. But with a thousandfold more research going on in Cites: Bert: Pre-training of deep bidirectional transformers for language