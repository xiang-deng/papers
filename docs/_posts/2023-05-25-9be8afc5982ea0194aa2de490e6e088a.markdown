--- 
layout: post 
title: "A Survey of Safety and Trustworthiness of Large Language Models through the Lens of Verification and Validation" 
date: 2023-05-25 03:51:47 -0400 
categories: jekyll update 
author: "X Huang, W Ruan, W Huang, G Jin, Y Dong, C Wu - arXiv preprint arXiv , 2023" 
--- 
Large Language Models (LLMs) have exploded a new heatwave of AI, for their ability to engage end-users in human-level conversations with detailed and articulate answers across many knowledge domains. In response to their fast adoption in many industrial applications, this survey concerns their safety and trustworthiness. First, we review known vulnerabilities of the LLMs, categorising them into inherent issues, intended attacks, and unintended bugs. Then, we consider if and how the Verification  Cites: Is Reinforcement Learning (Not) for Natural Language Processing