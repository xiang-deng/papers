---
layout: post
title:  "Optimizing Relevance Maps of Vision Transformers Improves Robustness"
date:   2022-06-06 21:51:57 -0400
categories: jekyll update
author: "H Chefer, I Schwartz, L Wolf - arXiv preprint arXiv:2206.01161, 2022"
---
It has been observed that visual classification models often rely mostly on the image background, neglecting the foreground, which hurts their robustness to distribution changes. To alleviate this shortcoming, we propose to monitor the model s relevancy signal and manipulate it such that the model is focused on the foreground object. This is done as a finetuning step, involving relatively few samples consisting of pairs of images and their associated foreground masks. Specifically, we encourage the …
Cites: ‪Pathologies of Neural Models Make Interpretation Difficult‬  