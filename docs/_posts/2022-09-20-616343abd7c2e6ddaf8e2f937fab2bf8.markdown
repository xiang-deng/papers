--- 
layout: post 
title: "Cold-Start Data Selection for Few-shot Language Model Fine-tuning: A Prompt-Based Uncertainty Propagation Approach" 
date: 2022-09-20 01:42:47 -0400 
categories: jekyll update 
author: "Y Yu, R Zhang, R Xu, J Zhang, J Shen, C Zhang - arXiv preprint arXiv:2209.06995, 2022" 
--- 
We propose PATRON, a new method that uses prompt-based uncertainty estimation for data selection for pre-trained language model fine-tuning under cold-start scenarios, ie, no initial labeled data are available. In PATRON, we design (1) a prompt-based uncertainty propagation approach to estimate the importance of data points and (2) a partition-then-rewrite (PTR) strategy to promote sample diversity when querying for annotations. Experiments on six text classification datasets show Cites: Selective Annotation Makes Language Models Better Few-Shot