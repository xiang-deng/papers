---
layout: post
title:  "LOT: A Story-Centric Benchmark for Evaluating Chinese Long Text Understanding and Generation"
date:   2022-04-16 01:25:48 -0400
categories: jekyll update
author: "J Guan, Z Feng, Y Chen, R He, X Mao, C Fan, M Huang - Transactions of the , 2022"
---
Standard multi-task benchmarks are essential for developing pretraining models that can generalize to various downstream tasks. Existing benchmarks for natural language processing (NLP) usually focus only on understanding or generating short texts. However, long text modeling requires many distinct abilities in contrast to short texts, such as the modeling of long-range discourse and commonsense relations, and the coherence and controllability of generation. The lack of standardized Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList