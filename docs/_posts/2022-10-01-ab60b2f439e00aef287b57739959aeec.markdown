--- 
layout: post 
title: "ConceptExplainer: Interactive Explanation for Deep Neural Networks from a Concept Perspective" 
date: 2022-10-01 01:08:34 -0400 
categories: jekyll update 
author: "J Huang, A Mishra, BC Kwon, C Bryan - IEEE Transactions on Visualization and , 2022" 
--- 
Traditional deep learning interpretability methods which are suitable for model users cannot explain network behaviors at the global level and are inflexible at providing fine-grained explanations. As a solution, concept-based explanations are gaining attention due to their human intuitiveness and their flexibility to describe both global and local model behaviors. Concepts are groups of similarly meaningful pixels that express a notion, embedded within the network s latent space and have commonly  Cites: Concept bottleneck models