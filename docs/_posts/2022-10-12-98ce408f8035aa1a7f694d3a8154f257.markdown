--- 
layout: post 
title: "Are Representations Built from the Ground Up? An Empirical Examination of Local Composition in Language Models" 
date: 2022-10-12 20:42:55 -0400 
categories: jekyll update 
author: "E Liu, G Neubig - arXiv preprint arXiv:2210.03575, 2022" 
--- 
Compositionality, the phenomenon where the meaning of a phrase can be derived from its constituent parts, is a hallmark of human language. At the same time, many phrases are non-compositional, carrying a meaning beyond that of each part in isolation. Representing both of these types of phrases is critical for language understanding, but it is an open question whether modern language models (LMs) learn to do so; in this work we examine this question. We first formulate a problem of Cites: Emergent linguistic structure in artificial neural networks trained by