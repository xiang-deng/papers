---
layout: post
title:  "Multimodal Emotion Analysis Based on Visual, Acoustic and Linguistic Features"
date:   2022-06-19 07:39:02 -0400
categories: jekyll update
author: "L Koren, T Stipancic, A Ricko, L Orsag - International Conference on Human …, 2022"
---
In this paper, a computational reasoning framework that can interpret social signals of the person in interaction by focusing on the person s emotional state is presented. Two distinct sources of social signals are used for this study: facial and voice emotion modalities. As a part of the first modality, a Convolutional Neural Network (CNN) is used to extract and process the facial features based on live stream video. The voice emotion analysis containing two sub-modalities is driven by CNN and Long Short …
Cites: ‪Learning to deceive with attention-based explanations‬  