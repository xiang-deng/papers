---
layout: post
title:  "Generación Automática de Código Fuente a través de Modelos Preentrenados de Lenguaje"
date:   2023-05-16 05:31:31 -0400
categories: jekyll update
author: "A Bender, S Nicolet, P Folino, JJ Lopez, G Hansen - Electronic Journal of SADIO (EJS …, 2023"
---
Un Transformer es un modelo de Aprendizaje Profundo creado en 2017 con el objetivo de realizar traducciones entre lenguajes naturales. Las innovaciones que introdujo, particularmente la de auto-atención, han permitido construir prototipos que tienen una noción intuitiva del contexto, y comprenden el significado y los patrones subyacentes del lenguaje. En 2020 OpenAI hizo público GPT-3, un modelo preentrenado enfocado hacia la generación de lenguaje,
Cites: ‪Codexglue: A machine learning benchmark dataset for code …‬