--- 
layout: post 
title: "Generacin Automtica de Cdigo Fuente a travs de Modelos Preentrenados de Lenguaje" 
date: 2023-05-16 05:31:31 -0400 
categories: jekyll update 
author: "A Bender, S Nicolet, P Folino, JJ Lopez, G Hansen - Electronic Journal of SADIO (EJS , 2023" 
--- 
Un Transformer es un modelo de Aprendizaje Profundo creado en 2017 con el objetivo de realizar traducciones entre lenguajes naturales. Las innovaciones que introdujo, particularmente la de auto-atencin, han permitido construir prototipos que tienen una nocin intuitiva del contexto, y comprenden el significado y los patrones subyacentes del lenguaje. En 2020 OpenAI hizo pblico GPT-3, un modelo preentrenado enfocado hacia la generacin de lenguaje, Cites: Codexglue: A machine learning benchmark dataset for code