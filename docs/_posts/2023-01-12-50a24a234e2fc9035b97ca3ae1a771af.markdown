--- 
layout: post 
title: "TrojanPuzzle: Covertly Poisoning Code-Suggestion Models" 
date: 2023-01-12 00:32:14 -0400 
categories: jekyll update 
author: "H Aghakhani, W Dai, A Manoel, X Fernandes - arXiv preprint arXiv , 2023" 
--- 
With tools like GitHub Copilot, automatic code suggestion is no longer a dream in software engineering. These tools, based on large language models, are typically trained on massive corpora of code mined from unvetted public sources. As a result, these models are susceptible to data poisoning attacks where an adversary manipulates the model s training or fine-tuning phases by injecting malicious data. Poisoning attacks could be designed to influence the model s suggestions at run time Cites: Incoder: A generative model for code infilling and synthesis