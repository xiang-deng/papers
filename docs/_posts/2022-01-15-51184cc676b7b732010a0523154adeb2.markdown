---
layout: post
title:  "Continual Learning of Long Topic Sequences in Neural Information Retrieval"
date:   2022-01-15 10:11:37 -0400
categories: jekyll update
author: "T Gerald, L Soulier - arXiv preprint arXiv:2201.03356, 2022"
---
In information retrieval (IR) systems, trends and users  interests may change over time, altering either the distribution of requests or contents to be recommended. Since neural ranking approaches heavily depend on the training data, it is crucial to understand the transfer capacity of recent IR approaches to address new domains in the long term. In this paper, we first propose a dataset based upon the MSMarco corpus aiming at modeling a long stream of topics as well as IR property-driven Cites: Dense Passage Retrieval for Open-Domain Question Answering