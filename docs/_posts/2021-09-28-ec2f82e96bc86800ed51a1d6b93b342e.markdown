---
layout: post
title:  "Zero-Shot Information Extraction as a Unified Text-to-Triple Translation"
date:   2021-09-28 14:54:04 -0400
categories: jekyll update
author: "C Wang, X Liu, Z Chen, H Hong, J Tang, D Song - arXiv preprint arXiv:2109.11171, 2021"
---
We cast a suite of information extraction tasks into a text-to-triple translation framework. Instead of solving each task relying on task-specific datasets and models, we formalize the task as a translation between task-specific input text and output triples. By taking the task-specific input, we enable a task-agnostic translation by leveraging the latent knowledge that a pre-trained language model has about the task. We further demonstrate that a simple pre-training task of predicting which Cites: Prefix-tuning: Optimizing continuous prompts for generation