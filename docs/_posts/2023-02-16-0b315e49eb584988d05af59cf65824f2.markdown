---
layout: post
title:  "Fixing Overconfidence in Dynamic Neural Networks"
date:   2023-02-16 06:16:46 -0400
categories: jekyll update
author: "L Meronen, M Trapp, A Pilzer, L Yang, A Solin - arXiv preprint arXiv:2302.06359, 2023"
---
Dynamic neural networks are a recent technique that promises a remedy for the increasing size of modern deep learning models by dynamically adapting their computational cost to the difficulty of the input samples. In this way, the model can adjust to a limited computational budget. However, the poor quality of uncertainty estimates in deep learning models makes it difficult to distinguish between hard and easy samples. To address this challenge, we present a computationally efficient …
Cites: ‪The right tool for the job: Matching model and instance complexities‬