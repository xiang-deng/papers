---
layout: post
title:  "i-Code: An Integrative and Composable Multimodal Learning Framework"
date:   2022-05-10 03:22:04 -0400
categories: jekyll update
author: "Z Yang, Y Fang, C Zhu, R Pryzant, D Chen, Y Shi, Y Xu - arXiv preprint arXiv , 2022"
---
Human intelligence is multimodal; we integrate visual, linguistic, and acoustic signals to maintain a holistic worldview. Most current pretraining methods, however, are limited to one or two modalities. We present i-Code, a self-supervised pretraining framework where users may flexibly combine the modalities of vision, speech, and language into unified and general-purpose vector representations. In this framework, data from each modality are first given to pretrained single-modality encoders. The Cites: MERLOT Reserve: Neural Script Knowledge through Vision and