--- 
layout: post 
title: "DisentQA: Disentangling Parametric and Contextual Knowledge with Counterfactual Question Answering" 
date: 2022-11-15 00:38:37 -0400 
categories: jekyll update 
author: "E Neeman, R Aharoni, O Honovich, L Choshen - arXiv preprint arXiv , 2022" 
--- 
Question answering models commonly have access to two sources of knowledge during inference time:(1) parametric knowledge-the factual knowledge encoded in the model weights, and (2) contextual knowledge-external knowledge (eg, a Wikipedia passage) given to the model to generate a grounded answer. Having these two sources of knowledge entangled together is a core issue for generative QA models as it is unclear whether the answer stems from the given non-parametric Cites: BoolQ: Exploring the surprising difficulty of natural yes/no questions