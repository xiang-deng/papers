--- 
layout: post 
title: "Causal Proxy Models for Concept-Based Model Explanations" 
date: 2022-10-04 00:49:37 -0400 
categories: jekyll update 
author: "Z Wu, K D Oosterlinck, A Geiger, A Zur, C Potts - arXiv preprint arXiv:2209.14279, 2022" 
--- 
Explainability methods for NLP systems encounter a version of the fundamental problem of causal inference: for a given ground-truth input text, we never truly observe the counterfactual texts necessary for isolating the causal effects of model representations on outputs. In response, many explainability methods make no use of counterfactual texts, assuming they will be unavailable. In this paper, we show that robust causal explainability methods can be created using approximate Cites: Polyjuice: Generating Counterfactuals for Explaining, Evaluating