---
layout: post
title:  "Reflection of Thought: Inversely Eliciting Numerical Reasoning in Language Models via Solving Linear Systems"
date:   2022-10-15 02:59:22 -0400
categories: jekyll update
author: "F Zhou, H Dong, Q Liu, Z Cheng, S Han, D Zhang - arXiv preprint arXiv:2210.05075, 2022"
---
Numerical reasoning over natural language has been a long-standing goal for the research community. However, cutting-edge language models have proven difficult to reliably generalize to a broad range of numbers, although they have shown proficiency in reasoning over common and simple numbers. In this paper, we propose a novel method to elicit and exploit the numerical reasoning knowledge hidden in pre-trained language models using simple anchor numbers. Concretely …
Cites: ‪Least-to-Most Prompting Enables Complex Reasoning in Large …‬