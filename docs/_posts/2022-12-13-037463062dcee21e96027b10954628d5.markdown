--- 
layout: post 
title: "Leveraging Unlabeled Data to Track Memorization" 
date: 2022-12-13 08:01:52 -0400 
categories: jekyll update 
author: "M Forouzesh, H Sedghi, P Thiran - arXiv preprint arXiv:2212.04461, 2022" 
--- 
Deep neural networks may easily memorize noisy labels present in real-world data, which degrades their ability to generalize. It is therefore important to track and evaluate the robustness of models against noisy label memorization. We propose a metric, called susceptibility, to gauge such memorization for neural networks. Susceptibility is simple and easy to compute during training. Moreover, it does not require access to ground-truth labels and it only uses unlabeled data. We empirically Cites: The break-even point on optimization trajectories of deep neural