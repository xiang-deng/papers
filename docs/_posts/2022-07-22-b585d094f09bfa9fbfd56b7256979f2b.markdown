--- 
layout: post 
title: "Generalizable Memory-driven Transformer for Multivariate Long Sequence Time-series Forecasting" 
date: 2022-07-22 21:48:17 -0400 
categories: jekyll update 
author: "M Li, X Zhao, R Liu, C Li, X Wang, X Chang - arXiv preprint arXiv:2207.07827, 2022" 
--- 
Multivariate long sequence time-series forecasting (M-LSTF) is a practical but challenging problem. Unlike traditional timer-series forecasting tasks, M-LSTF tasks are more challenging from two aspects: 1) M-LSTF models need to learn time-series patterns both within and between multiple time features; 2) Under the rolling forecasting setting, the similarity between two consecutive training samples increases with the increasing prediction length, which makes models more prone to  Cites: MART: Memory-Augmented Recurrent Transformer for Coherent