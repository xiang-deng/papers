---
layout: post
title:  "Towards Table-to-Text Generation with Pretrained Language Model: A Table Structure Understanding and Text Deliberating Approach"
date:   2023-01-10 01:37:31 -0400
categories: jekyll update
author: "M Chen, X Lu, T Xu, Y Li, J Zhou, D Dou, H Xiong - arXiv preprint arXiv:2301.02071, 2023"
---
Although remarkable progress on the neural table-to-text methods has been made, the generalization issues hinder the applicability of these models due to the limited source tables. Large-scale pretrained language models sound like a promising solution to tackle such issues. However, how to effectively bridge the gap between the structured table and the text input by fully leveraging table information to fuel the pretrained model is still not well explored. Besides, another challenge of integrating …
Cites: ‪TaBERT: Pretraining for joint understanding of textual and tabular …‬