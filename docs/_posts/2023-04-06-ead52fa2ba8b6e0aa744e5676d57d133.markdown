--- 
layout: post 
title: "Assessing Language Model Deployment with Risk Cards" 
date: 2023-04-06 06:45:39 -0400 
categories: jekyll update 
author: "L Derczynski, HR Kirk, V Balachandran, S Kumar - arXiv preprint arXiv , 2023" 
--- 
This paper introduces RiskCards, a framework for structured assessment and documentation of risks associated with an application of language models. As with all language, text generated by language models can be harmful, or used to bring about harm. Automating language generation adds both an element of scale and also more subtle or emergent undesirable tendencies to the generated text. Prior work establishes a wide variety of language model harms to many different actors Cites: Building Human Values into Recommender Systems: An