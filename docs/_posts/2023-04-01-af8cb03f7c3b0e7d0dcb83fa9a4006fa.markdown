--- 
layout: post 
title: "General Words Representation Method for Modern Language Model" 
date: 2023-04-01 04:48:36 -0400 
categories: jekyll update 
author: "AS Lokman, MA Ameedeen, NA Ghani - Journal of Telecommunication, Electronic , 2023" 
--- 
This paper proposes a new word representation method emphasizes general words over specific words. The main motivation for developing this method is to address the weighting bias in modern Language Models (LMs). Based on the Transformer architecture, contemporary LMs tend to naturally emphasize specific words through the Attention mechanism to capture the key semantic concepts in a given text. As a result, general words, including question words are often neglected by LMs, leading Cites: QuAC: Question answering in context