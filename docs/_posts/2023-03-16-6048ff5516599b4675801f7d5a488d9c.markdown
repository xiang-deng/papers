--- 
layout: post 
title: "Model-tuning Via Prompts Makes NLP Models Adversarially Robust" 
date: 2023-03-16 06:48:33 -0400 
categories: jekyll update 
author: "M Raman, P Maini, JZ Kolter, ZC Lipton, D Pruthi - arXiv preprint arXiv:2303.07320, 2023" 
--- 
In recent years, NLP practitioners have converged on the following practice:(i) import an off-the-shelf pretrained (masked) language model;(ii) append a multilayer perceptron atop the CLS token s hidden representation (with randomly initialized weights); and (iii) fine-tune the entire model on a downstream task (MLP). This procedure has produced massive gains on standard NLP benchmarks, but these models remain brittle, even to mild adversarial perturbations, such as word-level  Cites: Knowledgeable Prompt-tuning: Incorporating Knowledge into