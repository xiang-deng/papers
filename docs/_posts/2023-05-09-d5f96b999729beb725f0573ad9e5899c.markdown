--- 
layout: post 
title: "Lift Yourself Up: Retrieval-augmented Text Generation with Self Memory" 
date: 2023-05-09 11:33:00 -0400 
categories: jekyll update 
author: "X Cheng, D Luo, X Chen, L Liu, D Zhao, R Yan - arXiv preprint arXiv:2305.02437, 2023" 
--- 
With direct access to human-written reference as memory, retrieval-augmented generation has achieved much progress in a wide range of text generation tasks. Since better memory would typically prompt better generation~(we define this as primal problem), previous works mainly focus on how to retrieve better memory. However, one fundamental limitation exists for current literature: the memory is retrieved from a fixed corpus and is bounded by the quality of the corpus. Due to the Cites: Muppet: Massive multi-task representations with pre-finetuning