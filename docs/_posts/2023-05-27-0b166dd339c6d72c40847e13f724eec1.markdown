--- 
layout: post 
title: "Provable Offline Reinforcement Learning with Human Feedback" 
date: 2023-05-27 10:00:59 -0400 
categories: jekyll update 
author: "W Zhan, M Uehara, N Kallus, JD Lee, W Sun - arXiv preprint arXiv:2305.14816, 2023" 
--- 
In this paper, we investigate the problem of offline reinforcement learning with human feedback where feedback is available in the form of preference between trajectory pairs rather than explicit rewards. Our proposed algorithm consists of two main steps:(1) estimate the implicit reward using Maximum Likelihood Estimation (MLE) with general function approximation from offline data and (2) solve a distributionally robust planning problem over a confidence set around the MLE. We consider the  Cites: Is Reinforcement Learning (Not) for Natural Language Processing