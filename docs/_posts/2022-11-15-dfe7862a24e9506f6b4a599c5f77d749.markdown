---
layout: post
title:  "Can Transformers Reason in Fragments of Natural Language?"
date:   2022-11-15 00:38:37 -0400
categories: jekyll update
author: "V Schlegel, KV Pavlov, I Pratt-Hartmann - arXiv preprint arXiv:2211.05417, 2022"
---
State-of-the-art deep-learning-based approaches to Natural Language Processing (NLP) are credited with various capabilities that involve reasoning with natural language texts. In this paper we carry out a large-scale empirical study investigating the detection of formally valid inferences in controlled fragments of natural language for which the satisfiability problem becomes increasingly complex. We find that, while transformer-based language models perform surprisingly well in these scenarios, a …
Cites: ‪Leap-Of-Thought: Teaching Pre-Trained Models to Systematically …‬