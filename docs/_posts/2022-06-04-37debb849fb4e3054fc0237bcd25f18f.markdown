---
layout: post
title:  "Additive Feature Attribution Explainable Methods to Craft Adversarial Attacks for Text Classification and Text Regression"
date:   2022-06-04 01:43:25 -0400
categories: jekyll update
author: "Y Chai, R Liang, S Samtani, H Zhu, M Wang, Y Liu…"
---
Deep learning (DL) models have significantly improved the performance of text classification and text regression tasks. However, DL models are often strikingly vulnerable to adversarial attacks. Many researchers have aimed to develop adversarial attacks against DL models in realistic black-box settings (ie, assumes no model knowledge is accessible to attackers) that typically operate with a two-phase framework:(1) sensitivity estimation through gradient-based or deletion-based … Cites: ‪Anchors: High-Precision Model-Agnostic Explanations‬