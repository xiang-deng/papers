---
layout: post
title:  "Are Human Explanations Always Helpful? Towards Objective Evaluation of Human Natural Language Explanations"
date:   2023-05-11 03:26:59 -0400
categories: jekyll update
author: "B Yao, P Sen, L Popa, J Hendler, D Wang - arXiv preprint arXiv:2305.03117, 2023"
---
Human-annotated labels and explanations are critical for training explainable NLP models. However, unlike human-annotated labels whose quality is easier to calibrate (eg, with a majority vote), human-crafted free-form explanations can be quite subjective, as some recent works have discussed. Before blindly using them as ground truth to train ML models, a vital question needs to be asked: How do we evaluate a human-annotated explanation s quality? In this paper, we build on the …
Cites: ‪CommonsenseQA: A Question Answering Challenge Targeting …‬