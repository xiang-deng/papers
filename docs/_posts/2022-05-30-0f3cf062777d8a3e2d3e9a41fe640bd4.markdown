---
layout: post
title:  "Intermediate Training on Question Answering Datasets Improves Generative Data Augmentation"
date:   2022-05-30 22:20:45 -0400
categories: jekyll update
author: "D Mekala, T Vu, J Shang - arXiv preprint arXiv:2205.12604, 2022"
---
Manually annotating datasets requires domain experts to read through many documents and carefully label them, which is often expensive. Recently, pre-trained generative language models (GLMs) have demonstrated exceptional abilities in generating text which motivates to leverage them for generative data augmentation. We improve generative data augmentation by formulating the data generation as context generation task and use question answering (QA) datasets for intermediate  Cites: Strata: Self-training with task augmentation for better few-shot 