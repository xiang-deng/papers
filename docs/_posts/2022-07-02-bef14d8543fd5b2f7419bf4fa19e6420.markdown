---
layout: post
title:  "Do Trajectories Encode Verb Meaning?"
date:   2022-07-02 02:42:16 -0400
categories: jekyll update
author: "D Ebert, C Sun, E Pavlick - arXiv preprint arXiv:2206.11953, 2022"
---
Distributional models learn representations of words from text, but are criticized for their lack of grounding, or the linking of text to the non-linguistic world. Grounded language models have had success in learning to connect concrete categories like nouns and adjectives to the world via images and videos, but can struggle to isolate the meaning of the verbs themselves from the context in which they typically occur. In this paper, we investigate the extent to which trajectories (ie the position and rotation …
Cites: ‪Experience grounds language‬  