--- 
layout: post 
title: "IERL: Interpretable Ensemble Representation Learning-Combining CrowdSourced Knowledge and Distributed Semantic Representations" 
date: 2023-01-10 01:37:31 -0400 
categories: jekyll update 
author: "Y Zi, K Roy, V Narayanan, M Gaur, A Sheth - 2023" 
--- 
Abstract Large Language Models (LLMs) encode meanings of words in the form of distributed semantics. Distributed semantics capture common statistical patterns among language tokens (words, phrases, and sentences) from large amounts of data. LLMs perform exceedingly well across General Language Understanding Evaluation (GLUE) tasks designed to test a model s understanding of the meanings of the input tokens. However, recent studies have shown that LLMs tend to generate  Cites: Emergent abilities of large language models