--- 
layout: post 
title: "LM vs LM: Detecting Factual Errors via Cross Examination" 
date: 2023-05-25 03:51:47 -0400 
categories: jekyll update 
author: "R Cohen, M Hamri, M Geva, A Globerson - arXiv preprint arXiv:2305.13281, 2023" 
--- 
A prominent weakness of modern language models (LMs) is their tendency to generate factually incorrect text, which hinders their usability. A natural question is whether such factual errors can be detected automatically. Inspired by truth-seeking mechanisms in law, we propose a factuality evaluation framework for LMs that is based on cross-examination. Our key idea is that an incorrect claim is likely to result in inconsistency with other claims that the model generates. To discover such Cites: Answering Questions by Meta-Reasoning over Multiple Chains of