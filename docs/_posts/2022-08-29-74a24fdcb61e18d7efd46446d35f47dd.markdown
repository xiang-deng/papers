--- 
layout: post 
title: "Shortcut Learning of Large Language Models in Natural Language Understanding: A Survey" 
date: 2022-08-29 19:44:55 -0400 
categories: jekyll update 
author: "M Du, F He, N Zou, D Tao, X Hu - arXiv preprint arXiv:2208.11857, 2022" 
--- 
Large language models (LLMs) have achieved state-of-the-art performance on a series of natural language understanding tasks. However, these LLMs might rely on dataset bias and artifacts as shortcuts for prediction. This has significantly hurt their Out-of-Distribution (OOD) generalization and adversarial robustness. In this paper, we provide a review of recent developments that address the robustness challenge of LLMs. We first introduce the concepts and robustness challenge of LLMs. We then Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList