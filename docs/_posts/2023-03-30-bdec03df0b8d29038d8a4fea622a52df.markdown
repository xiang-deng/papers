--- 
layout: post 
title: "Strong Prediction: Language model surprisal explains multiple N400 effects" 
date: 2023-03-30 05:18:06 -0400 
categories: jekyll update 
author: "JA Michaelov, MD Bardolph, CK Van Petten" 
--- 
Theoretical accounts of the N400 are divided as to whether the amplitude of the N400 response to a stimulus reflects the extent to which the stimulus was predicted, the extent to which the stimulus is semantically similar to its preceding context, or both. We use state-of-the-art machine learning tools to investigate which of these three accounts is best supported by the evidence. GPT-3, a neural language model (LM) trained to compute the conditional probability of any word based on the words Cites: Byte Pair Encoding is Suboptimal for Language Model Pretraining