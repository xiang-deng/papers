--- 
layout: post 
title: "Learning multimodal relationship interaction for visual relationship detection" 
date: 2022-06-18 03:19:09 -0400 
categories: jekyll update 
author: "Z Liu, WS Zheng - Pattern Recognition, 2022" 
--- 
Visual relationship detection aims to recognize visual relationships in scenes as triplets< subject-predicate-object>. Previous works have shown remarkable progress by introducing multimodal features, external linguistics, scene context, etc. Due to the loss of informative multimodal hyper-relations (ie relations of relationships), the meaningful contexts of relationships are not fully captured yet, which limits the reasoning ability. In this work, we propose a Multimodal Similarity Guided Cites: Neural motifs: Scene graph parsing with global context