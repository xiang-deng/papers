---
layout: post
title:  "ConsistTL: Modeling Consistency in Transfer Learning for Low-Resource Neural Machine Translation"
date:   2022-12-13 08:01:52 -0400
categories: jekyll update
author: "Z Li, X Liu, DF Wong, LS Chao, M Zhang - arXiv preprint arXiv:2212.04262, 2022"
---
Transfer learning is a simple and powerful method that can be used to boost model performance of low-resource neural machine translation (NMT). Existing transfer learning methods for NMT are static, which simply transfer knowledge from a parent model to a child model once via parameter initialization. In this paper, we propose a novel transfer learning method for NMT, namely ConsistTL, which can continuously transfer knowledge from the parent model during the training of the child model …
Cites: ‪Semi-supervised sequence modeling with cross-view training‬