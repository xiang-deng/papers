--- 
layout: post 
title: "CogKTR: A Knowledge-Enhanced Text Representation Toolkit for Natural Language Understanding" 
date: 2023-02-11 02:41:58 -0400 
categories: jekyll update 
author: "Z Jin, T Men, H Yuan, Y Zhou, P Cao, Y Chen, Z Xue - Proceedings of the The , 2022" 
--- 
As the first step of modern natural language processing, text representation encodes discrete texts as continuous embeddings. Pre-trained language models (PLMs) have demonstrated strong ability in text representation and significantly promoted the development of natural language understanding (NLU). However, existing PLMs represent a text solely by its context, which is not enough to support knowledge-intensive NLU tasks. Knowledge is power, and fusing external knowledge explicitly Cites: Emergent linguistic structure in artificial neural networks trained by