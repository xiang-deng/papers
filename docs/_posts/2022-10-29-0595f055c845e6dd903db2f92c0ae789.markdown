--- 
layout: post 
title: "Performance Comparison of Improved Common Sequence to Sequence Paraphrasing Models" 
date: 2022-10-29 01:49:44 -0400 
categories: jekyll update 
author: "D Widjaja, T Fustian, H Lucky, D Suhartono - 2022 3rd International Conference on , 2022" 
--- 
Paraphrase generation is a widely known and complex task in the field of Natural Language Processing (NLP). With a variety of paraphrasing models, many researchers have developed their own methodology to overcome this task with better efficiency and quality paraphrases. In this paper, Text-to-Text Transfer Transformer (T5) and Back-Translation guided multi-round Paraphrase Generation (BTmPG), two popular algorithms in paraphrasing models, are compared. Paired paraphrased Cites: Neural Syntactic Preordering for Controlled Paraphrase Generation