--- 
layout: post 
title: "OPAL: Ontology-Aware Pretrained Language Model for End-to-End Task-Oriented Dialogue" 
date: 2022-09-17 00:49:30 -0400 
categories: jekyll update 
author: "Z Chen, Y Liu, L Chen, S Zhu, M Wu, K Yu - arXiv preprint arXiv:2209.04595, 2022" 
--- 
This paper presents an ontology-aware pretrained language model (OPAL) for end-to-end task-oriented dialogue (TOD). Unlike chit-chat dialogue models, task-oriented dialogue models fulfill at least two task-specific modules: dialogue state tracker (DST) and response generator (RG). The dialogue state consists of the domain-slot-value triples, which are regarded as the user s constraints to search the domain-related databases. The large-scale task-oriented dialogue data with the annotated Cites: Search-based Neural Structured Learning for Sequential Question