--- 
layout: post 
title: "Training Language Models with Natural Language Feedback" 
date: 2022-05-07 02:52:45 -0400 
categories: jekyll update 
author: "J Scheurer, JA Campos, JS Chan, A Chen, K Cho - arXiv preprint arXiv , 2022" 
--- 
Pretrained language models often do not perform tasks in ways that are in line with our preferences, eg, generating offensive text or factually incorrect summaries. Recent work approaches the above issue by learning from a simple form of human evaluation: comparisons between pairs of model-generated task outputs. Comparison feedback conveys limited information about human preferences per human evaluation. Here, we propose to learn from natural language feedback, which Cites: Realtoxicityprompts: Evaluating neural toxic degeneration in