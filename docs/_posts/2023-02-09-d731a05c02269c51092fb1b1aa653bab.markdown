--- 
layout: post 
title: "Measuring The Impact Of Programming Language Distribution" 
date: 2023-02-09 01:30:47 -0400 
categories: jekyll update 
author: "G Orlanski, K Xiao, X Garcia, J Hui, J Howland - arXiv preprint arXiv , 2023" 
--- 
Current benchmarks for evaluating neural code models focus on only a small subset of programming languages, excluding many popular languages such as Go or Rust. To ameliorate this issue, we present the BabelCode framework for execution-based evaluation of any benchmark in any language. BabelCode enables new investigations into the qualitative performance of models memory, runtime, and individual test case results. Additionally, we present a new code translation dataset Cites: Mconala: a benchmark for code generation from multiple natural