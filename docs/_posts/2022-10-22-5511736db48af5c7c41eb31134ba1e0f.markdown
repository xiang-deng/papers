---
layout: post
title:  "Model Interpretability for Natural Language Processing Applications"
date:   2022-10-22 02:20:44 -0400
categories: jekyll update
author: "G Chrysostomou - 2022"
---
This thesis focuses on model interpretability, an area concerned with under-standing model predictions in Natural Language Processing (NLP) tasks. The increase in adoption of opaque models, such as BERT, leads to an increasing need for explaining their predictions. This is typically performed by extract-ing a sub-set of the input, that is indicative of the true reasoning behind the model s prediction (ie a faithful explanation or rationale). Whilst there are multiple approaches in literature for …
Cites: ‪ERASER: A benchmark to evaluate rationalized NLP models‬