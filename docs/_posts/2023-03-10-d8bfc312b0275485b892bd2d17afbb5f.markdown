--- 
layout: post 
title: "Multi-resolution Interpretation and Diagnostics Tool for Natural Language Classifiers" 
date: 2023-03-10 16:03:48 -0400 
categories: jekyll update 
author: "P Jalali, N Zhou, Y Yu - arXiv preprint arXiv:2303.03542, 2023" 
--- 
Developing explainability methods for Natural Language Processing (NLP) models is a challenging task, for two main reasons. First, the high dimensionality of the data (large number of tokens) results in low coverage and in turn small contributions for the top tokens, compared to the overall model performance. Second, owing to their textual nature, the input variables, after appropriate transformations, are effectively binary (presence or absence of a token in an observation), making the input-output  Cites: No Explainability without Accountability: An Empirical Study of