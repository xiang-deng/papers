---
layout: post
title:  "Incorporating Knowledge into Document Summarization: an Application of Prefix-Tuning on GPT-2"
date:   2023-02-01 14:37:22 -0400
categories: jekyll update
author: "C Chen, WE Zhang - arXiv preprint arXiv:2301.11719, 2023"
---
Despite the great development of document summarization techniques nowadays, factual inconsistencies between the generated summaries and the original text still occur from time to time. This paper proposes a prefix-tuning-based approach that uses a set of trainable continuous prefix prompt together with discrete prompts to aid model generation, which makes a significant impact on both CNN/Daily Mail and XSum summaries generated using GPT-2. The improvements on fact preservation in …
Cites: ‪Understanding Neural Abstractive Summarization Models via …‬