--- 
layout: post 
title: "Iron: Private Inference on Transformers" 
date: 2022-11-24 01:38:18 -0400 
categories: jekyll update 
author: "M Hao, H Li, HCPXG Xu, T Zhang" 
--- 
We initiate the study of private inference on Transformer-based models in the client-server setting, where clients have private inputs and servers hold proprietary models. Our main contribution is to provide several new secure protocols for matrix multiplication and complex non-linear functions like Softmax, GELU activations, and LayerNorm, which are critical components of Transformers. Specifically, we first propose a customized homomorphic encryption-based protocol for matrix  Cites: Well-read students learn better: On the importance of pre-training