--- 
layout: post 
title: "Disentangling Task Relations for Few-shot Text Classification via Self-Supervised Hierarchical Task Clustering" 
date: 2022-11-18 16:55:42 -0400 
categories: jekyll update 
author: "J Zha, Z Li, Y Wei, Y Zhang - arXiv preprint arXiv:2211.08588, 2022" 
--- 
Few-Shot Text Classification (FSTC) imitates humans to learn a new text classifier efficiently with only few examples, by leveraging prior knowledge from historical tasks. However, most prior works assume that all the tasks are sampled from a single data source, which cannot adapt to real-world scenarios where tasks are heterogeneous and lie in different distributions. As such, existing methods may suffer from their globally knowledge-shared mechanisms to handle the task heterogeneity  Cites: Bert: Pre-training of deep bidirectional transformers for language