---
layout: post
title:  "Measuring and mitigating language model biases in abusive language detection"
date:   2023-02-11 02:41:58 -0400
categories: jekyll update
author: "R Song, F Giunchiglia, Y Li, L Shi, H Xu - Information Processing & Management, 2023"
---
Warning: This paper contains abusive samples that may cause discomfort to readers. Abusive language on social media reinforces prejudice against an individual or a specific group of people, which greatly hampers freedom of expression. With the rise of large-scale pre-trained language models, classification based on pre-trained language models has gradually become a paradigm for automatic abusive language detection. However, the effect of stereotypes inherent in language models on the …
Cites: ‪The risk of racial bias in hate speech detection‬