--- 
layout: post 
title: "Towards Linguistically Informed Multi-Objective Pre-Training for Natural Language Inference" 
date: 2022-12-20 02:26:19 -0400 
categories: jekyll update 
author: "M Pielka, S Schmidt, L Pucknat, R Sifa - arXiv preprint arXiv:2212.07428, 2022" 
--- 
We introduce a linguistically enhanced combination of pre-training methods for transformers. The pre-training objectives include POS-tagging, synset prediction based on semantic knowledge graphs, and parent prediction based on dependency parse trees. Our approach achieves competitive results on the Natural Language Inference task, compared to the state of the art. Specifically for smaller models, the method results in a significant performance boost, emphasizing the fact that  Cites: Stanza: A python natural language processing toolkit for many