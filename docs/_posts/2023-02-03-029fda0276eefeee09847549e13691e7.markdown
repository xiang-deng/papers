---
layout: post
title:  "Improving Few-Shot Generalization by Exploring and Exploiting Auxiliary Data"
date:   2023-02-03 14:16:33 -0400
categories: jekyll update
author: "A Albalak, C Raffel, WY Wang - arXiv preprint arXiv:2302.00674, 2023"
---
Few-shot learning involves learning an effective model from only a few labeled datapoints. The use of a small training set makes it difficult to avoid overfitting but also makes few-shot learning applicable to many important real-world settings. In this work, we focus on Few-shot Learning with Auxiliary Data (FLAD), a training paradigm that assumes access to auxiliary data during few-shot learning in hopes of improving generalization. Introducing auxiliary data during few-shot learning leads to essential …
Cites: ‪Exploring and predicting transferability across nlp tasks‬