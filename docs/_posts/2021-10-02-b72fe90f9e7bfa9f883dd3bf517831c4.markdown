--- 
layout: post 
title: "Paradigm Shift in Natural Language Processing" 
date: 2021-10-02 23:22:46 -0400 
categories: jekyll update 
author: "T Sun, X Liu, X Qiu, X Huang - arXiv preprint arXiv:2109.12575, 2021" 
--- 
In the era of deep learning, modeling for most NLP tasks has converged to several mainstream paradigms. For example, we usually adopt the sequence labeling paradigm to solve a bundle of tasks such as POS-tagging, NER, Chunking, and adopt the classification paradigm to solve tasks like sentiment analysis. With the rapid progress of pre-trained language models, recent years have observed a rising trend of Paradigm Shift, which is solving one NLP task by reformulating it as another Cites: Zero-shot relation extraction via reading comprehension