--- 
layout: post 
title: "Investigating the Robustness of Natural Language Generation from Logical Forms via Counterfactual Samples" 
date: 2022-10-20 02:20:28 -0400 
categories: jekyll update 
author: "C Liu, L Gan, K Kuang, F Wu - arXiv preprint arXiv:2210.08548, 2022" 
--- 
The aim of Logic2Text is to generate controllable and faithful texts conditioned on tables and logical forms, which not only requires a deep understanding of the tables and logical forms, but also warrants symbolic reasoning over the tables. State-of-the-art methods based on pre-trained models have achieved remarkable performance on the standard test dataset. However, we question whether these methods really learn how to perform logical reasoning, rather than just relying on the spurious  Cites: Unifiedskg: Unifying and multi-tasking structured knowledge