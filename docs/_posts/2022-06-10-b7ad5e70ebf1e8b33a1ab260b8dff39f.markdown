---
layout: post
title:  "The Two Dimensions of Worst-Case Training and Their Integrated Effect for Out-of-Domain Generalization"
date:   2022-06-10 22:27:43 -0400
categories: jekyll update
author: "Z Huang, H Wang, D Huang, YJ Lee, EP Xing -  of the IEEE/CVF Conference on , 2022"
---
Training with an emphasis on  hard-to-learn  components of the data has been proven as an effective method to improve the generalization of machine learning models, especially in the settings where robustness (eg, generalization across distributions) is valued. Existing literature discussing this  hard-to-learn  concept are mainly expanded either along the dimension of the samples or the dimension of the features. In this paper, we aim to introduce a simple view merging these two  Cites: " Why Should I Trust You?": Explaining the Predictions of Any