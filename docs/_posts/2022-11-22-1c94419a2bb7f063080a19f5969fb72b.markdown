--- 
layout: post 
title: "UniSumm: Unified Few-shot Summarization with Multi-Task Pre-Training and Prefix-Tuning" 
date: 2022-11-22 02:23:19 -0400 
categories: jekyll update 
author: "Y Chen, Y Liu, R Xu, Z Yang, C Zhu, M Zeng, Y Zhang - arXiv preprint arXiv , 2022" 
--- 
The diverse demands of different summarization tasks and their high annotation costs are driving a need for few-shot summarization. However, despite the emergence of many summarization tasks and datasets, the current training paradigm for few-shot summarization systems ignores potentially shareable knowledge in heterogeneous datasets. To this end, we propose\textsc {UniSumm}, a unified few-shot summarization model pre-trained with multiple summarization tasks and can be Cites: Few-shot learning for opinion summarization