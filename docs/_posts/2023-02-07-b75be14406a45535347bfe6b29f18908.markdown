--- 
layout: post 
title: "Improving Faithfulness by Augmenting Negative Summaries from Fake Documents" 
date: 2023-02-07 01:43:12 -0400 
categories: jekyll update 
author: "T Wang, F Ladhak, E Durmus, H He - Proceedings of the 2022 Conference on , 2022" 
--- 
Current abstractive summarization systems tend to hallucinate content that is unfaithful to the source document, posing a risk of misinformation. To mitigate hallucination, we must teach the model to distinguish hallucinated summaries from faithful ones. However, the commonly used maximum likelihood training does not disentangle factual errors from other model errors. To address this issue, we propose a back-translation-style approach to augment negative samples that mimic factual  Cites: BRIO: Bringing Order to Abstractive Summarization