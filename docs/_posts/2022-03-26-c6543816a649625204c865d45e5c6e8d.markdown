---
layout: post
title:  "Factual Consistency of Multilingual Pretrained Language Models"
date:   2022-03-26 03:19:20 -0400
categories: jekyll update
author: "C Fierro, A Sgaard - arXiv preprint arXiv:2203.11552, 2022"
---
Pretrained language models can be queried for factual knowledge, with potential applications in knowledge base acquisition and tasks that require inference. However, for that, we need to know how reliable this knowledge is, and recent work has shown that monolingual English language models lack consistency when predicting factual knowledge, that is, they fill-in-the-blank differently for paraphrases describing the same fact. In this paper, we extend the analysis of consistency to a Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList