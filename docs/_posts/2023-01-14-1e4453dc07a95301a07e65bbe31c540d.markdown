--- 
layout: post 
title: "Achieving and Understanding Out-of-Distribution Generaliza-tion in Systematic Reasoning in Small-Scale Transformers" 
date: 2023-01-14 01:50:54 -0400 
categories: jekyll update 
author: "AJ Nam, M Abdool, T Maxfield, JL McClelland - arXiv preprint arXiv:2210.03275, 2022" 
--- 
Out-of-distribution generalization (OODG) is a longstanding challenge for neural networks. This challenge is quite apparent in tasks with well-defined variables and rules, where explicit use of the rules could solve problems independently of the particular values of the variables, but networks tend to be tied to the range of values sampled in their training data. Large transformer-based language models have pushed the boundaries on how well neural networks can solve previously unseen  Cites: Train short, test long: Attention with linear biases enables input