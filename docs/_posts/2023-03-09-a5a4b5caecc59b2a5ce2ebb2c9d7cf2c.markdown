--- 
layout: post 
title: "Model Explanation Disparities as a Fairness Diagnostic" 
date: 2023-03-09 05:52:34 -0400 
categories: jekyll update 
author: "PW Chang, L Fishman, S Neel - arXiv preprint arXiv:2303.01704, 2023" 
--- 
In recent years, there has been a flurry of research focusing on the fairness of machine learning models, and in particular on quantifying and eliminating bias against subgroups. One prominent line of work generalizes the notion of subgroups beyond simple discrete classes by introducing the notion of a rich subgroup, and seeks to train models that are calibrated or equalize error rates with respect to these richer subgroup classes. Largely orthogonally, there has been growing recognition of  Cites: Why Should I Trust You? : Explaining the Predictions of Any