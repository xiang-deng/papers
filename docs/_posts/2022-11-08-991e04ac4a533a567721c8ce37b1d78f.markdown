--- 
layout: post 
title: "Towards Solving NLP Tasks with Optimal Transport Loss" 
date: 2022-11-08 00:47:36 -0400 
categories: jekyll update 
author: "R Bhardwaj, T Vaidya, S Poria - Journal of King Saud University-Computer and , 2022" 
--- 
Loss functions are essential to computing the divergence of a model s predicted distribution from the ground truth. Such functions play a vital role in machine learning algorithms as they steer the learning process. Most common loss functions in natural language processing (NLP), such as Kullback-Leibler (KL) and JensenShannon (JS) divergences, do not base their computations on the properties of label coordinates. Label coordinates can help encode the inter-label relationships. For the Cites: Well-Read Students Learn Better: On the Importance of Pre