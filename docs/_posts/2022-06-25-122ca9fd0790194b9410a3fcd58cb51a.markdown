---
layout: post
title:  "Lexical semantics enhanced neural word embeddings"
date:   2022-06-25 08:25:58 -0400
categories: jekyll update
author: "D Yang, N Li, L Zou, H Ma - Knowledge-Based Systems, 2022"
---
Current breakthroughs in natural language processing have benefited dramatically from-neural language models, through which distributional semantics can leverage neural data representations to facilitate downstream applications. Since neural embeddings use context prediction on word co-occurrences to yield dense vectors, they are inevitably prone to capture more semantic association than semantic similarity. To improve vector space models in deriving semantic similarity, we post 
Cites: Knowledge enhanced contextual word representations