--- 
layout: post 
title: "Network Expansion for Practical Training Acceleration" 
date: 2023-05-23 02:52:43 -0400 
categories: jekyll update 
author: "N Ding, Y Tang, K Han, C Xu, Y Wang - Proceedings of the IEEE/CVF Conference on , 2023" 
--- 
Recently, the sizes of deep neural networks and training datasets both increase drastically to pursue better performance in a practical sense. With the prevalence of transformer-based models in vision tasks, even more pressure is laid on the GPU platforms to train these heavy models, which consumes a large amount of time and computing resources as well. Therefore, it s crucial to accelerate the training process of deep neural networks. In this paper, we propose a general network expansion Cites: bert2BERT: Towards Reusable Pretrained Language Models