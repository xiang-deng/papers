--- 
layout: post 
title: "Can Transformers Process Recursive Nested Constructions, Like Humans?" 
date: 2022-10-15 02:59:22 -0400 
categories: jekyll update 
author: "Y Lakretz, T Desbordes, D Hupkes, S Dehaene - Proceedings of the 29th International , 2022" 
--- 
Recursive processing is considered a hallmark of human linguistic abilities. A recent study evaluated recursive processing in recurrent neural language models (RNN-LMs) and showed that such models perform below chance level on embedded dependencies within nested constructionsa prototypical example of recursion in natural language. Here, we study if state-of-the-art Transformer LMs do any better. We test eight different Transformer LMs on two different types of nested Cites: RNNs can generate bounded hierarchical languages with optimal