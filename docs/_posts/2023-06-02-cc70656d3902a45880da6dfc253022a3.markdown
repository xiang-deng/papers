---
layout: post
title:  "Dynamic Sparsity Is Channel-Level Sparsity Learner"
date:   2023-06-02 15:36:55 -0400
categories: jekyll update
author: "L Yin, G Li, M Fang, L Shen, T Huang, Z Wang… - arXiv preprint arXiv …, 2023"
---
Sparse training has received an upsurging interest in machine learning due to its tantalizing saving potential for the entire training process as well as inference. Dynamic sparse training (DST), as a leading sparse training approach, can train deep neural networks at high sparsity from scratch to match the performance of their dense counterparts. However, most if not all DST prior arts demonstrate their effectiveness on unstructured sparsity with highly irregular sparse patterns, which …
Cites: ‪Beyond the imitation game: Quantifying and extrapolating the …‬