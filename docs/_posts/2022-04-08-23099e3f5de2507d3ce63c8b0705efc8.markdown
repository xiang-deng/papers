---
layout: post
title:  "Multilinguals at SemEval-2022 Task 11: Transformer Based Architecture for Complex NER"
date:   2022-04-08 14:57:15 -0400
categories: jekyll update
author: "A Pandey, S Daw, V Pudi - arXiv preprint arXiv:2204.02173, 2022"
---
We investigate the task of complex NER for the English language. The task is non- trivial due to the semantic ambiguity of the textual structure and the rarity of occurrence of such entities in the prevalent literature. Using pre-trained language models such as BERT, we obtain a competitive performance on this task. We qualitatively analyze the performance of multiple architectures for this task. All our models are able to outperform the baseline by a significant margin. Our best Cites: SciREX: A challenge dataset for document-level information