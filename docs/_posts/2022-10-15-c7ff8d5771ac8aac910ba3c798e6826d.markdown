--- 
layout: post 
title: "Few-Shot Table Understanding: A Benchmark Dataset and Pre-Training Baseline" 
date: 2022-10-15 02:59:22 -0400 
categories: jekyll update 
author: "R Liu, S Yuan, A Dai, L Shen, T Zhu, M Chen, X He - Proceedings of the 29th , 2022" 
--- 
Few-shot table understanding is a critical and challenging problem in real-world scenario as annotations over large amount of tables are usually costly. Pre-trained language models (PLMs), which have recently flourished on tabular data, have demonstrated their effectiveness for table understanding tasks. However, few-shot table understanding is rarely explored due to the deficiency of public table pre-training corpus and well-defined downstream benchmark tasks, especially in Cites: bailin wang, Yi Chern Tan, Xinyi Yang, Dragomir Radev, richard