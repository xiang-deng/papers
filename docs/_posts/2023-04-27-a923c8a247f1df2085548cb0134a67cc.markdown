--- 
layout: post 
title: "Stability analysis of stochastic gradient descent for homogeneous neural networks and linear classifiers" 
date: 2023-04-27 01:18:20 -0400 
categories: jekyll update 
author: "AL Paquin, B Chaib-draa, P Gigure - Neural Networks, 2023" 
--- 
We prove new generalization bounds for stochastic gradient descent when training classifiers with invariances. Our analysis is based on the stability framework and covers both the convex case of linear classifiers and the non-convex case of homogeneous neural networks. We analyze stability with respect to the normalized version of the loss function used for training. This leads to investigating a form of angle-wise stability instead of euclidean stability in weights. For neural networks, the  Cites: The break-even point on optimization trajectories of deep neural