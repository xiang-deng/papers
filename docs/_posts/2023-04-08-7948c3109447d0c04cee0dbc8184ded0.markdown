---
layout: post
title:  "Neural Comprehension: Language Models with Compiled Neural Networks"
date:   2023-04-08 04:35:01 -0400
categories: jekyll update
author: "Y Weng, M Zhu, F Xia, B Li, S He, K Liu, J Zhao - arXiv preprint arXiv:2304.01665, 2023"
---
Language models have achieved impressive results in natural language processing tasks, but their ability to perform symbolic operations and arithmetic operations, remains limited, which attribute to their learn the rules implicitly from data. We explore how to incorporate compiled neural networks (CoNNs) which weight is specially designed, into the architecture of language models to enable the language model trained by gradient to obtain fully rule comprehension ability. The …
Cites: ‪Challenging BIG-Bench tasks and whether chain-of-thought can …‬