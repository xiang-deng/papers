--- 
layout: post 
title: "Pretraining Language Models with Human Preferences" 
date: 2023-02-23 04:09:00 -0400 
categories: jekyll update 
author: "T Korbak, K Shi, A Chen, R Bhalerao, CL Buckley - arXiv preprint arXiv , 2023" 
--- 
Language models (LMs) are pretrained to imitate internet text, including content that would violate human preferences if generated by an LM: falsehoods, offensive comments, personally identifiable information, low-quality or buggy code, and more. Here, we explore alternative objectives for pretraining LMs in a way that also guides them to generate text aligned with human preferences. We benchmark five objectives for pretraining with human feedback across three tasks and study how they affect the Cites: Quark: Controllable text generation with reinforced unlearning