--- 
layout: post 
title: "Contrastive Data and Learning for Natural Language Processing" 
date: 2022-07-16 11:01:18 -0400 
categories: jekyll update 
author: "R Zhang, Y Ji, Y Zhang, RJ Passonneau - Proceedings of the 2022 Conference of the , 2022" 
--- 
Current NLP models heavily rely on effective representation learning algorithms. Contrastive learning is one such technique to learn an embedding space such that similar data sample pairs have close representations while dissimilar samples stay far apart from each other. It can be used in supervised or unsupervised settings using different loss functions to produce task-specific or general-purpose representations. While it has originally enabled the success for vision tasks, recent years have seen a Cites: Prompting contrastive explanations for commonsense reasoning