--- 
layout: post 
title: "Assessing Hidden Risks of LLMs: An Empirical Study on Robustness, Consistency, and Credibility" 
date: 2023-05-19 23:52:25 -0400 
categories: jekyll update 
author: "W Ye, M Ou, T Li, X Ma, Y Yanggong, S Wu, J Fu - arXiv preprint arXiv , 2023" 
--- 
The recent popularity of large language models (LLMs) has brought a significant impact to boundless fields, particularly through their open-ended ecosystem such as the APIs, open-sourced models, and plugins. However, with their widespread deployment, there is a general lack of research that thoroughly discusses and analyzes the potential risks concealed. In that case, we intend to conduct a preliminary but pioneering study covering the robustness, consistency, and credibility Cites: Universal adversarial triggers for attacking and analyzing NLP