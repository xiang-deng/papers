--- 
layout: post 
title: "Curiosity in hindsight" 
date: 2022-11-24 01:38:18 -0400 
categories: jekyll update 
author: "D Jarrett, C Tallec, F Altch, T Mesnard, R Munos - arXiv preprint arXiv , 2022" 
--- 
Consider the exploration in sparse-reward or reward-free environments, such as Montezuma s Revenge. The curiosity-driven paradigm dictates an intuitive technique: At each step, the agent is rewarded for how much the realized outcome differs from their predicted outcome. However, using predictive error as intrinsic motivation is prone to fail in stochastic environments, as the agent may become hopelessly drawn to high-entropy areas of the state-action space, such as a noisy TV. Therefore it is Cites: Explore, discover and learn: Unsupervised discovery of state