--- 
layout: post 
title: "A Close Look into the Calibration of Pre-trained Language Models" 
date: 2022-11-04 15:58:33 -0400 
categories: jekyll update 
author: "Y Chen, L Yuan, G Cui, Z Liu, H Ji - arXiv preprint arXiv:2211.00151, 2022" 
--- 
Pre-trained language models (PLMs) achieve remarkable performance on many downstream tasks, but may fail in giving reliable estimates of their predictive uncertainty. Given the lack of a comprehensive understanding of PLMs calibration, we take a close look into this new research problem, aiming to answer two questions:(1) Do PLMs learn to become calibrated in the training process?(2) How effective are existing calibration methods? For the first question, we conduct fine Cites: Can Explanations Be Useful for Calibrating Black Box Models?