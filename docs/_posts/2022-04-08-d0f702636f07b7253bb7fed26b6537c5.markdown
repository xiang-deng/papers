---
layout: post
title:  "Socratic Models: Composing Zero-Shot Multimodal Reasoning with Language"
date:   2022-04-08 14:57:15 -0400
categories: jekyll update
author: "A Zeng, A Wong, S Welker, K Choromanski, F Tombari - arXiv preprint arXiv , 2022"
---
Large foundation models can exhibit unique capabilities depending on the domain of data they are trained on. While these domains are generic, they may only barely overlap. For example, visual-language models (VLMs) are trained on Internet-scale image captions, but large language models (LMs) are further trained on Internet- scale text with no images (eg from spreadsheets, to SAT questions). As a result, these models store different forms of commonsense knowledge across different Cites: MERLOT Reserve: Neural Script Knowledge through Vision and