--- 
layout: post 
title: "Contextualization and Generalization in Entity and Relation Extraction" 
date: 2022-06-19 07:39:02 -0400 
categories: jekyll update 
author: "B Taill - arXiv preprint arXiv:2206.07558, 2022" 
--- 
During the past decade, neural networks have become prominent in Natural Language Processing (NLP), notably for their capacity to learn relevant word representations from large unlabeled corpora. These word embeddings can then be transferred and finetuned for diverse end applications during a supervised training phase. More recently, in 2018, the transfer of entire pretrained Language Models and the preservation of their contextualization capacities enabled to reach Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList