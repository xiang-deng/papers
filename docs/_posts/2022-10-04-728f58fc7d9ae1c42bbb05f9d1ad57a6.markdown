--- 
layout: post 
title: "InFi: End-to-End Learning to Filter Input for Resource-Efficiency in Mobile-Centric Inference" 
date: 2022-10-04 00:49:37 -0400 
categories: jekyll update 
author: "M Yuan, L Zhang, F He, X Tong, MH Song, XY Li - arXiv preprint arXiv:2209.13873, 2022" 
--- 
Mobile-centric AI applications have high requirements for resource-efficiency of model inference. Input filtering is a promising approach to eliminate the redundancy so as to reduce the cost of inference. Previous efforts have tailored effective solutions for many applications, but left two essential questions unanswered:(1) theoretical filterability of an inference workload to guide the application of input filtering techniques, thereby avoiding the trial-and-error cost for resource-constrained mobile Cites: Mobilebert: a compact task-agnostic bert for resource-limited devices