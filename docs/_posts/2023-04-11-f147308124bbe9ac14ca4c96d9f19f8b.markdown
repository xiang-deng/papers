--- 
layout: post 
title: "Do the Rewards Justify the Means? Measuring Trade-Offs Between Rewards and Ethical Behavior in the MACHIAVELLI Benchmark" 
date: 2023-04-11 07:02:19 -0400 
categories: jekyll update 
author: "A Pan, CJ Shern, A Zou, N Li, S Basart, T Woodside - arXiv preprint arXiv , 2023" 
--- 
Artificial agents have traditionally been trained to maximize reward, which may incentivize power-seeking and deception, analogous to how next-token prediction in language models (LMs) may incentivize toxicity. So do agents naturally learn to be Machiavellian? And how do we measure these behaviors in general-purpose models such as GPT-4? Towards answering these questions, we introduce MACHIAVELLI, a benchmark of 134 Choose-Your-Own-Adventure games containing Cites: Holistic evaluation of language models