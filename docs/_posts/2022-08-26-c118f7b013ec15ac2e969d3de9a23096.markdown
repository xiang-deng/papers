--- 
layout: post 
title: "UKP-SQuARE v2 Explainability and Adversarial Attacks for Trustworthy QA" 
date: 2022-08-26 23:24:20 -0400 
categories: jekyll update 
author: "R Sachdeva, HPT Baumgrtner, S Tariverdian - arXiv preprint arXiv , 2022" 
--- 
Question Answering (QA) systems are increasingly deployed in applications where they support real-world decisions. However, state-of-the-art models rely on deep neural networks, which are difficult to interpret by humans. Inherently interpretable models or post hoc explainability methods can help users to comprehend how a model arrives at its prediction and, if successful, increase their trust in the system. Furthermore, researchers can leverage these insights to develop new methods that Cites: Pathologies of neural models make interpretations difficult