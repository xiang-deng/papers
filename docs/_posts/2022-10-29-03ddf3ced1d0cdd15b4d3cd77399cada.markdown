--- 
layout: post 
title: "Explaining neural activity in human listeners with deep learning via natural language processing of narrative text" 
date: 2022-10-29 01:49:44 -0400 
categories: jekyll update 
author: "AG Russo, A Ciarlo, S Ponticorvo, F Di Salle - Scientific Reports, 2022" 
--- 
Deep learning (DL) approaches may also inform the analysis of human brain activity. Here, a state-of-art DL tool for natural language processing, the Generative Pre-trained Transformer version 2 (GPT-2), is shown to generate meaningful neural encodings in functional MRI during narrative listening. Linguistic features of word unpredictability (surprisal) and contextual importance (saliency) were derived from the GPT-2 applied to the text of a 12-min narrative. Segments of variable duration Cites: Bert: Pre-training of deep bidirectional transformers for language