---
layout: post
title:  "Principle-Driven Self-Alignment of Language Models from Scratch with Minimal Human Supervision"
date:   2023-05-09 11:33:00 -0400
categories: jekyll update
author: "Z Sun, Y Shen, Q Zhou, H Zhang, Z Chen, D Cox… - arXiv preprint arXiv …, 2023"
---
Recent AI-assistant agents, such as ChatGPT, predominantly rely on supervised fine-tuning (SFT) with human annotations and reinforcement learning from human feedback (RLHF) to align the output of large language models (LLMs) with human intentions, ensuring they are helpful, ethical, and reliable. However, this dependence can significantly constrain the true potential of AI-assistant agents due to the high cost of obtaining human supervision and the related issues on quality, reliability …
Cites: ‪Beyond the imitation game: Quantifying and extrapolating the …‬