--- 
layout: post 
title: "Counterfactual Recipe Generation: Exploring Compositional Generalization in a Realistic Scenario" 
date: 2022-10-24 23:22:19 -0400 
categories: jekyll update 
author: "X Liu, Y Feng, J Tang, C Hu, D Zhao - arXiv preprint arXiv:2210.11431, 2022" 
--- 
People can acquire knowledge in an unsupervised manner by reading, and compose the knowledge to make novel combinations. In this paper, we investigate whether pretrained language models can perform compositional generalization in a realistic setting: recipe generation. We design the counterfactual recipe generation task, which asks models to modify a base recipe according to the change of an ingredient. This task requires compositional generalization at two levels: the surface  Cites: Compositional generalization and natural language variation: Can