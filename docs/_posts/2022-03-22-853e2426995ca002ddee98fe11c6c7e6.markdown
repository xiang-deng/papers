--- 
layout: post 
title: "Few-Shot Natural Language Processing by Meta-Learning Without Labeled Data" 
date: 2022-03-22 03:39:25 -0400 
categories: jekyll update 
author: "T Bansal - 2022" 
--- 
Humans show a remarkable capability to accurately solve a wide range of problems efficiently--utilizing a limited amount of computation and experience. Deep learning models, by stark contrast, can be trained to be highly accurate on a narrow task while being highly inefficient in terms of the amount of compute and data required to reach that accuracy. Within natural language processing (NLP), recent breakthroughs in unsupervised pretraining have enabled reusable models that can be applied to Cites: Dreca: A general task augmentation strategy for few-shot natural