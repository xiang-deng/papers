--- 
layout: post 
title: "TempoSum: Evaluating the Temporal Generalization of Abstractive Summarization" 
date: 2023-05-06 06:19:24 -0400 
categories: jekyll update 
author: "CS Cheang, HP Chan, DF Wong, X Liu, Z Li, Y Sun - arXiv preprint arXiv , 2023" 
--- 
Recent pre-trained language models (PLMs) achieve promising results in existing abstractive summarization datasets. However, existing summarization benchmarks overlap in time with the standard pre-training corpora and finetuning datasets. Hence, the strong performance of PLMs may rely on the parametric knowledge that is memorized during pre-training and fine-tuning. Moreover, the knowledge memorized by PLMs may quickly become outdated, which affects the generalization Cites: Asking and Answering Questions to Evaluate the Factual