---
layout: post
title:  "MAWT: Multi-Attention-Weight Transformers"
date:   2023-04-06 06:45:39 -0400
categories: jekyll update
author: "ED Askin - 2023"
---
Transformers are machine learning models designed to learn and predict sequential and structured data, which are crucial to tasks such as neural machine translation and semantic parsing. They have become state-of-the-art engines for both of these tasks and much research in natural language processing is devoted to increasing their performance by introducing modifications to their architectures. In light of this trend, this thesis introduces a new Transformer architecture called MAWT: Multi …
Cites: ‪Long short-term memory-networks for machine reading‬