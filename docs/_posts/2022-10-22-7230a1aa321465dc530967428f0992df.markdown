--- 
layout: post 
title: "Why Should Adversarial Perturbations be Imperceptible? Rethink the Research Paradigm in Adversarial NLP" 
date: 2022-10-22 02:20:44 -0400 
categories: jekyll update 
author: "Y Chen, H Gao, G Cui, F Qi, L Huang, Z Liu, M Sun - arXiv preprint arXiv:2210.10683, 2022" 
--- 
Textual adversarial samples play important roles in multiple subfields of NLP research, including security, evaluation, explainability, and data augmentation. However, most work mixes all these roles, obscuring the problem definitions and research goals of the security role that aims to reveal the practical concerns of NLP models. In this paper, we rethink the research paradigm of textual adversarial samples in security scenarios. We discuss the deficiencies in previous work and  Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList