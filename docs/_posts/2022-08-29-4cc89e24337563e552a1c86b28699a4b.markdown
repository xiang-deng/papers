--- 
layout: post 
title: "Semantic Similarity Measure for Topic Modeling Using Latent Dirichlet Allocation and Collapsed Gibbs Sampling" 
date: 2022-08-29 19:44:55 -0400 
categories: jekyll update 
author: "MO Ajinaja, OA Adetunmbi, CC Ugwu, PO Solomon - 2022" 
--- 
One of the key applications of Natural Language Processing (NLP) is to automatically extract topics from large volumes of text. Latent Dirichlet Allocation (LDA) technique is commonly used to extract topics based on word frequency from the pre-processed documents. A major issue of LDA is that the quality of topics extracted are poor if the document do not coherently discuss a single topic. However, Gibbs sampling uses word by word basis which changes the topic assignment of one  Cites: Beyond LDA: exploring supervised topic modeling for depression