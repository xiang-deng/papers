--- 
layout: post 
title: "Cross-Model Comparative Loss for Enhancing Neuronal Utility in Language Understanding" 
date: 2023-01-14 01:50:54 -0400 
categories: jekyll update 
author: "Y Zhu, L Pang, K Wu, Y Lan, H Shen, X Cheng - arXiv preprint arXiv:2301.03765, 2023" 
--- 
Current natural language understanding (NLU) models have been continuously scaling up, both in terms of model size and input context, introducing more hidden and input neurons. While this generally improves performance on average, the extra neurons do not yield a consistent improvement for all instances. This is because some hidden neurons are redundant, and the noise mixed in input neurons tends to distract the model. Previous work mainly focuses on extrinsically reducing low-utility Cites: Evaluation Paradigms in Question Answering