---
layout: post
title:  "ER-TEST: Evaluating Explanation Regularization Methods for NLP Models"
date:   2022-05-30 22:20:45 -0400
categories: jekyll update
author: "B Joshi, A Chan, Z Liu, S Nie, M Sanjabi, H Firooz - arXiv preprint arXiv , 2022"
---
Neural language models (NLMs ) reasoning processes are notoriously hard to explain. Recently, there has been much progress in automatically generating machine rationales of NLM behavior, but less in utilizing the rationales to improve NLM behavior. For the latter, explanation regularization (ER) aims to improve NLM generalization by pushing the machine rationales to align with human rationales. Whereas prior works primarily evaluate such ER models via in-distribution (ID)  Cites: Beyond Accuracy: Behavioral Testing of NLP Models with CheckList