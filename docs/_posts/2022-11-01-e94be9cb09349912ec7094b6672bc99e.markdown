--- 
layout: post 
title: "FedNLP: Benchmarking federated learning models for natural language processing tasks" 
date: 2022-11-01 03:49:43 -0400 
categories: jekyll update 
author: "BY Lin, C He, Z Zeng, H Wang, Y Huang, C Dupuy - 2022" 
--- 
Increasing concerns and regulations about data privacy and sparsity necessitate the study of privacy-preserving, decentralized learning methods for natural language processing (NLP) tasks. Federated learning (FL) provides promising approaches for a large number of clients (eg, personal devices or organizations) to collaboratively learn a shared global model to benefit all clients while allowing users to keep their data locally. Despite interest in studying FL methods for NLP tasks, a systematic Cites: Prefix-tuning: Optimizing continuous prompts for generation