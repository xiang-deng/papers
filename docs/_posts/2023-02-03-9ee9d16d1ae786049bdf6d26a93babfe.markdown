--- 
layout: post 
title: "Large Language Models Can Be Easily Distracted by Irrelevant Context" 
date: 2023-02-03 14:16:33 -0400 
categories: jekyll update 
author: "F Shi, X Chen, K Misra, N Scales, D Dohan, E Chi - arXiv preprint arXiv , 2023" 
--- 
Large language models have achieved impressive performance on various natural language processing tasks. However, so far they have been evaluated primarily on benchmarks where all information in the input context is relevant for solving the task. In this work, we investigate the distractibility of large language models, ie, how the model problem-solving accuracy can be influenced by irrelevant context. In particular, we introduce Grade-School Math with Irrelevant Context (GSM-IC), an Cites: Learning what is essential in questions