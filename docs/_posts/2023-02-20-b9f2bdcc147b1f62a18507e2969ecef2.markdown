--- 
layout: post 
title: "Shared Microexponents: A Little Shifting Goes a Long Way" 
date: 2023-02-20 23:17:05 -0400 
categories: jekyll update 
author: "B Rouhani, R Zhao, V Elango, R Shafipour, M Hall - arXiv preprint arXiv , 2023" 
--- 
This paper introduces Block Data Representations (BDR), a framework for exploring and evaluating a wide spectrum of narrow-precision formats for deep learning. It enables comparison of popular quantization standards, and through BDR, new formats based on shared microexponents (MX) are identified, which outperform other state-of-the-art quantization approaches, including narrow-precision floating-point and block floating-point. MX utilizes multiple levels of quantization scaling with ultra Cites: The case for 4-bit precision: k-bit Inference Scaling Laws