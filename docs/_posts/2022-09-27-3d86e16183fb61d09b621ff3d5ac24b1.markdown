--- 
layout: post 
title: "Representing Affect Information in Word Embeddings" 
date: 2022-09-27 02:04:52 -0400 
categories: jekyll update 
author: "Y Zhang, W Chen, R Zhang, X Zhang - arXiv preprint arXiv:2209.10583, 2022" 
--- 
A growing body of research in natural language processing (NLP) and natural language understanding (NLU) is investigating human-like knowledge learned or encoded in the word embeddings from large language models. This is a step towards understanding what knowledge language models capture that resembles human understanding of language and communication. Here, we investigated whether and how the affect meaning of a word (ie, valence, arousal, dominance) is Cites: Emergent linguistic structure in artificial neural networks trained by