--- 
layout: post 
title: "Are Data-driven Explanations Robust against Out-of-distribution Data?" 
date: 2023-04-01 04:48:36 -0400 
categories: jekyll update 
author: "T Li, F Qiao, M Ma, X Peng - arXiv preprint arXiv:2303.16390, 2023" 
--- 
As black-box models increasingly power high-stakes applications, a variety of data-driven explanation methods have been introduced. Meanwhile, machine learning models are constantly challenged by distributional shifts. A question naturally arises: Are data-driven explanations robust against out-of-distribution data? Our empirical results show that even though predict correctly, the model might still yield unreliable explanations under distributional shifts. How to develop robust explanations against Cites: Do feature attribution methods correctly attribute features?