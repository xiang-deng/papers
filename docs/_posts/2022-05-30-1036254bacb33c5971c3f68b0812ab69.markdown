---
layout: post
title:  "Inception Transformer"
date:   2022-05-30 22:20:45 -0400
categories: jekyll update
author: "C Si, W Yu, P Zhou, Y Zhou, X Wang, S Yan - arXiv preprint arXiv:2205.12956, 2022"
---
Recent studies show that Transformer has strong capability of building long-range dependencies, yet is incompetent in capturing high frequencies that predominantly convey local information. To tackle this issue, we present a novel and general-purpose Inception Transformer, or iFormer for short, that effectively learns comprehensive features with both high-and low-frequency information in visual data. Specifically, we design an Inception mixer to explicitly graft the advantages of … Cites: ‪Palm: Scaling language modeling with pathways‬