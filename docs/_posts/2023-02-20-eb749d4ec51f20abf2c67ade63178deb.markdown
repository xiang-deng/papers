--- 
layout: post 
title: "Dialogue State Distillation Network with Inter-Slot Contrastive Learning for Dialogue State Tracking" 
date: 2023-02-20 23:17:05 -0400 
categories: jekyll update 
author: "J Xu, D Song, C Liu, SC Hui, F Li, Q Ju, X He, J Xie - arXiv preprint arXiv:2302.08220, 2023" 
--- 
In task-oriented dialogue systems, Dialogue State Tracking (DST) aims to extract users intentions from the dialogue history. Currently, most existing approaches suffer from error propagation and are unable to dynamically select relevant information when utilizing previous dialogue states. Moreover, the relations between the updates of different slots provide vital clues for DST. However, the existing approaches rely only on predefined graphs to indirectly capture the relations. In this paper, we Cites: A simple language model for task-oriented dialogue