--- 
layout: post 
title: "Learning Semantic Textual Similarity via Topic-informed Discrete Latent Variables" 
date: 2022-11-10 01:14:02 -0400 
categories: jekyll update 
author: "E Yu, L Du, Y Jin, Z Wei, Y Chang - arXiv preprint arXiv:2211.03616, 2022" 
--- 
Recently, discrete latent variable models have received a surge of interest in both Natural Language Processing (NLP) and Computer Vision (CV), attributed to their comparable performance to the continuous counterparts in representation learning, while being more interpretable in their predictions. In this paper, we develop a topic-informed discrete latent variable model for semantic textual similarity, which learns a shared latent space for sentence-pair representation via vector quantization  Cites: Evidence-aware inferential text generation with vector quantised