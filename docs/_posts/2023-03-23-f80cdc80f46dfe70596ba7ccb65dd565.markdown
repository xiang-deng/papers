--- 
layout: post 
title: "Exploratory Inference Chain: Exploratorily Chaining Multi-hop Inferences with Large Language Models for Question-Answering" 
date: 2023-03-23 03:27:25 -0400 
categories: jekyll update 
author: "S Haji, K Suekane, H Sano, T Takagi - 2023 IEEE 17th International Conference on , 2023" 
--- 
Successful few-shot question-answering with large language models (LLMs) has been reported for a variety of tasks. In the usual approach, an answer is generated by a single call to an LLM, but it has been pointed out that the performance of multi-hop inference by LLMs is not sufficient. Thus, an LLM is unable to perform the complex processing necessary to get an answer, which leads to poor performance. Moreover, the inference process is opaque. Against this, approaches that call an  Cites: Rationale-augmented ensembles in language models