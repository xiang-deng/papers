--- 
layout: post 
title: "Efficient Few-Shot Fine-Tuning for Opinion Summarization" 
date: 2022-05-10 03:22:04 -0400 
categories: jekyll update 
author: "A Brainskas, R Nallapati, M Bansal, M Dreyer - arXiv preprint arXiv:2205.02170, 2022" 
--- 
Abstractive summarization models are typically pre-trained on large amounts of generic texts, then fine-tuned on tens or hundreds of thousands of annotated samples. However, in opinion summarization, large annotated datasets of reviews paired with reference summaries are not available and would be expensive to create. This calls for fine-tuning methods robust to overfitting on small datasets. In addition, generically pre-trained models are often not accustomed to the specifics of Cites: Aspect-controllable opinion summarization