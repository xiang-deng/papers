--- 
layout: post 
title: "Optimization-Induced Graph Implicit Nonlinear Diffusion" 
date: 2022-07-14 01:37:31 -0400 
categories: jekyll update 
author: "Q Chen, Y Wang, Y Wang, J Yang, Z Lin - International Conference on Machine , 2022" 
--- 
Due to the over-smoothing issue, most existing graph neural networks can only capture limited dependencies with their inherently finite aggregation layers. To overcome this limitation, we propose a new kind of graph convolution, called Graph Implicit Nonlinear Diffusion (GIND), which implicitly has access to infinite hops of neighbors while adaptively aggregating features with nonlinear diffusion to prevent over-smoothing. Notably, we show that the learned representation can be formalized Cites: Graph Neural Networks with Generated Parameters for Relation