--- 
layout: post 
title: "Towards Attribute-Entangled Controllable Text Generation: A Pilot Study of Blessing Generation" 
date: 2023-02-07 01:43:12 -0400 
categories: jekyll update 
author: "A Marfurt, J Henderson - Proceedings of the 2nd Workshop on Natural , 2022" 
--- 
Hallucinations in abstractive summarization are model generations that are unfaithful to the source document. Current methods for detecting hallucinations operate mostly on noun phrases and named entities, and restrict themselves to the XSum dataset, which is known to have hallucinations in 3 out of 4 training examples (Maynez et al., 2020). We instead consider the CNN/DailyMail dataset where the summarization model has not seen abnormally many hallucinations during training. We  Cites: Handling divergent reference texts when evaluating table-to-text