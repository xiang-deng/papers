---
layout: post
title:  "Designing AI for Appropriation Will Calibrate Trust"
date:   2023-03-18 01:48:35 -0400
categories: jekyll update
author: "ZT ZHANG, Y LIU, A BUTZ - 2023"
---
Calibrating users  trust on AI to an appropriate level is widely considered one of the key mechanisms to manage brittle AI performance. However, trust calibration is hard to achieve, with numerous interacting factors that can tip trust into one direction or the other. In this position paper, we argue that instead of focusing on trust calibration to achieve resilient human-AI interactions, it might be helpful to design AI systems for appropriation first, ie allowing users to use an AI system according to their intention …
Cites: ‪Does the Whole Exceed its Parts? The Effect of AI Explanations on …‬