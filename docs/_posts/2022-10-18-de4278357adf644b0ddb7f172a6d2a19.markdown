--- 
layout: post 
title: "Assessing Out-of-Domain Language Model Performance from Few Examples" 
date: 2022-10-18 02:49:27 -0400 
categories: jekyll update 
author: "P Singhal, J Forristal, X Ye, G Durrett - arXiv preprint arXiv:2210.06725, 2022" 
--- 
While pretrained language models have exhibited impressive generalization capabilities, they still behave unpredictably under certain domain shifts. In particular, a model may learn a reasoning process on in-domain training data that does not hold for out-of-domain test data. We address the task of predicting out-of-domain (OOD) performance in a few-shot fashion: given a few target-domain examples and a set of models with similar training performance, can we understand how these Cites: Connecting Attributions and QA Model Behavior on Realistic