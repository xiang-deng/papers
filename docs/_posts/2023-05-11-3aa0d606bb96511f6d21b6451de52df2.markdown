--- 
layout: post 
title: "Reactive Perturbation Defocusing for Textual Adversarial Defense" 
date: 2023-05-11 03:26:59 -0400 
categories: jekyll update 
author: "H Yang, K Li - arXiv preprint arXiv:2305.04067, 2023" 
--- 
Recent studies have shown that large pre-trained language models are vulnerable to adversarial attacks. Existing methods attempt to reconstruct the adversarial examples. However, these methods usually have limited performance in defense against adversarial examples, while also negatively impacting the performance on natural examples. To overcome this problem, we propose a method called Reactive Perturbation Defocusing (RPD). RPD uses an adversarial detector to identify Cites: Word-level Textual Adversarial Attacking as Combinatorial