---
layout: post
title:  "Graph-Text Multi-Modal Pre-training for Medical Representation Learning"
date:   2022-03-26 03:19:20 -0400
categories: jekyll update
author: "S Park, S Bae, J Kim, T Kim, E Choi - arXiv preprint arXiv:2203.09994, 2022"
---
As the volume of Electronic Health Records (EHR) sharply grows, there has been emerging interest in learning the representation of EHR for healthcare applications. Representation learning of EHR requires appropriate modeling of the two dominant modalities in EHR: structured data and unstructured text. In this paper, we present MedGTX, a pre-trained model for multi-modal representation learning of the structured and textual EHR data. MedGTX uses a novel graph encoder to exploit the Cites: Graphcodebert: Pre-training code representations with data flow