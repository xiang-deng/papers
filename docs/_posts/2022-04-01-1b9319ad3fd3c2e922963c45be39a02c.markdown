---
layout: post
title:  "Learning to Answer Questions in Dynamic Audio-Visual Scenarios"
date:   2022-04-01 17:06:07 -0400
categories: jekyll update
author: "G Li, Y Wei, Y Tian, C Xu, JR Wen, D Hu - arXiv preprint arXiv:2203.14072, 2022"
---
In this paper, we focus on the Audio-Visual Question Answering (AVQA) task, which aims to answer questions regarding different visual objects, sounds, and their associations in videos. The problem requires comprehensive multimodal understanding and spatio-temporal reasoning over audio-visual scenes. To benchmark this task and facilitate our study, we introduce a large-scale MUSIC- AVQA dataset, which contains more than 45K question-answer pairs covering 33 Cites: Multimodalqa: Complex question answering over text, tables and