--- 
layout: post 
title: "Disentangled Text Representation Learning with Information-Theoretic Perspective for Adversarial Robustness" 
date: 2022-11-01 03:49:43 -0400 
categories: jekyll update 
author: "J Zhao, W Mao - arXiv preprint arXiv:2210.14957, 2022" 
--- 
Adversarial vulnerability remains a major obstacle to constructing reliable NLP systems. When imperceptible perturbations are added to raw input text, the performance of a deep learning model may drop dramatically under attacks. Recent work argues the adversarial vulnerability of the model is caused by the non-robust features in supervised training. Thus in this paper, we tackle the adversarial robustness challenge from the view of disentangled representation learning, which is  Cites: Achieving Model Robustness through Discrete Adversarial Training