--- 
layout: post 
title: "Text Characterization Toolkit" 
date: 2022-10-08 00:45:41 -0400 
categories: jekyll update 
author: "D Simig, T Wang, V Dankers, P Henderson, K Batsuren - arXiv preprint arXiv , 2022" 
--- 
In NLP, models are usually evaluated by reporting single-number performance scores on a number of readily available benchmarks, without much deeper analysis. Here, we argue that-especially given the well-known fact that benchmarks often contain biases, artefacts, and spurious correlations-deeper results analysis should become the de-facto standard when presenting new models or benchmarks. We present a tool that researchers can use to study properties of the dataset and the Cites: End-to-end Neural Coreference Resolution