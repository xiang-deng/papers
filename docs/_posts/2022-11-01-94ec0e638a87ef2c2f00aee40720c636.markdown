--- 
layout: post 
title: "What is the intended usage context of this model?-An exploratory study of pre-trained models on various model repositories" 
date: 2022-11-01 03:49:43 -0400 
categories: jekyll update 
author: "L Gong, J Zhang, M Wei, H Zhang, Z Huang - ACM Transactions on Software , 2022" 
--- 
There is a trend of researchers and practitioners to directly apply the pre-trained models to solve their specific tasks. For example, researchers in Software Engineering (SE) have successfully exploited the pre-trained language models to automatically generate the source code and comments. However, there are domain gaps in different benchmark datasets. These data-driven (or ML-based) models trained on one benchmark dataset may not operate smoothly on other benchmarks Cites: Codebert: A pre-trained model for programming and natural