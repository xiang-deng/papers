--- 
layout: post 
title: "Domain-Oriented Prefix-Tuning: Towards Efficient and Generalizable Fine-tuning for Zero-Shot Dialogue Summarization" 
date: 2022-04-16 01:25:48 -0400 
categories: jekyll update 
author: "L Zhao, F Zheng, W Zeng, K He, W Xu, H Jiang, W Wu - arXiv preprint arXiv , 2022" 
--- 
The most advanced abstractive dialogue summarizers lack generalization ability on new domains and the existing researches for domain adaptation in summarization generally rely on large-scale pre-trainings. To explore the lightweight fine-tuning methods for domain adaptation of dialogue summarization, in this paper, we propose an efficient and generalizable Domain-Oriented Prefix-tuning model, which utilizes a domain word initialized prefix module to alleviate domain entanglement and adopts Cites: GSum: A general framework for guided neural abstractive