--- 
layout: post 
title: "Diffusion Models as Masked Autoencoders" 
date: 2023-04-11 07:02:19 -0400 
categories: jekyll update 
author: "C Wei, K Mangalam, PY Huang, Y Li, H Fan, H Xu - arXiv preprint arXiv , 2023" 
--- 
There has been a longstanding belief that generation can facilitate a true understanding of visual data. In line with this, we revisit generatively pre-training visual representations in light of recent interest in denoising diffusion models. While directly pre-training with diffusion models does not produce strong representations, we condition diffusion models on masked input and formulate diffusion models as masked autoencoders (DiffMAE). Our approach is capable of (i) serving as a strong Cites: Electra: Pre-training text encoders as discriminators rather than