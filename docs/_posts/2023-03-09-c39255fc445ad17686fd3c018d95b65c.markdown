--- 
layout: post 
title: "On the Feasibility of Specialized Ability Stealing for Large Language Code Models" 
date: 2023-03-09 05:52:34 -0400 
categories: jekyll update 
author: "Z Li, C Wang, P Ma, C Liu, S Wang, D Wu, C Gao - arXiv preprint arXiv:2303.03012, 2023" 
--- 
Recent progress in large language code models (LLCMs) has led to a dramatic surge in the use of software development. Nevertheless, it is widely known that training a well-performed LLCM requires a plethora of workforce for collecting the data and high quality annotation. Additionally, the training dataset may be proprietary (or partially open source to the public), and the training process is often conducted on a large-scale cluster of GPUs with high costs. Inspired by the recent success of  Cites: Self-consistency improves chain of thought reasoning in language