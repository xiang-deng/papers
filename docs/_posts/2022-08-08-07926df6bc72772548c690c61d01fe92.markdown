--- 
layout: post 
title: "XDAI: A Tuning-free Framework for Exploiting Pre-trained Language Models in Knowledge Grounded Dialogue Generation" 
date: 2022-08-08 22:47:49 -0400 
categories: jekyll update 
author: "J Yu, X Zhang, Y Xu, X Lei, X Guan, J Zhang, L Hou - 2022" 
--- 
Foundation model is the subject of a paradigm shift, claimed by a group of experienced scientists recently [2], suggesting that various AI-driven systems in the future tend to directly build upon or heavily integrate large-scale pre-trained language models (PLMs) such as GPT [3], BERT [6], and T5 [22], because such big models have already demonstrated incredible advances on a large number of natural language processing (NLP) tasks such as question answering [12], machine Cites: Cpm-2: Large-scale cost-effective pre-trained language models