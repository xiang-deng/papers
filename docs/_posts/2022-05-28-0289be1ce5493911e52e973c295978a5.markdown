---
layout: post
title:  "Revisiting Pre-trained Language Models and their Evaluation for Arabic Natural Language Understanding"
date:   2022-05-28 02:05:27 -0400
categories: jekyll update
author: "A Ghaddar, Y Wu, S Bagga, A Rashid, K Bibi… - arXiv preprint arXiv …, 2022"
---
There is a growing body of work in recent years to develop pre-trained language models (PLMs) for the Arabic language. This work concerns addressing two major problems in existing Arabic PLMs which constraint progress of the Arabic NLU and NLG fields. First, existing Arabic PLMs are not well-explored and their pre-trainig can be improved significantly using a more methodical approach. Second, there is a lack of systematic and reproducible evaluation of these models in the literature. In this … Cites: ‪Palm: Scaling language modeling with pathways‬