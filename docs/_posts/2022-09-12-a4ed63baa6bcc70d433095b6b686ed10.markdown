--- 
layout: post 
title: "More Like This: Semantic Retrieval with Linguistic Information" 
date: 2022-09-12 23:50:28 -0400 
categories: jekyll update 
author: "S Remus, G Wiedemann, S Anwar, F Petersen-Frey - Proceedings of the 18th , 2022" 
--- 
We investigate the semantic retrieval potential of pre-trained contextualized word embeddings (CWEs) such as BERT, in combination with explicit linguistic information, for various NLP tasks in an information retrieval setup. In this paper, we compare different strategies to aggregate contextualized word embeddings along lexical, syntactic, or grammatical dimensions to perform semantic retrieval for various natural language tasks. We apply this for fine-grained named entities, word senses  Cites: What does BERT look at? An analysis of BERT s attention