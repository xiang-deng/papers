---
layout: post
title:  "PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models"
date:   2022-05-28 02:05:27 -0400
categories: jekyll update
author: "Y Yao, Q Chen, A Zhang, W Ji, Z Liu, TS Chua, M Sun - arXiv preprint arXiv …, 2022"
---
Vision-language pre-training (VLP) has shown impressive performance on a wide range of cross-modal tasks, where VLP models without reliance on object detectors are becoming the mainstream due to their superior computation efficiency and competitive performance. However, the removal of object detectors also deprives the capability of VLP models in explicit object modeling, which is essential to various position-sensitive vision-language (VL) tasks, such as referring expression … Cites: ‪Unifying Vision-and-Language Tasks via Text Generation‬