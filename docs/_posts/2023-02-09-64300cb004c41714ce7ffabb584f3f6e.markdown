--- 
layout: post 
title: "Curriculum-Guided Abstractive Summarization" 
date: 2023-02-09 01:30:47 -0400 
categories: jekyll update 
author: "S Sotudeh, H Deilamsalehy, F Dernoncourt - arXiv preprint arXiv , 2023" 
--- 
Recent Transformer-based summarization models have provided a promising approach to abstractive summarization. They go beyond sentence selection and extractive strategies to deal with more complicated tasks such as novel word generation and sentence paraphrasing. Nonetheless, these models have two shortcomings:(1) they often perform poorly in content selection, and (2) their training strategy is not quite efficient, which restricts model performance. In this paper, we  Cites: Muppet: Massive multi-task representations with pre-finetuning