--- 
layout: post 
title: "Controlling Large Language Models to Generate Secure and Vulnerable Code" 
date: 2023-02-16 06:16:46 -0400 
categories: jekyll update 
author: "J He, M Vechev - arXiv preprint arXiv:2302.05319, 2023" 
--- 
Large language models (LMs) are increasingly pretrained on massive corpora of open-source programs and applied to solve program synthesis tasks. However, a fundamental limitation of LMs is their unawareness of security and vulnerability during pretraining and inference. As a result, LMs produce secure or vulnerable programs with high uncertainty (eg, around 60%/40% chances for GitHub Copilot according to a recent study). This greatly impairs LMs usability, especially in security Cites: Gedi: Generative discriminator guided sequence generation