---
layout: post
title:  "Adversarial Attacks and Defenses in Text Classification"
date:   2022-06-01 23:51:30 -0400
categories: jekyll update
author: "B Alshemali - 2022"
---
Deep learning models have achieved great success in solving a variety of natural language processing (NLP) problems. An ever-growing body of research, however, illustrates the vulnerability of deep neural networks (DNNs) to adversarial examples–inputs modified by introducing small perturbations to deliberately fool a target model into outputting incorrect results. The vulnerability to adversarial examples has become one of the main hurdles precluding neural network deployment into safety … Cites: ‪Paraphrasing revisited with neural machine translation‬