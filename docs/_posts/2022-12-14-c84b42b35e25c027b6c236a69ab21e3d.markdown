--- 
layout: post 
title: "On Computing Probabilistic Abductive Explanations" 
date: 2022-12-14 16:04:21 -0400 
categories: jekyll update 
author: "Y Izza, X Huang, A Ignatiev, N Narodytska, MC Cooper - arXiv preprint arXiv , 2022" 
--- 
The most widely studied explainable AI (XAI) approaches are unsound. This is the case with well-known model-agnostic explanation approaches, and it is also the case with approaches based on saliency maps. One solution is to consider intrinsic interpretability, which does not exhibit the drawback of unsoundness. Unfortunately, intrinsic interpretability can display unwieldy explanation redundancy. Formal explainability represents the alternative to these non-rigorous approaches, with one  Cites: Anchors: High-Precision Model-Agnostic Explanations