--- 
layout: post 
title: "Visualizing Loss landscape of LLMs" 
date: 2023-03-21 04:56:52 -0400 
categories: jekyll update 
author: "A Agrawal, S Bassi, R Sankar" 
--- 
Trained deep learning models performing poorly on Out-Of-Distribution (OOD) datasets have motivated researchers to study how can models generalize. Observing objective metrics on held-out test data is a good first measure to analyze if a model generalizes well. It is argued that flatter minima in loss landscape lead to a generalized model. We experiment by empirically visualizing the loss landscape of Large Language Models to observe if smoother, flatter minima correspond to a Cites: Semantic parsing on freebase from question-answer pairs