--- 
layout: post 
title: "Global Concept-Based Interpretability for Graph Neural Networks via Neuron Analysis" 
date: 2022-08-26 23:24:20 -0400 
categories: jekyll update 
author: "H Xuanyuan, P Barbiero, D Georgiev, LC Magister - arXiv preprint arXiv , 2022" 
--- 
Graph neural networks (GNNs) are highly effective on a variety of graph-related tasks; however, they lack interpretability and transparency. Current explainability approaches are typically local and treat GNNs as black-boxes. They do not look inside the model, inhibiting human trust in the model and explanations. Motivated by the ability of neurons to detect high-level semantic concepts in vision models, we perform a novel analysis on the behaviour of individual GNN neurons to answer Cites: Concept bottleneck models