---
layout: post
title:  "Non-Monotonic Latent Alignments for CTC-Based Non-Autoregressive Machine Translation"
date:   2022-10-15 02:59:22 -0400
categories: jekyll update
author: "C Shao, Y Feng - arXiv preprint arXiv:2210.03953, 2022"
---
Non-autoregressive translation (NAT) models are typically trained with the cross-entropy loss, which forces the model outputs to be aligned verbatim with the target sentence and will highly penalize small shifts in word positions. Latent alignment models relax the explicit alignment by marginalizing out all monotonic latent alignments with the CTC loss. However, they cannot handle non-monotonic alignments, which is non-negligible as there is typically global word reordering in …
Cites: ‪Latent-variable non-autoregressive neural machine translation …‬