---
layout: post
title:  "Revisiting the Gold Standard: Grounding Summarization Evaluation with Robust Human Evaluation"
date:   2022-12-20 02:26:19 -0400
categories: jekyll update
author: "Y Liu, AR Fabbri, P Liu, Y Zhao, L Nan, R Han, S Han… - arXiv preprint arXiv …, 2022"
---
Human evaluation is the foundation upon which the evaluation of both summarization systems and automatic metrics rests. However, existing human evaluation protocols and benchmarks for summarization either exhibit low inter-annotator agreement or lack the scale needed to draw statistically significant conclusions, and an in-depth analysis of human evaluation is lacking. In this work, we address the shortcomings of existing summarization evaluation along the …
Cites: ‪Beam Decoding with Controlled Patience‬