---
layout: post
title:  "Review of Knowledge-Enhanced Pre-trained Language Models"
date:   2022-04-01 17:06:07 -0400
categories: jekyll update
author: "HAN Yi, Q Linbo, LI Dongsheng, L Xiangke - Journal of Frontiers of Computer Science &"
---
The disadvantage that the pre-trained language models are difficult to deal with the factual commonsense knowledge has seriously hindered their further development, while the rich knowledge of factual entities stored in the knowledge graph can provide important help. The knowledge-enhanced pre-trained language models attempt to use the structured knowledge stored in the knowledge graph to strengthen the pre-trained language models, so that they can learn not only the general Cites: K-adapter: Infusing knowledge into pre-trained models with adapters