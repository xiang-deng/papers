--- 
layout: post 
title: "Membership Inference Attacks against Language Models via Neighbourhood Comparison" 
date: 2023-06-02 15:36:55 -0400 
categories: jekyll update 
author: "J Mattern, F Mireshghallah, Z Jin, B Schlkopf - arXiv preprint arXiv , 2023" 
--- 
Membership Inference attacks (MIAs) aim to predict whether a data sample was present in the training data of a machine learning model or not, and are widely used for assessing the privacy risks of language models. Most existing attacks rely on the observation that models tend to assign higher probabilities to their training samples than non-training points. However, simple thresholding of the model score in isolation tends to lead to high false-positive rates as it does not account for the  Cites: DetectGPT: Zero-shot machine-generated text detection using