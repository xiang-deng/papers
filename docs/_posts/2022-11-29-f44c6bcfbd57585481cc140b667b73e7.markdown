--- 
layout: post 
title: "Locating and editing factual associations in gpt" 
date: 2022-11-29 02:31:48 -0400 
categories: jekyll update 
author: "K Meng, D Bau, AJ Andonian, Y Belinkov - Advances in Neural Information , 2022" 
--- 
We analyze the storage and recall of factual associations in autoregressive transformer language models, finding evidence that these associations correspond to localized, directly-editable computations. We first develop a causal intervention for identifying neuron activations that are decisive in a model s factual predictions. This reveals a distinct set of steps in middle-layer feed-forward modules that mediate factual predictions while processing subject tokens. To test our hypothesis that these  Cites: BERT: Pre-training of Deep Bidirectional Transformers for