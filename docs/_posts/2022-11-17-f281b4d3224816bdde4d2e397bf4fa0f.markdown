---
layout: post
title:  "Self-distillation with Online Diffusion on Batch Manifolds Improves Deep Metric Learning"
date:   2022-11-17 00:57:01 -0400
categories: jekyll update
author: "Z Zeng, F Yang, H Liu, S Satoh - arXiv preprint arXiv:2211.07566, 2022"
---
Recent deep metric learning (DML) methods typically leverage solely class labels to keep positive samples far away from negative ones. However, this type of method normally ignores the crucial knowledge hidden in the data (eg, intra-class information variation), which is harmful to the generalization of the trained model. To alleviate this problem, in this paper we propose Online Batch Diffusion-based Self-Distillation (OBD-SD) for DML. Specifically, we first propose a simple but effective …
Cites: ‪Ranking on data manifolds.‬