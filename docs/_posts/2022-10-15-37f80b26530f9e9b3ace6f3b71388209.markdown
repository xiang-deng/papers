--- 
layout: post 
title: "Decoupled Context Processing for Context Augmented Language Modeling" 
date: 2022-10-15 02:59:22 -0400 
categories: jekyll update 
author: "Z Li, R Guo, S Kumar - arXiv preprint arXiv:2210.05758, 2022" 
--- 
Language models can be augmented with a context retriever to incorporate knowledge from large external databases. By leveraging retrieved context, the neural network does not have to memorize the massive amount of world knowledge within its internal parameters, leading to better parameter efficiency, interpretability and modularity. In this paper we examined a simple yet effective architecture for incorporating external context into language models based on decoupled Encoder Cites: Palm: Scaling language modeling with pathways