--- 
layout: post 
title: "Visual Comparison of Language Model Adaptation" 
date: 2022-08-22 23:37:16 -0400 
categories: jekyll update 
author: "R Sevastjanova, E Cakmak, S Ravfogel, R Cotterell - arXiv preprint arXiv , 2022" 
--- 
Neural language models are widely used; however, their model parameters often need to be adapted to the specific domains and tasks of an application, which is time-and resource-consuming. Thus, adapters have recently been introduced as a lightweight alternative for model adaptation. They consist of a small set of task-specific parameters with a reduced training time and simple parameter composition. The simplicity of adapter training and composition comes along with new challenges Cites: Don t stop pretraining: adapt language models to domains and tasks