--- 
layout: post 
title: "ImpNet: Imperceptible and blackbox-undetectable backdoors in compiled neural networks" 
date: 2022-10-08 00:45:41 -0400 
categories: jekyll update 
author: "T Clifford, I Shumailov, Y Zhao, R Anderson, R Mullins - arXiv preprint arXiv , 2022" 
--- 
Early backdoor attacks against machine learning set off an arms race in attack and defence development. Defences have since appeared demonstrating some ability to detect backdoors in models or even remove them. These defences work by inspecting the training data, the model, or the integrity of the training procedure. In this work, we show that backdoors can be added during compilation, circumventing any safeguards in the data preparation and model training stages. As an illustration  Cites: Mind the Style of Text! Adversarial and Backdoor Attacks Based on