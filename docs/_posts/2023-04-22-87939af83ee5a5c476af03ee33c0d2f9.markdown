--- 
layout: post 
title: "A Comprehensive Review on Word Embedding Techniques" 
date: 2023-04-22 04:11:24 -0400 
categories: jekyll update 
author: "A Neelima, S Mehrotra - 2023 International Conference on Intelligent Systems , 2023" 
--- 
Word embeddings are a linguistic representation that can be used to gain insight into a person s mental process in order to train a computer to think like that person. Real numbers can be used as representations in the form of a vector. Word embeddings attempt to capture the meanings of words by depicting them randomly in an n-dimensional space. This research aims to survey the landscape of available word embedding techniques. Based on this survey, we can identify three widely used word Cites: Deep contextualized word representations. arXiv 2018