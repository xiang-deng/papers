--- 
layout: post 
title: "Automatic Evaluation of Attribution by Large Language Models" 
date: 2023-05-13 06:32:20 -0400 
categories: jekyll update 
author: "X Yue, B Wang, K Zhang, Z Chen, Y Su, H Sun - arXiv preprint arXiv:2305.06311, 2023" 
--- 
A recent focus of large language model (LLM) development, as exemplified by generative search engines, is to incorporate external references to generate and support their claims. However, evaluating the attribution, ie, verifying whether the generated statement is indeed fully supported by the cited reference, remains an open problem. Although human evaluation is common practice, it is costly and time-consuming. In this paper, we investigate the automatic evaluation of attribution by Cites: Evaluating the factual consistency of abstractive text summarization