--- 
layout: post 
title: "Transformers, Tables and Frame Semantics" 
date: 2023-03-23 03:27:25 -0400 
categories: jekyll update 
author: "M Ramirez, A Bogatu, NW Paton, A Freitas - 2023 IEEE 17th International Conference , 2023" 
--- 
Transformer-based language models are able to capture linguistic patterns at scale by encoding both syntactic and semantic dimensions of natural language representations with the aim of achieving language understanding. While Transformers have been adapted for generating table embeddings, less research effort has been dedicated to investigating the extent to which these models can encode table semantics. To address this limitation, we propose a method to transfer  Cites: TURL: Table Understanding through Representation Learning