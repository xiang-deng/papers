--- 
layout: post 
title: "Elaboration-Generating Commonsense Question Answering at Scale" 
date: 2022-09-10 00:05:49 -0400 
categories: jekyll update 
author: "W Wang, V Srikumar, H Hajishirzi, NA Smith - arXiv preprint arXiv:2209.01232, 2022" 
--- 
In question answering requiring common sense, language models (eg, GPT-3) have been used to generate text expressing background knowledge that helps improve performance. Yet the cost of working with such models is very high; in this work, we finetune smaller language models to generate useful intermediate context, referred to here as elaborations. Our framework alternates between updating two language models--an elaboration generator and an answer predictor--allowing each to Cites: Generated knowledge prompting for commonsense reasoning