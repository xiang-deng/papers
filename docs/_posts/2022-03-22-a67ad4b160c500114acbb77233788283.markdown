---
layout: post
title:  "Revisiting Supervised Word Embeddings."
date:   2022-03-22 03:39:25 -0400
categories: jekyll update
author: "D VU, K TRUONG, K NGUYEN, NGO VAN LINH - Journal of Information , 2022"
---
Word embeddings are playing a crucial role in a variety of applications. However, most previous works focus on word embeddings which are either non-discriminative or hardly interpretable. In this work, we investigate a novel approach, referred to as SWET, which learns supervised word embeddings using topic models from labeled corpora. SWET inherits the interpretability of topic models, the discriminativeness of supervised inference from labels. More importantly, SWET enables us to directly Cites: Mobilebert: a compact task-agnostic bert for resource-limited devices