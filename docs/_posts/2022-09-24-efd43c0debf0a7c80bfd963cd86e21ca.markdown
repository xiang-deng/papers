---
layout: post
title:  "A Step-by-Step Gradient Penalty with Similarity Calculation for Text Summary Generation"
date:   2022-09-24 00:16:11 -0400
categories: jekyll update
author: "S Zhao, Q Li, T He, J Wen - Neural Processing Letters, 2022"
---
The summary generation model equipped with gradient penalty avoids overfitting and makes the model more stable. However, the traditional gradient penalty faces two issues:(i) calculating the gradient twice increases training time, and (ii) the disturbance factor requires repeated trials to find the best value. To this end, we propose a step-by-step gradient penalty model with similarity calculation (S2SGP). Firstly, the step-by-step gradient penalty is applied to the summary generation model …
Cites: ‪Text summarization with pretrained encoders‬