--- 
layout: post 
title: "An empirical study on how humans appreciate automated counterfactual explanations which embrace imprecise information" 
date: 2022-11-08 00:47:36 -0400 
categories: jekyll update 
author: "I Stepin, JM Alonso-Moral, A Catala, M Pereira-Faria - Information Sciences, 2022" 
--- 
The explanatory capacity of interpretable fuzzy rule-based classifiers is usually limited to offering explanations for the predicted class only. A lack of potentially useful explanations for non-predicted alternatives can be overcome by designing methods for the so-called counterfactual reasoning. Nevertheless, state-of-the-art methods for counterfactual explanation generation require special attention to human evaluation aspects, as the final decision upon the classification under Cites: Why Should I Trust You? : Explaining the Predictions of Any