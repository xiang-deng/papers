--- 
layout: post 
title: "Adding Instructions during Pretraining: Effective Way of Controlling Toxicity in Language Models" 
date: 2023-02-18 05:28:11 -0400 
categories: jekyll update 
author: "S Prabhumoye, M Patwary, M Shoeybi, B Catanzaro - arXiv preprint arXiv , 2023" 
--- 
Pretrained large language models have become indispensable for solving various natural language processing (NLP) tasks. However, safely deploying them in real world applications is challenging because they generate toxic content. To address this challenge, we propose two novel pretraining data augmentation strategies that significantly reduce model toxicity without compromising its utility. Our two strategies are:(1) MEDA: adds raw toxicity score as meta-data to the pretraining samples, and  Cites: DExperts: Decoding-time controlled text generation with experts