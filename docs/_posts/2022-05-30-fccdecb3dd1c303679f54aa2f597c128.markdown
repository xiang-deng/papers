---
layout: post
title:  "Dynamically Relative Position Encoding-Based Transformer for Automatic Code Edit"
date:   2022-05-30 22:20:45 -0400
categories: jekyll update
author: "S Qi, Y Li, C Gao, X Su, S Gao, Z Zheng, C Liu - arXiv preprint arXiv:2205.13522, 2022"
---
Adapting Deep Learning (DL) techniques to automate non-trivial coding activities, such as code documentation and defect detection, has been intensively studied recently. Learning to predict code changes is one of the popular and essential investigations. Prior studies have shown that DL techniques such as Neural Machine Translation (NMT) can benefit meaningful code changes, including bug fixing and code refactoring. However, NMT models may encounter bottleneck when modeling  Cites: Graphcodebert: Pre-training code representations with data flow