--- 
layout: post 
title: "Sentiment Lexical Strength Enhanced Self-supervised Attention Learning for sentiment analysis" 
date: 2022-07-02 02:42:16 -0400 
categories: jekyll update 
author: "X Wang, M Fan, M Kong, Z Pei - Knowledge-Based Systems, 2022" 
--- 
Abstract In Natural Language Processing (NLP), attention mechanism is often used to quantify the importance of the context word in sentiment prediction. However, it tends to focus on high-frequency words, while ignoring low-frequency words that have an active effect in some positions. In this paper, we propose a Sentiment Lexical Strength Enhanced Self-supervised Attention Learning (SLS-ESAL) approach. Specifically, we iteratively mine attention supervision information from all Cites: Pre-Trained Models: Past, Present and Future