--- 
layout: post 
title: "APPLYING CROSS-VIEW TRAINING FOR DEPENDENCY PARSING IN VIETNAMESE" 
date: 2022-09-15 00:14:14 -0400 
categories: jekyll update 
author: "DH Trinh, TLP Ngo, LHB Nguyen, D Dinh" 
--- 
Dependency parsing aims to identify syntactic relations or dependencies between word pairs in the sentence. Recent research has shown that contextual model like BERT implicitly captures linguistics information, eg, syntax, and semantic at different hidden layers. In addition, as dependency parsing can be formulated as a classification problem, supervised deep learning models have recently outperformed other methods. However, these supervised models demand a large labeled dataset  Cites: What does BERT look at? An analysis of BERT s attention