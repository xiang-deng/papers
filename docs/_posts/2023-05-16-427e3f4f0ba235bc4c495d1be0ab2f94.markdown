---
layout: post
title:  "Evaluating Open-Domain Question Answering in the Era of Large Language Models"
date:   2023-05-16 05:31:31 -0400
categories: jekyll update
author: "E Kamalloo, N Dziri, CLA Clarke, D Rafiei - arXiv preprint arXiv:2305.06984, 2023"
---
Lexical matching remains the de facto evaluation method for open-domain question answering (QA). Unfortunately, lexical matching fails completely when a plausible candidate answer does not appear in the list of gold answers, which is increasingly the case as we shift from extractive to generative models. The recent success of large language models (LLMs) for QA aggravates lexical matching failures since candidate answers become longer, thereby making matching with the gold answers even more …
Cites: ‪Evidentiality-guided generation for knowledge-intensive nlp tasks‬