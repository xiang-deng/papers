--- 
layout: post 
title: "Challenges in Domain-Specific Abstractive Summarization and How to Overcome Them" 
date: 2023-03-10 16:03:48 -0400 
categories: jekyll update 
author: "A Afzal, J Vladika, D Braun, F Matthes - 15th International Conference on Agents and , 2023" 
--- 
Large Language Models work quite well with general-purpose data and many tasks in Natural Language Processing. However, they show several limitations when used for a task such as domain-specific abstractive text summarization. This paper identifies three of those limitations as research problems in the context of abstractive text summarization: 1) Quadratic complexity of transformer-based models with respect to the input text length; 2) Model Hallucination, which is a model s ability to Cites: Detecting Hallucinated Content in Conditional Neural Sequence