---
layout: post
title:  "Deep Batch Active Learning and Knowledge Distillation for Person Re-identification"
date:   2022-06-18 03:19:09 -0400
categories: jekyll update
author: "Z Hu, W Hou, X Liu - IEEE Sensors Journal, 2022"
---
For deep learning model training, most existing supervised learning-based person re-identification (Re-ID) models require considerable data with annotations as samples. However, it is labor-intensive to generate labeled data in many real-world situations. Meanwhile, the large scale of the existing models increases the load of model learning. To this end, this paper proposes a person Re-ID method by deep batch active learning and knowledge distillation. With the goal of minimizing the human  Cites: Cold-start active learning through self-supervised language