---
layout: post
title:  "A Transformer-based Approach for Persian Text Chunking"
date:   2022-06-27 23:23:24 -0400
categories: jekyll update
author: "P Kavehzadeh, MM Abdollah Pour, S Momtazi - Journal of AI and Data Mining, 2022"
---
Over the last few years, text chunking has taken a significant part in the sequence labeling tasks. Although a large variety of methods have been proposed for shallow parsing in English, most of the proposed approaches for text chunking in the Persian language are based on the simple and traditional concepts. In this paper, we propose using the state-of-the-art transformer-based contextualized models, namely BERT and XLM-RoBERTa, as the major structure of our models. Conditional random  Cites: BERT with History Answer Embedding for Conversational Question