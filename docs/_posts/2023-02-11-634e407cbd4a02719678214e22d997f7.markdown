--- 
layout: post 
title: "Transformer-based Models for Long-Form Document Matching: Challenges and Empirical Analysis" 
date: 2023-02-11 02:41:58 -0400 
categories: jekyll update 
author: "A Jha, A Samavedhi, V Rakesh, J Chandrashekar - arXiv preprint arXiv , 2023" 
--- 
Recent advances in the area of long document matching have primarily focused on using transformer-based models for long document encoding and matching. There are two primary challenges associated with these models. Firstly, the performance gain provided by transformer-based models comes at a steep cost-both in terms of the required training time and the resource (memory and energy) consumption. The second major limitation is their inability to handle more than a pre-defined input  Cites: Blockwise Self-Attention for Long Document Understanding