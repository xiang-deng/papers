--- 
layout: post 
title: "Textual Manifold-based Defense Against Natural Language Adversarial Examples" 
date: 2023-02-07 01:43:12 -0400 
categories: jekyll update 
author: "DN Minh, AT Luu - Proceedings of the 2022 Conference on Empirical , 2022" 
--- 
Despite the recent success of large pretrained language models in NLP, they are susceptible to adversarial examples. Concurrently, several studies on adversarial images have observed an intriguing property: the adversarial images tend to leave the low-dimensional natural data manifold. In this study, we find a similar phenomenon occurs in the contextualized embedding space of natural sentences induced by pretrained language models in which textual adversarial examples tend Cites: Semantically Equivalent Adversarial Rules for Debugging NLP