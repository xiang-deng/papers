---
layout: post
title:  "Topics in Contextualised Attention Embeddings"
date:   2023-01-14 01:50:54 -0400
categories: jekyll update
author: "M Talebpour, AGS de Herrera, S Jameel - arXiv preprint arXiv:2301.04339, 2023"
---
Contextualised word vectors obtained via pre-trained language models encode a variety of knowledge that has already been exploited in applications. Complementary to these language models are probabilistic topic models that learn thematic patterns from the text. Recent work has demonstrated that conducting clustering on the word-level contextual representations from a language model emulates word clusters that are discovered in latent topics of words from Latent …
Cites: ‪Is automated topic model evaluation broken? the incoherence of …‬