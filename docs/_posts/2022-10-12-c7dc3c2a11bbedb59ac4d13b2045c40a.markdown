--- 
layout: post 
title: "Out-of-Distribution Generalization in Algorithmic Reasoning Through Curriculum Learning" 
date: 2022-10-12 20:42:55 -0400 
categories: jekyll update 
author: "AJ Nam, M Abdool, T Maxfield, JL McClelland - arXiv preprint arXiv:2210.03275, 2022" 
--- 
Out-of-distribution generalization (OODG) is a longstanding challenge for neural networks, and is quite apparent in tasks with well-defined variables and rules, where explicit use of the rules can solve problems independently of the particular values of the variables. Large transformer-based language models have pushed the boundaries on how well neural networks can generalize to novel inputs, but their complexity obfuscates they achieve such robustness. As a step toward  Cites: Chain of thought prompting elicits reasoning in large language