--- 
layout: post 
title: "Low Variance Off-policy Evaluation with State-based Importance Sampling" 
date: 2022-12-13 08:01:52 -0400 
categories: jekyll update 
author: "DM Bossens, P Thomas - arXiv preprint arXiv:2212.03932, 2022" 
--- 
In off-policy reinforcement learning, a behaviour policy performs exploratory interactions with the environment to obtain state-action-reward samples which are then used to learn a target policy that optimises the expected return. This leads to a problem of off-policy evaluation, where one needs to evaluate the target policy from samples collected by the often unrelated behaviour policy. Importance sampling is a traditional statistical technique that is often applied to off-policy evaluation. While  Cites: Breaking the curse of horizon: Infinite-horizon off-policy estimation