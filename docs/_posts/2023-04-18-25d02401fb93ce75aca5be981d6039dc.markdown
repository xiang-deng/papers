---
layout: post
title:  "AGIEval: A Human-Centric Benchmark for Evaluating Foundation Models"
date:   2023-04-18 05:50:22 -0400
categories: jekyll update
author: "W Zhong, R Cui, Y Guo, Y Liang, S Lu, Y Wang… - arXiv preprint arXiv …, 2023"
---
Evaluating the general abilities of foundation models to tackle human-level tasks is a vital aspect of their development and application in the pursuit of Artificial General Intelligence (AGI). Traditional benchmarks, which rely on artificial datasets, may not accurately represent human-level capabilities. In this paper, we introduce AGIEval, a novel benchmark specifically designed to assess foundation model in the context of human-centric standardized exams, such as college entrance exams, law school …
Cites: ‪Scaling instruction-finetuned language models‬