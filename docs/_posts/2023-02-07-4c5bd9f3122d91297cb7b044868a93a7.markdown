--- 
layout: post 
title: "CodeRetriever: A Large Scale Contrastive Pre-Training Method for Code Search" 
date: 2023-02-07 01:43:12 -0400 
categories: jekyll update 
author: "X Li, Y Gong, Y Shen, X Qiu, H Zhang, B Yao, W Qi - Proceedings of the 2022 , 2022" 
--- 
In this paper, we propose the CodeRetriever model, which learns the function-level code semantic representations through large-scale code-text contrastive pre-training. We adopt two contrastive learning schemes in CodeRetriever: unimodal contrastive learning and bimodal contrastive learning. For unimodal contrastive learning, we design an unsupervised learning approach to build semantic-related code pairs based on the documentation and function name. For bimodal contrastive learning  Cites: Learning to mine aligned code and natural language pairs from