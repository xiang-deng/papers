--- 
layout: post 
title: "Continually Learning from Existing Models: Knowledge Accumulation for Neural Machine Translation" 
date: 2022-12-22 13:00:23 -0400 
categories: jekyll update 
author: "Y Zhang, P Li, M Sun, Y Liu - arXiv preprint arXiv:2212.09097, 2022" 
--- 
Although continually extending an existing NMT model to new domains or languages has attracted intensive interest in recent years, the equally valuable problem of continually improving a given NMT model in its domain by leveraging knowledge from an unlimited number of existing NMT models is not explored yet. To facilitate the study, we propose a formal definition for the problem named knowledge accumulation for NMT (KA-NMT) with corresponding datasets and evaluation metrics Cites: Knowledge Inheritance for Pre-trained Language Models