--- 
layout: post 
title: "In and Out-of-Domain Text Adversarial Robustness via Label Smoothing" 
date: 2022-12-23 23:45:02 -0400 
categories: jekyll update 
author: "Y Yang, S Dan, D Roth, I Lee - arXiv preprint arXiv:2212.10258, 2022" 
--- 
Recently it has been shown that state-of-the-art NLP models are vulnerable to adversarial attacks, where the predictions of a model can be drastically altered by slight modifications to the input (such as synonym substitutions). While several defense techniques have been proposed, and adapted, to the discrete nature of text adversarial attacks, the benefits of general-purpose regularization methods such as label smoothing for language models, have not been studied. In this paper, we study  Cites: Calibration of Pre-trained Transformers