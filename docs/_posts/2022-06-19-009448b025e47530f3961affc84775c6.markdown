---
layout: post
title:  "Coarse-to-Fine Vision-Language Pre-training with Fusion in the Backbone"
date:   2022-06-19 07:39:02 -0400
categories: jekyll update
author: "ZY Dou, A Kamath, Z Gan, P Zhang, J Wang, L Li, Z Liu… - arXiv preprint arXiv …, 2022"
---
Vision-language (VL) pre-training has recently received considerable attention. However, most existing end-to-end pre-training approaches either only aim to tackle VL tasks such as image-text retrieval, visual question answering (VQA) and image captioning that test high-level understanding of images, or only target region-level understanding for tasks such as phrase grounding and object detection. We present FIBER (Fusion-In-the-Backbone-based transformER), a new VL model architecture …
Cites: ‪Vinvl: Revisiting visual representations in vision-language models‬  