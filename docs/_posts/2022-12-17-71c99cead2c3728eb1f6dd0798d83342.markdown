---
layout: post
title:  "Attention in the Faithful Self-Explanatory NLP Models"
date:   2022-12-17 01:50:56 -0400
categories: jekyll update
author: "M Rafaiejokandan - 2022"
---
Deep neural networks (DNNs) can perform impressively in many natural language processing (NLP) tasks, but their black-box nature makes them inherently challenging to explain or interpret. Self-Explanatory models are a new approach to overcoming this challenge, generating explanations in human-readable languages besides task objectives like answering questions. The main focus of this thesis is the explainability of NLP tasks, as well as how attention methods can help enhance …
Cites: ‪Looking beyond the surface: A challenge set for reading …‬