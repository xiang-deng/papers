---
layout: post
title:  "Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models"
date:   2022-10-12 20:42:55 -0400
categories: jekyll update
author: "D Wingate, M Shoeybi, T Sorensen - arXiv preprint arXiv:2210.03162, 2022"
---
We explore the idea of compressing the prompts used to condition language models, and show that compressed prompts can retain a substantive amount of information about the original prompt. For severely compressed prompts, while fine-grained information is lost, abstract information and general sentiments can be retained with surprisingly few parameters, which can be useful in the context of decode-time algorithms for controllability and toxicity reduction. We explore contrastive …
Cites: ‪Realtoxicityprompts: Evaluating neural toxic degeneration in …‬