--- 
layout: post 
title: "Design Choices for Crowdsourcing Implicit Discourse Relations: Revealing the Biases Introduced by Task Design" 
date: 2023-04-06 06:45:39 -0400 
categories: jekyll update 
author: "V Pyatkin, F Yung, MCJ Scholman, R Tsarfaty, I Dagan - arXiv preprint arXiv , 2023" 
--- 
Disagreement in natural language annotation has mostly been studied from a perspective of biases introduced by the annotators and the annotation frameworks. Here, we propose to analyze another source of bias: task design bias, which has a particularly strong impact on crowdsourced linguistic annotations where natural language is used to elicit the interpretation of laymen annotators. For this purpose we look at implicit discourse relation annotation, a task that has repeatedly been shown  Cites: What Can We Learn from Collective Human Opinions on Natural