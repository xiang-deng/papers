--- 
layout: post 
title: "Open-Domain Dialog Evaluation using Follow-Ups Likelihood" 
date: 2022-09-17 00:49:30 -0400 
categories: jekyll update 
author: "M De Bruyn, E Lotfi, J Buhmann, W Daelemans - arXiv preprint arXiv:2209.05185, 2022" 
--- 
Automatic evaluation of open-domain dialogs remains an unsolved problem. Moreover, existing methods do not correlate strongly with human annotations. This paper presents a new automated evaluation method using follow-ups: we measure the probability that a language model will continue the conversation with a fixed set of follow-ups (eg, not really relevant here, what are you trying to say). When compared against twelve existing methods, our new evaluation achieves the highest  Cites: Understanding and predicting user dissatisfaction in a neural