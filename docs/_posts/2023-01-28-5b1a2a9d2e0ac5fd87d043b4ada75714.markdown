---
layout: post
title:  "BDMMT: Backdoor Sample Detection for Language Models through Model Mutation Testing"
date:   2023-01-28 04:04:00 -0400
categories: jekyll update
author: "J Wei, M Fan, W Jiao, W Jin, T Liu - arXiv preprint arXiv:2301.10412, 2023"
---
Deep neural networks (DNNs) and natural language processing (NLP) systems have developed rapidly and have been widely used in various real-world fields. However, they have been shown to be vulnerable to backdoor attacks. Specifically, the adversary injects a backdoor into the model during the training phase, so that input samples with backdoor triggers are classified as the target class. Some attacks have achieved high attack success rates on the pre-trained language models (LMs), but …
Cites: ‪Weight Poisoning Attacks on Pre-trained Models‬