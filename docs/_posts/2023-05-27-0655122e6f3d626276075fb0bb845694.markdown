--- 
layout: post 
title: "Using Natural Language Explanations to Rescale Human Judgments" 
date: 2023-05-27 10:00:59 -0400 
categories: jekyll update 
author: "M Wadhwa, J Chen, JJ Li, G Durrett - arXiv preprint arXiv:2305.14770, 2023" 
--- 
The rise of large language models (LLMs) has brought a critical need for high-quality human-labeled data, particularly for processes like human feedback and evaluation. A common practice is to label data via consensus annotation over the judgments of multiple crowdworkers. However, different annotators may have different interpretations of labeling schemes unless given extensive training, and for subjective NLP tasks, even trained expert annotators can diverge heavily. We show Cites: A Critical Evaluation of Evaluations for Long-form Question