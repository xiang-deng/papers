---
layout: post
title:  "ВВЕДЕНИЕ В АТАКИ ОТРАВЛЕНИЕМ НА МОДЕЛИ МАШИННОГО ОБУЧЕНИЯ"
date:   2023-03-14 05:28:18 -0400
categories: jekyll update
author: "ДЕ Намиот - International Journal of Open Information Technologies, 2023"
---
В настоящей статье рассматривается один из возможных классов атак на системы машинного обучения-атаки отравлением. Классически, атаки отравлением-это специальные модификации тренировочных данных, которые призваны воздействовать на полученную после обучения модель необходимым атакующему образом. Атаки могут быть направлены на то, чтобы понизить общую точность или честность модели, или же на то, чтобы, например …
Cites: ‪Weight Poisoning Attacks on Pre-trained Models‬