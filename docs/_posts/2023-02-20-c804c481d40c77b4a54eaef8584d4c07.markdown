---
layout: post
title:  "GraphPrompt: Unifying Pre-Training and Downstream Tasks for Graph Neural Networks"
date:   2023-02-20 23:17:05 -0400
categories: jekyll update
author: "Z Liu, X Yu, Y Fang, X Zhang - arXiv preprint arXiv:2302.08043, 2023"
---
Graphs can model complex relationships between objects, enabling a myriad of Web applications such as online page/article classification and social recommendation. While graph neural networks (GNNs) have emerged as a powerful tool for graph representation learning, in an end-to-end supervised setting, their performance heavily rely on a large amount of task-specific supervision. To reduce labeling requirement, the  pre-train, fine-tune  and  pre-train, prompt  paradigms have …
Cites: ‪Pre-train, prompt, and predict: A systematic survey of prompting …‬