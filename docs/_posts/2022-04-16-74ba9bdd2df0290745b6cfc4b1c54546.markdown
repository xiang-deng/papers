---
layout: post
title:  "Towards Understanding Large-Scale Discourse Structures in Pre-Trained and Fine-Tuned Language Models"
date:   2022-04-16 01:25:48 -0400
categories: jekyll update
author: "P Huber, G Carenini - arXiv preprint arXiv:2204.04289, 2022"
---
With a growing number of BERTology work analyzing different components of pre- trained language models, we extend this line of research through an in-depth analysis of discourse information in pre-trained and fine-tuned language models. We move beyond prior work along three dimensions: First, we describe a novel approach to infer discourse structures from arbitrarily long documents. Second, we propose a new type of analysis to explore where and how accurately intrinsic Cites: Don t give me the details, just the summary! topic-aware