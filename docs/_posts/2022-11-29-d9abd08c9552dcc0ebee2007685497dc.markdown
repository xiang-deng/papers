--- 
layout: post 
title: "N-GPETS: Neural Attention Graph-Based Pretrained Statistical Model for Extractive Text Summarization" 
date: 2022-11-29 02:31:48 -0400 
categories: jekyll update 
author: "M Umair, I Alam, A Khan, I Khan, N Ullah, MY Momand - 2022" 
--- 
Te extractive summarization approach involves selecting the source document s salient sentences to build a summary. One of the most important aspects of extractive summarization is learning and modelling cross-sentence associations. Inspired by the popularity of Transformer-based Bidirectional Encoder Representations (BERT) pretrained linguistic model and graph attention network (GAT) having a sophisticated network that captures intersentence associations, this research work proposes a Cites: Neural Extractive Text Summarization with Syntactic Compression