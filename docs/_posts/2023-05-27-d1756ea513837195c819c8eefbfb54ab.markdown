--- 
layout: post 
title: "Preserving Knowledge Invariance: Rethinking Robustness Evaluation of Open Information Extraction" 
date: 2023-05-27 10:00:59 -0400 
categories: jekyll update 
author: "J Qi, C Zhang, X Wang, K Zeng, J Yu, J Liu, J Sun - arXiv preprint arXiv , 2023" 
--- 
The robustness to distribution changes ensures that NLP models can be successfully applied in the realistic world, especially for information extraction tasks. However, most prior evaluation benchmarks have been devoted to validating pairwise matching correctness, ignoring the crucial measurement of robustness. In this paper, we present the first benchmark that simulates the evaluation of open information extraction models in the real world, where the syntactic and expressive distributions Cites: RoMQA: A Benchmark for Robust, Multi-evidence, Multi-answer