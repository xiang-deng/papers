--- 
layout: post 
title: "Selective Amnesia: On Efficient, High-Fidelity and Blind Suppression of Backdoor Effects in Trojaned Machine Learning Models" 
date: 2022-12-14 16:04:21 -0400 
categories: jekyll update 
author: "R Zhu, D Tang, S Tang, XF Wang, H Tang - arXiv preprint arXiv:2212.04687, 2022" 
--- 
In this paper, we present a simple yet surprisingly effective technique to induce selective amnesia on a backdoored model. Our approach, called SEAM, has been inspired by the problem of catastrophic forgetting (CF), a long standing issue in continual learning. Our idea is to retrain a given DNN model on randomly labeled clean data, to induce a CF on the model, leading to a sudden forget on both primary and backdoor tasks; then we recover the primary task by retraining the randomized Cites: Mobilebert: a compact task-agnostic bert for resource-limited devices