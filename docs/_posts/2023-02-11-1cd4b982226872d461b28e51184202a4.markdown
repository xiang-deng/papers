--- 
layout: post 
title: "An Empirical Comparison of Pre-Trained Models of Source Code" 
date: 2023-02-11 02:41:58 -0400 
categories: jekyll update 
author: "C Niu, C Li, V Ng, D Chen, J Ge, B Luo - arXiv preprint arXiv:2302.04026, 2023" 
--- 
While a large number of pre-trained models of source code have been successfully developed and applied to a variety of software engineering (SE) tasks in recent years, our understanding of these pre-trained models is arguably fairly limited. With the goal of advancing our understanding of these models, we perform the first systematic empirical comparison of 19 recently-developed pre-trained models of source code on 13 SE tasks. To gain additional insights into these models, we adopt  Cites: Deep contextualized word representations