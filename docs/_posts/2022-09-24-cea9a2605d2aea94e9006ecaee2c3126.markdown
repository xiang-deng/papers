---
layout: post
title:  "Will It Blend? Mixing Training Paradigms & Prompting for Argument Quality Prediction"
date:   2022-09-24 00:16:11 -0400
categories: jekyll update
author: "M van der Meer, M Reuver, U Khurana, L Krause… - arXiv preprint arXiv …, 2022"
---
This paper describes our contributions to the Shared Task of the 9th Workshop on Argument Mining (2022). Our approach uses Large Language Models for the task of Argument Quality Prediction. We perform prompt engineering using GPT-3, and also investigate the training paradigms multi-task learning, contrastive learning, and intermediate-task training. We find that a mixed prediction setup outperforms single models. Prompting GPT-3 works best for predicting argument validity, and argument …
Cites: ‪When to Use Multi-Task Learning vs Intermediate Fine-Tuning for …‬