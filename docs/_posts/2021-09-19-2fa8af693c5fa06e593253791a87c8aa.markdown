---
layout: post
title:  "xGQA: Cross-Lingual Visual Question Answering"
date:   2021-09-19 02:15:47 -0400
categories: jekyll update
author: "J Pfeiffer, G Geigle, A Kamath, JMO Steitz, S Roth - arXiv preprint arXiv , 2021"
---
Recent advances in multimodal vision and language modeling have predominantly focused on the English language, mostly due to the lack of multilingual multimodal datasets to steer modeling efforts. In this work, we address this gap and provide xGQA, a new multilingual evaluation benchmark for the visual question answering task. We extend the established English GQA dataset to 7 typologically diverse languages, enabling us to detect and explore crucial challenges in cross-lingual Cites: K-adapter: Infusing knowledge into pre-trained models with adapters