--- 
layout: post 
title: "No Offense Taken: Eliciting Offensiveness from Language Models" 
date: 2022-11-15 00:38:37 -0400 
categories: jekyll update 
author: "A Srivastava, R Ahuja, R Mukku" 
--- 
For safe and reliable deployment of language models in the real world, testing needs to be robust. This robustness can be characterized by the difficulty and diversity of the test cases we evaluate these models on. Limitations in human-in-the-loop test case generation has prompted an advent of automated test case generation approaches. In particular, we focus on Red Teaming Language Models with Language Models by Perez et al.(2022). Our contributions include developing a Cites: Beat the AI: Investigating adversarial human annotation for reading