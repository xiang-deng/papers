--- 
layout: post 
title: "Interactively Providing Explanations for Transformer Language Models" 
date: 2022-06-01 23:51:30 -0400 
categories: jekyll update 
author: "F Friedrich, P Schramowski, C Tauchmann, K Kersting - arXiv e-prints, 2021" 
--- 
Results. As Tab. 2 shows and expected from literature [7], interpretability comes along with a trade-off in accuracy. Still, our first experimental results demonstrate that Proto-Trex networks perform on par with non-interpretable baseline LMs. More importantly, we showcase that users can interact with ease by simply manipulating the interpretable layer, ie a prototype (cf. Fig. 1). In Tab. 1, a user manipulates a prototypical explanation successively. While the accuracy remains unchanged, the Cites: Why Should I Trust You? : Explaining the Predictions of Any