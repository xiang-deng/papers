--- 
layout: post 
title: "Liquid Structural State-Space Models" 
date: 2022-10-01 01:08:34 -0400 
categories: jekyll update 
author: "R Hasani, M Lechner, TH Wang, M Chahine, A Amini - arXiv preprint arXiv , 2022" 
--- 
A proper parametrization of state transition matrices of linear state-space models (SSMs) followed by standard nonlinearities enables them to efficiently learn representations from sequential data, establishing the state-of-the-art on a large series of long-range sequence modeling benchmarks. In this paper, we show that we can improve further when the structural SSM such as S4 is given by a linear liquid time-constant (LTC) state-space model. LTC neural networks are causal continuous  Cites: Diagonal State Spaces are as Effective as Structured State Spaces