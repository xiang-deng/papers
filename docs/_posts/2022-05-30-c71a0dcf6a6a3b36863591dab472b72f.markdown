--- 
layout: post 
title: "An Empirical Study on Distribution Shift Robustness From the Perspective of Pre-Training and Data Augmentation" 
date: 2022-05-30 22:20:45 -0400 
categories: jekyll update 
author: "Z Liu, Y Xu, Y Xu, Q Qian, H Li, R Jin, X Ji, AB Chan - arXiv preprint arXiv:2205.12753, 2022" 
--- 
The performance of machine learning models under distribution shift has been the focus of the community in recent years. Most of current methods have been proposed to improve the robustness to distribution shift from the algorithmic perspective, ie, designing better training algorithms to help the generalization in shifted test distributions. This paper studies the distribution shift problem from the perspective of pre-training and data augmentation, two important factors in the practice of deep Cites: Examining and Combating Spurious Features under Distribution Shift