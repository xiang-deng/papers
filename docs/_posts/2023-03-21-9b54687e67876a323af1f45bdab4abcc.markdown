--- 
layout: post 
title: "SelfCheckGPT: Zero-Resource Black-Box Hallucination Detection for Generative Large Language Models" 
date: 2023-03-21 04:56:52 -0400 
categories: jekyll update 
author: "P Manakul, A Liusie, MJF Gales - arXiv preprint arXiv:2303.08896, 2023" 
--- 
Generative Large Language Models (LLMs) such as GPT-3 are capable of generating highly fluent responses to a wide variety of user prompts. However, LLMs are known to hallucinate facts and make non-factual statements which can undermine trust in their output. Existing fact-checking approaches either require access to token-level output probability distribution (which may not be available for systems such as ChatGPT) or external databases that are interfaced via separate  Cites: Palm: Scaling language modeling with pathways