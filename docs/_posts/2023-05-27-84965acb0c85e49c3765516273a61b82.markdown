--- 
layout: post 
title: "Aligning Large Language Models through Synthetic Feedback" 
date: 2023-05-27 10:00:59 -0400 
categories: jekyll update 
author: "S Kim, S Bae, J Shin, S Kang, D Kwak, KM Yoo, M Seo - arXiv preprint arXiv , 2023" 
--- 
Aligning large language models (LLMs) to human values has become increasingly important as it enables sophisticated steering of LLMs, eg, making them follow given instructions while keeping them less toxic. However, it requires a significant amount of human demonstrations and feedback. Recently, open-sourced models have attempted to replicate the alignment learning process by distilling data from already aligned LLMs like InstructGPT or ChatGPT. While this process reduces human  Cites: Beyond the Imitation Game: Quantifying and extrapolating the