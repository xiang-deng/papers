--- 
layout: post 
title: "ProGen: Progressive Zero-shot Dataset Generation via In-context Feedback" 
date: 2022-10-26 13:20:27 -0400 
categories: jekyll update 
author: "J Ye, J Gao, J Feng, Z Wu, T Yu, L Kong - arXiv preprint arXiv:2210.12329, 2022" 
--- 
Recently, dataset-generation-based zero-shot learning has shown promising results by training a task-specific model with a dataset synthesized from large pre-trained language models (PLMs). The final task-specific model often achieves compatible or even better performance than PLMs under the zero-shot setting, with orders of magnitude fewer parameters. However, synthetic datasets have their drawbacks. They have long been suffering from low-quality issues (eg, low informativeness and Cites: Lingpeng Kong, Rui Zhang, Noah A