--- 
layout: post 
title: "Emergent and Predictable Memorization in Large Language Models" 
date: 2023-04-27 01:18:20 -0400 
categories: jekyll update 
author: "S Biderman, US Prashanth, L Sutawika, H Schoelkopf - arXiv preprint arXiv , 2023" 
--- 
Memorization, or the tendency of large language models (LLMs) to output entire sequences from their training data verbatim, is a key concern for safely deploying language models. In particular, it is vital to minimize a model s memorization of sensitive datapoints such as those containing personal identifiable information (PII). The prevalence of such undesirable memorization can pose issues for model trainers, and may even require discarding an otherwise functional model. We Cites: Beyond the imitation game: Quantifying and extrapolating the