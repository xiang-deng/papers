---
layout: post
title:  "According to...  Prompting Language Models Improves Quoting from Pre-Training Data"
date:   2023-05-25 03:51:47 -0400
categories: jekyll update
author: "O Weller, M Marone, N Weir, D Lawrie, D Khashabi… - arXiv preprint arXiv …, 2023"
---
Large Language Models (LLMs) may hallucinate and generate fake information, despite pre-training on factual data. Inspired by the journalistic device of  according to sources , we propose according-to prompting: directing LLMs to ground responses against previously observed text. To quantify this grounding, we propose a novel evaluation metric (QUIP-Score) that measures the extent to which model-produced answers are directly found in underlying text corpora. We illustrate with experiments …
Cites: ‪Beyond the imitation game: Quantifying and extrapolating the …‬