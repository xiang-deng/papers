--- 
layout: post 
title: "Self-critiquing models for assisting human evaluators" 
date: 2022-06-18 03:19:09 -0400 
categories: jekyll update 
author: "W Saunders, C Yeh, J Wu, S Bills, L Ouyang, J Ward - arXiv preprint arXiv , 2022" 
--- 
We fine-tune large language models to write natural language critiques (natural language critical comments) using behavioral cloning. On a topic-based summarization task, critiques written by our models help humans find flaws in summaries that they would have otherwise missed. Our models help find naturally occurring flaws in both model and human written summaries, and intentional flaws in summaries written by humans to be deliberately misleading. We study scaling Cites: Chain of thought prompting elicits reasoning in large language