---
layout: post
title:  "Can We Really Trust Explanations? Evaluating the Stability of Feature Attribution Explanation Methods via Adversarial Attack"
date:   2022-10-10 14:05:52 -0400
categories: jekyll update
author: "Z Yang, Y Zhang, Z Jiang, Y Ju, J Zhao, K Liu - China National Conference on …, 2022"
---
Explanations can increase the transparency of neural networks and make them more trustworthy. However, can we really trust explanations generated by the existing explanation methods? If the explanation methods are not stable enough, the credibility of the explanation will be greatly reduced. Previous studies seldom considered such an important issue. To this end, this paper proposes a new evaluation frame to evaluate the stability of current typical feature attribution …
Cites: ‪On the opportunities and risks of foundation models‬