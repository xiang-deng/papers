--- 
layout: post 
title: "CLiMB: A Continual Learning Benchmark for Vision-and-Language Tasks" 
date: 2022-06-25 08:25:58 -0400 
categories: jekyll update 
author: "T Srinivasan, TY Chang, LLP Alva, G Chochlakis - arXiv preprint arXiv , 2022" 
--- 
Current state-of-the-art vision-and-language models are evaluated on tasks either individually or in a multi-task setting, overlooking the challenges of continually learning (CL) tasks as they arrive. Existing CL benchmarks have facilitated research on task adaptation and mitigating catastrophic forgetting , but are limited to vision-only and language-only tasks. We present CLiMB, a benchmark to study the challenge of learning multimodal tasks in a CL setting, and to systematically evaluate Cites: Merlot: Multimodal neural script knowledge models