---
layout: post
title:  "DisCLIP: Open-Vocabulary Referring Expression Generation"
date:   2023-06-02 15:36:55 -0400
categories: jekyll update
author: "L Bracha, E Shaar, A Shamsian, E Fetaya, G Chechik - arXiv preprint arXiv …, 2023"
---
Referring Expressions Generation (REG) aims to produce textual descriptions that unambiguously identifies specific objects within a visual scene. Traditionally, this has been achieved through supervised learning methods, which perform well on specific data distributions but often struggle to generalize to new images and concepts. To address this issue, we present a novel approach for REG, named DisCLIP, short for discriminative CLIP. We build on CLIP, a large-scale visual-semantic model, to guide …
Cites: ‪ReCLIP: A Strong Zero-Shot Baseline for Referring Expression …‬