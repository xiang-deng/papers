---
layout: post
title:  "Learning Joint Representation of Human Motion and Language"
date:   2022-11-01 03:49:43 -0400
categories: jekyll update
author: "J Kim, Y Yu, S Shin, T Byun, S Choi - arXiv preprint arXiv:2210.15187, 2022"
---
In this work, we present MoLang (a Motion-Language connecting model) for learning joint representation of human motion and language, leveraging both unpaired and paired datasets of motion and language modalities. To this end, we propose a motion-language model with contrastive learning, empowering our model to learn better generalizable representations of the human motion domain. Empirical results show that our model learns strong representations of human motion data through …
Cites: ‪Contrastive learning of medical visual representations from paired …‬