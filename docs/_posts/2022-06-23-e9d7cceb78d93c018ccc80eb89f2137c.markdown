---
layout: post
title:  "Is Semantic-aware BERT more Linguistically Aware? A Case Study on Natural Language Inference"
date:   2022-06-23 20:09:31 -0400
categories: jekyll update
author: "L Liu, I Jindal, Y Li"
---
Recent work has shown that predicateargument label representations from semantic role labeling (SRL) can be concatenated with BERT representations to improve natural language understanding tasks such as natural language inference (NLI) and reading comprehension. Two natural questions that arise are whether infusing SRL representations with BERT 1) improves model performance and 2) increases the model s linguistic awareness. This paper aims at answering both questions with a 
Cites: Stress Test Evaluation for Natural Language Inference