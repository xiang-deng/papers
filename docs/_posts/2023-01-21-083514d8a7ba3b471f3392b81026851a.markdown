---
layout: post
title:  "A 95.6-TOPS/W Deep Learning Inference Accelerator With Per-Vector Scaled 4-bit Quantization in 5 nm"
date:   2023-01-21 07:31:42 -0400
categories: jekyll update
author: "B Keller, R Venkatesan, S Dai, SG Tell, B Zimmer… - IEEE Journal of Solid-State …, 2023"
---
The energy efficiency of deep neural network (DNN) inference can be improved with custom accelerators. DNN inference accelerators often employ specialized hardware techniques to improve energy efficiency, but many of these techniques result in catastrophic accuracy loss on transformer-based DNNs, which have become ubiquitous for natural language processing (NLP) tasks. This article presents a DNN accelerator designed for efficient execution of transformers. The proposed …
Cites: ‪Efficientnetv2: Smaller models and faster training‬