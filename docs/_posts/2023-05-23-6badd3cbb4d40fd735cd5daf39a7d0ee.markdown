---
layout: post
title:  "A Better Way to Do Masked Language Model Scoring"
date:   2023-05-23 02:52:43 -0400
categories: jekyll update
author: "C Kauf, A Ivanova - arXiv preprint arXiv:2305.10588, 2023"
---
Estimating the log-likelihood of a given sentence under an autoregressive language model is straightforward: one can simply apply the chain rule and sum the log-likelihood values for each successive token. However, for masked language models, there is no direct way to estimate the log-likelihood of a sentence. To address this issue, Salazar et al.(2020) propose to estimate sentence pseudo-log-likelihood (PLL) scores, computed by successively masking each sentence token, retrieving its score …
Cites: ‪Surface form competition: Why the highest probability answer isn t …‬