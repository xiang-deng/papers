--- 
layout: post 
title: "Knowledge-in-Context: Towards Knowledgeable Semi-Parametric Language Models" 
date: 2022-11-03 01:42:13 -0400 
categories: jekyll update 
author: "X Pan, W Yao, H Zhang, D Yu, D Yu, J Chen - arXiv preprint arXiv:2210.16433, 2022" 
--- 
Fully-parametric language models generally require a huge number of model parameters to store the necessary knowledge for solving multiple natural language tasks in zero/few-shot settings. In addition, it is hard to adapt to the evolving world knowledge without the costly model re-training. In this paper, we develop a novel semi-parametric language model architecture, Knowledge-in-Context (KiC), which empowers a parametric text-to-text language model with a knowledge-rich external  Cites: (comet-) atomic 2020: On symbolic and neural commonsense