---
layout: post
title:  "Knowledge Enhanced BERT Based on Corpus Associate Generation"
date:   2023-01-17 00:23:00 -0400
categories: jekyll update
author: "L Jiarong, X Hong, J Wenchao, Y Jianren, W Tao - International Conference on …, 2023"
---
The pre-training model represented by BERT has limited accuracy due to a lack of professional domain knowledge support. The knowledge-enhanced BERT model effectively improves the lack of knowledge in downstream tasks in different fields by introducing external professional knowledge and has achieved better results than the BERT model. However, the knowledge-enhanced BERT injected large-scale external knowledge, resulting in a sharp increase in computing resource …
Cites: ‪Overview of the NLPCC 2017 shared task: Open domain chinese …‬