--- 
layout: post 
title: "Discovering Latent Knowledge in Language Models Without Supervision" 
date: 2022-12-10 20:24:02 -0400 
categories: jekyll update 
author: "C Burns, H Ye, D Klein, J Steinhardt - arXiv preprint arXiv:2212.03827, 2022" 
--- 
Existing techniques for training language models can be misaligned with the truth: if we train models with imitation learning, they may reproduce errors that humans make; if we train them to generate text that humans rate highly, they may output errors that human evaluators can t detect. We propose circumventing this issue by directly finding latent knowledge inside the internal activations of a language model in a purely unsupervised way. Specifically, we introduce a method for accurately  Cites: BoolQ: Exploring the Surprising Difficulty of Natural Yes/No