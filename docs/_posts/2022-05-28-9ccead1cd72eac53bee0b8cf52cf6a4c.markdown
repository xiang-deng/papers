---
layout: post
title:  "Set-based Meta-Interpolation for Few-Task Meta-Learning"
date:   2022-05-28 02:05:27 -0400
categories: jekyll update
author: "S Lee, B Andreis, K Kawaguchi, J Lee, SJ Hwang - arXiv preprint arXiv:2205.09990, 2022"
---
Meta-learning approaches enable machine learning systems to adapt to new tasks given few examples by leveraging knowledge from related tasks. However, a large number of meta-training tasks are still required for generalization to unseen tasks during meta-testing, which introduces a critical bottleneck for real-world problems that come with only few tasks, due to various reasons including the difficulty and cost of constructing tasks. Recently, several task augmentation methods have been  Cites: DReCa: A general task augmentation strategy for few-shot natural 