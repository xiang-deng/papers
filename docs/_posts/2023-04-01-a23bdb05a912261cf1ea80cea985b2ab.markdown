--- 
layout: post 
title: "Adversarial Multi-Teacher Distillation for Semi-Supervised Relation Extraction" 
date: 2023-04-01 04:48:36 -0400 
categories: jekyll update 
author: "W Li, T Qian, X Li, L Zou - IEEE Transactions on Neural Networks and Learning , 2023" 
--- 
The shortage of labeled data has been a long-standing challenge for relation extraction (RE) tasks. Semi-supervised RE (SSRE) is a promising way through annotating unlabeled samples with pseudolabels as additional training data. However, some pseudolabels on unlabeled data might be erroneous and will bring misleading knowledge into SSRE models. For this reason, we propose a novel adversarial multi-teacher distillation (AMTD) framework, which includes multi-teacher  Cites: Position-aware Attention and Supervised Data Improve Slot Filling