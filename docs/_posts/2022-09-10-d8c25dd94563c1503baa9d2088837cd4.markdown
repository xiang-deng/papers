--- 
layout: post 
title: "White-Box Adversarial Policies in Deep Reinforcement Learning" 
date: 2022-09-10 00:05:49 -0400 
categories: jekyll update 
author: "S Casper, D Hadfield-Menell, G Kreiman - arXiv preprint arXiv:2209.02167, 2022" 
--- 
Adversarial examples against AI systems pose both risks via malicious attacks and opportunities for improving robustness via adversarial training. In multiagent settings, adversarial policies can be developed by training an adversarial agent to minimize a victim agent s rewards. Prior work has studied black-box attacks where the adversary only sees the state observations and effectively treats the victim as any other part of the environment. In this work, we experiment with white-box adversarial policies to  Cites: Opponent modeling in deep reinforcement learning