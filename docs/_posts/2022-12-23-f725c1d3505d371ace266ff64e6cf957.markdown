---
layout: post
title:  "Geographic and Geopolitical Biases of Language Models"
date:   2022-12-23 23:45:02 -0400
categories: jekyll update
author: "F Faisal, A Anastasopoulos - arXiv preprint arXiv:2212.10408, 2022"
---
Pretrained language models (PLMs) often fail to fairly represent target users from certain world regions because of the under-representation of those regions in training datasets. With recent PLMs trained on enormous data sources, quantifying their potential biases is difficult, due to their black-box nature and the sheer scale of the data sources. In this work, we devise an approach to study the geographic bias (and knowledge) present in PLMs, proposing a Geographic-Representation Probing …
Cites: ‪Multilingual autoregressive entity linking‬