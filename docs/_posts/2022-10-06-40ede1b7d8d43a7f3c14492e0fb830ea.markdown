---
layout: post
title:  "Edgevits: Competing light-weight cnns on mobile devices with vision transformers"
date:   2022-10-06 01:25:19 -0400
categories: jekyll update
author: "J Pan, A Bulat, F Tan, X Zhu, L Dudziak, H Li… - arXiv preprint arXiv …, 2022"
---
Self-attention based models such as vision transformers (ViTs) have emerged as a very competitive architecture alternative to convolutional neural networks (CNNs) in computer vision. Despite increasingly stronger variants with ever higher recognition accuracies, due to the quadratic complexity of self-attention, existing ViTs are typically demanding in computation and model size. Although several successful design choices (eg, the convolutions and hierarchical multi-stage structure) of prior …
Cites: ‪Efficientnetv2: Smaller models and faster training‬