--- 
layout: post 
title: "A Memory Transformer Network for Incremental Learning" 
date: 2022-10-15 02:59:22 -0400 
categories: jekyll update 
author: "A Iscen, T Bird, M Caron, A Fathi, C Schmid - arXiv preprint arXiv:2210.04485, 2022" 
--- 
We study class-incremental learning, a training setup in which new classes of data are observed over time for the model to learn from. Despite the straightforward problem formulation, the naive application of classification models to class-incremental learning results in the catastrophic forgetting of previously seen classes. One of the most successful existing methods has been the use of a memory of exemplars, which overcomes the issue of catastrophic forgetting by saving a  Cites: REALM: Retrieval-Augmented Language Model Pre-Training