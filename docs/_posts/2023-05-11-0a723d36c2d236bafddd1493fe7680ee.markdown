--- 
layout: post 
title: "Residual Prompt Tuning: Improving Prompt Tuning with Residual Reparameterization" 
date: 2023-05-11 03:26:59 -0400 
categories: jekyll update 
author: "A Razdaibiedina, Y Mao, R Hou, M Khabsa, M Lewis - arXiv preprint arXiv , 2023" 
--- 
Prompt tuning is one of the successful approaches for parameter-efficient tuning of pre-trained language models. Despite being arguably the most parameter-efficient (tuned soft prompts constitute< 0.1% of total parameters), it typically performs worse than other efficient tuning methods and is quite sensitive to hyper-parameters. In this work, we introduce Residual Prompt Tuning-a simple and efficient method that significantly improves the performance and stability of prompt tuning. We propose to Cites: Looking beyond the surface: A challenge set for reading