---
layout: post
title:  "Interpreting Transformer s Attention Dynamic Memory and Visualizing the Semantic Information Flow of GPT"
date:   2023-05-27 10:00:59 -0400
categories: jekyll update
author: "S Katz, Y Belinkov - arXiv preprint arXiv:2305.13417, 2023"
---
Recent advances in interpretability suggest we can project weights and hidden states of transformer-based language models (LMs) to their vocabulary, a transformation that makes them human interpretable and enables us to assign semantics to what was seen only as numerical vectors. In this paper, we interpret LM attention heads and memory values, the vectors the models dynamically create and recall while processing a given input. By analyzing the tokens they represent through …
Cites: ‪Analyzing transformers in embedding space‬