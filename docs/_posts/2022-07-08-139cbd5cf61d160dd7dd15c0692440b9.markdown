---
layout: post
title:  "Preventing Catastrophic Forgetting in Continual Learning of New Natural Language Tasks"
date:   2022-07-08 09:39:49 -0400
categories: jekyll update
author: "S Kar, G Castellucci, S Filice, S Malmasi, O Rokhlenko - 2022"
---
ABSTRACT Multi-Task Learning (MTL) is widely-accepted in Natural Language Processing as a standard technique for learning multiple related tasks in one model. Training an MTL model requires having the training data for all tasks available at the same time. As systems usually evolve over time,(eg, to support new functionalities), adding a new task to an existing MTL model usually requires retraining the model from scratch on all the tasks and this can be time-consuming and computationally …
Cites: ‪BAM! Born-Again Multi-Task Networks for Natural Language …‬  