--- 
layout: post 
title: "Exploiting Programmatic Behavior of LLMs: Dual-Use Through Standard Security Attacks" 
date: 2023-02-16 06:16:46 -0400 
categories: jekyll update 
author: "D Kang, X Li, I Stoica, C Guestrin, M Zaharia - arXiv preprint arXiv , 2023" 
--- 
Recent advances in instruction-following large language models (LLMs) have led to dramatic improvements in a range of NLP tasks. Unfortunately, we find that the same improved capabilities amplify the dual-use risks for malicious purposes of these models. Dual-use is difficult to prevent as instruction-following capabilities now enable standard attacks from computer security. The capabilities of these instruction-following LLMs provide strong economic incentives for dual-use by malicious actors Cites: On the opportunities and risks of foundation models