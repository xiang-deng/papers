---
layout: post
title:  "Bridging the Gap between Recognition-level Pre-training and Commonsensical Vision-language Tasks"
date:   2022-04-19 07:59:02 -0400
categories: jekyll update
author: "Y Wan, Y Ma, H You, Z Wang, S Chang - ACL 2022 Workshop on Commonsense , 2022"
---
Large-scale visual-linguistic pre-training aims to capture the generic representations from multimodal features, which are essential for downstream vision-language tasks. Existing methods mostly focus on learning the semantic connections between visual objects and linguistic content, which tend to be recognitionlevel information and may not be sufficient for commonsensical reasoning tasks like VCR. In this paper, we propose a novel commonsensical vision-language pre-training framework to bridge Cites: Visualcomet: Reasoning about the dynamic context of a still image