---
layout: post
title:  "Contextual Word Embeddings Clustering Through Multiway Analysis: A Comparative Study"
date:   2023-04-04 07:39:57 -0400
categories: jekyll update
author: "M Ait-Saada, M Nadif - Advances in Intelligent Data Analysis XXI: 21st …, 2023"
---
Transformer-based contextual word embedding models are widely used to improve several NLP tasks such as text classification and question answering. Knowledge about these multi-layered models is growing in the literature, with several studies trying to understand what is learned by each of the layers. However, little is known about how to combine the information provided by these different layers in order to make the most of the deep Transformer models. On the other hand, even less is …
Cites: ‪Linguistic knowledge and transferability of contextual representations‬