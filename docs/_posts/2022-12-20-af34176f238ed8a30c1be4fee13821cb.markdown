---
layout: post
title:  "Generación Automática de Código Fuente a través de Modelos Preentrenados de Lenguaje, un análisis de la literatura"
date:   2022-12-20 02:26:19 -0400
categories: jekyll update
author: "A Bender, S Nicolet, P Folino, JJ Lopez, G Hansen - Memorias de las JAIIO, 2022"
---
Un Transformer es un modelo de Aprendizaje Profundo creado en 2017 con el objetivo de realizar traducciones entre lenguajes naturales. Las innovaciones que introdujo, particularmente la de auto-atención, han permitido construir prototipos que tienen una noción intuitiva del contexto, y comprenden el significado y los patrones subyacentes del lenguaje. En 2020 OpenAI hizo público GPT-3, un modelo preentrenado enfocado hacia la generación de lenguaje, que mostró resultados …
Cites: ‪A Systematic Evaluation of Large Language Models of Code‬