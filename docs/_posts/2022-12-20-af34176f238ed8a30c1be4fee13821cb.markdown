--- 
layout: post 
title: "Generacin Automtica de Cdigo Fuente a travs de Modelos Preentrenados de Lenguaje, un anlisis de la literatura" 
date: 2022-12-20 02:26:19 -0400 
categories: jekyll update 
author: "A Bender, S Nicolet, P Folino, JJ Lopez, G Hansen - Memorias de las JAIIO, 2022" 
--- 
Un Transformer es un modelo de Aprendizaje Profundo creado en 2017 con el objetivo de realizar traducciones entre lenguajes naturales. Las innovaciones que introdujo, particularmente la de auto-atencin, han permitido construir prototipos que tienen una nocin intuitiva del contexto, y comprenden el significado y los patrones subyacentes del lenguaje. En 2020 OpenAI hizo pblico GPT-3, un modelo preentrenado enfocado hacia la generacin de lenguaje, que mostr resultados Cites: A Systematic Evaluation of Large Language Models of Code