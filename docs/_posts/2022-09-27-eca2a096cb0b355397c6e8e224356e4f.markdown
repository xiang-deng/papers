--- 
layout: post 
title: "Selecting Better Samples from Pre-trained LLMs: A Case Study on Question Generation" 
date: 2022-09-27 02:04:52 -0400 
categories: jekyll update 
author: "X Yuan, T Wang, YH Wang, E Fine, R Abdelghani - arXiv preprint arXiv , 2022" 
--- 
Large Language Models (LLMs) have in recent years demonstrated impressive prowess in natural language generation. A common practice to improve generation diversity is to sample multiple outputs from the model. However, there lacks a simple and robust way of selecting the best output from these stochastic samples. As a case study framed in the context of question generation, we propose two prompt-based approaches to selecting high-quality questions from a set of LLM-generated Cites: Learning To Retrieve Prompts for In-Context Learning