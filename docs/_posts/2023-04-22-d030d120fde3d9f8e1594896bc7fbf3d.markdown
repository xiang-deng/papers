--- 
layout: post 
title: "On Uncertainty Calibration and Selective Generation in Probabilistic Neural Summarization: A Benchmark Study" 
date: 2023-04-22 04:11:24 -0400 
categories: jekyll update 
author: "P Zablotskaia, D Phan, J Maynez, S Narayan, J Ren - arXiv preprint arXiv , 2023" 
--- 
Modern deep models for summarization attains impressive benchmark performance, but they are prone to generating miscalibrated predictive uncertainty. This means that they assign high confidence to low-quality predictions, leading to compromised reliability and trustworthiness in real-world applications. Probabilistic deep learning methods are common solutions to the miscalibration problem. However, their relative effectiveness in complex autoregressive summarization tasks are not well  Cites: Understanding Neural Abstractive Summarization Models via