--- 
layout: post 
title: "Task Compass: Scaling Multi-task Pre-training with Task Prefix" 
date: 2022-10-15 02:59:22 -0400 
categories: jekyll update 
author: "Z Zhang, S Wang, Y Xu, Y Fang, W Yu, Y Liu, H Zhao - arXiv preprint arXiv , 2022" 
--- 
Leveraging task-aware annotated data as supervised signals to assist with self-supervised learning on large-scale unlabeled data has become a new trend in pre-training language models. Existing studies show that multi-task learning with large-scale supervised tasks suffers from negative effects across tasks. To tackle the challenge, we propose a task prefix guided multi-task pre-training framework to explore the relationships among tasks. We conduct extensive experiments on 40  Cites: Beyond the Imitation Game: Quantifying and extrapolating the