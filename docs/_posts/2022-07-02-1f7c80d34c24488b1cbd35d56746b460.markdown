---
layout: post
title:  "Sequence-aware Knowledge Distillation for a Lightweight Event Representation"
date:   2022-07-02 02:42:16 -0400
categories: jekyll update
author: "J Zheng, F Cai, Y Ling, H Chen - ACM Transactions on Information Systems (TOIS), 2022"
---
Event representation targets to model the event-reasoning process as a machine-readable format. Previous studies on event representation mostly concentrate on a sole modeling perspective and have not well investigated the scenario-level knowledge, which can cause information loss. To cope with this dilemma, we propose a unified fine-tuning architecture-based approach (UniFA-S) that integrates all levels of trainings, including the scenario-level knowledge. However, another 
Cites: Electra: Pre-training text encoders as discriminators rather than