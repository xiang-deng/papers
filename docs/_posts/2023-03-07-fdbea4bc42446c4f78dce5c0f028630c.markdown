--- 
layout: post 
title: "Grounded Decoding: Guiding Text Generation with Grounded Models for Robot Control" 
date: 2023-03-07 06:19:37 -0400 
categories: jekyll update 
author: "W Huang, F Xia, D Shah, D Driess, A Zeng, Y Lu - arXiv preprint arXiv , 2023" 
--- 
Recent progress in large language models (LLMs) has demonstrated the ability to learn and leverage Internet-scale knowledge through pre-training with autoregressive models. Unfortunately, applying such models to settings with embodied agents, such as robots, is challenging due to their lack of experience with the physical world, inability to parse non-language observations, and ignorance of rewards or safety constraints that robots may require. On the other hand, language  Cites: Chain of thought prompting elicits reasoning in large language