---
layout: post
title:  "Binary Early-Exit Network for Adaptive Inference on Low-Resource Devices"
date:   2022-06-25 08:25:58 -0400
categories: jekyll update
author: "A Saeed - arXiv preprint arXiv:2206.09029, 2022"
---
Deep neural networks have significantly improved performance on a range of tasks with the increasing demand for computational resources, leaving deployment on low-resource devices (with limited memory and battery power) infeasible. Binary neural networks (BNNs) tackle the issue to an extent with extreme compression and speed-up gains compared to real-valued models. We propose a simple but effective method to accelerate inference through unifying BNNs with an early-exiting strategy. Our  Cites: The right tool for the job: Matching model and instance complexities