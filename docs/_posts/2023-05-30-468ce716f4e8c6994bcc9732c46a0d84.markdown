--- 
layout: post 
title: "Quantifying the Intrinsic Usefulness of Attributional Explanations for Graph Neural Networks with Artificial Simulatability Studies" 
date: 2023-05-30 03:09:06 -0400 
categories: jekyll update 
author: "J Teufel, L Torresi, P Friederich - arXiv preprint arXiv:2305.15961, 2023" 
--- 
Despite the increasing relevance of explainable AI, assessing the quality of explanations remains a challenging issue. Due to the high costs associated with human-subject experiments, various proxy metrics are often used to approximately quantify explanation quality. Generally, one possible interpretation of the quality of an explanation is its inherent value for teaching a related concept to a student. In this work, we extend artificial simulatability studies to the domain of graph neural  Cites: Explain, Edit, and Understand: Rethinking User Study Design for