---
layout: post
title:  "LMentry: A Language Model Benchmark of Elementary Language Tasks"
date:   2022-11-10 01:14:02 -0400
categories: jekyll update
author: "A Efrat, O Honovich, O Levy - arXiv preprint arXiv:2211.02069, 2022"
---
As the performance of large language models rapidly improves, benchmarks are getting larger and more complex as well. We present LMentry, a benchmark that avoids this  arms race  by focusing on a compact set of tasks that are trivial to humans, eg writing a sentence containing a specific word, identifying which words in a list belong to a specific category, or choosing which of two words is longer. LMentry is specifically designed to provide quick and interpretable insights into the …
Cites: ‪Rethinking the Role of Demonstrations: What Makes In-Context …‬