--- 
layout: post 
title: "Improving Out-of-Distribution Detection via Epistemic Uncertainty Adversarial Training" 
date: 2022-09-12 23:50:28 -0400 
categories: jekyll update 
author: "D Everett, AT Nguyen, LE Richards, E Raff - arXiv preprint arXiv:2209.03148, 2022" 
--- 
The quantification of uncertainty is important for the adoption of machine learning, especially to reject out-of-distribution (OOD) data back to human experts for review. Yet progress has been slow, as a balance must be struck between computational efficiency and the quality of uncertainty estimates. For this reason many use deep ensembles of neural networks or Monte Carlo dropout for reasonable uncertainty estimates at relatively minimal compute and memory. Surprisingly, when we focus on Cites: Learning at Low False Positive Rates.