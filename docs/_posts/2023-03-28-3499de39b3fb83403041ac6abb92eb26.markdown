--- 
layout: post 
title: "OptimStore: In-Storage Optimization of Large Scale DNNs with On-Die Processing" 
date: 2023-03-28 04:46:22 -0400 
categories: jekyll update 
author: "J Kim, M Kang, Y Han, YG Kim, LS Kim - 2023 IEEE International Symposium on High , 2023" 
--- 
Training deep neural network (DNN) models is a resource-intensive, iterative process. For this reason, nowadays, complex optimizers like Adam are widely adopted as it increases the speed and efficiency of training. These optimizers, however, employ additional variables and raise the memory demand 2 to 3 of model parameters, worsening the memory capacity bottleneck. Moreover, as the size of DNN models is projected to grow even further, it is not practical to assume that the Cites: Detecting formal thought disorder by deep contextualized word