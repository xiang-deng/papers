--- 
layout: post 
title: "SAFARI: Versatile and Efficient Evaluations for Robustness of Interpretability" 
date: 2022-08-26 23:24:20 -0400 
categories: jekyll update 
author: "W Huang, X Zhao, G Jin, X Huang - arXiv preprint arXiv:2208.09418, 2022" 
--- 
Interpretability of Deep Learning (DL) models is arguably the barrier in front of trustworthy AI. Despite great efforts made by the Explainable AI (XAI) community, explanations lack robustness--indistinguishable input perturbations may lead to different XAI results. Thus, it is vital to assess how robust DL interpretability is, given an XAI technique. To this end, we identify the following challenges that state-of-the-art is unable to cope with collectively: i) XAI techniques are highly heterogeneous; ii) Cites: Why Should I Trust You? : Explaining the Predictions of Any