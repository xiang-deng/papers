--- 
layout: post 
title: "GreekBART: The First Pretrained Greek Sequence-to-Sequence Model" 
date: 2023-04-06 06:45:39 -0400 
categories: jekyll update 
author: "I Evdaimon, H Abdine, C Xypolopoulos, S Outsios - arXiv preprint arXiv , 2023" 
--- 
The era of transfer learning has revolutionized the fields of Computer Vision and Natural Language Processing, bringing powerful pretrained models with exceptional performance across a variety of tasks. Specifically, Natural Language Processing tasks have been dominated by transformer-based language models. In Natural Language Inference and Natural Language Generation tasks, the BERT model and its variants, as well as the GPT model and its successors, demonstrated exemplary  Cites: Don t give me the details, just the summary! topic-aware