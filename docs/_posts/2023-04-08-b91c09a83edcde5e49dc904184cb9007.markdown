--- 
layout: post 
title: "Human-like Summarization Evaluation with ChatGPT" 
date: 2023-04-08 04:35:01 -0400 
categories: jekyll update 
author: "M Gao, J Ruan, R Sun, X Yin, S Yang, X Wan - arXiv preprint arXiv:2304.02554, 2023" 
--- 
Evaluating text summarization is a challenging problem, and existing evaluation metrics are far from satisfactory. In this study, we explored ChatGPT s ability to perform human-like summarization evaluation using four human evaluation methods on five datasets. We found that ChatGPT was able to complete annotations relatively smoothly using Likert scale scoring, pairwise comparison, Pyramid, and binary factuality evaluation. Additionally, it outperformed commonly used automatic Cites: Benchmarking large language models for news summarization