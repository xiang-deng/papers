---
layout: post
title:  "Memory efficient continual learning with transformers"
date:   2022-10-29 01:49:44 -0400
categories: jekyll update
author: "B Ermis, G Zappella, M Wistuba, C Archambeau - 2022"
---
In many real-world scenarios, data to train machine learning models becomes available over time. Unfortunately, these models struggle to continually learn new concepts without forgetting what has been learnt in the past. This phenomenon is known as catastrophic forgetting and it is difficult to prevent due to practical constraints. For instance, the amount of data that can be stored or the computational resources that can be used might be limited. Moreover, applications increasingly rely …
Cites: ‪Benchmarking zero-shot text classification: Datasets, evaluation …‬