--- 
layout: post 
title: "Self-Repetition in Abstractive Neural Summarizers" 
date: 2022-10-20 02:20:28 -0400 
categories: jekyll update 
author: "N Salkar, T Trikalinos, BC Wallace, A Nenkova - arXiv preprint arXiv:2210.08145, 2022" 
--- 
We provide a quantitative and qualitative analysis of self-repetition in the output of neural summarizers. We measure self-repetition as the number of n-grams of length four or longer that appear in multiple outputs of the same system. We analyze the behavior of three popular architectures (BART, T5, and Pegasus), fine-tuned on five datasets. In a regression analysis, we find that the three architectures have different propensities for repeating content across output summaries for inputs, with BART Cites: Dissecting Generation Modes for Abstractive Summarization