---
layout: post
title:  "Outlier Suppression+: Accurate quantization of large language models by equivalent and optimal shifting and scaling"
date:   2023-04-22 04:11:24 -0400
categories: jekyll update
author: "X Wei, Y Zhang, Y Li, X Zhang, R Gong, J Guo, X Liu - arXiv preprint arXiv …, 2023"
---
Quantization of transformer language models faces significant challenges due to the existence of detrimental outliers in activations. We observe that these outliers are asymmetric and concentrated in specific channels. To address this issue, we propose the Outlier Suppression+ framework. First, we introduce channel-wise shifting and scaling operations to eliminate asymmetric presentation and scale down problematic channels. We demonstrate that these operations can be seamlessly …
Cites: ‪Jingfei Du, Mandar Joshi, Danqi Chen, Omer Levy, Mike Lewis …‬