--- 
layout: post 
title: "Large Language Models Can Self-Improve" 
date: 2022-10-26 13:20:27 -0400 
categories: jekyll update 
author: "J Huang, SS Gu, L Hou, Y Wu, X Wang, H Yu, J Han - arXiv preprint arXiv:2210.11610, 2022" 
--- 
Large Language Models (LLMs) have achieved excellent performances in various tasks. However, fine-tuning an LLM requires extensive supervision. Human, on the other hand, may improve their reasoning abilities by self-thinking without external inputs. In this work, we demonstrate that an LLM is also capable of self-improving with only unlabeled datasets. We use a pre-trained LLM to generate high-confidence rationale-augmented answers for unlabeled questions using Chain-of  Cites: Did aristotle use a laptop? a question answering benchmark with