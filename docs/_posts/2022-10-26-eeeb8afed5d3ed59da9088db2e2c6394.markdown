---
layout: post
title:  "Leveraging Large Language Models for Multiple Choice Question Answering"
date:   2022-10-26 13:20:27 -0400
categories: jekyll update
author: "J Robinson, CM Rytting, D Wingate - arXiv preprint arXiv:2210.12353, 2022"
---
While large language models (LLMs) like GPT-3 have achieved impressive results on multiple choice question answering (MCQA) tasks in the zero, one, and few-shot settings, they generally lag behind the MCQA state of the art (SOTA). MCQA tasks have traditionally been presented to LLMs like cloze tasks. An LLM is conditioned on a question (without the associated answer options) and its chosen option is the one assigned the highest probability after normalization (for length, etc.). A more natural …
Cites: ‪Testing the Ability of Language Models to Interpret Figurative …‬