--- 
layout: post 
title: "APOLLO: A Simple Approach for Adaptive Pretraining of Language Models for Logical Reasoning" 
date: 2022-12-22 13:00:23 -0400 
categories: jekyll update 
author: "S Sanyal, Y Xu, S Wang, Z Yang, R Pryzant, W Yu - arXiv preprint arXiv , 2022" 
--- 
Logical reasoning of text is an important ability that requires understanding the information present in the text, their interconnections, and then reasoning through them to infer new conclusions. Prior works on improving the logical reasoning ability of language models require complex processing of training data (eg, aligning symbolic knowledge to text), yielding task-specific data augmentation solutions that restrict the learning of general logical reasoning skills. In this work, we propose  Cites: Logic-driven context extension and data augmentation for logical