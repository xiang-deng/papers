--- 
layout: post 
title: "Contrastive Search Is What You Need For Neural Text Generation" 
date: 2022-10-29 01:49:44 -0400 
categories: jekyll update 
author: "Y Su, N Collier - arXiv preprint arXiv:2210.14140, 2022" 
--- 
Generating text with autoregressive language models (LMs) is of great importance to many natural language processing (NLP) applications. Previous solutions for this task often produce text that contains degenerative expressions or lacks semantic consistency. Recently, Su et al. introduced a new decoding method, contrastive search, based on the isotropic representation space of the language model and obtained new state of the art on various benchmarks. Additionally, Su et al. argued Cites: Lamda: Language models for dialog applications