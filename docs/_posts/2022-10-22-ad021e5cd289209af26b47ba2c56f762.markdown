---
layout: post
title:  "Towards a neural architecture of language: Deep learning versus logistics of access in neural architectures for compositional processing"
date:   2022-10-22 02:20:44 -0400
categories: jekyll update
author: "F van der Velde - arXiv preprint arXiv:2210.10543, 2022"
---
Recently, a number of articles have argued that deep learning models such as GPT could also capture key aspects of language processing in the human mind and brain. However, I will argue that these models are not suitable as neural models of human language. Firstly, because they fail on fundamental boundary conditions, such as the amount of learning they require. This would in fact imply that the mechanisms of GPT and brain language processing are fundamentally different. Secondly, because they …
Cites: ‪Hurdles to Progress in Long-form Question Answering‬