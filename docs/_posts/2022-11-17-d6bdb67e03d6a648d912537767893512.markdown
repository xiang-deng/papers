--- 
layout: post 
title: "Follow the Wisdom of the Crowd: Effective Text Generation via Minimum Bayes Risk Decoding" 
date: 2022-11-17 00:57:01 -0400 
categories: jekyll update 
author: "M Suzgun, L Melas-Kyriazi, D Jurafsky - arXiv preprint arXiv:2211.07634, 2022" 
--- 
In open-ended natural-language generation, existing text decoding methods typically struggle to produce text which is both diverse and high-quality. Greedy and beam search are known to suffer from text degeneration and linguistic diversity issues, while temperature, top-k, and nucleus sampling often yield diverse but low-quality outputs. In this work, we present crowd sampling, a family of decoding methods based on Bayesian risk minimization, to address this diversity-quality trade-off Cites: Palm: Scaling language modeling with pathways