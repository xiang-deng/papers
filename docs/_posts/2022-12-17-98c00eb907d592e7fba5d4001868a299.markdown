--- 
layout: post 
title: "Diverse Demonstrations Improve In-context Compositional Generalization" 
date: 2022-12-17 01:50:56 -0400 
categories: jekyll update 
author: "I Levy, B Bogin, J Berant - arXiv preprint arXiv:2212.06800, 2022" 
--- 
In-context learning has shown great success in iid semantic parsing splits, where the training and test sets are drawn from the same distribution. In this setup, models are typically prompted with demonstrations that are similar to the input question. However, in the setup of compositional generalization, where models are tested on outputs with structures that are absent from the training set, selecting similar demonstrations is insufficient, as often no example will be similar enough to the  Cites: Metaicl: Learning to learn in context