--- 
layout: post 
title: "Automatic Prompt Optimization with Gradient Descent and Beam Search" 
date: 2023-05-11 03:26:59 -0400 
categories: jekyll update 
author: "R Pryzant, D Iter, J Li, YT Lee, C Zhu, M Zeng - arXiv preprint arXiv:2305.03495, 2023" 
--- 
Large Language Models (LLMs) have shown impressive performance as general purpose agents, but their abilities remain highly dependent on prompts which are hand written with onerous trial-and-error effort. We propose a simple and nonparametric solution to this problem, Automatic Prompt Optimization (APO), which is inspired by numerical gradient descent to automatically improve prompts, assuming access to training data and an LLM API. The algorithm uses minibatches of  Cites: GrIPS: Gradient-free, Edit-based Instruction Search for Prompting