--- 
layout: post 
title: "How to Train Your DRAGON: Diverse Augmentation Towards Generalizable Dense Retrieval" 
date: 2023-02-18 05:28:11 -0400 
categories: jekyll update 
author: "SC Lin, A Asai, M Li, B Oguz, J Lin, Y Mehdad, W Yih - arXiv preprint arXiv , 2023" 
--- 
Various techniques have been developed in recent years to improve dense retrieval (DR), such as unsupervised contrastive learning and pseudo-query generation. Existing DRs, however, often suffer from effectiveness tradeoffs between supervised and zero-shot retrieval, which some argue was due to the limited model capacity. We contradict this hypothesis and show that a generalizable DR can be trained to achieve high accuracy in both supervised and zero-shot retrieval without increasing Cites: When Not to Trust Language Models: Investigating Effectiveness