--- 
layout: post 
title: "CosPGD: a unified white-box adversarial attack for pixel-wise prediction tasks" 
date: 2023-02-09 01:30:47 -0400 
categories: jekyll update 
author: "S Agnihotri, M Keuper - arXiv preprint arXiv:2302.02213, 2023" 
--- 
While neural networks allow highly accurate predictions in many tasks, their lack in robustness towards even slight input perturbations hampers their deployment in many real-world applications. Recent research towards evaluating the robustness of neural networks such as the seminal\emph {projected gradient descent}(PGD) attack and subsequent works and benchmarks have therefore drawn significant attention. Yet, such methods focus predominantly on classification tasks, while only a few  Cites: Semantically Equivalent Adversarial Rules for Debugging NLP