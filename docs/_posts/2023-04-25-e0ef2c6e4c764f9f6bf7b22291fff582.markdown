--- 
layout: post 
title: "SparseEmbed: Learning Sparse Lexical Representations with Contextual Embeddings for Retrieval" 
date: 2023-04-25 03:38:40 -0400 
categories: jekyll update 
author: "W Kong, JM Dudek, C Li, M Zhang, M Bendersky - 2023" 
--- 
In dense retrieval, prior work has largely improved retrieval effectiveness using multi-vector dense representations, exemplified by ColBERT. In sparse retrieval, more recent work, such as SPLADE, demonstrated that one can also learn sparse lexical representations to achieve comparable effectiveness while enjoying better interpretability. In this work, we combine the strengths of both the sparse and dense representations for first-stage retrieval. Specifically, we propose SparseEmbeda  Cites: Sparse, dense, and attentional representations for text retrieval