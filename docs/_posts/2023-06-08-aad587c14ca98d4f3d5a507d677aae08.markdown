---
layout: post
title:  "Learning Transformer Programs"
date:   2023-06-08 03:52:18 -0400
categories: jekyll update
author: "D Friedman, A Wettig, D Chen - arXiv preprint arXiv:2306.01128, 2023"
---
Recent research in mechanistic interpretability has attempted to reverse-engineer Transformer models by carefully inspecting network weights and activations. However, these approaches require considerable manual effort and still fall short of providing complete, faithful descriptions of the underlying algorithms. In this work, we introduce a procedure for training Transformers that are mechanistically interpretable by design. We build on RASP [Weiss et al., 2021], a programming language that can …
Cites: ‪Saturated transformers are constant-depth threshold circuits‬