---
layout: post
title:  "Generating Content-Preserving and Semantics-Flipping Adversarial Text"
date:   2022-05-28 02:05:27 -0400
categories: jekyll update
author: "W Pei, C Yue - Proceedings of the 2022 ACM on Asia Conference on , 2022"
---
ABSTRACT Natural Language Processing (NLP) models are often vulnerable to semantics-preserving adversarial attacks. That is, they make different semantic predictions on input instances with similar content and semantics. However, it remains unclear to which extent modern NLP models are vulnerable to content-preserving and semantics-flipping (CPSF) adversarial attacks. That is, they would make the same semantic prediction on input instances with similar content but  Cites: Adversarial Example Generation with Syntactically Controlled