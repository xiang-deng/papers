---
layout: post
title:  "Domain-specific Language Pre-training for Dialogue Comprehension on Clinical Inquiry-Answering Conversations"
date:   2022-06-10 22:27:43 -0400
categories: jekyll update
author: "Z Liu, P Krishnaswamy, NF Chen - arXiv preprint arXiv:2206.02428, 2022"
---
There is growing interest in the automated extraction of relevant information from clinical dialogues. However, it is difficult to collect and construct large annotated resources for clinical dialogue tasks. Recent developments in natural language processing suggest that large-scale pre-trained language backbones could be leveraged for such machine comprehension and information extraction tasks. Yet, due to the gap between pre-training and downstream clinical domains, it remains …
Cites: ‪TOD-BERT: Pre-trained natural language understanding for task …‬  