---
layout: post
title:  "All You May Need for VQA are Image Captions"
date:   2022-05-10 03:22:04 -0400
categories: jekyll update
author: "S Changpinyo, D Kukliansky, I Szpektor, X Chen - arXiv preprint arXiv , 2022"
---
Visual Question Answering (VQA) has benefited from increasingly sophisticated models, but has not enjoyed the same level of engagement in terms of data creation. In this paper, we propose a method that automatically derives VQA examples at volume, by leveraging the abundance of existing image-caption annotations combined with neural models for textual question generation. We show that the resulting data is of high-quality. VQA models trained on our data improve state-of-the Cites: Syn-QG: Syntactic and shallow semantic rules for question