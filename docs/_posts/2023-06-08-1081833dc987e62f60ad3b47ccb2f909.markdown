--- 
layout: post 
title: "Joint Pre-training and Local Re-training: Transferable Representation Learning on Multi-source Knowledge Graphs" 
date: 2023-06-08 03:52:18 -0400 
categories: jekyll update 
author: "Z Sun, J Huang, J Lin, X Xu, Q Chen, W Hu - arXiv preprint arXiv:2306.02679, 2023" 
--- 
In this paper, we present the``joint pre-training and local re-training framework for learning and applying multi-source knowledge graph (KG) embeddings. We are motivated by the fact that different KGs contain complementary information to improve KG embeddings and downstream tasks. We pre-train a large teacher KG embedding model over linked multi-source KGs and distill knowledge to train a student model for a task-specific KG. To enable knowledge transfer across different  Cites: K-adapter: Infusing knowledge into pre-trained models with adapters