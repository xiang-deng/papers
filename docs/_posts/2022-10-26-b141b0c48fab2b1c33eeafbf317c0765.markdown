--- 
layout: post 
title: "On the Transformation of Latent Space in Fine-Tuned NLP Models" 
date: 2022-10-26 13:20:27 -0400 
categories: jekyll update 
author: "N Durrani, H Sajjad, F Dalvi, F Alam - arXiv preprint arXiv:2210.12696, 2022" 
--- 
We study the evolution of latent space in fine-tuned NLP models. Different from the commonly used probing-framework, we opt for an unsupervised method to analyze representations. More specifically, we discover latent concepts in the representational space using hierarchical clustering. We then use an alignment function to gauge the similarity between the latent space of a pre-trained model and its fine-tuned version. We use traditional linguistic concepts to facilitate our  Cites: Latent Topology Induction for Understanding Contextualized